{
  "title": "Paper_1209",
  "abstract": "pmc Diagnostics (Basel) Diagnostics (Basel) 2841 diagno diagnostics Diagnostics 2075-4418 Multidisciplinary Digital Publishing Institute  (MDPI) PMC12468862 PMC12468862.1 12468862 12468862 41008694 10.3390/diagnostics15182322 diagnostics-15-02322 1 Article Automated Computer-Assisted Diagnosis of Pleural Effusion in Chest X-Rays via Deep Learning https://orcid.org/0009-0009-0505-3375 Huang Ya-Yun Methodology Writing – original draft Writing – review & editing 1 https://orcid.org/0000-0002-0702-5169 Lin Yu-Ching Investigation Resources Data curation 2 3 4 Tsai Sung-Hsin Investigation Resources Data curation 5 https://orcid.org/0009-0003-7109-6492 Chi Tsun-Kuang Conceptualization Supervision Funding acquisition 6 * https://orcid.org/0009-0003-5964-6084 Chen Tsung-Yi Methodology Project administration Funding acquisition 7 * Chung Shih-Wei Software Validation Formal analysis 7 https://orcid.org/0000-0002-0110-5491 Li Kuo-Chen Conceptualization Writing – original draft Visualization 8 https://orcid.org/0000-0003-1134-5859 Tu Wei-Chen Visualization Supervision 1 9 https://orcid.org/0000-0002-8848-6644 R. Abu Patricia Angela Writing – original draft Writing – review & editing 10 Chen Chih-Cheng Software Validation Formal analysis 11 12 Moran Cesar A. Academic Editor 1 m28124023@gs.ncku.edu.tw wctu@gs.ncku.edu.tw 2 lin0927@cgmh.org.tw 3 4 5 mpq689@cgmh.org.tw 6 7 m1208782@o365.fcu.edu.tw 8 kuochen@cycu.edu.tw 9 10 pabu@ateneo.edu 11 chenccheng@fcu.edu.tw 12 * simonchi@mail.mcut.edu.tw tsungychen@fcu.edu.tw 13 9 2025 9 2025 15 18 497628 2322 12 8 2025 05 9 2025 11 9 2025 13 09 2025 27 09 2025 29 09 2025 © 2025 by the authors. 2025 https://creativecommons.org/licenses/by/4.0/ Licensee MDPI, Basel, Switzerland. This article is an open access article distributed under the terms and conditions of the Creative Commons Attribution (CC BY) license ( https://creativecommons.org/licenses/by/4.0/ Background/Objectives: Methods: Results: Conclusions: medical image image enhancement chest X-rays pleural effusion deep learning National Science and Technology Council 112-2410-H-197-002-MY2 113-2314-B-182A-140 113-2221-E-131-026 114-2221-E-035-032 114-2221-E-131-009 114-2314-B-182A-051 Research Support of the Feng Chia University Research Program 24H00810 This work was supported, in part, by the National Science and Technology Council, Taiwan, under grant numbers 112-2410-H-197-002-MY2, 113-2314-B-182A-140, 113-2221-E-131-026, 114-2221-E-035-032, 114-2221-E-131-009, and 114-2314-B-182A-051. And This work was supported by the Research Support of the Feng Chia University Research Program, grant no. 24H00810. pmc-status-qastatus 0 pmc-status-live yes pmc-status-embargo no pmc-status-released yes pmc-prop-open-access yes pmc-prop-olf no pmc-prop-manuscript no pmc-prop-legally-suppressed no pmc-prop-has-pdf yes pmc-prop-has-supplement no pmc-prop-pdf-only no pmc-prop-suppress-copyright no pmc-prop-is-real-version no pmc-prop-is-scanned-article no pmc-prop-preprint no pmc-prop-in-epmc yes 1. Introduction According to the chronic obstructive pulmonary disease (COPD) statistics released by the World Health Organization (WHO) in 2023 [ 1 2 3 Medical imaging technologies have played a crucial role in achieving this goal, with chest X-rays (CXR) serving as one of the most widely used diagnostic tools in pulmonary medicine [ 4 5 6 7 Figure 1 Figure 1 Building upon the importance of CXR imaging in diagnosing pleural effusion, recent advancements in automated medical imaging technologies have demonstrated strong potential to improve both diagnostic efficiency and accuracy in clinical practice [ 8 9 10 11 12 13 5 14 15 16 17 To address this need, the present study proposes a CXR-based analysis method designed to provide radiologists with standardized diagnostic information, thereby automating clinical workflows and reducing inter-observer variability in image interpretation [ 18 19 20 This study employs image segmentation to pre-process lung X-rays, retaining only the lower half of the lungs, from below the heart to the costophrenic angle, thereby enabling the model to focus more effectively on the target region. An effective image enhancement approach is introduced, which improves model performance by 4.33% compared with results obtained without enhancement. The proposed system integrates image cropping, image enhancement, and CNN classification, achieving an accuracy of 927%, representing a substantial improvement of 21.30% over existing studies. 2. Methods This study proposed a system for detecting pleural effusion in CXR images by integrating various image processing methods with artificial intelligence. To achieve accurate detection, the workflow was divided into four main stages, as shown in Figure 2 2.1. Image Preprocessing for CXR Image However, the costophrenic angle is a key anatomical landmark for examining pleural effusion. Under normal conditions, the structure of the costophrenic angle is clearly visible on CXR images. When pleural effusion occurs, fluid accumulates in these angles, causing them to appear blurred or obscured on CXR images. Additionally, since pleural effusion is influenced by gravity and tends to accumulate in the lower parts of the lungs, this study focused on the lower half of the lung, specifically the region from the heart to the costophrenic angle, as the target area. To further improve the accuracy of region extraction, an image preprocessing method was introduced to enable precise segmentation of the costophrenic angle. 2.1.1. Standardization Negative To enhance the clarity of lung boundaries, the original CXR images were first converted to grayscale before applying further preprocessing, thereby reducing computational complexity. Each pixel was converted based on the weighted average of its red, green, and blue (RGB) channel values. The resulting grayscale image is shown in Figure 3 Subsequently, a negative transformation was applied to the grayscale image, as defined in Equation (1). By inverting the grayscale values, darker regions became brighter, while brighter regions became darker, increasing the contrast between the lungs and surrounding tissues. This process effectively enhanced the lung contours, making the lung regions more distinguishable, as shown in Figure 3 (1) I n e g a t i v e = 1 − I g r a y 2.1.2. AHE After grayscale conversion and negative transformation, the lung regions became more visually prominent. To further enhance image contrast and improve the visibility of fine details, adaptive histogram equalization (AHE) was applied to the preprocessed images, as shown in Figure 3 2.1.3. Binarization To further simplify the image for subsequent segmentation, binarization was applied to convert the grayscale image into a binary format containing only black and white pixels, thereby reducing its complexity. A threshold value of 0.5 was selected for the binarization process. This process enhanced the contrast between the lung regions and the surrounding background, facilitating more efficient and accurate analysis in the following computational steps. After binarization, the lung area could be delineated more precisely. However, to further refine the lung boundaries and eliminate noise, morphological operations were employed to improve the structural integrity of the segmented regions. Morphological processing is a widely used technique in image analysis, particularly effective in enhancing specific image features. Among various operations, dilation and erosion are the most fundamental, with their definitions provided in Equations (2) and (3), respectively. The result of the image preprocessing step is presented in Figure 3 (2) A ∘ B = ( A ⊕ B ) ⊖ B (3) A ● B = ( A ⊖ B ) ⊕ B 2.2. Image Segmentation After binarization, the pixel values of the image were summed column by column to generate a vertical projection profile. This profile provides an intuitive view of pixel intensity distribution across the image and serves as the basis for determining suitable cropping boundaries. In this study, the vertical projection was used to identify the left and right cropping positions. Specifically, within the leftmost one-fifth of the image, the position with the lowest accumulated pixel value was selected as the candidate for the left boundary. Similarly, the rightmost one-fifth was analyzed to determine the right boundary based on the minimum pixel sum. Once both the left and right boundaries were identified, they were mapped back to the original CXR image to perform precise cropping, as shown in Figure 4 To further separate the lung region from surrounding structures, horizontal cropping was performed following the vertical cropping step. The horizontal cropping method followed a similar procedure to the vertical approach, in which pixel values were summed row by row to generate the cumulative vertical projection from top to bottom. To determine the upper boundary, the first row within the central one-third of the image whose total pixel value exceeded a predefined threshold was selected. This ensured accurate preservation of the upper margin of the lungs. The lower boundary was determined by identifying the row with the minimum accumulated pixel value in the lower half of the image, thereby preserving the complete structure of the costophrenic angle. Once the upper and lower boundaries were confirmed, they were mapped onto the CXR image that had already been cropped along the left and right boundaries, and vertical cropping was performed accordingly, as shown in Figure 4 Additionally, to highlight the key features of pleural effusion, the lung region was further horizontally divided at the midpoint after completing both horizontal and vertical cropping, with only the lower half of the lung, from the heart to the costophrenic angle, being retained. The final cropped images were uniformly resized to 227×227 pixels to standardize the input dimensions for model training and ensure compatibility with the subsequent model requirements. The results of image segmentation and normalization are shown in Figure 4 2.3. Image Enhancement In CXR images, pleural effusion typically occurred in the lower regions of the lungs and appeared as white or grayish-white areas, whereas healthy lung tissue was represented by relatively darker pixels. The visibility of pleural effusion on CXR images was influenced by various factors, including the extent, density, and location of the fluid. Therefore, accurately identifying pleural effusion was challenging. To address this issue, this study developed a feature enhancement algorithm for pleural effusion. The algorithm was applied to the cropped CXR images, representing the region of interest (ROI), and combined histogram stretching with Sobel gradient edge detection [ 21 22 2.3.1. Histogram Stretching Enhanced imaging was necessary to better distinguish pleural effusion symptoms from surrounding lung contours. In CXR images, pleural effusion typically appeared as gray and blurred regions, while normal lung tissue remained relatively dark. This made accurate detection difficult, particularly in early stages. To improve image contrast, this study tested three enhancement methods: logarithmic transformation [ 23 24 25 Figure 5 Histogram stretching worked by identifying the minimum and maximum pixel intensity values in the input image and linearly mapping them to the full dynamic range. This transformation amplified subtle differences in pixel intensity, making previously indistinct features more pronounced. The detailed algorithmic steps are presented in Algorithm 1. Algorithm 1. Histogram Stretching. Input I i : filtering input image. I o : Scaling constant. ( K w , K h ) : Dimensions of the input image. Output I o  : Transformed output image. I o x , y = ( I i x , y − m i n ) × 255 / ( max − m i n ) Hint: x ∊ 0 … K w − 1 ,  n ∊ 0 … K h − 1 min, max: minimum and maximum pixel values in input image 2.3.2. Sobel Gradient Edge Detection Since histogram stretching enhanced the visibility of the costophrenic angle but was insufficient to highlight the features of pleural effusion, this study further employed edge detection techniques to enhance pleural effusion characteristics. The performance of several methods, including Sobel [ 26 27 28 29 3 × 3 Algorithm 2. Sobel Gradient Edge Detection. 1. Apply Gaussian filter to reduce noise (optional pre-processing step). G x , y = 1 2 π σ 2 e x p − ( x 2 + y 2 ) 2 σ 2 2. Apply Sobel operators to compute horizontal and vertical gradients. G x = − 1 ,  0 ,  1 ,  − 2 ,  0 ,  2 ,  − 1 ,  0 ,  1 × I x , y G y = [ [ − 1 , − 2 , − 1 ] ,  [ 0 ,  0 ,  0 ] ,  [ 1 ,  2 ,  1 ] ] × I ( x , y ) 3. Calculate gradient magnitude. | G | = ( G x 2 + G y 2 ) 4. Calculate gradient direction (optional). θ ( x , y ) = t a n − 1 ( G y / G x ) 5. Apply threshold to create binary edge map (optional). If |G| > threshold, pixel is an edge Otherwise, pixel is not an edge 6. Combine with original image (optional). Result = α × O r i g i n a l + β × G r a d i e n t _ m a p After applying the Sobel gradient edge detection, the resulting gradient map enhanced the visibility of the costophrenic angle. In normal lung tissue, the contour of the costophrenic angle appeared sharp and exhibited a steep gradient. However, in the presence of pleural effusion, this region became blurred. This distinct difference in gradient patterns enabled the model to better capture the characteristics of pleural effusion, thereby improving diagnostic accuracy. The results of image enhancement are shown in Figure 6 Figure 6 Figure 6 2.4. CNN Training and Validation With the rapid advancement of machine learning and artificial intelligence technologies, CNNs have been increasingly applied to image processing tasks and have demonstrated significant success in various image classification problems. In terms of model selection, this study evaluated several CNN architectures, including MobileNet-v3 [ 30 31 32 33 Table 1 34 During CNN training, hyperparameters played a crucial role in influencing the learning behavior and overall performance of the model. The learning rate, batch size, and epochs are among the most commonly adjusted hyperparameters. The learning rate controlled the step size for weight updates during training. Specifically, a higher learning rate accelerated model convergence but could miss the optimal solution, whereas a lower learning rate ensured more stable updates but required significantly more training time. In addition, the batch size defined how many samples were used to update the model parameters in each iteration of training. Larger batch sizes could accelerate training and provide smoother gradient estimates but required more memory. On the other hand, smaller batch sizes introduced more variance in updates, which could help avoid local minimum but might also lead to instability during training. Moreover, the number of epochs referred to how many times the model was trained on the entire training dataset. Although increasing the number of epochs allowed the model to learn more effectively from the data, it also increased the risk of overfitting. Therefore, selecting appropriate hyperparameters was essential to ensure effective model training. The specific hyperparameter settings used in this study are summarized in Table 2 3. Results The study procedures complied with ethical standards and were approved by the Institutional Review Board (IRB) of Chiayi Chang Gung Memorial Hospital (IRB No. 202301914B0). All CXR images used in this study were collected from adult patients (aged 18 and above), and the Chang Gung Medical Foundation Institutional Review Board approves the waiver of the participants’ consent. A total of 922 CXR images were included, comprising 461 images of normal lungs and 461 images diagnosed with pleural effusion. Among them, 80% (738 images) were used for model training, while the remaining 20% (184 images) were reserved for validation. The distribution of the training data is summarized in Table 3 This section presents the experimental results of the proposed CNN approach for detecting pleural effusion in CXR images. The evaluation includes four main components: the performance metrics used in this study, a comparison of model performance with single-lung and whole-lung as inputs, an assessment of various image enhancement methods, and a comparative analysis of classification results across multiple CNN architectures. The following subsections describe these experiments in detail, highlighting the key findings and their implications for clinical application. 3.1. Performance Metrics The primary objective was to reduce the workload of radiologists while minimizing the risk of misdiagnosis. Accuracy, precision, recall, and F1 score were adopted as evaluation metrics for the model’s performance, as they are commonly used in classification tasks. As shown in Table 4 (4) Accuracy = TP + TN TP + TN + FP + FN (5) Precision = TP TP + FP (6) Recall = TP TP + FN (7) F 1  s core = 2 × Precision  ×  Recall Precision + Recall 3.2. Comparison of Single-Lung and Whole-Lung Inputs In this study, the performance of single-lung and whole-lung inputs was compared. The comparison results of single-lung and whole-lung inputs are shown in Table 5 Furthermore, the heart’s position made the imaging characteristics of the left lung more complex, making it more difficult to accurately capture symptomatic information. As a result, the average single-lung accuracy was 69.84%. In contrast, the whole-lung input achieved an accuracy of 84.24%, showing that pleural effusion features were more clearly represented in the whole-lung images. Based on these comparative results, the whole-lung image was ultimately selected as the CNN input for training and validation. 3.3. Evaluation of Different Image Enhancement Method To effectively improve model accuracy, this study applied multiple image enhancement techniques to the cropped CXR images. The enhancement process was divided into two stages, targeting the costophrenic angle and pleural effusion features, respectively. For the enhancement of costophrenic angle features, three methods were compared: logarithmic transformation, CLAHE, and histogram stretching, along with the unenhanced images. The training results for each method are summarized in Table 6 Following the selection of histogram stretching for enhancing the costophrenic angle features, this study further evaluated multiple edge detection techniques to enhance the features of pleural effusion. The experiments were conducted on images that had been cropped and processed with histogram stretching. The evaluated methods included Sobel, Sobel gradient, sharpening, and Canny edge detection, and the results are presented in Table 7 Table 7 3.4. The Classification Results of CNN To further verify the stability of the proposed pleural effusion detection model, 5-fold cross-validation was conducted to evaluate multiple deep learning architectures. Five different CNN architectures were tested, including MobileNet-v3, SqueezeNet, DarkNet19, AlexNet, and EfficientNet-B0. As shown in Table 8 35 To evaluate the contribution of the proposed system, a comparison was conducted with previous studies, as summarized in Table 9 5 17 16 14 4. Discussion Building on the comparative results presented in the previous section, this study specifically addressed the diagnostic challenges radiologists face in detecting pleural effusion, particularly in its early stages when the symptoms are subtle and often indistinguishable on standard CXR images. Analysis of our experimental results revealed that, while the detection accuracy for the right lung was comparable to that of whole-lung imaging, the accuracy for the left lung was adversely affected by its anatomical overlap with the heart. This observation motivated our focus on isolating the costophrenic angle to enhance detection accuracy. To optimize feature extraction, a series of targeted image processing techniques were applied, including selective cropping and enhancement of the costophrenic angle. Among the evaluated enhancement methods, the combination of histogram stretching and Sobel gradient edge detection achieved the most significant improvement, with accuracy, precision, recall, and F1 score all exceeding 91.85%, outperforming other edge detection techniques. Regarding classification performance, EfficientNet-B0 demonstrated the highest overall effectiveness, achieving an accuracy of 93.27%, which was substantially higher than other deep learning models tested. Compared with previous studies, the proposed method achieved a 93.27% accuracy, representing an improvement of 21.30%, and obtained the highest model reliability as reflected in the top-performing F1 score. These improvements can be attributed to the integrated approach of costophrenic angle cropping, advanced image enhancement, and edge detection, which collectively amplified pleural effusion features, thereby facilitating more efficient and accurate model training. In contrast, methods [ 5 15 16 17 5 15 16 17 5. Conclusions This study proposed an automated pleural effusion detection system that achieved significant advancements in diagnosis through optimized image preprocessing and deep learning models. The system first performed precise cropping of CXR images to preserve the critical costophrenic angles, followed by image enhancement using histogram stretching and Sobel gradient edge detection. The proposed preprocessing workflow proved more effective than other approaches, increasing the accuracy from 87.50% without enhancement to 91.85%, thereby confirming that image enhancement can effectively improve the visibility of key features and provide a solid foundation for the subsequent classification stage. In the classification step, 5-fold cross-validation was employed to evaluate the performance of multiple CNN architectures. EfficientNet-B0 was ultimately selected as the classification model, achieving an accuracy of 93.27%. Compared with previous methods, the proposed system improved accuracy by approximately 21.30%, with both precision and recall exceeding 92.00%, demonstrating reliable detection capabilities for both positive and negative pleural effusion cases. Overall, by integrating precise cropping with efficient image enhancement, the proposed system substantially improved the accuracy and robustness of pleural effusion detection, showing strong potential for clinical application. Future study will focus on expanding the dataset and further enhancing image preprocessing techniques to continually improve the model’s practicality and reliability in real-world clinical environments. Disclaimer/Publisher’s Note: Author Contributions Conceptualization, T.-K.C. and K.-C.L.; Data curation, Y.-C.L. and S.-H.T.; Formal analysis, S.-W.C. and C.-C.C.; Funding acquisition, T.-K.C. and T.-Y.C.; Investigation, Y.-C.L. and S.-H.T.; Methodology, Y.-Y.H. and T.-Y.C.; Project administration, T.-Y.C.; Resources, Y.-C.L. and S.-H.T.; Software, S.-W.C. and C.-C.C.; Supervision, T.-K.C. and W.-C.T.; Validation, S.-W.C. and C.-C.C.; Visualization, K.-C.L. and W.-C.T.; Writing—original draft, Y.-Y.H., K.-C.L. and P.A.R.A.; Writing—review and editing, Y.-Y.H. and P.A.R.A. All authors will be updated at each stage of manuscript processing, including submission, revision, and revision reminder, via emails from our system or the assigned Assistant Editor. All authors have read and agreed to the published version of the manuscript. Institutional Review Board Statement Chang Gung Medical Foundation Institutional Review Board; IRB number: 202301914B0; Date of Approval: 20 December 2023; Protocol Title: Application of Convolutional Neural Network for Disease Identification from Chest Radiograph; Executing Institution: Chang-Gung Medical Foundation Chiayi Chang-Gung Memorial Hospital of Chiayi; Duration of Approval: From 1 January 2024 to 31 December 2024; The IRB reviewed and determined that it is expedited review according to Case research or cases treated or diagnosed by clinical routines. However, this does not include HIV-positive cases. Informed Consent Statement The Chang Gung Medical Foundation Institutional Review Board approves the waiver of the participants’ consent. The research does not adversely affect the rights and welfare of the subjects. The study uses de-identified or non-traceable data, records, documents, information, or specimens obtained from a legally established biological database, ensuring that individual identities cannot be identified. Data Availability Statement The datasets presented in this article are not readily available because they are part of an ongoing study and will be made available only after the completion of data collection and analysis. Requests to access the datasets should be directed to the corresponding authors at simon-chi@mail.mcut.edu.tw tsungychen@fcu.edu.tw Conflicts of Interest The authors declare no conflicts of interest. References 1. Tripathy R.K. Dash S. Rath A. Panda G. Pachori R.B. Automated Detection of Pulmonary Diseases From Lung Sound Signals Using Fixed-Boundary-Based Empirical Wavelet Transform IEEE Sens. Lett. 2022 6 7001504 10.1109/LSENS.2022.3167121 2. Chen Z. Zhou Y.P. Liu X. Jiang X. Wu T. Ghista D. Xu X.Q. Zhang H. Jing Z.C. A Personalized Pulmonary Circulation Model to Non-Invasively Calculate Fractional Flow Reserve for Artery Stenosis Detection IEEE Trans. Biomed. Eng. 2022 69 1435 1448 10.1109/TBME.2021.3119188 34633925 3. Roy A. Thakur A. Satija U. VGAResNet: A Unified Visibility Graph Adjacency Matrix-Based Residual Network for Chronic Obstructive Pulmonary Disease Detection Using Lung Sounds IEEE Sens. Lett. 2023 7 7006604 10.1109/LSENS.2023.3326118 4. Shah P.M. Ullah F. Shah D. Gani A. Maple C. Wang Y. Abrar M. Islam S.U. Deep GRU-CNN Model for COVID-19 Detection From Chest X-Rays Data IEEE Access 2022 10 35094 35105 10.1109/ACCESS.2021.3077592 35582498 PMC9088790 5. Serte S. Serener A. Early pleural effusion detection from respiratory diseases including COVID-19 via deep learning Proceedings of the 2020 Medical Technologies Congress (TIPTEKNO) Antalya, Turkey 19–20 November 2020 1 4 10.1109/TIPTEKNO50054.2020.9299300 6. Hu J. Zhang C. Zhou K. Gao S. Chest X-Ray Diagnostic Quality Assessment: How Much Is Pixel-Wise Supervision Needed? IEEE Trans. Med. Imaging 2022 41 1711 1723 10.1109/TMI.2022.3149171 35120002 7. Wu Y. Kong Q. Zhang L. Castiglione A. Nappi M. Wan S. CDT-CAD: Context-Aware Deformable Transformers for End-to-End Chest Abnormality Detection on X-Ray Images IEEE/ACM Trans. Comput. Biol. Bioinform. 2024 21 823 834 10.1109/TCBB.2023.3258455 37030846 8. Nahiduzzaman M. Goni M.O.F. Anower M.S. Islam M.R. Ahsan M. Haider J. Gurusamy S. Hassan R. Islam M.R. A Novel Method for Multivariant Pneumonia Classification Based on Hybrid CNN-PCA Based Feature Extraction Using Extreme Learning Machine With CXR Images IEEE Access 2021 9 147512 147526 10.1109/ACCESS.2021.3123782 9. Paranjape K. Schinkel M. Nanayakkara P. Short Keynote Paper: Mainstreaming Personalized Healthcare–Transforming Healthcare Through New Era of Artificial Intelligence IEEE J. Biomed. Health Inform. 2020 24 1860 1863 10.1109/JBHI.2020.2970807 32054591 10. Ahmed I. Jeon G. Piccialli F. From Artificial Intelligence to Explainable Artificial Intelligence in Industry 4.0: A Survey on What, How, and Where IEEE Trans. Ind. Inform. 2022 18 5031 5042 10.1109/TII.2022.3146552 11. Sogancioglu E. Van Ginneken B. Behrendt F. Bengs M. Schlaefer A. Radu M. Xu D. Sheng K. Scalzo F. Marcus E. Nodule Detection and Generation on Chest X-Rays: NODE21 Challenge IEEE Trans. Med. Imaging 2024 43 2839 2853 10.1109/TMI.2024.3382042 38530714 12. Ji H. Li J. Wang L. Fan L. Zhang Y. Wang W. COVID-19 Detection in CXR Image Using High Frequency Emphasis Filtering Based Convolutional Neural Network Proceedings of the 2022 IEEE 11th Data Driven Control and Learning Systems Conference (DDCLS) Chengdu, China 3–5 August 2022 929 934 10.1109/DDCLS55054.2022.9858590 13. Bhadra R. Kar S. COVID Detection from CXR Scans using Deep Multi-layered CNN Proceedings of the 2020 IEEE Bombay Section Signature Conference (IBSSC) Mumbai, India 4–6 December 2020 214 218 10.1109/IBSSC51096.2020.9332210 14. Liu Y. Liang Z. Yang J. Yuan S. Wang S. Huang W. Wu A. Diagnostic and comparative performance for the prediction of tuberculous pleural effusion using machine learning algorithms Int. J. Med. Inform. 2024 182 105320 10.1016/j.ijmedinf.2023.105320 38118260 15. Thapa M. Kaur R. An Explainable Deep—Learning based Multi-Label Image Classification for Chest X-Rays Procedia Comput. Sci. 2025 258 2425 2434 10.1016/j.procs.2025.04.505 16. Furriel B.C. Paulo A.J. Ribeiro G.A. Santos P.V. Reis E.P. Mendes G.S. Paiva J.Q. Loureiro R.M. Rittner L. Reis M.R. Convolutional Neural Network for Pleural Effusion Classification Proceedings of the 2023 IEEE Latin American Conference on Computational Intelligence (LA-CCI) Recife-Pe, Brazil 29 October–1 November 2023 1 6 10.1109/LA-CCI58595.2023.10409349 17. Serte S. Serener A. Classification of COVID-19 and pleural effusion on chest radiographs using CNN fusion Proceedings of the 2021 International Conference on INnovations in Intelligent SysTems and Applications (INISTA) Kocaeli, Turkey 25–27 August 2021 1 6 10.1109/INISTA52262.2021.9548502 18. Chowdary G.J. Kanhangad V. A Dual-Branch Network for Diagnosis of Thorax Diseases From Chest X-Rays IEEE J. Biomed. Health Inform. 2022 26 6081 6092 10.1109/JBHI.2022.3215694 36260564 19. Taphorn K. Mechlem K. Sellerer T. De Marco F. Viermetz M. Pfeiffer F. Pfeiffer D. Herzen J. Direct Differentiation of Pathological Changes in the Human Lung Parenchyma With Grating-Based Spectral X-ray Dark-Field Radiography IEEE Trans. Med. Imaging 2021 40 1568 1578 10.1109/TMI.2021.3061253 33617451 20. Ijaz A. Akbar S. AlGhofaily B. Hassan S.A. Saba T. Deep Learning for Pneumonia Diagnosis Using CXR Images Proceedings of the 2023 Sixth International Conference of Women in Data Science at Prince Sultan University (WiDS PSU) Riyadh, Saudi Arabia 14–15 March 2023 53 58 10.1109/WiDS-PSU57071.2023.00023 21. Langarizadeh M. Mahmud R. Ramli A.R. Napis S. Beikzadeh M.R. Rahman W.E.Z.W.A. Improvement of digital mammogram images using histogram equalization, histogram stretching and median filter J. Med. Eng. Technol. 2011 35 103 108 10.3109/03091902.2010.542271 21204610 22. AS R.A. Gopalan S. Comparative Analysis of Eight Direction Sobel Edge Detection Algorithm for Brain Tumor MRI Images Procedia Comput. Sci. 2022 201 487 494 10.1016/j.procs.2022.03.063 23. Sedgwick P. Log transformation of data BMJ 2012 345 e6727 10.1136/bmj.e6727 24. Sahu S. Singh A.K. Ghrera S.P. Elhoseny M. An approach for de-noising and contrast enhancement of retinal fundus image using CLAHE Opt. Laser Technol. 2019 110 87 98 10.1016/j.optlastec.2018.06.061 25. Li X. Hu H. Zhao L. Wang H. Yu Y. Wu L. Liu T. Polarimetric image recovery method combining histogram stretching for underwater imaging Sci. Rep. 2018 8 12430 10.1038/s41598-018-30566-8 30127366 PMC6102268 26. Gao W. Zhang X. Yang L. Liu H. An improved Sobel edge detection Proceedings of the 2010 3rd International Conference on Computer Science and Information Technology Chengdu, China 9–11 July 2010 67 71 10.1109/ICCSIT.2010.5563693 27. Sun J. Lv Y. Tang C. Sima H. Wu X. Face Recognition Based on Local Gradient Number Pattern and Fuzzy Convex-Concave Partition IEEE Access 2020 8 35777 35791 10.1109/ACCESS.2020.2975312 28. Ding F. Zhu G. Yang J. Xie J. Shi Y.-Q. Edge Perpendicular Binary Coding for USM Sharpening Detection IEEE Signal Process. Lett. 2015 22 327 331 10.1109/LSP.2014.2359033 29. Bao P. Zhang L. Wu X. Canny edge detection enhancement by scale multiplication IEEE Trans. Pattern Anal. Mach. Intell. 2005 27 1485 1490 10.1109/TPAMI.2005.173 16173190 30. Huang J. Mei L. Long M. Liu Y. Sun W. Li X. Shen H. Zhou F. Ruan X. Wang D. BM-Net: CNN-Based MobileNet-V3 and Bilinear Structure for Breast Cancer Detection in Whole Slide Images Bioengineering 2022 9 261 10.3390/bioengineering9060261 35735504 PMC9220285 31. Tsivgoulis M. Papastergiou T. Megalooikonomou V. An improved SqueezeNet model for the diagnosis of lung cancer in CT scans Mach. Learn. Appl. 2022 10 100399 10.1016/j.mlwa.2022.100399 32. Baygin M. Yaman O. Barua P.D. Dogan S. Tuncer T. Acharya U.R. Exemplar Darknet19 feature generation technique for automated kidney stone detection with coronal CT images Artif. Intell. Med. 2022 127 102274 10.1016/j.artmed.2022.102274 35430036 33. Shanthi T. Sabeenian R.S. Modified Alexnet architecture for classification of diabetic retinopathy images Comput. Electr. Eng. 2019 76 56 64 10.1016/j.compeleceng.2019.03.004 34. Goutham V. Sameerunnisa A. Babu S. Prakash T.B. Brain Tumor Classification using EfficientNet-B0 Model Proceedings of the 2022 2nd International Conference on Advance Computing and Innovative Technologies in Engineering (ICACITE) Greater Noida, India 28–29 April 2022 2503 2509 10.1109/ICACITE53722.2022.9823526 35. Wang X. Peng Y. Lu L. Lu Z. Bagheri M. Summers R.M. ChestX-ray8: Hospital-scale Chest X-ray Database and Benchmarks on Weakly-Supervised Classification and Localization of Common Thorax Diseases Proceedings of the 2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR) Honolulu, HI, USA 21–26 July 2017 3462 3471 10.1109/CVPR.2017.369 Figure 1 Pleural effusion symptoms on CXR image. ( a b Figure 2 The flowchart of the proposed system for automated detection of pleural effusion in CXR images. Figure 3 The CXR image preprocessing result. ( a b c d Figure 4 The results of the CXR image segmentation. ( a b c d e Figure 5 Results after applying histogram stretching. ( a b Figure 6 Results after applying image enhancement method. ( a b diagnostics-15-02322-t001_Table 1 Table 1 The hardware and software platform used in this study. Hardware Platform Version CPU Intel ® GPU NVIDIA GeForce RTX™ 3060 Ti Software platform Version Matlab 2023a diagnostics-15-02322-t002_Table 2 Table 2 The hyperparameters used in CNN model training. Hyperparameter Value Learning Rate 0.00001 Batch Size 32 Epochs 20 diagnostics-15-02322-t003_Table 3 Table 3 The distribution of the training and validation database. Database Training Validation Total Normal Lung 369 92 461 Pleural Effusion 369 92 461 diagnostics-15-02322-t004_Table 4 Table 4 An example of the confusion matrix.  Ground Truth Value True False Predicted Value True T p F p False F n T n diagnostics-15-02322-t005_Table 5 Table 5 Performance comparison of using CNN to train single-lung and whole-lung pleural effusion classification.  Left Lung Right Lung Average Lungs Whole Lungs Accuracy 66.30% 73.37% 69.84% 84.24% Precision 79.87% 82.62% 81.25% 86.97% Recall 66.30% 73.37% 69.84% 84.24% F1 Score 61.99% 71.34% 66.67% 83.94% diagnostics-15-02322-t006_Table 6 Table 6 Comparison between the case without image enhancement and various image enhancement methods.  Original Log Transform CLAHE Histogram Stretch Accuracy 87.50% 64.13% 87.50% 89.67% Precision 88.52% 77.38% 88.04% 90.06% Recall 87.50% 64.13% 87.50% 89.67% F1 Score 87.42% 59.19% 87.46% 89.65% diagnostics-15-02322-t007_Table 7 Table 7 The comparison between various edge detection.  Histogram Stretch Histogram Stretch + Canny Histogram Stretch + Sharpen Histogram Stretch + Sobel Gradient Accuracy 89.67% 83.15% 88.04% 91.85% Precision 90.06% 83.16% 88.50% 91.86% Recall 89.67% 83.15% 88.04% 91.85% F1 Score 89.65% 83.15% 88.01% 91.85% diagnostics-15-02322-t008_Table 8 Table 8 The result with 5-fold cross-validation results of different CNN architectures.  Mobilenet_v3 Squeezenet Darknet19 Alexnet Efficientnet_b0 Accuracy 77.53% 90.02% 89.49% 92.74% 93.27% diagnostics-15-02322-t009_Table 9 Table 9 Comparison of Deep Learning Methods for Pleural Effusion Detection.  Method 17 Method 5 Method 16 Method 14 Method 15 This Work Accuracy (%) 83.00 77.00 91.00 87.70 87.18 93.27 Precision (%) 99.00 82.25 84.21 85.30 N/A 92.95 Recall (%) 75.00 91.50 100.00 94.70 N/A 92.81 F1 score (%) 75.00 82.00 91.43 86.00 N/A 92.79 ",
  "metadata": {
    "Title of this paper": "ChestX-ray8: Hospital-scale Chest X-ray Database and Benchmarks on Weakly-Supervised Classification and Localization of Common Thorax Diseases",
    "Journal it was published in:": "Diagnostics",
    "URL": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC12468862/"
  }
}