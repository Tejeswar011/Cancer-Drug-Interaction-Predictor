{
  "title": "Paper_1079",
  "abstract": "pmc J Imaging J Imaging 4082 jimaging jimaging Journal of Imaging 2313-433X Multidisciplinary Digital Publishing Institute  (MDPI) PMC12470960 PMC12470960.1 12470960 12470960 41003364 10.3390/jimaging11090314 jimaging-11-00314 1 Article Enhancing Breast Lesion Detection in Mammograms via Transfer Learning https://orcid.org/0000-0002-0284-0949 Abdikenov Beibit Conceptualization Resources Writing – review & editing Supervision Project administration Funding acquisition * https://orcid.org/0009-0004-2310-4168 Rakishev Dimash Conceptualization Methodology Validation Formal analysis Data curation Writing – original draft Visualization Project administration * https://orcid.org/0009-0004-9826-625X Orazayev Yerzhan Software Validation Investigation Supervision https://orcid.org/0009-0002-8749-1967 Zhaksylyk Tomiris Writing – original draft Kwon Goorak Academic Editor Science and Innovation Center “Artificial Intelligence”, Astana IT University, Astana 010000, Kazakhstan; y.orazayev@astanait.edu.kz zhaksylyk.tomiris@astanait.edu.kz * beibit.abdikenov@astanait.edu.kz 242707@astanait.edu.kz 13 9 2025 9 2025 11 9 497645 314 08 8 2025 09 9 2025 10 9 2025 13 09 2025 27 09 2025 27 09 2025 © 2025 by the authors. 2025 https://creativecommons.org/licenses/by/4.0/ Licensee MDPI, Basel, Switzerland. This article is an open access article distributed under the terms and conditions of the Creative Commons Attribution (CC BY) license ( https://creativecommons.org/licenses/by/4.0/ Early detection of breast cancer via mammography enhances patient survival rates, prompting this study to assess object detection models—Cascade R-CNN, YOLOv12 (S, L, and X variants), RTMDet-X, and RT-DETR-X—for detecting masses and calcifications across four public datasets (INbreast, CBIS-DDSM, VinDr-Mammo, and EMBED). The evaluation employs a standardized preprocessing approach (CLAHE, cropping) and augmentation (rotations, scaling), with transfer learning tested by training on combined datasets (e.g., INbreast + CBIS-DDSM) and validating on held-out sets (e.g., VinDr-Mammo). Performance is measured using precision, recall, mean Average Precision at IoU 0.5 ( mAP 50 mAP 50 mAP 50 mAP 50 mAP 50 mAP 50 mAP 50 mammography deep learning lesion detection transfer learning data augmentation preprocessing object detection YOLO Cascade R-CNN RTMDet RT-DETR transformer The Committee of Science of the Ministry of Science and Higher Education of the Republic of Kazakhstan BR24993145 This research was funded by the Committee of Science of the Ministry of Science and Higher Education of the Republic of Kazakhstan, grant number BR24993145. pmc-status-qastatus 0 pmc-status-live yes pmc-status-embargo no pmc-status-released yes pmc-prop-open-access yes pmc-prop-olf no pmc-prop-manuscript no pmc-prop-legally-suppressed no pmc-prop-has-pdf yes pmc-prop-has-supplement no pmc-prop-pdf-only no pmc-prop-suppress-copyright no pmc-prop-is-real-version no pmc-prop-is-scanned-article no pmc-prop-preprint no pmc-prop-in-epmc yes 1. Introduction Breast cancer is one of the most prevalent cancers globally and the leading cause of cancer-related mortality among women. Early detection through mammography screening significantly improves patient outcomes by enabling timely intervention [ 1 2 3 4 5 6 7 However, mammography presents unique challenges, including subtle lesions, high-resolution images, and variability across datasets due to differences in imaging devices, patient populations, and annotation schemes, which introduce domain shifts that hinder model generalization. To address these challenges, several large-scale mammography datasets have been made publicly available, such as Curated Breast Imaging Subset of DDSM (CBIS-DDSM) [ 2 8 9 10 In this work, we propose the following key contributions to advance mammogram lesion detection using deep learning: Systematic evaluation of advanced deep learning object detectors, including Cascade R-CNN, YOLOv12 (S, M, L, and X variants), RTMDet-X, and RT-DETR-X, on four mammography datasets (CBIS-DDSM, VinDr-Mammo, EMBED, and INbreast) for detecting masses and calcifications. Standardized preprocessing pipeline with contrast-limited adaptive histogram equalization (CLAHE), breast cropping, and data augmentation techniques like rotations and scaling to enhance model robustness. Transfer learning assessment by fine-tuning pretrained models on dataset pairs (e.g., CBIS-DDSM+VinDr-Mammo) and testing on held-out datasets (e.g., INbreast), leveraging additional medical imaging datasets (e.g., VinDr-CXR) to improve generalization. Our results demonstrate that larger YOLOv12 models, particularly YOLOv12-X, and Cascade R-CNN deliver superior performance, achieving mean Average Precision ( mAP 50 2. Related Work The application of deep learning to mammography has seen significant advancements, with various architectures being adapted for lesion detection. Early computer-aided detection (CAD) systems relied on handcrafted features, but deep convolutional neural networks (CNNs) have since demonstrated superior performance. For instance, Ribli et al. utilized RetinaNet for detecting masses and calcifications, while other studies have applied Faster R-CNN and YOLO to this task [ 11 2.1. YOLO-Based Methods The YOLO (You Only Look Once) family of detectors has been particularly effective due to its balance of speed and accuracy. Al-Masni et al. (2018) introduced a YOLO-based CAD system for simultaneous detection and classification of breast masses [ 12 13 14 15 16 2.2. Transformer-Based Methods Transformer-based architectures have gained traction for their ability to capture global dependencies in images. Chen et al. (2022) used a Vision Transformer to process four mammographic views simultaneously, achieving improved diagnostic accuracy [ 17 18 19 20 2.3. Unsupervised and Ensemble Methods Multi-view fusion strategies, such as Merged Dual-View and Dual-Branch Ensemble models, have further improved detection accuracy in mammography [ 21 22 23 24 2.4. Transfer Learning Transfer learning is crucial for adapting models trained on large natural image datasets to medical imaging tasks. Pan and Yang (2010) provide a foundational survey of transfer learning techniques, widely applied in medical imaging to leverage knowledge from diverse domains [ 25 26 2.5. Comprehensive Overviews Recent reviews, such as Carriero et al. (2024), provide a comprehensive overview of deep learning advancements in breast cancer imaging, summarizing state-of-the-art techniques as of early 2024 [ 27 Our study builds on these advancements by evaluating cutting-edge models like YOLOv12 and RT-DETR-X, which are not yet extensively explored in mammography. We compare Cascade R-CNN, YOLOv12 variants, and RT-DETR-X across multiple mammography datasets, focusing on preprocessing, augmentation, and cross-dataset transfer learning to address domain shifts and enhance generalization. 3. Materials and Methods 3.1. Datasets We used four public mammography datasets. The summary of the datasets is provided in Table 1 Figure 1 INbreast CBIS-DDSM The VinDr-Mammo EMBED For transfer learning (TL) VinDr-CXR 28 VinDr-SpineXR 29 RSNA Pneumonia Detection Challenge Dataset 30 ChestX-Det10 31 FracAtlas 32 COVID-19 Image Data Collection 33 3.2. Preprocessing and Augmentation Mammogram images were preprocessed to enhance contrast and remove irrelevant background before training. Figure 2 Figure 3 3.2.1. CLAHE Algorithm All mammograms undergo a standard preprocessing pipeline. To enhance local contrast in mammogram images, we applied Contrast Limited Adaptive Histogram Equalization (CLAHE) using the OpenCV library [ 34 Figure 3 35 36 3.2.2. Cropping Algorithm To isolate the breast region and remove extraneous black background in mammograms, we implemented an automated cropping algorithm tailored for high-resolution mammography images. The overall preprocessing pipeline, including cropping, is illustrated in Figure 2 c r o p x m i n c r o p x m a x 37 38 3.2.3. Augmentation During training, we apply data augmentation to the minority class (calcifications) to mitigate class imbalance and enhance model robustness. Random horizontal flips, small rotations (±15°), and scaling (zoom in/out up to 10%) are selectively applied to calcification samples to increase their diversity, as masses outnumber calcifications (e.g., CBIS-DDSM, 891 masses vs. 753 calcifications, Table 1 39 3.3. Transfer Learning Strategy To enhance model generalization across diverse mammography datasets and address domain shifts caused by variations in imaging devices, patient demographics, and annotation protocols, we implemented a comprehensive transfer learning (TL) strategy. This strategy encompasses two approaches: (1) cross-dataset transfer learning within mammography datasets, and (2) transfer learning from other medical imaging datasets to leverage complementary knowledge from related radiographic domains. 3.3.1. Cross-Dataset Transfer Learning Cross-dataset transfer learning was designed to evaluate model generalization across mammography datasets with differing characteristics. We adopted a leave-one-out strategy, training models on a combination of two mammography datasets and testing on the third, held-out dataset. Specifically, the combinations were as follows: Training on INbreast + CBIS-DDSM, testing on VinDr-Mammo. Training on INbreast + VinDr-Mammo, testing on CBIS-DDSM. Training on CBIS-DDSM + VinDr-Mammo, testing on INbreast. The EMBED dataset was excluded due to label ambiguity from unconfirmed pathology annotations and limited single-ROI subset size. Models were initialized with COCO pretrained weights to leverage general object detection features, then fine-tuned on the combined mammography datasets without further fine-tuning on the target dataset. This approach tests feature robustness against domain shifts, such as differences in imaging modalities (FFDM vs. digitized film in CBIS-DDSM) and annotation schemes (e.g., INbreast’s precise contours vs. VinDr-Mammo’s BI-RADS-based annotations). This cross-dataset strategy aligns with standard medical imaging practices for evaluating performance on unseen data distributions. 3.3.2. Transfer Learning from Medical Imaging Datasets To further improve generalization, we incorporated transfer learning from other medical imaging datasets, specifically chest and musculoskeletal X-ray datasets described earlier (VinDr-CXR, VinDr-SpineXR, RSNA Pneumonia Detection Challenge Dataset, ChestX-Det10, FracAtlas, and COVID-19 Image Data Collection; Table 2 3.4. Deep Learning Models Our study employs end-to-end object detection models (e.g., YOLOv12, RTMDet-X) to localize and classify lesions, unlike classification-focused approaches using traditional ML classifiers (e.g., SVM in [ 24 We evaluate four detector families: Cascade R-CNN YOLOv12 (S/L/X) 40 mAP 50 RT-DETR-X RTMDet-X All models are initialized with COCO weights (backbones pretrained) and then trained on our mammography datasets. Inference outputs bounding boxes for two classes. 3.5. Evaluation Metrics To assess the performance of object detection models for mammogram lesion detection, we employed metrics tailored for evaluating detection tasks, particularly suited for medical imaging with imbalanced lesion classes (masses and calcifications). All metrics are reported for the positive classes (mass, calcification) to align with clinical priorities, emphasizing accurate detection of abnormalities. Precision Precision = TP TP + FP Recall Recall = TP TP + FN Mean Average Precision mAP 50 mAP 50 F1-score F 1 = 2 × precision × recall precision + recall It is particularly useful for imbalanced datasets, providing a balanced measure of detection performance for masses and calcifications, where masses are more prevalent than calcifications. These metrics are computed per class (mass, calcification) and for combined detection, providing a comprehensive assessment of model performance across datasets. Precision, recall, and F1-score are threshold-dependent, while mAP 50 3.6. Implementation Details All experiments were conducted on a workstation with dual NVIDIA GeForce RTX 2080 Ti GPUs (11 GB VRAM each), leveraging CUDA and cuDNN for acceleration. The software environment used Ubuntu 22.04.5 LTS, Python 3.10.12, and PyTorch 2.4.0+cu121 as the primary deep learning framework, with MMDetection 3.3.0, MMCV 2.1.0, and Ultralytics 8.3.147 for model implementation and training. Model training and evaluation utilized DataParallel for multi-GPU processing. The key implementation parameters were as follows: Batch size Optimizer β 1 = 0.9 β 2 = 0.999 1 × 10 − 4 Learning rate 1 × 10 − 4 Loss function Epochs Input size Validation Strategy: Given the large dataset sizes and significant computational demands, we employed hold-out validation with an 80/10/10 train/validation/test split at the exam level to prevent data leakage from the same patient. This ensures independent evaluation while optimizing efficiency. For the smaller INbreast dataset (410 images), performance metrics were averaged across runs with different random seeds to enhance reliability. However, this approach may limit robustness compared to cross-validation. Future studies will incorporate 5-fold cross-validation to further assess model generalization across diverse subsets. 4. Results We evaluate precision, recall, mean Average Precision at IoU = 0.5 ( mAP 50 Figure 4 4.1. Impact of Preprocessing The impact of these preprocessing steps is demonstrated in Table 3 50 p 50 p 50 p 50 p 4.2. Performance on Individual Datasets Table 4 Table 5 Table 6 mAP 50 mAP 50 Table 7 50 50 4.3. Comparison Across Architectures Table 8 mAP 50 mAP 50 mAP 50 mAP 50 mAP 50 mAP 50 Table 9 4.4. Cross-Dataset Transfer Learning Table 10 mAP 50 mAP 50 mAP 50 Visualization of Model Performance To enhance interpretability, we included confusion matrices for the best-performing models (YOLOv12-L on INbreast, CBIS-DDSM, VinDr-Mammo) in Figure 5 Figure 6 Figure 7 Figure 8 Figure 9 Figure 10 mAP 50 4.5. Transfer Learning from Medical Imaging Figure 11 mAP 50 Table 11 Figure 11 mAP 50 mAP 50 4.6. Comparison with State-of-the-Art Methods Table 12 mAP 50 mAP 50 Summary: YOLOv12-L excels in mass detection, achieving an mAP 50 50 50 50 50 50 5. Discussion Our results highlight key trends in mammogram lesion detection. YOLOv12-L achieved the highest mAP 50 mAP 50 mAP 50 mAP 50 mAP 50 INbreast, with high-quality images and precise annotations, yielded the best performance ( mAP 50 mAP 50 mAP 50 mAP 50 The consistently low performance in calcification detection ( mAP 50 Transfer learning improved INbreast performance ( mAP 50 mAP 50 Methodologically, the standardized preprocessing pipeline ensured fair model comparisons. Transfer learning with TL datasets (e.g., VinDr-CXR, ChestX-Det10) improved generalization, with RTMDet-X achieving the highest mAP 50 5.1. Limitations of This Study While our study has made significant strides in advancing mammographic lesion detection, several limitations highlight areas for future improvement. The dataset sizes, while substantial (e.g., 20,000 images in VinDr-Mammo), are still limited compared to the diversity required for comprehensive generalization, potentially restricting the model’s ability to capture all variations in real-world mammography. The lack of external validation poses a challenge, as our results are based on internal hold-out sets without independent clinical confirmation, which could affect their applicability across different institutions. Generalizability is further constrained by domain shifts and annotation inconsistencies across datasets (e.g., CBIS-DDSM vs. INbreast), which impact transfer learning performance. Notably, detecting calcifications proved challenging due to their small size and annotation variability, reflected in a modest mAP 50 Domain shifts across datasets like CBIS-DDSM and VinDr-Mammo led to transfer learning performance variations, with reductions of 5–11% in some cases. Despite this, our approach demonstrated resilience in adapting to diverse data sources, and future efforts will focus on advanced domain adaptation techniques to further boost generalization. Similarly, the use of the EMBED dataset was constrained by label ambiguity and limited subset size, without external clinical validation. Yet, our careful curation of data subsets ensured reliable preliminary results, and we are actively planning partnerships for clinical validation to strengthen real-world applicability. Class imbalance, with masses outnumbering calcifications, was mitigated through data augmentation but not fully resolved. Our augmentation strategies still achieved balanced detection performance, and future work will incorporate advanced resampling or weighting techniques to further address this. The computational demands of large models like RTMDet-X, while substantial, powered our state-of-the-art detection capabilities. We are optimistic about optimizing these models for real-time deployment, leveraging efficient architectures in upcoming studies. Overall, our study showcases a promising framework with strong detection performance, and the identified challenges pave the way for impactful future advancements. 5.2. Clinical Interpretation From a clinical perspective, our models can integrate into mammography workflows as computer-aided detection (CAD) tools to support radiologists. For instance, YOLOv12-L’s high mAP 50 For radiologist support, the models act as a “second reader,” offering explainable insights into detection rationale to foster trust. Transfer learning enhancements (e.g., mAP 50 mAP 50 6. Conclusions This study evaluates advanced deep learning detectors—Cascade R-CNN, YOLOv12 (S, L, and X variants), RTMDet-X, and RT-DETR-X—for mammogram lesion detection, employing a standardized preprocessing pipeline (CLAHE, cropping) and transfer learning framework. Key findings reveal that preprocessing and augmentation (rotations, scaling) substantially enhance performance, with mAP 50 mAP 50 mAP 50 mAP 50 mAP 50 mAP 50 Disclaimer/Publisher’s Note: Author Contributions Conceptualization, B.A. and D.R.; methodology, D.R.; software, Y.O.; validation, D.R. and Y.O.; formal analysis, D.R.; investigation, Y.O.; resources, B.A.; data curation, D.R. and T.Z.; writing—original draft preparation, D.R. and T.Z.; writing—review and editing, B.A.; visualization, D.R.; supervision, B.A. and Y.O.; project administration, B.A. and D.R.; funding acquisition, B.A. All authors have read and agreed to the published version of the manuscript. Institutional Review Board Statement Ethical review and approval were waived for this study due to the data used were obtained from the public databases. Informed Consent Statement Patient consent was waived due to the data used were obtained from the public databases. Data Availability Statement The datasets used in this study are sourced from publicly available repositories or can be accessed upon request: INbreast is available at: https://www.kaggle.com/datasets/ramanathansp20/inbreast-dataset https://www.cancerimagingarchive.net/collections/cbis-ddsm https://www.kaggle.com/competitions/rsna-pneumonia-detection-challenge https://github.com/Deepwise-AILab/ChestX-Det10-Dataset https://figshare.com/articles/dataset/The_dataset/22363012?file=43283628 https://github.com/ieee8023/covid-chestxray-dataset https://vindr.ai/datasets/mammo https://registry.opendata.aws/emory-breast-imaging-dataset-embed/ https://physionet.org/content/vindr-cxr/1.0.0/ https://physionet.org/content/vindr-spinexr/1.0.0/ Conflicts of Interest The authors declare no conflicts of interest. Abbreviations The following abbreviations are used in this manuscript: BI-RADS Breast Imaging–Reporting and Data System CAD Computer-Aided Detection CLAHE Contrast Limited Adaptive Histogram Equalization CNN Convolutional Neural Network CXR Chest X-ray DBT Digital Breast Tomosynthesis DDSM Digital Database for Screening Mammography DETR DEtection TRansformer FFDM Full-Field Digital Mammography FPN Feature Pyramid Network IoU Intersection over Union mAP Mean Average Precision NMS Non-Maximum Suppression ROC Receiver Operating Characteristic ROI Region of Interest SVM Support Vector Machine TL Transfer Learning YOLO You Only Look Once References 1. World Health Organization Breast Cancer 2023 Available online: https://www.who.int/news-room/fact-sheets/detail/breast-cancer (accessed on 14 June 2025) 2. Lee R.S. Gimenez F. Hoogi A. Miyake K.K. Gorovoy M. Rubin D.L. A curated mammography data set for use in computer-aided detection and diagnosis research Sci. Data 2017 4 170177 10.1038/sdata.2017.177 29257132 PMC5735920 3. Redmon J. Divvala S. Girshick R. Farhadi A. You only look once: Unified, real-time object detection Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition Las Vegas, NV, USA 27–30 June 2016 779 788 4. Cai Z. Vasconcelos N. Cascade R-CNN: High Quality Object Detection and Instance Segmentation IEEE Trans. Pattern Anal. Mach. Intell. 2021 43 1483 1498 10.1109/TPAMI.2019.2956516 31794388 5. Lyu C. Zhang W. Huang H. Zhou Y. Wang Y. Liu Y. Zhang S. Chen K. RTMDet: An Empirical Study of Designing Real-Time Object Detectors arXiv 2022 10.48550/arXiv.2212.07784 2212.07784 6. Carion N. Massa F. Synnaeve G. Usunier N. Kirillov A. Zagoruyko S. End-to-end object detection with transformers Proceedings of the European Conference on Computer Vision Glasgow, UK 23–28 August 2020 Springer Cham, Switzerland 2020 213 229 7. Lin T.Y. Maire M. Belongie S. Hays J. Perona P. Ramanan D. Dollár P. Zitnick C.L. Microsoft coco: Common objects in context Proceedings of the European Conference on Computer Vision Zurich, Switzerland 6–12 September 2014 Springer Cham, Switzerland 2014 740 755 8. Nguyen H.T. Nguyen H.Q. Pham H.H. Lam K. Le L.T. Dao M. Vu V. VinDr-Mammo: A large-scale benchmark dataset for computer-aided diagnosis in full-field digital mammography Sci. Data 2023 10 277 10.1038/s41597-023-02100-7 37173336 PMC10182079 9. Jeong J.J. Vey B.L. Bhimireddy A. Kim T. Santos T. Correa R. Dutt R. Mosunjac M. Oprea-Ilies G. Smith G. The EMory BrEast imaging Dataset (EMBED): A racially diverse, granular dataset of 3.4 million screening and diagnostic mammographic images Radiol. Artif. Intell. 2023 5 e220047 10.1148/ryai.220047 36721407 PMC9885379 10. Moreira I.C. Amaral I. Domingues I. Cardoso A. Cardoso M.J. Cardoso J.S. Inbreast: Toward a full-field digital mammographic database Acad. Radiol. 2012 19 236 248 10.1016/j.acra.2011.09.014 22078258 11. Ribli D. Horváth A. Unger Z. Pollner P. Csabai I. Detecting and classifying lesions in mammograms with deep learning Sci. Rep. 2018 8 4165 10.1038/s41598-018-22437-z 29545529 PMC5854668 12. Al-Masni M.A. Al-Antari M.A. Park J.M. Gi G. Kim T.Y. Rivera P. Valarezo E. Choi M.T. Han S.M. Kim T.S. Simultaneous detection and classification of breast masses in digital mammograms via a deep learning YOLO-based CAD system Comput. Methods Programs Biomed. 2018 157 85 94 10.1016/j.cmpb.2018.01.017 29477437 13. Zhang L. Li Y. Chen H. Wu W. Chen K. Wang S. Anchor-free YOLOv3 for mass detection in mammogram Expert Syst. Appl. 2022 191 116273 10.1016/j.eswa.2021.116273 14. Aly G.H. Marey M. El-Sayed S.A. Tolba M.F. YOLO-Based Breast Masses Detection and Classification in Full-Field Digital Mammograms Comput. Methods Programs Biomed. 2021 200 105823 10.1016/j.cmpb.2020.105823 33190942 15. Baccouche A. Garcia-Zapirain B. Castillo-Olea C. Elmaghraby A.S. Breast Lesions Detection and Classification via YOLO-Based Fusion Models Comput. Mater. Contin. 2021 69 1407 1427 10.32604/cmc.2021.018461 16. Su Y. Liu Q. Xie W. Hu P. YOLO-LOGO: A transformer-based YOLO segmentation model for breast mass detection and segmentation in digital mammograms Comput. Methods Programs Biomed. 2022 221 106903 10.1016/j.cmpb.2022.106903 35636358 17. Chen X. Zhang K. Abdoli N. Gilley P.W. Wang X. Liu H. Zheng B. Qiu Y. Transformers improve breast cancer diagnosis from unregistered multi-view mammograms Diagnostics 2022 12 1549 10.3390/diagnostics12071549 35885455 PMC9320758 18. Betancourt Tarifa A.S. Marrocco C. Molinara M. Tortorella F. Bria A. Transformer-based mass detection in digital mammograms J. Ambient. Intell. Humaniz. Comput. 2023 14 2723 2737 10.1007/s12652-023-04517-9 19. Kamran S.A. Hossain K.F. Tavakkoli A. Bebis G. Baker S. Swin-sftnet: Spatial feature expansion and aggregation using swin transformer for whole breast micro-mass segmentation Proceedings of the 2023 IEEE 20th International Symposium on Biomedical Imaging (ISBI) Cartagena, Colombia 17–21 April 2023 IEEE New York, NY, USA 2023 1 5 20. Zhao Y. Lv W. Xu S. Wei J. Wang G. Dang Q. Liu Y. Chen J. DETRs Beat YOLOs on Real-time Object Detection arXiv 2024 10.48550/arXiv.2304.08069 2304.08069 21. Abdikenov B. Zhaksylyk T. Imasheva A. Orazayev Y. Karibekov T. Innovative Multi-View Strategies for AI-Assisted Breast Cancer Detection in Mammography J. Imaging 2025 11 247 10.3390/jimaging11080247 40863457 PMC12387149 22. Park S. Lee K.H. Ko B. Kim N. Unsupervised anomaly detection with generative adversarial networks in mammography Sci. Rep. 2023 13 2925 10.1038/s41598-023-29521-z 36805637 PMC9941466 23. McKinney S.M. Sieniek M. Godbole V. Godwin J. Antropova N. Ashrafian H. Back T. Chesus M. Corrado G.S. Darzi A. International evaluation of an AI system for breast cancer screening Nature 2020 577 89 94 10.1038/s41586-019-1799-6 31894144 24. Manalı D. Demirel H. Eleyan A. Deep Learning Based Breast Cancer Detection Using Decision Fusion Computers 2024 13 294 10.3390/computers13110294 25. Pan S.J. Yang Q. A survey on transfer learning IEEE Trans. Knowl. Data Eng. 2009 22 1345 1359 10.1109/TKDE.2009.191 26. Agarwal R. Díaz O. Yap M.H. Lladó X. Martí R. Deep learning for mass detection in Full Field Digital Mammograms Comput. Biol. Med. 2020 121 103774 10.1016/j.compbiomed.2020.103774 32339095 27. Carriero A. Groenhoff L. Vologina E. Basile P. Albera M. Deep Learning in Breast Cancer Imaging: State of the Art and Recent Advancements in Early 2024 Diagnostics 2024 14 848 10.3390/diagnostics14080848 38667493 PMC11048882 28. Nguyen H.Q. Lam K. Le L.T. Pham H.H. Tran D.Q. Nguyen D.B. Le D.D. Pham C.M. Tong H.T. Dinh D.H. VinDr-CXR: An open dataset of chest X-rays with radiologist’s annotations Sci. Data 2022 9 429 10.1038/s41597-022-01498-w 35858929 PMC9300612 29. Nguyen H.T. Pham H.H. Nguyen N.T. Nguyen H.Q. Huynh T.Q. Dao M. Vu V. VinDr-SpineXR: A deep learning framework for spinal lesions detection and classification from radiographs Proceedings of the International Conference on Medical Image Computing and Computer-Assisted Intervention Strasbourg, France 27 September–1 October 2021 Springer Cham, Switzerland 2021 291 301 30. Anouk Stein M. Wu C. Carr C. Shih G. Dulkowski J. kalpathy Chen L. Prevedello L. Marc Kohli M. McDonald M. RSNA Pneumonia Detection Challenge Kaggle 2018 Available online: https://kaggle.com/competitions/rsna-pneumonia-detection-challenge (accessed on 10 July 2025) 31. Liu J. Lian J. Yu Y. ChestX-Det10: Chest X-ray Dataset on Detection of Thoracic Abnormalities arXiv 2020 10.48550/arXiv.2006.10550 2006.10550 32. Abedeen I. Rahman M.A. Prottyasha F.Z. Ahmed T. Chowdhury T.M. Shatabda S. FracAtlas: A Dataset for Fracture Classification, Localization and Segmentation of Musculoskeletal Radiographs Sci. Data 2023 10 521 10.1038/s41597-023-02432-4 37543626 PMC10404222 33. Cohen J.P. Morrison P. Dao L. COVID-19 image data collection arXiv 2020 10.48550/arXiv.2003.11597 2003.11597 34. Bradski G. The OpenCV Library Dr. Dobb’s J. Softw. Tools 2000 25 120 123 35. Al-Juboori R.A.L. Contrast enhancement of the mammographic image using retinex with CLAHE methods Iraqi J. Sci. 2017 58 327 336 36. Pisano E.D. Zong S. Hemminger B.M. DeLuca M. Johnston R.E. Muller K. Braeuning M.P. Pizer S.M. Contrast limited adaptive histogram equalization image processing to improve the detection of simulated spiculations in dense mammograms J. Digit. Imaging 1998 11 193 10.1007/BF03178082 9848052 PMC3453156 37. Boss R.S.C. Thangavel K. Daniel D.A.P. Automatic Mammogram image Breast Region Extraction and Removal of Pectoral Muscle arXiv 2013 10.48550/arXiv.1307.7474 1307.7474 38. Zhou K. Li W. Zhao D. Deep learning-based breast region extraction of mammographic images combining pre-processing methods and semantic segmentation supported by Deeplab v3+ Technol. Health Care 2022 30 173 190 10.3233/THC-228017 35124595 PMC9028646 39. Oza P. Sharma P. Patel S. Adedoyin F. Bruno A. Image augmentation techniques for mammogram analysis J. Imaging 2022 8 141 10.3390/jimaging8050141 35621905 PMC9147240 40. Tian Y. Ye Q. Doermann D. YOLOv12: Attention-Centric Real-Time Object Detectors arXiv 2025 10.48550/arXiv.2502.12524 2502.12524 41. Al-Antari M.A. Al-Masni M.A. Kim T.S. Deep Learning Computer-Aided Diagnosis for Breast Lesion in Digital Mammogram Adv. Exp. Med. Biol. 2020 1213 59 72 10.1007/978-3-030-33128-3_4 32030663 42. Ribeiro R.F. Gomes-Fonseca J. Torres H.R. Oliveira B. Vilhena E. Morais P. Vilaca J.L. Deep learning methods for lesion detection on mammography images: A comparative analysis Proceedings of the Annual International Conference of the IEEE Engineering in Medicine and Biology Society Glasgow, UK 11–15 July 2022 3526 3529 10.1109/EMBC48229.2022.9871447 36086472 43. Karaca Aydemir B.K. Telatar Z. Güney S. Dengiz B. Detecting and classifying breast masses via YOLO-based deep learning Neural Comput. Appl. 2025 37 11555 11582 10.1007/s00521-025-11153-1 44. Cao Z. Yang J. Gao F. Chen D. Automated abnormalities detection in mammography using deep learning Complex Intell. Syst. 2024 10 567 578 10.1007/s40747-024-01532-x Figure 1 Examples of craniocaudal (CC) and mediolateral oblique (MLO) view pairs from mammography datasets. ( top left top right bottom left bottom right Figure 2 Illustration of the image preprocessing steps applied to a mammogram. The process includes the original image, image cropping, contrast enhancement using CLAHE, and the final preprocessed image. Figure 3 Histograms of pixel intensity distribution before ( left right Figure 4 Overall pipeline for mammogram preprocessing and lesion detection. Figure 5 Confusion matrix for YOLOv12-L on the INbreast dataset. Figure 6 Confusion matrix for YOLOv12-L on the CBIS-DDSM dataset. Figure 7 Confusion matrix for YOLOv12-L on the VinDr-Mammo dataset. Figure 8 Visual example of a mammogram with detected masses overlaid, marked with red bounding boxes. Figure 9 Examples of calcification detection errors. Red bounding boxes indicate false positives (regions incorrectly detected as calcifications), while actual calcifications that remain unmarked correspond to false negatives (missed detections). These cases highlight the difficulty of detecting small calcifications in mammograms. Figure 10 Confusion matrix for RTMDET-X on the Combined dataset using TL. Figure 11 Bar chart comparing mAP 50 jimaging-11-00314-t001_Table 1 Table 1 Comparison of mammography datasets used in this study. Dataset Images Patients Annotations Modality INbreast 410 115 Masses, calcifications FFDM CBIS-DDSM 3318 1566 Masses (891), calcifications (753) Digitized film VinDr-Mammo 20,000 5000 Masses, calcifications FFDM EMBED ∼3,400,000 110,000 60,000 lesions FFDM, DBT jimaging-11-00314-t002_Table 2 Table 2 Public datasets used for transfer learning (TL) in this study. Dataset Images Region Task Modality VinDr-CXR 18,000 Chest Disease classification X-ray VinDr-SpineXR 10,469 Spine Spinal lesion classification X-ray RSNA Pneumonia 26,684 Chest Pneumonia detection X-ray ChestX-Det10 3543 Chest Multi-disease detection X-ray FracAtlas 4083 Musculoskeletal Fracture localization X-ray COVID-19 Image Data Collection 800+ Chest COVID-19 classification X-ray, CT jimaging-11-00314-t003_Table 3 Table 3 Comparing results with preprocessing (CLAHE and cropping) and not (YOLOv12-L), including 95% confidence intervals (CI) for mAP 50 p Dataset Type Precision Recall mAP 50 F1 INbreast Raw 0.832 0.553 0.754 (0.732–0.776) 0.664 INbreast CLAHE/cropped 0.987 0.857 0.963 (0.941–0.985) 0.917 CBIS-DDSM Raw 0.764 0.342 0.471 (0.449–0.493) 0.471 CBIS-DDSM CLAHE/cropped 0.615 0.552 0.566 (0.544–0.588) 0.582 VinDr-Mammo Raw 0.574 0.398 0.438 (0.416–0.460) 0.472 VinDr-Mammo CLAHE/cropped 0.735 0.513 0.590 (0.568–0.612) 0.604 p p p p p jimaging-11-00314-t004_Table 4 Table 4 Precision, recall, mAP 50 Class Model Precision Recall   mAP 50 F1 Mass YOLOv12-L 0.987 0.857 0.963 0.917 Calcification YOLOv12-L 0.051 0.034 0.006 0.041 Mass and calcification YOLOv12-L 0.772 0.474 0.497 0.590 Mass and calcification YOLOv12-S 0.68 0.53 0.554 0.596 jimaging-11-00314-t005_Table 5 Table 5 Precision, recall, mAP 50 Class Model Precision Recall   mAP 50 F1 Mass YOLOv12-L 0.615 0.552 0.566 0.582 Calcification YOLOv12-L 0.001 0.143 0.001 0.002 Mass and calcification YOLOv12-L 0.753 0.263 0.238 0.391 jimaging-11-00314-t006_Table 6 Table 6 Precision, recall, mAP 50 Class Model Precision Recall   mAP 50 F1 Mass YOLOv12-L 0.735 0.513 0.59 0.604 Calcification YOLOv12-L 0.003 0.488 0.014 0.006 Mass and calcification YOLOv12-L 0.672 0.28 0.22 0.395 jimaging-11-00314-t007_Table 7 Table 7 Precision, recall, mAP 50 Class Model Precision Recall   mAP 50 F1 1 class YOLOv12-L 0.156 0.257 0.126 0.194 1 class + VinDr-Mammo (1 class) YOLOv12-L 0.512 0.294 0.306 0.373 jimaging-11-00314-t008_Table 8 Table 8 Precision, recall, mAP 50 Class Model Precision Recall   mAP 50 F1 Mass RTMDet-X 0.736 0.659 0.688 0.695 Mass RT-DETR-X 0.721 0.613 0.626 0.662 Mass CASCADE R-CNN X101 0.687 0.603 0.614 0.642 Mass YOLOv12-X 0.616 0.518 0.552 0.563 Mass YOLOv12-L 0.719 0.59 0.634 0.648 Calcification RT-DETR-X 0.193 0.319 0.116 0.241 Calcification YOLOv12-L 0.303 0.101 0.096 0.152 Mass and calcification RT-DETR-X 0.555 0.487 0.467 0.519 Mass and calcification YOLOv12-L 0.376 0.315 0.288 0.343 Low calcification performance likely due to small lesion size and annotation variability. jimaging-11-00314-t009_Table 9 Table 9 Model computational metrics. Model Params (M) FLOPs (G) Inference Time (ms) Memory (GB) YOLOv12-L 46.7 68.5 29 4.7 YOLOv12-X 68.2 95.3 42 6.2 Cascade R-CNN X101 85.4 110.2 55 7.8 RTMDet-X 53.9 82.1 36 5.3 RT-DETR-X 62.3 89.7 48 6.5 jimaging-11-00314-t010_Table 10 Table 10 Cross-dataset transfer learning results for mass detection (YOLOv12-L). Dataset Precision Recall   mAP 50 F1 INbreast 0.987 0.857 0.963 0.917 VinDr-Mammo + CBIS-DDSM 0.626 0.54 0.555 0.579 VinDr-Mammo + CBIS-DDSM on INbreast 0.969 0.999 0.995 0.984 CBIS-DDSM 0.615 0.552 0.566 0.582 INbreast + VinDr-Mammo 0.626 0.54 0.555 0.579 INbreast + VinDr-Mammo on CBIS-DDSM 0.523 0.5 0.447 0.511 VinDr-Mammo 0.735 0.513 0.59 0.604 CBIS-DDSM + INbreast 0.561 0.542 0.519 0.551 CBIS-DDSM + INbreast on VinDr-Mammo 0.602 0.504 0.5 0.548 jimaging-11-00314-t011_Table 11 Table 11 Performance of models on combined datasets (INbreast, CBIS-DDSM, VinDr-Mammo) for mass detection, with and without transfer learning from medical imaging datasets. Model Precision Recall   mAP 50 F1 YOLOv12-L 0.719 0.590 0.634 0.648 YOLOv12-L with TL 0.700 0.644 0.678 0.671 YOLOv12-X 0.616 0.518 0.552 0.563 YOLOv12-X with TL 0.719 0.607 0.647 0.658 Cascade R-CNN X101 0.687 0.603 0.614 0.642 Cascade R-CNN X101 with TL 0.719 0.627 0.646 0.670 RTMDet-X 0.736 0.659 0.688 0.695 RTMDet-X with TL 0.754 0.667 0.697 0.708 RT-DETR-X 0.721 0.613 0.626 0.662 RT-DETR-X with TL 0.661 0.675 0.656 0.668 jimaging-11-00314-t012_Table 12 Table 12 Comparison with state-of-the-art methods for mammography lesion detection. Reference Year Metric (mAP/AP, F1) Dataset Method Al-Antari et al. [ 41 2020 F1: 0.988 (detection) INbreast YOLOv3 Su et al. [ 16 2022 mAP: 0.650, F1: 0.745 CBIS-DDSM YOLO-LOGO (YOLOv5L6) Ribeiro et al. [ 42 2022 mAP: 0.694, F1: 0.712 CBIS-DDSM YOLOv5 Karaca Aydemir et al. [ 43 2025 mAP: 0.843; F1: 0.812 INbreast (TL from CBIS-DDSM/VinDr-Mammo) YOLOv5-CAD (YOLOv5) Cao et al. [ 44 2024 mAP 50 INbreast YOLOv8 with TL Current study 2025 mAP 50 INbreast YOLOv12-L with TL Current study 2025 mAP 50 Combined dataset RTMDet-X with TL ",
  "metadata": {
    "Title of this paper": "Automated abnormalities detection in mammography using deep learning",
    "Journal it was published in:": "Journal of Imaging",
    "URL": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC12470960/"
  }
}