{
  "title": "Paper_1182",
  "abstract": "pmc Healthcare (Basel) Healthcare (Basel) 2994 healthcare healthcare Healthcare 2227-9032 Multidisciplinary Digital Publishing Institute  (MDPI) PMC12469309 PMC12469309.1 12469309 12469309 41008468 10.3390/healthcare13182340 healthcare-13-02340 1 Review How Could Artificial Intelligence Change the Doctor–Patient Relationship? A Medical Ethics Perspective Montanari Vergallo Gianluca 1 https://orcid.org/0000-0002-4458-5165 Campanozzi Laura Leondina 2 https://orcid.org/0000-0002-0146-1314 Gulino Matteo 3 https://orcid.org/0009-0005-9851-7458 Bassis Lorena 1 * https://orcid.org/0000-0003-4015-8825 Ricci Pasquale 4 https://orcid.org/0000-0001-5741-7139 Zaami Simona 1 https://orcid.org/0009-0009-5135-8196 Marinelli Susanna 5 Tambone Vittoradolfo 2 6 https://orcid.org/0000-0002-0358-7965 Frati Paola 1 Giansanti Daniele Academic Editor 1 gianluca.montanarivergallo@uniroma1.it simona.zaami@uniroma1.it paola.frati@uniroma1.it 2 l.campanozzi@unicampus.it v.tambone@unicampus.it 3 matteo.gulino@uniroma2.it 4 p.ricci@unilink.it 5 s.marinelli@pm.univpm.it 6 * lorena.bassis@uniroma1.it 17 9 2025 9 2025 13 18 497454 2340 28 7 2025 15 9 2025 16 9 2025 17 09 2025 27 09 2025 29 09 2025 © 2025 by the authors. 2025 https://creativecommons.org/licenses/by/4.0/ Licensee MDPI, Basel, Switzerland. This article is an open access article distributed under the terms and conditions of the Creative Commons Attribution (CC BY) license ( https://creativecommons.org/licenses/by/4.0/ Background: Methods: Results and Conclusions: artificial intelligence doctor–patient relationship medical ethics informed consent confidentiality patient autonomy medical professionalism This research received no external funding. pmc-status-qastatus 0 pmc-status-live yes pmc-status-embargo no pmc-status-released yes pmc-prop-open-access yes pmc-prop-olf no pmc-prop-manuscript no pmc-prop-legally-suppressed no pmc-prop-has-pdf yes pmc-prop-has-supplement no pmc-prop-pdf-only no pmc-prop-suppress-copyright no pmc-prop-is-real-version no pmc-prop-is-scanned-article no pmc-prop-preprint no pmc-prop-in-epmc yes 1. Introduction The core notion of artificial intelligence (AI) has been broadly debated since the 1950s; however, it was only at the turn of the millennium that AI saw an exponential growth due to the rise in and development of deep-learning algorithms, which brought about a significant breakthrough in the field [ 1 While there is still no agreed-upon and universally acknowledged definition of Artificial Intelligence, a workable definition is as follows: ‘AI system’ means a machine-based system that is designed to operate with varying levels of autonomy and that may exhibit adaptiveness after deployment, and that, for explicit or implicit objectives, infers, from the input it receives, how to generate outputs such as predictions, content, recommendations, or decisions that can influence physical or virtual environments [ 2 3 4 5 Overall, AI has the potential to enhance healthcare practice by reducing both diagnostic and therapeutic uncertainty. It supports clinicians in the prevention, classification, and stratification of patients’ conditions; it predicts whether recovery requires specific treatment, and it interprets images and detects signals that are imperceptible to the human eye through data collection and analysis. Furthermore, AI contributes to understanding how and why diseases develop; it helps identify the most appropriate treatment options and assists physicians and healthcare professionals by providing access to updated and evidence-based guidelines, even in real time, both in the ward and during surgical procedures [ 6 In order to better understand the opportunities and risks of these fascinating but controversial technologies, it is worth focusing on the use of AI in supporting diagnostics, particularly in radiology and dermatology [ 7 8 9 AI applications have also been harnessed in various medical fields to assist with diagnoses. Such realms include, but are not limited to, cardiology [ 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 In view of the concrete and wide-ranging benefits that AI systems seem to foreshadow by improving healthcare quality, a critical evaluation of the potential disadvantages and consequences of these practices in routine clinical settings cannot be overlooked. Special attention should be paid to the fundamental cornerstone of the medical profession: the doctor–patient relationship. Although it is still uncertain how and to what extent AI technologies may affect the doctor–patient relationship, there is no doubt that establishing and maintaining a good healthcare relationship is of utmost importance in the delivery of effective assistance, both in terms of care experience and clinical outcomes [ 37 38 39 Artificial intelligence systems hold considerable promise as valuable adjuncts across a wide range of clinical domains [ 40 Table 1 41 42 43 44 45 46 47 This article aims to lay out an overview of the potential challenges related to AI technologies for the doctor–patient relationship. The scenario thus delineated will hopefully serve as a valuable framework for defining future research priorities and evidence-based practices for safeguarding and enhancing the therapeutic alliance. Any failure to acknowledge and respect well-balanced standards and boundaries can compromise the quality and effectiveness of care, thereby jeopardizing patient health and well-being. 2. Methods The present contribution is a narrative review of the scientific literature and most significant international policy documents. This methodology was chosen in order to bring to the fore bioethical, medical, and regulatory perspectives, which can be challenging to fully outline through the strictly quantitative criteria of systematic reviews. The databases PubMed, Scopus, Web of Science, and Google Scholar were drawn upon, along with official documents, recommendations, and policy papers issued by the World Health Organization (WHO), the United Nations Educational, Scientific, and Cultural Organization (UNESCO), and the World Medical Association (WMA). Such institutions were selected by virtue of their authority and, consequently, for their capacity to influence future regulatory choices of individual states. To assess whether the recommendations of these international bodies have been incorporated within the European Union, China, and the United States, the principal regulatory frameworks of such nations (or supranational institutions such as the EU) were also accounted for. The EU, China, and the USA were selected as representative jurisdictions of the three principal world regions. The analysis included academic articles, guidelines, and institutional reports published between 2015 and 2025, focusing on clinical applications of AI as well as on ethical and legal aspects (informed consent, trust, autonomy, equity, dignity). This approach enabled the identification of four major thematic areas: grounds for employing AI technology for patients; communication about the use of AI to patients; confidentiality; and therapeutic alliance and healthcare professionalism. The authors excluded studies published in languages other than English or Italian, as well as those with a predominantly technical–engineering focus lacking ethical or legal analysis. 3. Results 3.1. Grounds for Employing AI Technology for Patients On 23 November 2021, as part of its mandate, UNESCO adopted an important Recommendation addressing ethical issues related to AI, cutting across different domains of application. The document elaborates on a number of salient points that inform the investigation under consideration, and it is noteworthy for its explicit references to the necessity of investing in research that explores the impact of AI systems on human–human relationships, as well as of ensuring due attention is paid to the importance of the patient’s relationship with healthcare staff [ 48 Among the ethical issues addressed, the document points out that the employment of AI systems must be supported by the following arguments: (a) the AI method selected should be appropriate, desirable, and proportionate to achieve a lawful aim; (b) the AI method selected should not violate or abuse human rights or infringe upon the foundational values; and (c) the chosen AI method should be suitable for the context and based on rigorous scientific principles [ 48 At this point, it is highly advisable to adopt a cautious approach when deciding whether or not to implement an AI technology in a given context, taking into account respect for human dignity and prioritizing the patient’s well-being and health, and not a mere cost–benefit analysis based on an industry-like logic. It is worth taking into account, for example, an algorithm system designed to predict the life expectancy of seriously ill patients, identifying those who would not benefit from hospitalization and who should therefore stay at home. The rationale which the company adopted to delineate the decision-making process may be unknown, and yet such a system could risk violating the patient’s human dignity and autonomy by evaluating human beings and their life expectancy based predominantly on hidden financial interests [ 49 Such aspects and complexities were addressed more extensively in the guidance document developed by the WHO on ‘Ethics and Governance of Artificial Intelligence for Health’ in June 2021. The premise of this report revolves around the need to move beyond an approach overly reliant on AI technologies as a panacea, since AI-based solutions are not immune to bias and error [ 50 Specifically, the reliability of any AI tool is contingent upon the quality and quantity of the data employed in order to generate a clinical decision. If the data are not suitable for providing reliable indications with regard to the characteristics of the specific case, it is likely that the AI tool will make errors in diagnosis and therapy [ 50 50 Starting from St. Thomas Aquinas’s assertion that what is useful does not have in itself (i.e., insofar as it is useful) the reason for the good, but rather the reason as a means to the good (in the same way that a bitter medicine is useful insofar as it is conducive to recovery), it cannot therefore be argued that what is useful is, in and of itself, necessarily good. Rather, what is good is also truly useful [ 51 52 Accordingly, creating durable and privacy-preserving data access mechanisms that promote better training and validation of AI models using high-quality data will make AI much safer [ 48 There is, therefore, broad agreement in the literature on the need to prevent artificial intelligence tools from being designed or programmed in ways that could infringe patients’ rights to health, self-determination, and confidentiality by prioritizing financial interests. From this perspective, AI should not alter the physician–patient relationship, which has been traditionally oriented toward safeguarding the patient under the physician’s responsibility. 3.2. Communication About the Use of AI to Patients It is doubtful that hospitals or healthcare providers will disclose to patients that AI was utilized in a decision-making process to support, validate, or even replace a physician. There is no precedent for obtaining patients’ permission before using technology for therapeutic or diagnostic purposes. However, the foundation of informed consent and broader public confidence in healthcare may be called into question by the use of AI in medicine and the omission of its use. This problem arises from the question of whether the application of AI in decision-making and clinical treatment could compromise any of the rationales for obtaining informed consent, including protection, autonomy, averting abusive practices, trust, self-ownership, non-dominance, and personal integrity. Doctors should inform patients about the use of AI in an open and straightforward manner and in a timely fashion [ 53 Continuing with the aforementioned example, if the AI system were configured to suggest a care pathway based on data concerning hospitalization expenses, and the physician accepted its predictions regarding the allocation of life opportunities without critical evaluation, the decision-making process would be adversely impacted, leading to inequitable treatment of patients overall [ 49 Physicians have to make every effort to clarify to their patients the rationale behind the use of AI, its mechanisms, and its explainability, i.e., the degree to which humans can grasp the reasons behind a model’s decisions or predictions, which is instrumental in making the “black box” of complex AI systems more transparent and understandable, and in enabling users to comprehend why a given model arrived at a particular outcome. Healthcare professionals should therefore thoroughly expound upon the types of data that are gathered and relied on and how such data are utilized and shared with outside parties and elaborate on the security measures in place to uphold patient privacy. Physicians ought to be open and honest about any biases, privacy issues, or data breaches that may arise from the use of AI technology. The use of AI in healthcare and health science, including clinical trials and hospital practices, can only be successful in the long run by ensuring transparency, explainability, and intelligibility. All such components are functional in that they represent grounds for building trust, which is essential to advance an effective use of AI in medicine [ 50 54 In circumstances where decisions are influenced by or based on AI algorithms, thorough information must be provided to patients, particularly in cases where such decisions may impact their safety or human rights. In such instances, individuals should also be entitled to request clarification from the relevant AI entity or public sector institution in charge of overseeing such techniques and their implementation. Furthermore, it is crucial that individuals have the capacity to comprehend the rationales supporting every decision that has the potential to affect their rights and self-determination. In addition, they should be allowed to submit comments to a designated employee of a public or private sector organization who will be tasked with the examination and potential amendment of the decision. In instances where a good or service is delivered directly to customers or with the assistance of AI systems, it is incumbent upon AI actors to ensure that users are promptly and appropriately notified [ 48 Therefore, it is essential to inform patients they are interacting with an AI system, since that can foster a trust-based relationship with healthcare professionals and the very institution of informed consent, and prevent the onset of novel and more insidious forms of paternalism in healthcare, which may be rooted in the unsupported claim that ‘computers know best’ [ 55 Thus, the use of artificial intelligence in clinical practice appears to complicate the physician–patient relationship, as it requires the physician to inform patients about the adoption of such tools and, where possible, to explain their functioning and degree of reliability. Consequently, the time devoted to the human dimension of the therapeutic encounter should, in principle, increase. 3.3. Confidentiality One of the most important values in preserving the human right to privacy in the relationship between doctors and patients is confidentiality. Its importance in the medical field has been acknowledged since the time of Hippocrates. Safeguarding data is tantamount to safeguarding trust. When patients suspect that their health information could be circulated beyond the strict purposes of care, they are likely to withhold relevant details. Such withholding not only undermines the therapeutic alliance but also diminishes the physician’s ability to provide accurate diagnoses and effective treatment, thereby jeopardizing the overall quality of care [ 56 Concerning the great advancement of AI systems in the healthcare sector, the recent Report commissioned by the Steering Committee for Human Rights in the field of Biomedicine and Health of the Council of Europe, in December 2021, has highlighted how unfettered innovation can pose a major threat on this front [ 57 Specifically, when AI systems are developed, used, and relied upon with increasing regularity in healthcare, there may be a larger requirement to generate or choose high-quality real-world patient datasets for system testing and training purposes. In this regard, there are two ways that innovation could compromise confidentiality and privacy, as also pointed out by several studies. First, there is the granting of third-party access to (de-identified) patient data and electronic health records to test and build AI systems. Second, there exists a concern that physicians might be inclined to request additional tests and analyses for the purpose of training or assessing AI systems, rather than for their clinical benefit. This issue is especially pertinent as it subjects patients to unnecessary risks associated with data leaks or other breaches of confidentiality, alongside escalating healthcare expenses. The right to privacy may be infringed upon by any data generation that possesses dubious therapeutic value or is evidently driven solely by its usefulness for the testing or development of AI systems. The utilization of patient health records for the purposes of testing and training AI systems should, at the very least, adhere to sufficient deidentification and privacy-enhancing protocols. One such option is differential privacy, which involves the addition of noise to prevent the identification of specific individuals in the dataset [ 57 58 59 Similar concerns have also been expressed in the WHO guidance document, which recommends establishing clear and more comprehensive data management plans, stressing that confidentiality obligations alone may not be effective enough to protect data used for AI health technologies [ 50 Given the potential need for medical monitoring, the United Nations Educational, Scientific, and Cultural Organization (UNESCO) has urged Member States to take special care when regulating prediction, detection, and treatment solutions for healthcare in AI applications, in addition to ensuring compliance with all applicable national and international data protection requirements, upholding privacy safeguards, and establishing effective mechanisms to ensure that individuals whose personal data is being analysed are informed about its use and grant consent thereof. Furthermore, this process should never hinder individual access to healthcare [ 48 Confidentiality is not only a legal obligation, but an ethical and philosophical core value as well, which is part and parcel of the very nature of healthcare. Accordingly, AI in medicine must never forgo rigorous respect for confidentiality, in order to prevent the patient from losing control over their information, trust in the healthcare professionals, and ultimately, the perception of being treated as a human being and not as a mere statistic. Non-compliance with the value of confidentiality can potentially bring about a sense of alienation in patients, who may come to perceive themselves as being treated as mere ‘assets’ within a system that no longer acknowledges their individuality, but rather views them exclusively as a repository or source of health data. Therefore, even in matters of confidentiality, artificial intelligence tools may pose significant risks. In this regard, and regardless of whether specific national regulations exist, healthcare professionals must adhere to their duty of confidentiality and uphold the primacy of patient welfare, ensuring that the protection of sensitive health information takes precedence over the commercial interests of AI developers and producers. 3.4. Therapeutic Alliance and Healthcare Professionalism Numerous contemporary studies corroborate the findings of the Council of Europe Report, expressing concern that an excessive reliance on artificial intelligence by medical professionals—wherein they delegate total control of patient care to the technology—may result in an inappropriate dependence on such technology. This over-reliance could potentially lead to a decline in the skills of medical practitioners (de-skilling), ultimately diminishing their diagnostic sensitivity [ 57 60 61 62 Shared decision-making (SDM) is genuinely achieved when both physicians and patients are able to contribute to the final choice (physicians by bringing medical expertise and empathy, and patients by providing information, values, and personal preferences) even when artificial intelligence is involved in the process [ 63 64 65 66 67 68 68 69 70 71 72 73 74 75 76 Furthermore, patients may turn to AI software for healthcare guidance, as AI-generated medical opinions become more widely available and supposedly trustworthy. Thus, the emergence of AI-generated medical opinions will probably cause a further change in the relationship between physicians, who have always held all the knowledge and experience, and patients or family members, who can now access increasingly sophisticated and accurate AI-generated opinions through large language model (LLM) chatbots like Google’s Bard or OpenAI’s GPT-4. Glass AI is a consumer technology designed specifically for the medical field. It is based on the GPT-4 algorithm and allows users to enter a clinical scenario to generate a differential diagnosis or clinical management plan. As such technologies become more widely available and popular, patients are likely to bring certain expectations to clinical examinations [ 77 On the other hand, generative AI tools are increasingly employed to draft medical reports, synthesize clinical documentation, and render medical language more comprehensible to patients. In doing so, they enable physicians to perform their tasks more efficiently and, consequently, free up additional time to listen to patients, fully assess their needs, and set forth treatment alternatives and predicted outcomes, as AI helps with data retrieval and interpretation. Namely, physicians could spend more time with patients in contact, rather than concerning themselves with time-consuming bureaucratic duties and “paperwork” relative to electronic health records, which is known to create dissatisfaction and exhaustion [ 50 69 78 79 80 81 82 In addition to the potential for time savings through the transcription and documentation processes, technology may also contribute to a reduction in physician burnout and to a deeper connection with the humanistic aspect of medicine. By enabling timely access to patient information in a comprehensible format, this approach can also contribute to the democratization of patient care [ 83 AI technologies can facilitate contact and communication, thereby strengthening the doctor–patient bond, rather than disrupting it. For instance, they can analyse various treatment options so that the doctor can discuss them with the patient by disclosing benefits as well as risks [ 50 84 Scientists are pushing the boundaries even further. In the future, tools already tested successfully in the commercial sector—capable of recognizing customers’ emotions through facial expressions as well as patterns of speech and writing—may find application in healthcare, with the aim of delivering increasingly personalized services [ 85 86 87 The potential inversion of the means–ends ratio with regard to the dimension of technique in medicine could result in a negative shift in the doctor–patient relationship. If the doctor comes to be viewed as a mere processor of data, rather than a provider of care, and the patient is reduced to a piece of statistics, rather than a person, the medical decision ultimately risks losing its dialogical value, because AI offers optimal solutions based on big data, thereby reducing the margin for personalization. It is imperative to acknowledge the distinction between physicians and technicians and to emphasize that such figures will never be interchangeable. This distinction is further compounded by the imperative that physicians should not be subject to the directives of robots or AI technologies. The doctor–patient relationship and alliance should be strengthened, not weakened; yet, as the literature indicates, AI entails not only benefits but also risks across every dimension of the physician–patient relationship ( Table 2 4. Discussion The potential for improvement through the implementation of AI in healthcare is undeniable. For instance, telemedicine-based monitoring has shown a high degree of reliability and significant benefits for patients with serious conditions of diverse nature [ 89 90 91 92 93 94 48 50 57 95 96 In order to verify the validity of any AI-based decision, clinicians must undertake an evaluation of the same instrumental tests and clinical data that have previously been analysed by the artificial intelligence. That is to say, in order to check the correctness of the diagnosis and therapy, or any other contribution offered by the AI, the clinician must also make the diagnosis and decide on the therapy. The use of generative AI for diagnosis and therapeutic decisions seems to further complicate medical practice and student training, as medical curricula should place greater importance on AI literacy to enhance patients’ understanding of the tools used by doctors, thereby fostering a trust-based relationship [ 69 The process of doctor–patient communication is more than the mere conveying of information; rather, it is a relational and interpretative endeavour that is built on trust, empathy, and mutual understanding. The integration of AI has the potential to affect such a delicate balance in several ways, leading to increased opacity and asymmetry in communication, especially if not all participants can access the same information and have the same level of understanding [ 97 98 The aforementioned recommendations issued by WHO, UNESCO, and WMA, despite their authority, have not been uniformly implemented at the global level, as reflected in Table 3 In Europe, the General Data Protection Regulation (GDPR) requires that data collection be limited to what is strictly necessary (data minimization), that it be used only in proportion to the stated purposes (proportionality), and that it be processed within a framework of responsibility and traceability (accountability), which entails obligations to document how and why such data are used. With specific regard to artificial intelligence, Article 22 of the GDPR establishes the right not to be subject to decisions based solely on automated processing [ 99 Moreover, European Regulation 2024/1689 (the AI Act), Articles 14–15, classifies health-related systems as “high-risk,” thereby imposing requirements of technical robustness, transparency, explainability (the capacity to provide understandable reasons for algorithmic decisions), and human oversight, precisely to ensure that both patients and physicians retain ultimate control over algorithm-driven decisions [ 100 Equally significant is Regulation 2017/745, Annex I, Section 23, which requires manufacturers of medical software to provide clear instructions to healthcare professionals, thereby enabling them to supply patients with adequate information regarding the artificial intelligence tools employed [ 101 A completely different approach has been adopted by China. The Personal Information Protection Law, under Article 13, regulates the use of sensitive personal data, including health data, establishing consent as its legal basis. However, the law does not lay out exactly what kind of information must be provided to the patient: it is not mandatory to explain in detail how the algorithm functions; a general notice on the use of technological tools in the processing of personal data is considered sufficient. Moreover, Article 13 states that consent is not required in various circumstances, including when the use of personal data is necessary for the fulfilment of state duties or obligations, to respond to public health emergencies, or to safeguard the life, health, or property security of a natural person [ 102 The 2022 Guidelines of the National Medical Products Administration (NMPA) on AI-based medical devices address technical requirements, clinical validation, and data quality. The document focuses primarily on the relationship between the manufacturer and the public authority, rather than on patient–physician communication [ 103 104 An intermediate model is represented by the United States, where no federal regulatory framework exists, unlike in Europe and China. In the United States as well, the applicable regulations stipulate that artificial intelligence may support—but never replace—the physician’s decision-making role [ 105 However, patients in the United States are not granted the right to demand human review of an algorithmic decision, as is provided under the European AI Act. This does not preclude, on the one hand, the patient’s ability to refuse a treatment proposed on the basis of an algorithm, and, on the other hand, the possibility that, where a diagnosis or therapy has been determined through artificial intelligence, withholding such information from the patient may constitute a breach of the physician’s duty of disclosure and thus give rise to liability for damages [ 106 According to the American Medical Association (one of the most prominent standard-bearers in clinical practice), the obligation to inform patients about the use of artificial intelligence is directly proportional to the level of risk that such technology may pose to patient safety [ 107 108 109 110 111 112 113 109 111 112 113 114 healthcare-13-02340-t003_Table 3 Table 3 Regulatory comparison between the European Union, China, and the United States. Dimension European Union China United States Main Regulatory Sources  - GDPR 2016/679 [ 99 - AI Act 2024/1689 [ 100 - Regulation 2017/745 [ 101  - Personal Information Protection Law (PIPL, 2021) [ 102 - NMPA Guidelines (2022) [ 103  - FDA, Clinical Decision Support Guidance (2022) [ 105 - FDA, AI/ML SaMD Action Plan (2021) [ 106 - Absence of a unified federal framework AI–Physician Relationship AI is not a substitute for human healthcare professionals, but it is to be viewed as an auxiliary tool AI is not a substitute for human healthcare professionals but rather serves as an auxiliary tool AI cannot replace human healthcare professionals but serves as an auxiliary tool Transparency toward Patients  - Obligation to inform patients when AI affects diagnosis or therapy - Explainability - Right to be informed of limitations and margins of error  - No obligation to disclose the use of AI or to explain the functioning of the algorithm  - AMA (2024) [ 107 Right to Contest Algorithmic Decisions  - Right to human intervention and to refuse automated decisions (Art. 22 GDPR)  - Not provided  - Not recognized as a right visàvis the physician, although the latter may be held liable for failing to disclose the use of AI Conception of the Physician–Patient Relationship  - Safeguardoriented model: primacy of patient autonomy  - Collectivist model: trust placed in the physician/institution; limited informed consent - Centrality of state and technical control  - Intermediate model: autonomy safeguarded through informed consent and physician’s legal responsibility 5. Conclusions Future changes in the medical profession and in the doctor–patient relationship will depend on what types of artificial intelligence make their way into clinical practice. As mentioned earlier, if AI replaces doctors in bureaucratic and repetitive tasks, they will have more time for their patients and for the proper management of AI systems. If, instead, in addition to bureaucratic duties, doctors are required to understand how the AI generated a diagnosis or therapy in order to verify its soundness, the doctor–patient relationship could be negatively affected. Alternatively, they could come to rely completely upon AI. However, in this scenario, doctors would lose their professional skills and autonomy. This concern is clearly expressed by the WHO, who state that “[i]f introduction of AI is not effectively managed, physicians could become dissatisfied and even leave medical practice” [ 50 Certainly, as technology evolves, it is safe to say that AI and machine learning are still very far from thoroughly fulfilling their potential, whose boundaries are not even definable right now. In fact, as research in quantum computing advances, it leads to the emergence of quantum machine learning, which represents the intersection of quantum computing and artificial intelligence. This confluence promises to solve computational problems that are currently beyond the reach of even the most powerful “conventional” systems available today. The potential of this development is enormous and is likely to pave the way for increasingly powerful and far-reaching applications [ 115 116 However, based on the analysis herein outlined, such changes will arguably have a positive impact, provided that the medical profession should maintain its current conception of artificial intelligence as a valuable asset in daily clinical practice, overseen by qualified and adequately trained healthcare professionals. This approach should be deemed essential to ensure the preservation of the doctor–patient relationship. The role of AI in healthcare should never be viewed as a surrogate or replacement for medical professionals. Instead, it should be considered a powerful means to the ultimate end of enhancing diagnostic accuracy, optimizing clinical processes, and freeing up time for what is indeed irreplaceable and non-negotiable: the human relationship with the patient. As Hans Jonas reminds us, technology must be responsible, and its application in medicine has to reinforce, rather than undermine, the ethics of care [ 98 Disclaimer/Publisher’s Note: Author Contributions Conceptualization, G.M.V. and S.M.; methodology, G.M.V., L.L.C., P.R. and S.Z.; investigation, S.M., L.B. and P.R.; writing—original draft preparation, G.M.V., L.B., S.M., P.R. and S.Z.; writing—review and editing, L.L.C. and M.G.; supervision, P.F., S.Z. and V.T. All authors have read and agreed to the published version of the manuscript. Institutional Review Board Statement Not applicable. Informed Consent Statement Not applicable. Conflicts of Interest The authors declare no conflicts of interest. Abbreviations The following abbreviations are used in this manuscript: AI artificial intelligence WHO World Health Organization WMA World Medical Association UNESCO United Nations Educational, Social, and Cultural Organization CDBIO Council of Europe’s Steering Committee for Human Rights in the fields of Biomedicine and Health References 1. Kaul V. Enslin S. Gross S.A. History of artificial intelligence in medicine Gastrointest. Endosc. 2020 92 807 812 10.1016/j.gie.2020.06.040 32565184 2. The European Parliament and the Council of the European Union Regulation (EU) 2024/1689 of the European Parliament and of the Council of 13 June 2024 Off. J. Eur. Union 2024 Available online: https://eur-lex.europa.eu/eli/reg/2024/1689/oj (accessed on 24 April 2025) 3. Mahesh B. Machine Learning Algorithms—A Review Int. J. Sci. Res. 2020 9 381 386 10.21275/ART20203995 4. Hamet P. Tremblay J. Artificial Intelligence in Medicine Metabolism 2017 69S S36 S40 10.1016/j.metabol.2017.01.011 28126242 5. Kulkarni S. Seneviratne N. Baig M.S. Khan A.H.A. Artificial Intelligence in Medicine: Where Are We Now? Acad. Radiol. 2020 27 62 70 10.1016/j.acra.2019.10.001 31636002 6. Italian National Bioethics Committee and Italian National Committee for Biosafety, Biotechnologies and Life Sciences Joint Opinion on Artificial Intelligence and Medicine: Ethical Aspects Available online: https://bioetica.governo.it/en/opinions/joint-opinions-icbicbbsl/artificial-intelligence-and-medicine-some-ethical-aspects/ (accessed on 25 April 2025) 7. Naylor C.D. On the prospects for a (deep) learning health care system JAMA 2018 320 1099 1100 10.1001/jama.2018.11103 30178068 8. Xiang F. Li Z. Jiang S. Li C. Li S. Gao T. He K. Chen J. Zhang J. Zhang J. Multimodal Masked Autoencoder Based on Adaptive Masking for Vitiligo Stage Classification J. Imaging Inform. Med. 2025 10.1007/s10278-025-01521-7 40301294 9. Wang X. Peng Y. Lu L. Lu Z. Bagheri M. Summers R.M. Chest X-ray: Hospital-scale chest X-ray database and benchmarks on weakly supervised classification and localization of common thorax diseases Deep Learning and Convolutional Neural Networks for Medical Imaging and Clinical Informatics Lu L. Wang X. Carneiro G. Yang L. Springer Cham, Switzerland 2019 369 392 10. Vidal-Perez R. Vazquez-Rodriguez J.M. Role of artificial intelligence in cardiology World J. Cardiol. 2023 15 116 118 10.4330/wjc.v15.i4.116 37124979 PMC10130891 11. Itchhaporia D. Artificial intelligence in cardiology Trends Cardiovasc. Med. 2022 32 34 41 10.1016/j.tcm.2020.11.007 33242635 12. Sangaiah A.K. Arumugam M. Bian G.-B. An intelligent learning approach for improving ECG signal classification and arrhythmia analysis Artif. Intell. Med. 2020 103 101788 10.1016/j.artmed.2019.101788 32143795 13. Hillis J.M. Bizzo B.C. Use of Artificial Intelligence in Clinical Neurology Semin. Neurol. 2022 42 39 47 10.1055/s-0041-1742180 35576929 14. Cerasa A. Crowe B. Generative artificial intelligence in neurology: Opportunities and risks Eur. J. Neurol. 2024 31 e16232 10.1111/ene.16232 38328960 PMC11235660 15. Bhinder B. Gilvary C. Madhukar N.S. Elemento O. Artificial Intelligence in Cancer Research and Precision Medicine Cancer Discov. 2021 11 900 915 10.1158/2159-8290.CD-21-0090 33811123 PMC8034385 16. Chen Z.H. Lin L. Wu C.F. Li C.F. Xu R.H. Sun Y. Artificial intelligence for assisting cancer diagnosis and treatment in the era of precision medicine Cancer Commun. 2021 41 1100 1115 10.1002/cac2.12215 PMC8626610 34613667 17. Hosny A. Parmar C. Quackenbush J. Schwartz L.H. Aerts H.J.W.L. Artificial intelligence in radiology Nat. Rev. Cancer 2018 18 500 510 10.1038/s41568-018-0016-5 29777175 PMC6268174 18. Li G. Wu X. Ma X. Artificial intelligence in radiotherapy Semin. Cancer Biol. 2022 86 160 171 10.1016/j.semcancer.2022.08.005 35998809 19. Siddique S. Chow J.C.L. Artificial intelligence in radiotherapy Rep. Pract. Oncol. Radiother. 2020 25 656 666 10.1016/j.rpor.2020.03.015 32617080 PMC7321818 20. Rottier J.B. Artificial intelligence: Reinforcing the place of humans in our healthcare system Rev. Prat. 2018 68 1150 1151 30869231 21. Uche-Anya E. Anyane-Yeboa A. Berzin T.M. Ghassemi M. May F.P. Artificial intelligence in gastroenterology and hepatology: How to advance clinical practice while ensuring health equity Gut 2022 71 1909 1915 10.1136/gutjnl-2021-326271 35688612 PMC10323754 22. Kröner P.T. Engels M.M. Glicksberg B.S. Johnson K.W. Mzaik O. van Hooft J.E. Wallace M.B. El-Serag H.B. Krittanawong C. Artificial intelligence in gastroenterology: A state-of-the-art review World J. Gastroenterol. 2021 27 6794 6824 10.3748/wjg.v27.i40.6794 34790008 PMC8567482 23. Akazawa M. Hashimoto K. Artificial intelligence in gynecologic cancers: Current status and future challenges—A systematic review Artif. Intell. Med. 2021 120 102164 10.1016/j.artmed.2021.102164 34629152 24. Jiang Y. Wang C. Zhou S. Artificial intelligence-based risk stratification, accurate diagnosis and treatment prediction in gynecologic oncology Semin. Cancer Biol. 2023 96 82 99 10.1016/j.semcancer.2023.09.005 37783319 25. Mundinger A. Mundinger C. Artificial Intelligence in Senology—Where Do We Stand and What Are the Future Horizons? Eur. J. Breast Health 2024 20 73 80 10.4274/ejbh.galenos.2024.2023-12-13 38571686 PMC10985572 26. Bassi E. Russo A. Oliboni E. Zamboni F. De Santis C. Mansueto G. Montemezzi S. Foti G. The role of an artificial intelligence software in clinical senology: A mammography multi-reader study Radiol. Med. 2024 129 202 210 10.1007/s11547-023-01751-1 38082194 27. Radakovich N. Artificial Intelligence in Hematology: Current Challenges and Opportunities Curr. Hematol. Malig. Rep. 2020 15 203 210 10.1007/s11899-020-00575-4 32239350 28. Peiffer-Smadja N. Machine learning for clinical decision support in infectious diseases: A narrative review of current applications Clin. Microbiol. Infect. 2020 26 584 595 10.1016/j.cmi.2019.09.009 31539636 29. Valizadeh A. Moassefi M. Nakhostin-Ansari A. Heidari Some’eh S. Hosseini-Asl H. Saghab Torbati M. Aghajani R. Maleki Ghorbani Z. Menbari-Oskouie I. Aghajani F. Automated diagnosis of autism with artificial intelligence: State of the art Rev. Neurosci. 2023 35 141 163 10.1515/revneuro-2023-0050 37678819 30. Dufour M.M. Lanovaz M.J. Cardinal P. Artificial intelligence for the measurement of vocal stereotypy J. Exp. Anal. Behav. 2020 114 368 380 10.1002/jeab.636 33145781 PMC7756764 31. Liu R. Salisbury J.P. Vahabzadeh A. Sahin N.T. Feasibility of an Autism-Focused Augmented Reality Smartglasses System for Social Communication and Behavioral Coaching Front. Pediatr. 2017 5 145 10.3389/fped.2017.00145 28695116 PMC5483849 32. Ferrara R. Iovino L. Di Renzo M. Ricci P. Babies under 1 year with atypical development: Perspectives for preventive individuation and treatment Front. Psychol. 2022 13 1016886 10.3389/fpsyg.2022.1016886 36467138 PMC9713249 33. Ferrara R. Ricci P. Damato F.M. Iovino L. Ricci L. Cicinelli G. Simeoli R. Keller R. Pregnancy in autistic women and social medical considerations: Scoping review and meta-synthesis Front. Psychiatry 2023 14 1222127 10.3389/fpsyt.2023.1222127 37965368 PMC10641492 34. Ferrara R. Damato F. Iovino L. Marti F. Latina R. Colombi C. Ricci P. ESDM intervention in severe preschool autism: An Italian Case report, psychological and social medicine reflections Ital. J. Pediatr. 2024 50 60 10.1186/s13052-024-01626-9 38575971 PMC10993588 35. Ferrara R. Ansermet F. Massoni F. Petrone L. Onofri E. Ricci P. Archer T. Ricci S. Autism Spectrum Disorder and intact executive functioning Clin. Ter. 2016 167 e96 e101 27845486 10.7417/CT.2016.1951 36. Troili G.M. Businaro R. Massoni F. Ricci L. Petrone L. Ricci P. Ricci S. Investigation on a group of autism children: Risk factors and medical social considerations Clin. Ter. 2013 164 (Suppl. S5) e273 e278 10.7417/ct.2013.1587 24045522 37. Nagy M. Sisk B. How will artificial intelligence affect patient-clinician relationships? AMA J. Ethics 2020 22 E395 E400 10.1001/amajethics.2020.395 32449655 38. Wu Q. Jin Z. Wang P. The relationship between the physician-patient relationship, physician empathy, and patient trust J. Gen. Intern. Med. 2022 37 1388 1393 10.1007/s11606-021-07008-9 34405348 PMC9086002 39. Ardenghi S. Russo S. Rampoldi G. Bani M. Strepparava M.G. Medical students’ attitude toward patient-centeredness: A longitudinal study Patient Educ. Couns. 2024 118 108003 10.1016/j.pec.2023.108003 37820544 40. Poalelungi D.G. Musat C.L. Fulga A. Neagu M. Neagu A.I. Piraianu A.I. Fulga I. Advancing Patient Care: How Artificial Intelligence Is Transforming Healthcare J. Pers. Med. 2023 13 1214 10.3390/jpm13081214 37623465 PMC10455458 41. Akingbola A. Adeleke O. Idris A. Adewole O. Adegbesan A. Artificial intelligence and the dehumanization of patient care J. Med. Surg. Public Health 2024 3 100138 10.1016/j.glmedi.2024.100138 42. Mennella C. Maniscalco U. De Pietro G. Esposito M. Ethical and regulatory challenges of AI technologies in healthcare: A narrative review Heliyon 2024 10 e26297 10.1016/j.heliyon.2024.e26297 38384518 PMC10879008 43. Dankwa-Mullan I. Health Equity and Ethical Considerations in Using Artificial Intelligence in Public Health and Medicine Prev. Cronic Dis. 2024 21 E64 10.5888/pcd21.240245 PMC11364282 39173183 44. Ratti E. Morrison M. Ethical and social considerations of applying artificial intelligence in healthcare—A two-pronged scoping review BMC Med. Ethics 2025 26 68 10.1186/s12910-025-01198-1 40420080 PMC12107984 45. Elendu C. Amaechi D.C. Elendu T.C. Jingwa K.A. Okoye O.K. Okah M.J. Ladele J.A. Farah A.H. Alimi H.A. Ethical implications of AI and robotics in healthcare: A review Medicine 2023 102 e36671 10.1097/MD.0000000000036671 38115340 PMC10727550 46. Chinta S.V. Wang Z. Palikhe A. Zhang X. Kashif A. Smith M.A. Liu J. Zhang W. AI-driven healthcare: A review on ensuring fairness and mitigating bias PLoS Digit. Health 2025 4 e0000864 10.1371/journal.pdig.0000864 40392801 PMC12091740 47. Weiner E.B. Dankwa-Mullan I. Nelson W.A. Hassanpour S. Ethical challenges and evolving strategies in the integration of artificial intelligence into clinical practice PLoS Digit. Health 2025 4 e0000810 10.1371/journal.pdig.0000810 40198594 PMC11977975 48. UNESCO Recommendation on the Ethics of Artificial Intelligence. Paris, France, 23 November 2021 Available online: https://www.unesco.org/en/articles/recommendation-ethics-artificial-intelligence (accessed on 13 February 2025) 49. Woopen C. Ethical principles and democratic prerequisites for shaping robotics and artificial intelligence Humans, Machines and Health: Proceedings of the XXV General Assembly of Members: Vatican City, Vatican, 25–27 February 2019 Paglia V. Pegoraro R. Pontifical Academy for Life Vatican City, Vatican 2019 217 50. World Health Organization (WHO) Ethics and Governance of Artificial Intelligence for Health WHO Geneva, Switzerland 2021 Available online: https://iris.who.int/bitstream/handle/10665/341996/9789240029200-eng.pdf (accessed on 14 February 2025) 51. Aquinas T. Summa Theologica, Fathers of the English Dominican Province, Trans University of Notre Dame Press Notre Dame, IN, USA 1981 Volume 1 52. Lysdahl K.B. Oortwijn W. van der Wilt G.J. Refolo P. Sacchini D. Mozygemba K. Gerhardus A. Brereton L. Hofmann B. Ethical analysis in HTA of complex health interventions BMC Med. Ethics 2016 17 16 10.1186/s12910-016-0099-z 27004792 PMC4804607 53. Prakash S. Balaji J.N. Joshi A. Surapaneni K.M. Ethical Conundrums in the Application of Artificial Intelligence (AI) in Healthcare—A Scoping Review of Reviews J. Pers. Med. 2022 12 1914 10.3390/jpm12111914 36422090 PMC9698424 54. Hildt E. What Is the Role of Explainability in Medical Artificial Intelligence? A Case-Based Approach Bioengineering 2025 12 375 10.3390/bioengineering12040375 40281735 PMC12025101 55. McDougall R.J. Computer knows best? The need for value-flexibility in medical AI J. Med. Ethics 2019 45 156 160 10.1136/medethics-2018-105118 30467198 56. Nicholas N. Sotiris S. Understanding confidentiality and the law on access to medical records Obstet. Gynaecol. Reprod. Med. 2010 20 161 163 10.1016/j.ogrm.2010.02.005 57. Mittelstadt B. The Impact of Artificial Intelligence on the Doctor-Patient Relationship Council of Europe Strasbourg, France 2021 Available online: https://rm.coe.int/inf-2022-5-report-impact-of-ai-on-doctor-patient-relations-e/1680a68859 (accessed on 26 February 2025) 58. Dwork C. Differential privacy Automata, Languages and Programming Bugliesi M. Preneel B. Sasson V. Wegener I. Springer Berlin, Germany 2006 1 12 59. Ohm P. Broken promises of privacy: Responding to the surprising failure of anonymization UCLA Law Rev. 2010 57 1701 1777 60. Chen Y. Stavropoulou C. Narasinkan R. Baker A. Scarbrough H. Professionals’ responses to the introduction of AI innovations in radiology and their implications for future adoption: A qualitative study BMC Health Serv. Res. 2021 21 813 10.1186/s12913-021-06861-y 34389014 PMC8364018 61. Arnold M. Teasing out AI in medicine: An ethical critique of AI and machine learning in medicine J. Bioethical Inq. 2021 18 121 139 10.1007/s11673-020-10080-1 PMC7790358 33415596 62. Coeckelbergh M. E-care as craftsmanship: Virtuous work, skilled engagement, and information technology in health care Med. Health Care Philos. 2013 16 807 816 10.1007/s11019-013-9463-7 23338289 63. Lorenzini g. Arbelaez Ossa l. Shaw D.M. Elger B.S. Artificial intelligence and the doctor–patient relationship expanding the paradigm of shared decision making Bioethics 2023 37 424 429 10.1111/bioe.13158 36964989 64. Rajpurkar P. Chen E. Banerjee O. Topol E.J. AI in health and medicine Nat. Med. 2022 28 31 38 10.1038/s41591-021-01614-0 35058619 65. Wang D. Wang L. Zhang Z. Wang D. Zhu H. Gao Y. Fan X. Tian F. “Brilliant AI doctor” in rural China: Tensions and challenges in AI-powered CDSS deployment Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems Yokohama, Japan 8–13 May 2021 1 18 10.1145/3411764.3445432 66. Shortliffe E.H. Sepúlveda M.J. Clinical decision support in the era of artificial intelligence JAMA 2018 320 2199 2200 10.1001/jama.2018.17163 30398550 67. Cohen I.G. Graver H. A doctor’s touch: What big data in health care can teach us about predictive policing J. Law Med. Ethics 2019 47 (Suppl. S2) 91 98 10.2139/ssrn.3432095 68. Bauer K. Cybermedicine and the moral integrity of the physician–patient relationship Ethics Inf. Technol. 2004 6 83 91 10.1007/s10676-004-4591-7 69. Sauerbrei A. Kerasidou A. Lucivero F. Hallowell N. The impact of artificial intelligence on the person-centred, doctor-patient relationship: Some problems and solutions BMC Med. Inform. Decis. Mak. 2023 23 73 10.1186/s12911-023-02162-y 37081503 PMC10116477 70. Salmon C. Bell K. Reyes E. Ireland E. Danek R. An analysis of telehealth in a post-pandemic rural, Midwestern community: Increased comfort and a preference for primary care BMC Health Serv. Res. 2025 25 270 10.1186/s12913-025-12413-5 39966908 PMC11837642 71. Pairon A. Philips H. Verhoeven V. A scoping review on the use and usefulness of online symptom checkers and triage systems: How to proceed? Front. Med. 2023 9 1040926 10.3389/fmed.2022.1040926 PMC9853165 36687416 72. Wanderås M.R. Abildsnes E. Thygesen E. Martinez S.G. Video consultation in general practice: A scoping review on use, experiences, and clinical decisions BMC Health Serv. Res. 2023 23 316 10.1186/s12913-023-09309-7 36997997 PMC10063329 73. Payne R. Clarke A. Swann N. van Dael J. Brenman N. Rosen R. Mackridge A. Moore L. Kalin A. Ladds E. Patient safety in remote primary care encounters: Multimethod qualitative study combining Safety I and Safety II analysis BMJ Qual. Saf. 2024 33 573 586 10.1136/bmjqs-2023-016674 38050161 PMC11347200 74. Różyńska J. Taking the principle of the primacy of the human being seriously Med. Health Care Philos. 2021 24 547 562 10.1007/s11019-021-10043-2 34318429 PMC8557179 75. Hofmann B. The death of dignity is greatly exaggerated: Reflections 15 years after the declaration of dignity as a useless concept Bioethics 2020 34 602 611 10.1111/bioe.12752 32483841 76. World Medical Association WMA Statement on Augmented Intelligence in Medical Care. October 2019 Available online: https://www.wma.net/policies-post/wma-statement-on-augmented-intelligence-in-medical-care/ (accessed on 28 August 2025) 77. Hryciw B.N. Fortin Z. Ghossein J. Kyeremanteng K. Doctor-patient interactions in the age of AI: Navigating innovation and expertise Front. Med. 2023 10 1241508 10.3389/fmed.2023.1241508 PMC10498385 37711734 78. Bresnick J. EHR Users Want Their Time Back, and Artificial Intelligence Can Help. HealthITAnalytics, 2018 Available online: https://healthitanalytics.com/news/ehr-users-want-their-time-back-and-artificial-intelligence-can-help (accessed on 15 March 2025) 79. Scaffardi L. La medicina alla prova dell’intelligenza artificiale DPCE Online 2022 1 349 359 80. Aminololama-Shakeri S. López J.E. The doctor-patient relationship with artificial intelligence Am. J. Roentgenol. 2019 212 308 310 10.2214/AJR.18.20509 30540210 81. Sung J.J.Y. Savulescu J. Ngiam K.Y. An B. Ang T.L. Yeoh K.G. Cham T.J. Tsao S. Chua T.S. Artificial intelligence for gastroenterology: Singapore artificial intelligence for Gastroenterology Working Group Position Statement J. Gastroenterol. Hepatol. 2023 38 1669 1676 10.1111/jgh.16241 37277693 82. Hung A.J. Chen A.B. Cacciamani G.E. Gill I.S. Artificial intelligence will (may) make doctors expendable (in good ways): Pro Eur. Urol. Focus 2021 7 683 684 10.1016/j.euf.2021.03.011 33771475 83. Kingsford P.A. Ambrose J.A. Artificial intelligence and the doctor-patient relationship Am. J. Med. 2024 137 381 382 10.1016/j.amjmed.2024.01.005 38281657 84. Geantă M. Bădescu D. Chirca N. Nechita O.C. Radu C.G. Rascu S. Rădăvoi D. Sima C. Toma C. Jinga V. The Potential Impact of Large Language Models on Doctor-Patient Communication: A Case Study in Prostate Cancer Healthcare 2024 12 1548 10.3390/healthcare12151548 39120251 PMC11311818 85. Zhu C. Research on Emotion Recognition-Based Smart Assistant System: Emotional Intelligence and Personalized Services J. Syst. Manag. Sci. 2023 13 227 242 10.33168/jsms.2023.0515 86. Finkenberg J. NASS 2023 presidential address: Artificial intelligence and its effect on the art of medicine and the physician-patient relationship Spine J. 2024 24 191 194 10.1016/j.spinee.2023.11.001 37944759 87. Liu X. Keane P.A. Denniston A.K. Time to regenerate: The doctor in the age of artificial intelligence J. R. Soc. Med. 2018 111 113 116 10.1177/0141076818762648 29648509 PMC5900836 88. Ratkevičiūtė K. Aliukonis V. Exploring Opportunities and Challenges of AI in Primary Healthcare: A Qualitative Study with Family Doctors in Lithuania Healthcare 2025 13 1429 10.3390/healthcare13121429 40565456 PMC12193594 89. Marinelli S. Basile G. Zaami S. Telemedicine, Telepsychiatry and COVID-19 Pandemic: Future Prospects for Global Health Healthcare 2022 10 2085 10.3390/healthcare10102085 36292533 PMC9602461 90. Bellini V. Valente M. Gaddi A.V. Pelosi P. Bignami E. Artificial Intelligence and Telemedicine in Anesthesia: Potential and Problems Minerva Anestesiol. 2022 88 729 734 10.23736/S0375-9393.21.16241-8 35164492 91. Basile G. Accetta R. Marinelli S. D’Ambrosi R. Petrucci Q.A. Giorgetti A. Nuara A. Zaami S. Fozzato S. Traumatology: Adoption of the Sm@rtEven Application for the Remote Evaluation of Patients and Possible Medico-Legal Implications J. Clin. Med. 2022 11 3644 10.3390/jcm11133644 35806929 PMC9267866 92. Braun M. Hummel P. Beck S. Dabrock P. Primer on an ethics of AI-based decision support systems in the clinic J. Med. Ethics 2021 47 e3 10.1136/medethics-2019-105860 PMC8639945 32245804 93. Taddeo M. Floridi L. How AI can be a force for good Science 2018 361 751 752 10.1126/science.aat5991 30139858 94. Garza-Herrera R. Humans use tools: From handcrafted tools to artificial intelligence J. Vasc. Surg. Venous Lymphat. Disord. 2024 12 101705 10.1016/j.jvsv.2023.101705 37956905 PMC11523427 95. Čartolovni A. Malešević A. Poslon L. Critical analysis of the AI impact on the patient-physician relationship: A multi-stakeholder qualitative study Digit. Health 2023 9 20552076231220833 10.1177/20552076231220833 38130798 PMC10734361 96. Geis J.R. Brady A.P. Wu C.C. Spencer J. Ranschaert E. Jaremko J.L. Langer S.G. Kitts A.B. Birch J. Shields W.F. Ethics of Artificial Intelligence in Radiology: Summary of the Joint European and North American Multisociety Statement J. Am. Coll. Radiol. 2019 16 1516 1521 10.1016/j.jacr.2019.07.028 31585696 97. Habermas J. Moral Consciousness and Communicative Action Polity Press Cambridge, UK 1992 98. Jonas H. The Imperative of Responsibility: In Search of An Ethics for the Technological Age University of Chicago Press Chicago, IL, USA 1984 21 194 21–26, 141–153, 130–194 99. European Parliament & Council Regulation (EU) 2016/679 of the European Parliament and of the Council of 27 April 2016 on the Protection of Natural Persons with Regard to the Processing of Personal Data and on the Free Movement of Such Data (General Data Protection Regulation, GDPR) Off. J. Eur. Union 2016 L119 1 88 Available online: https://gdpr-info.eu (accessed on 26 August 2025) 100. European Parliament & Council Regulation (EU) 2024/1689 of the European Parliament and of the Council of 13 June 2024 Laying Down Harmonised Rules on Artificial Intelligence (Artificial Intelligence Act) Off. J. Eur. Union 2024 1 152 Available online: https://eur-lex.europa.eu (accessed on 26 August 2025) 101. European Parliament & Council Regulation (EU) 2017/745 of the European Parliament and of the Council of 5 April 2017 on Medical Devices, Amending Directive 2001/83/EC, Regulation (EC) No 178/2002 and Regulation (EC) No 1223/2009 and Repealing Council Directives 90/385/EEC and 93/42/EEC Available online: https://eur-lex.europa.eu/legal-content/EN/TXT/PDF/?uri=CELEX:32017R0745 (accessed on 27 August 2025) 102. China Personal Information Protection Law, 20 August 2021 Available online: https://personalinformationprotectionlaw.com/ (accessed on 1 September 2025) 103. Han Y. Ceross A. Bergmann J. Regulatory Frameworks for AI-Enabled Medical Device Software in China: Comparative Analysis and Review of Implications for Global Manufacturer JMIR AI 2024 3 e46871 10.2196/46871 39073860 PMC11319888 104. Sun S. Research on the Application of Artificial Intelligence in Medical Field from the Perspective of Behavioral Law Beijing Law Rev. 2024 15 899 920 10.4236/blr.2024.152055 105. Food and Drug Administration Clinical Decision Support Software. Guidance for Industry and Food and Drug Administration Staff, 28 September 2022 Available online: https://www.fda.gov/media/109618/download?utm_source=chatgpt.com (accessed on 3 September 2025) 106. Food and Drug Administration, Artificial Intelligence/Machine Learning (AI/ML)-Based Software as a Medical Device (SaMD) Action Plan, January 2021 Available online: https://www.fda.gov/media/145022/download?utm_source=chatgpt.com (accessed on 3 September 2025) 107. AMA, Augmented Intelligence Development, Deployment, and Use in Health Care, November 2024; p. 16 Available online: https://www.ama-assn.org/system/files/ama-ai-principles.pdf?utm_source=chatgpt.com (accessed on 1 September 2025) 108. Zaami S. Melcarne R. Patrone R. Gullo G. Negro F. Napoletano G. Monti M. Aceti V. Panarese A. Borcea M.C. Oncofertility and Reproductive Counseling in Patients with Breast Cancer: A Retrospective Study J. Clin. Med. 2022 11 1311 10.3390/jcm11051311 35268402 PMC8911138 109. Zampatti S. Peconi C. Megalizzi D. Calvino G. Trastulli G. Cascella R. Strafella C. Caltagirone C. Giardina E. Innovations in Medicine: Exploring ChatGPT’s Impact on Rare Disorder Management Genes 2024 15 421 10.3390/genes15040421 38674356 PMC11050022 110. Gulìa C. Signore F. Gaffi M. Gigli S. Votino R. Nucciotti R. Bertacca L. Zaami S. Baffa A. Santini E. Y RNA: An Overview of Their Role as Potential Biomarkers and Molecular Targets in Human Cancers Cancers 2020 12 1238 10.3390/cancers12051238 32423154 PMC7281143 111. Meekins-Doherty L. Dive L. McEwen A. Sexton A. Generative AI and the Profession of Genetic Counseling J. Genet. Couns. 2025 34 e2009 10.1002/jgc4.2009 40110624 112. Piergentili R. Del Rio A. Signore F. Umani Ronchi F. Marinelli E. Zaami S. CRISPR-Cas and Its Wide-Ranging Applications: From Human Genome Editing to Environmental Implications, Technical Limitations, Hazards and Bioethical Issues Cells 2021 10 969 10.3390/cells10050969 33919194 PMC8143109 113. Johnson K.B. Wei W.-Q. Weeraratne D. Frisse M.E. Misulis K. Rhee K. Zhao J. Snowdon J.L. Precision Medicine, AI, and the Future of Personalized Health Care Clin. Transl. Sci. 2021 14 86 93 10.1111/cts.12884 32961010 PMC7877825 114. Mello M.M. Char D. Xu S.H. Ethical Obligations to Inform Patients About Use of AI Tools JAMA 2025 334 767 770 10.1001/jama.2025.11417 40690211 115. Devadas R.M. Sowmya T. Quantum Machine Learning: A Comprehensive Review of Integrating AI with Quantum Computing for Computational Advancements MethodsX 2025 14 103318 10.1016/j.mex.2025.103318 40331033 PMC12053761 116. Durant T.J.S. Knight E. Nelson B. Dudgeon S. Lee S.J. Walliman D. Young H.P. Ohno-Machado L. Schulz W.L. A Primer for Quantum Computing and Its Applications to Healthcare and Biomedical Research J. Am. Med. Inform. Assoc. 2024 31 1774 1784 10.1093/jamia/ocae149 38934288 PMC11258415 healthcare-13-02340-t001_Table 1 Table 1 Main applications of artificial intelligence in healthcare and their impact on the therapeutic relationship. AI Application in Healthcare Opportunities Main Ethical Concerns Assisted Diagnostics (radiology, dermatology, digital pathology) Increased diagnostic accuracy; reduction of errors; faster diagnosis Shift of clinical authority from practitioner to algorithm; AI-related errors; de-skilling; challenges to informed consent; opacity of the decision-making process Predictive Medicine and Big Data Analytics Personalized prevention; improvement of care pathways Excessive patient profiling; risk of stigmatization; data confidentiality issues Generative AI (reports, clinical documentation, communication) Faster, more timely drafting of reports and records, resulting in higher efficiency Risk of errors or misleading information; loss of confidentiality Telemedicine and Automated Triage Broader and faster access to care; remote monitoring Reduction of human interaction; exclusion of less digitally literate patients; risk of over-reliance on automated systems Clinical Decision Support Systems (CDSSs) Greater therapeutic precision; lower prescribing errors; fostering tailored, personalized forms of treatment Shift of clinical authority from practitioner to algorithm; AI-related errors; de-skilling; challenges to informed consent; opacity of the decision-making process Surgical and Assistive Robotics Higher surgical precision; reduced invasivity; support in daily care activities Physical and emotional distancing from patients; high costs and inequitable access; de-skilling healthcare-13-02340-t002_Table 2 Table 2 How AI integration impacts different layers of the doctor–patient relationship. Dimension Potential Benefits Ethical Risks and Critical Issues Quality of Care Greater diagnostic and therapeutic accuracy; personalization of treatments; predictive medicine Possible errors due to data bias; opacity of AI systems; AI-related errors; professional de-skilling; programming choices that prioritize interests other than those of patients Accessibility Shorter waiting times; improved continuity of care; possibility of remote follow-up Exclusion of less digitally literate patients; inequities in access due to economic or technological barriers Physician Autonomy Decision-making support; reduction in bureaucratic workload; more time for patient interaction Professional de-skilling; shift of decision-making authority from clinician to AI system Informed Consent and Trust More time available to inform patients Increased complexity of the information process; opacity of AI systems; loss of trust in physicians Equity Potential reduction in disparities through standardization Limited usefulness of AI for minority groups, as algorithms are trained on datasets that do not adequately represent them [ 88 Data Confidentiality Automatic anonymization Use of data without consent; breaches of anonymity ",
  "metadata": {
    "Title of this paper": "A Primer for Quantum Computing and Its Applications to Healthcare and Biomedical Research",
    "Journal it was published in:": "Healthcare",
    "URL": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC12469309/"
  }
}