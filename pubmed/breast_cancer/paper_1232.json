{
  "title": "Paper_1232",
  "abstract": "pmc Cancers (Basel) Cancers (Basel) 2105 cancers cancers Cancers 2072-6694 Multidisciplinary Digital Publishing Institute  (MDPI) PMC12468616 PMC12468616.1 12468616 12468616 41008835 10.3390/cancers17182991 cancers-17-02991 1 Article A Deep Learning Framework for Classification of Neuroendocrine Neoplasm Whole Slide Images https://orcid.org/0000-0003-1063-4261 Hadjifaradji Amir Software Formal analysis Investigation Writing – original draft 1 https://orcid.org/0009-0001-1541-7517 Diaz-Stewart Michael Writing – original draft Writing – review & editing 1 https://orcid.org/0000-0002-1841-3175 Chu Jenny Investigation 2 3 https://orcid.org/0000-0001-8589-4354 Farnell David Investigation 2 4 Schaeffer David Investigation 2 4 Farahani Hossein Supervision Project administration 1 Bashashati Ali Writing – review & editing Supervision Project administration 1 2 * https://orcid.org/0000-0001-8189-2132 Loree Jonathan M. 5 * Mok Samuel C. Academic Editor Jiang Xia Academic Editor 1 ahadjifaradji@gmail.com michael.diaz@ubc.ca h.farahani@ubc.ca 2 jenny.chu@islandhealth.ca david.farnell@vch.ca david.schaeffer@vch.ca 3 4 5 * ali.bashashati@ubc.ca jonathan.loree@bccancer.bc.ca 13 9 2025 9 2025 17 18 497140 2991 13 6 2025 01 9 2025 09 9 2025 13 09 2025 27 09 2025 29 09 2025 © 2025 by the authors. 2025 https://creativecommons.org/licenses/by/4.0/ Licensee MDPI, Basel, Switzerland. This article is an open access article distributed under the terms and conditions of the Creative Commons Attribution (CC BY) license ( https://creativecommons.org/licenses/by/4.0/ Simple Summary Neuroendocrine tumors are uncommon cancers that use grade to guide management. Grading relies on cell counts of the number of cells undergoing mitosis and those staining positive for Ki67. This study developed a machine learning tool to automate grading by analyzing tissue images. The tool showed potential to identify patients with worse outcomes, even when their tumors appeared low grade. This could lead to better-informed treatment decisions. Abstract Background/Objectives Methods Results p n n Conclusions neuroendocrine deep learning grading object detection mitotic figures BC Cancer Foundation Michael Smith Health Professional Investigator Award This work was supported by philanthropic funds from the BC Cancer Foundation. Dr. Loree is supported by a Michael Smith Health Professional Investigator Award. Dr. Bashashati is supported by a Michael Smith Health Scholar Award as well as funding from the Canada Foundation for Innovation and Natural Sciences & Engineering Research Council of Canada. pmc-status-qastatus 0 pmc-status-live yes pmc-status-embargo no pmc-status-released yes pmc-prop-open-access yes pmc-prop-olf no pmc-prop-manuscript no pmc-prop-legally-suppressed no pmc-prop-has-pdf yes pmc-prop-has-supplement no pmc-prop-pdf-only no pmc-prop-suppress-copyright no pmc-prop-is-real-version no pmc-prop-is-scanned-article no pmc-prop-preprint no pmc-prop-in-epmc yes 1. Introduction Neuroendocrine cells are specialized cells dispersed throughout the body. Uncommon neoplasms known as neuroendocrine neoplasms (NENs) may develop in these cells and commonly originate within the gastrointestinal (GI) tract, pancreas, and lungs [ 1 2 3 4 1 5 6 Clinicians utilize two measures for grading as follows: Mitotic count and Ki-67 index (see Table 1 2 1 2 6 7 8 NENs, though relatively rare with an estimated incidence of 3–6 per 100,000 annually, have been increasing in prevalence over the past several decades [ 1 2 3 5 A challenging aspect of clinically assessing NETs is the heterogeneity of tumors. Heterogeneity, in this case, means that within different portions of the tumor, some areas have higher proliferation than others and identifying these hot spots can be difficult. Furthermore, identifying proliferating cells suffers inter- and intra-observer variability. Cells undergoing mitosis can resemble pyknotic nuclei, inflammatory cells, and hyperchromatic cells. The key morphological difference is jagged chromatin edges rather than smooth edges [ 9 10 11 12 Several recent studies have investigated the application of deep learning and digital pathology to the grading or prognostication of NENs, though most have focused on specific aspects such as Ki-67 quantification or imaging-based prediction, rather than offering a comprehensive grading framework. For example, automated analysis of Ki-67 immunohistochemistry on whole slide images has demonstrated strong concordance with manual assessment in pancreatic NENs, with one study reporting a Pearson correlation of 0.968 and 92.4% grade concordance using a commercial image analysis platform [ 13 14 Other related studies have explored broader applications of computational pathology to NENs and other tumor types, including prognostication and molecular subtyping. One study integrated deep learning-based radiomics from CT imaging with pathomic features derived from Ki-67 staining to predict postoperative liver metastasis in pancreatic NENs, achieving high predictive performance (AUC > 0.96) in internal validation [ 15 16 17 There is great potential for digital pathology to aid pathologists by providing areas to focus on, reducing variability, and efficiently processing whole-slide images (WSIs). The current research aims to provide a standardized tool for evaluating NENs, which combats inter- and intra-observer variability, especially in low-volume centers. Through this, we may also alleviate some of the burden experienced in clinical practice and improve management of the disease or increase efficiency [ 18 2. Materials and Methods 2.1. Data Acquisition and Processing The development of our NEN grading framework utilized two datasets. The first phase of development utilized MItosis DOmain Generalization 2022 (MIDOG22) [ 19 Table 2 20 21 For the purpose of training, the internal dataset was split into three cross-validation folds. This led to three cross-validation permutations where in each permutation, two folds are used for training (approx. 66% of the data), and the last fold is split into testing and validation data (approx. 17% of the data each). Folds were stratified by grade to ensure consistent class distribution. Balanced accuracy was used as the target metric to correct for data imbalance. Additionally, class-weighting was applied to ensure equal grade-wise importance during training. We report the average of these three folds. 2.2. Machine Learning-Based Analysis Workflow Figure 1 2.2.1. Tissue Masks As a preprocessing step to our framework, we ran an open-source software, HistoQC (version 2.1) [ 22 2.2.2. Tumor Masks The first step of our pipeline is to identify tumor regions in WSIs, as these are the areas used to assess tumor grade. A total of 80 WSIs were annotated by a pathologist to mark areas that contain a tumor. The 80 WSIs were divided into small patches, and we reduced the problem to patch-based classification to create these tumor segmentations by splitting the WSI into tumor and normal patches. The highest magnification of the digital slides was 40× and, with the 80 annotated WSIs, we extracted 71,659 PNG images (35,570 “Normal” and 36,089 “Tumor”) at the size of 1024 × 1024 pixel and downsampled the images to 512 × 512 pixel, giving patches an effective magnification of 20×. With these images, we proceeded to build a binary tumor-normal classifier with EfficientNet-B3 [ 23 −6 2.2.3. Mitotic Figures Detection Using MIDOG22, we trained a variation in RetinaNet [ 24 25 2.2.4. Ki-67 Detection Many studies for immunopositive cell detection [ 12 26 27 2.2.5. Density Map Generation Density maps of mitotic activity and Ki-67 index were generated for each slide. In H&E slides, we achieve this by quantifying the number of candidate mitotic figures detected by our object detection model for every 512 × 512 pixel patch. We then pass a 2 mm 2 2 2.2.6. Aggregation Modules The small chunks of data used to process a WSI must eventually be aggregated in a manner that represents the slide- or patient-level. In our study, we evaluate three common aggregation techniques: (i) Majority Voting, (ii) Multi-Instance Learning, and (iii) Histogram of Density Maps. If two or more slides from the same patient have different grades, the higher grade is assigned to the patient). (i) Majority Voting. Patches are considered independent from one another and are separately passed through a neural network for training. For inference, the neural network will try to classify the patch, and a final slide-level label is determined by taking the major predicted class for a slide. If patients have multiple slides, the slide with the highest grade is assigned the final grade. (ii) Multi-Instance Learning (MIL). We extract features describing each patch using the KimiaNet [ 28 29 30 31 32 2 (iii) Histogram of Density Maps. The histogram represents cell proliferation, mitotic activity, or Ki-67 index, across a slide. The H&E slide’s histogram values range from 0 to 48, for a total of 49 bins and the frequencies are normalized. There were 6 cases that exceeded a mitotic count of 48, the array with the density maps for these cases were clipped to 48 because it is well above the G3 threshold. Figure 2 2.2.7. Statistical Methodology Survival analysis was performed using the Lifelines Python library (version 0.27.8), which supports right-censored data by default [ 33 34 35 3. Results 3.1. NEN Grading Table 3 Once we determined that the histogram of mitotic activity yielded the best performance, our next investigation was to determine the added benefits of processing Ki-67 to our deep learning pipeline. When incorporating Ki-67, we investigated four possible aggregations, two naïve approaches which treat the two stains as separate pipelines, and two concatenated approaches which combine the histograms from both stains. “Naïve Approach 1” takes the max grade from the grade predicted by H&E neural network and Ki-67 index as defined by WHO. “Naive Approach 2” takes the max grade from the predictions of a Ki-67 neural network and the H&E neural network. Both naive approaches improve results in our three-fold balanced accuracy by 4.6%. The best model for the three-fold average balanced accuracy was the concatenated feature MLP. This model concatenates the generated histograms from RetinaNet-DA mitotic activity, and the Ki-67 detections into a single vector and trains a single neural network. This model achieved a 3-fold balanced accuracy of 83.0%. The performance improved by 5.5% when compared to the performance of the previous. Finally, we re-examined the misclassified cases with an expert NET pathologist who provided insight into possible reasons for their misclassification. Seven misclassified cases were attributed to poor segmentation masks from the tumor-normal classifier. These segmentations included reactive, liver, or epithelial with hotspots detected in these areas. Furthermore, two cases were clinically misattributed with a grade 1 label and later deemed as G2s. This pathologist-guided examination allowed us to correct these cases by adjusting the tumor masks and correcting the grading labels. Results for the corrections on the full cohort are noted and can be seen in Table 4 Table 5 cancers-17-02991-t004_Table 4 Table 4 Classification metrics with 95% confidence intervals for our framework and corrections. Source Method Precision Recall F1 Score H&E Histogram MLP 0.667 (0.590, 0.741) 0.719 (0.646, 0.787) 0.686 (0.611, 0.756) H&E + Ki67 Naïve Combination 1 0.695 (0.620, 0.769) 0.784 (0.732, 0.832) 0.721 (0.650, 0.790) Naïve Combination 2 0.690 (0.618, 0.763) 0.781 (0.729, 0.832) 0.718 (0.647, 0.784) MLP Concatenated Features 0.759 (0.689, 0.826) 0.757 (0.686, 0.824) 0.756 (0.690, 0.818) H&E + Ki67 Naïve Combination 1 0.730 (0.654, 0.804) 0.811 (0.759, 0.857) 0.757 (0.689, 0.825) Naïve Combination 2 0.721 (0.649, 0.796) 0.803 (0.749, 0.850) 0.749 (0.681, 0.813) H&E Pathologist Grade 0.924 (0.886, 0.955) 0.810 (0.732, 0.880) 0.849 (0.774, 0.910) H&E + Ki67 Pathologist Grade (Ground Truth) 1 (1, 1) 1 (1, 1) 1 (1, 1) cancers-17-02991-t005_Table 5 Table 5 Summarized survival with our framework and corrections. Source Method c-Index Median Survival (yrs)     G1  G2  G3  H&E  Histogram MLP 0.63 7.20 4.88 1.74  H&E + Ki67  Naïve Combination 1 0.63 6.85 4.88 1.74  Naïve Combination 2 0.65 7.78 4.56 2.10  MLP Concatenated Features 0.63 6.77 4.63 1.22  H&E + Ki67 (Corrected)  Naïve Combination 1 0.63 7.20 4.88 1.74  Naïve Combination 2 0.65 7.50 4.56 1.74  H&E  Pathologist Grade 0.63 6.86 4.56 0.99  H&E + Ki67  Pathologist Grade 0.64 7.20 4.88 1.22 3.2. Survival Results Kaplan–Meier (KM) curves for our computer-graded groups and pathologist-assessed grades can be found in Figure 3 p Figure 3 Figure 3 n n 3.3. Multivariate Analysis We investigate the confounding effects of various factors by performing a multivariate analysis on grades, sites, differentiation, and metastasis at diagnosis. Figure 4 The bottom forest plot in Figure 4 4. Discussion Deep learning and digital pathology are rapidly evolving with substantial advances in diagnostics, prognostics, and discovery. Our research continues to merge these two fields to assist pathologists in NEN grading. Previous studies applying deep learning to NENs have largely focused on Ki-67 quantification due to its clinical relevance and well-defined thresholds [ 36 37 A central design consideration in our framework is the method of aggregating local features into slide-level or patient-level predictions. The majority voting approach serves as a simple baseline, whereas MIL is a robust approach designed for weakly supervised settings, operating under the assumption that one or more informative patches are sufficient to determine the class label. We observed that histogram-based aggregation outperformed patch-based and MIL methods, supporting recent findings that tumor-level statistical summaries often better capture histopathological heterogeneity than local features [ 38 This improved performance highlights a key insight: local patch-wise analysis, especially in heterogeneous tumors like NETs, often lacks sufficient spatial context for accurate grading. While MIL frameworks assume that a single discriminative patch can determine a slide-level label, this assumption fails in NEN grading, where proliferation must be assessed over standardized tissue areas (e.g., 2 mm 2 39 Based on our results and the biology of NENs, we infer that the poor performance of majority voting and MIL-based methods is due to both the inherent heterogeneity of these tumors and the small field of view in patch-based models. A 512 × 512 pixel patch at 40× magnification covers less than 1/100th of the required 2 mm 2 2 15 38 From a translational perspective, the clinical deployment of deep learning models presents both opportunities and barriers. Reliable deployment depends on high-quality WSIs, standardized staining, and access to computational resources. These conditions that may not be universally met across institutions. Regulatory approval and clinician acceptance will also require transparency and interpretability, which remains a key challenge in deep learning. While our model is not inherently explainable in a rule-based sense, the use of histograms and heatmaps provides a middle ground that supports visual inspection and clinical reasoning [ 40 Another promising frontier is the integration of radiomics or combined imaging modalities with histopathology. Integrating these imaging biomarkers into our histogram-based deep learning framework could provide a more comprehensive assessment of tumor biology and may streamline preoperative decision-making. For example, research has shown that endoscopic ultrasonography (EUS) allows high-resolution visualization of pancreatic and gastrointestinal NETs, improving tumor delineation and prognostication when combined with radiomic texture features extracted from CT, MRI, or elastography images [ 41 42 Several other limitations must also be acknowledged. First, our model was trained on a dataset from British Columbia, which may limit generalizability to other regions or institutions. Although the cohort is diverse in geography and clinical practice, global variability in grading standards, staining protocols, and scanner types could affect model performance. External validation on international datasets is essential for robustness. Second, although our framework improves interpretability through visual summaries, the underlying deep learning architectures remain largely opaque, making it difficult to fully explain model decisions to clinicians. Additionally, while we have taken effort to combat data imbalance through the use of class-weighting and balanced accuracy as a target metric, additional exploration into sophisticated methods such as resampling or ensemble strategies could lead to improved performance. Furthermore, tumor pathology assessment does not rely solely on mitotic count and Ki-67 index. Important prognostic markers such as necrosis, vascular invasion, and molecular alterations were not included in our model. Future work should consider incorporating these data streams using multimodal AI approaches, instead of just focusing on grade. Lastly, real-world implementation of such a system would require robust preprocessing pipelines, reliable tumor segmentation, and a pathologist-in-the-loop design to mitigate errors, such as those which we encountered during our pathologist review. Ultimately, our results demonstrate the potential for deep learning to support and augment traditional pathology workflows. However, successful clinical translation will depend on addressing these feasibility and interpretability barriers and validating generalizability across broader patient populations and clinical settings. 5. Conclusions In conclusion, using histograms of proliferating cell markers can produce good slide-level representations and yield high performing models. In our study, we demonstrated that our framework achieved an average balanced accuracy of approximately 83%. Our survival analysis with pathologist-guided input demonstrated that AI grades have a c-index of 0.65, and each grading group was separated with a significant p p −6 Disclaimer/Publisher’s Note: Author Contributions Formal analysis, A.H.; Funding acquisition, J.M.L.; Investigation, A.H., J.C., D.F. and D.S.; Project administration, H.F., A.B. and J.M.L.; Software, A.H.; Supervision, H.F., A.B. and J.M.L.; Writing—original draft, A.H. and M.D.-S.; Writing—review and editing, M.D.-S., A.B. and J.M.L. All authors have read and agreed to the published version of the manuscript. Institutional Review Board Statement The research was conducted with approval from the University of British Columbia—BC Cancer Research Ethics Board, certificate number H18-03646 and H18-01396. A waiver of consent was obtained for this study. Data Availability Statement The MIDOG22 dataset is available for download on Zenodo.org [ https://zenodo.org/records/4643381 Conflicts of Interest The authors declare no conflicts of interest. Abbreviations The following abbreviations are used in this manuscript: NEN Neuroendocrine Neoplasm H&E Hematoxylin and Eosin NEC Neuroendocrine Carcinoma WHO World Health Organization GI Gastrointestinal WSI Whole Slide Image MIDOG22 Mitosis Domain Generalization Challenge 2022 MIL Multiple Instance Learning MLP Multi-Layer Perceptron KM Kaplan–Meier References 1. Klimstra D.S. Yang Z. Pathology, classification, and grading of neuroendocrine neoplasms arising in the digestive system UpToDate UpToDate, Inc. Waltham, MA, USA 2019 2. Oronsky B. Ma P.C. Morgensztern D. Carter C.A. Nothing But NET: A Review of Neuroendocrine Tumors and Carcinomas Neoplasia 2017 19 981 992 10.1016/j.neo.2017.09.002 29091800 PMC5678742 3. Cleveland Clinic Neuroendocrine Tumor: Diagnosis, Symptoms, Treatment, & What It Is Available online: https://my.clevelandclinic.org/health/diseases/22006-neuroendocrine-tumors-net (accessed on 14 November 2022) 4. Klimstra D.S. Kloppel G. La Rosa S. Rindi G. Classification of neuroendocrine neoplasms of the digestive system WHO Classification of Tumours, Digestive System Tumours 5th ed. IARC Press Lyon, France 2019 5. Popa O. Taban S. Pantea S. Plopeanu A. Barna R. Cornianu M. Pascu A.-A. Dema A.L. The new WHO classification of gastrointestinal neuroendocrine tumors and immunohistochemical expression of somatostatin receptor 2 and 5 Exp. Ther. Med. 2021 22 705 10.3892/etm.2021.10613 34475969 PMC8406677 6. Pavel M. Öberg K. Falconi M. Krenning E. Sundin A. Perren A. Berruti A. O’Connor J.M. Tamburrano P. Uz Zanabili A. Gastroenteropancreatic neuroendocrine neoplasms: ESMO Clinical Practice Guidelines for diagnosis, treatment and follow-up Ann. Oncol. 2020 31 844 860 10.1016/j.annonc.2020.03.304 32272208 7. Fukushima N. Neuroendocrine Neoplasms of the Pancreas: The Pathological Viewpoint JOP J. Pancreas 2018 19 328 334 8. Halfdanarson T.R. Strosberg J.R. Tang L. Bellizzi A.M. Bergsland E.K. O’Dorisio T.M. Halperin D.M. Fishbein L. Eads J. Hope T.A. The North American neuroendocrine tumor society consensus guidelines for surveillance and medical management of pancreatic neuroendocrine tumors Pancreas 2020 49 863 881 10.1097/MPA.0000000000001597 32675783 9. Donovan T.A. Moore F.M. Bertram C.A. Luong R. Bolfa P. Klopfleisch R. Tvedten H. Salas E.N. Whitley D.B. Aubreville M. Mitotic figures—Normal, atypical, and imposters: A guide to identification Vet. Pathol. 2021 58 243 257 10.1177/0300985820980049 33371818 10. Bertram C.A. Aubreville M. Marzahl C. Maier A. Klopfleisch R. A large-scale dataset for mitotic figure assessment on whole slide images of canine cutaneous mast cell tumor Sci. Data 2019 6 293 10.1038/s41597-019-0290-4 31754105 PMC6872565 11. Elmaci I. Altinoz M.A. Sari R. Bolukbasi F.H. Phosphorylated histone H3 (PHH3) as a novel cell proliferation marker and prognosticator for meningeal tumors: A short review Appl. Immunohistochem. Mol. Morphol. 2018 26 627 631 10.1097/PAI.0000000000000499 28777144 12. Govind D. Jen K.-Y. Matsukuma K. Gao G. Olson K.A. Gui D. Wilding G. Border S.P. Sarder P. Improving the accuracy of gastrointestinal neuroendocrine tumor grading with deep learning Sci. Rep. 2020 10 14811 10.1038/s41598-020-67880-z 32632119 PMC7338406 13. Shaker N. Shen R. Limbach A.L. Satturwar S. Kobalka P. Ahmadian S. Sun S. Chen W. Lujan G. Esnakula A. Automated imaging analysis of Ki-67 immunohistochemistry on whole slide images of cell blocks from pancreatic neuroendocrine neoplasms J. Am. Soc. Cytopathol. 2024 13 205 212 10.1016/j.jasc.2024.02.001 38433072 14. Houpt J.A. Liu E. Wang H. Cecchini M.J. Ling C. Zhang Q. Determination of Ki-67 indices in neuroendocrine tumours of the gastrointestinal tract: The past, the present, and the future Virchows Arch. 2025 486 1001 1009 10.1007/s00428-024-03963-w 39516292 15. Ma M. Gu W. Liang Y. Han X. Zhang M. Xu M. Gao H. Tang W. Huang D. A novel model for predicting postoperative liver metastasis in R0 resected pancreatic neuroendocrine tumors: Integrating computational pathology and deep learning-radiomics J. Transl. Med. 2024 22 768 10.1186/s12967-024-05449-4 39143624 PMC11323380 16. Li X. Yang F. Zhang Y. Yang Z. Chen R. Zhou M. Yang L. DeepTFtyper: An interpretable morphology-aware graph neural network for translating histopathology images into molecular subtypes in small cell lung cancer Brief. Bioinform. 2025 26 bbaf284 10.1093/bib/bbaf284 40539233 PMC12204680 17. Shen Z. Simard M. Brand D. Andrei V. Al-Khader A. Oumlil F. Trevers K. Butters T. Haefliger S. Kara E. A deep learning framework deploying segment anything to detect pan-cancer mitotic figures from haematoxylin and eosin-stained slides Commun. Biol. 2024 7 1674 10.1038/s42003-024-07398-6 39702417 PMC11659629 18. Farnell D.A. Huntsman D. Bashashati A. The coming 15 years in gynaecological pathology: Digitisation, artificial intelligence, and new technologies Histopathology 2020 76 153 163 10.1111/his.13991 31846526 19. Aubreville M. Bertram C.A. Breininger K. Jabari S. Stathonikos N. Veta M. MItosis DOmain Generalization Challenge 2022. Zenodo 2022 Available online: 10.5281/zenodo.6362337 (accessed on 14 November 2022) 20. Burgart L.J. Chopp W.V. Jain D. Protocol for the Examination of Specimens from Patients with Well-Differentiated Neuroendocrine Tumors (Carcinoid Tumors) College of American Pathologists Northfield, IL, USA 2021 21. Chu J. Department of Pathology and Laboratory Medicine, University of British Columbia, Vancouver, BC V6T 1Z7, Canada Personal communication 10 March 2023 22. Janowczyk A. Zuo R. Gilmore H. Feldman M. Madabhushi A. HistoQC: An open-source quality control tool for digital pathology slides JCO Clin. Cancer Inform. 2019 3 1 7 10.1200/CCI.18.00157 30990737 PMC6552675 23. Tan M. Le Q.V. Efficientnet: Rethinking model scaling for convolutional neural networks Proceedings of the 36th International Conference on Machine Learning Long Beach, CA, USA 9–15 June 2019 6105 6114 24. Lin T.-Y. Goyal P. Girshick R. He K. Dollár P. Focal loss for dense object detection Proceedings of the IEEE International Conference on Computer Vision Venice, Italy 22–29 October 2017 2980 2988 25. Wilm F. Marzahl C. Breininger K. Aubreville M. Domain adversarial RetinaNet as a reference algorithm for the MItosis DOmain generalization challenge Proceedings of the MICCAI 2021 Challenges Strasbourg, France 27 September–1 October 2021 5 13 26. Lakshmi S. Ritwik K.V.S. Vijayasenan D. Sreeram S. Suresh P.K. Deep learning model based Ki-67 index estimation with automatically labelled data Proceedings of the 42nd Annual International Conference of the IEEE Engineering in Medicine & Biology Society (EMBC) Montreal, QC, Canada 20–24 July 2020 1412 1415 10.1109/EMBC44109.2020.9175752 33018254 27. OpenCV Hough Circle Transform Available online: https://docs.opencv.org/4.x/d9/d61/tutorial_py_morphological_ops.html (accessed on 13 April 2023) 28. Riasatian A. Babaie M. Maleki D. Kalra S. Valipour M. Hemati S. Zaveri M. Safarpoor A. Shafiei S. Afshari M. Fine-tuning and training of densenet for histopathology image representation using TCGA diagnostic slides Med. Image Anal. 2021 70 102028 10.1016/j.media.2021.102032 33773296 29. Ilse M. Tomczak J.M. Welling M. Attention-based deep multiple instance learning Proceedings of the 35th International Conference on Machine Learning Stockholm, Sweden 10–15 July 2018 2127 2136 30. Farahani H. Boschman J. Farnell D. Darbandsari A. Zhang A. Ahmadvand P. Jones S.J.M. Huntsman D.G. Köbel M. Gilks C.B. Deep learning-based histotype diagnosis of ovarian carcinoma whole-slide pathology images Mod. Pathol. 2022 35 1983 1990 10.1038/s41379-022-01146-z 36065012 31. Schirris Y. Gavves E. Nederlof I. Horlings H.M. Teuwen J. DeepSMILE: Self-supervised heterogeneity-aware multiple instance learning for DNA damage response defect classification directly from H&E whole-slide images arXiv 2021 2107.09405 32. Kraus O.Z. Ba J.L. Frey B.J. Classifying and segmenting microscopy images with deep multiple instance learning Bioinformatics 2016 32 i52 i59 10.1093/bioinformatics/btw252 27307644 PMC4908336 33. Davidson-Pilon C. lifelines: Survival analysis in Python J. Open Source Softw. 2019 4 1317 10.21105/joss.01317 34. Alabdallah A. Ohlsson M. Pashami S. Rognvaldsson T. The Concordance Index decomposition—A measure for a deeper understanding of survival prediction models arXiv 2022 10.2139/ssrn.4024162 2203.00144 38325926 35. Scikit Survival Evaluating Survival Models Available online: https://scikit-survival.readthedocs.io/en/stable/user_guide/evaluating-survival-models.html (accessed on 1 January 2023) 36. Vesterinen T. Säilä J. Blom S. Pennanen M. Leijon H. Arola J. Automated assessment of Ki-67 proliferation index in neuroendocrine tumors by deep learning APMIS 2022 130 11 20 10.1111/apm.13190 34741788 PMC9299468 37. Luchini C. Pantanowitz L. Adsay V. Asa S.L. Antonini P. Girolami I. Veronese N. Nottegar A. Cingarlini S. Landoni L. Ki-67 assessment of pancreatic neuroendocrine neoplasms: Systematic review and meta-analysis of manual vs. digital pathology scoring Mod. Pathol. 2022 35 712 720 10.1038/s41379-022-01055-1 35249100 PMC9174054 38. Kosaraju S. Park J. Lee H. Yang J.W. Kang M. Deep learning-based framework for slide-based histopathological image analysis Sci. Rep. 2022 12 19075 10.1038/s41598-022-23166-0 36351997 PMC9646838 39. Zhang M. Tan C. Wang X. Ding X. Zhang B. Yang Z. Wang Y. Sheng W. Huang D. Digital Image Analysis of Ki67 heterogeneity improves the diagnosis and prognosis of gastroenteropancreatic neuroendocrine neoplasms Mod. Pathol. 2023 36 100017 10.1016/j.modpat.2022.100017 36788066 40. Bera K. Schalper K.A. Rimm D.L. Velcheti V. Madabhushi A. Artificial intelligence in digital pathology—New tools for diagnosis and precision oncology Nat. Rev. Clin. Oncol. 2019 16 703 715 10.1038/s41571-019-0252-y 31399699 PMC6880861 41. Ayesha S. Karim M.M. Shahid A.H. Rehman A.U. Uddin Z. Abid S. Diagnostic role of endoscopic ultrasonography in defining the clinical features and histopathological spectrum of gastroenteropancreatic neuroendocrine tumors World J. Gastrointest. Endosc. 2025 17 104539 10.4253/wjge.v17.i6.104539 40547552 PMC12179946 42. Massironi S. Conte D. Sciola V. Pirola L. Paggi S. Fraquelli M. Ciafardini C. Spampatti M.P. Peracchi M. Contrast-enhanced ultrasonography in evaluating hepatic metastases from neuroendocrine tumours Dig. Liver Dis. 2010 42 635 641 10.1016/j.dld.2010.01.009 20172770 Figure 1 High-level overview of extended Ki-67 framework approach. Original Tissue: WSI thumbnail. Tissue Masks: HistoQC fused masks, pink areas are the usable tissue areas with minimal artifacts. Tumor Masks: identified tumor areas overlapped on WSI. Detection: Mitotic Activity and Ki-67 index density maps. Aggregation Module: histogram combined with machine learning classifications. Figure 2 Overview of the histogram approach of the H&E framework. Figure 3 Survival analyses and grade-prediction confusion matrix. Shaded areas surrounding survival curves represent 95% confidence intervals. At-risk tables broken-down by grade can be found under the corresponding Kaplan–Meier curves. ( A B C D Figure 4 ( A B C cancers-17-02991-t001_Table 1 Table 1 2019 WHO classification of NENs. Biology Grade Mitotic Count 1 Ki-67 Index 2  G1 <2 <3 Well-Differentiated (NETs) G2 2–20 3–20  G3 >20 >20 Poorly Differentiated (NECs) G3 >20 >20 1 2 2 + cancers-17-02991-t002_Table 2 Table 2 Histopathological grading and imaging breakdown. H&E-stained slides capture general tissue architecture and morphology and are used to ascertain mitotic count. Ki-67 staining is used to observe cells expressing the nuclear protein Ki-67, which is present in all actively dividing cells. These measures are central to NEN grading (see Table 1 Stain Unit  Grade    G1 G2 G3 H&E Patients 109 56 21  Slides 145 76 26 Ki-67 Patients 77 38 20  Slides 78 38 22 cancers-17-02991-t003_Table 3 Table 3 Three-fold classification of NEN grades for various methods and architectures. Source Method 3-Fold Average H&E Patch-Based 52.8 DeepMIL [ 29 46.6 VarMIL [ 31 36.5 NoisyAND [ 32 41.5 Histogram MLP RetinaNet-DA [ 25 77.5 H&E + Ki-67 Naïve Combination 1 82.1 Naïve Combination 2 82.1  MLP Concatenated Features  83.0 Log Concatenated Features 74.5 Bold indicates best result. ",
  "metadata": {
    "Title of this paper": "Contrast-enhanced ultrasonography in evaluating hepatic metastases from neuroendocrine tumours",
    "Journal it was published in:": "Cancers",
    "URL": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC12468616/"
  }
}