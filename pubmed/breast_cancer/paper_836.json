{
  "title": "Paper_836",
  "abstract": "pmc Cancer Inform Cancer Inform 363 cancerinform CIX Cancer Informatics 1176-9351 SAGE Publications PMC12476512 PMC12476512.1 12476512 12476512 41024938 10.1177/11769351251376192 10.1177_11769351251376192 1 Original Research Robust Multimodal Fusion for Survival Prediction in Cancer Patients https://orcid.org/0009-0006-4083-5709 Flack Dominic 1 Tripathi Aakash 2 Waqas Asim 2 Rasool Ghulam 2 https://orcid.org/0000-0002-7168-5858 Dera Dimah 1 1 2 Dominic Flack, Chester F. Carlson Center for Imaging Science, Rochester Institute of Technology, 54 Lomb Memorial Dr, Rochester, NY 14623, USA. Emails: daf6674@rit.edu dominic416@gmail.com 27 9 2025 2025 24 480433 11769351251376192 14 4 2025 14 8 2025 27 09 2025 29 09 2025 30 09 2025 © The Author(s) 2025 2025 SAGE Publications Ltd unless otherwise noted. Manuscript content on this site is licensed under Creative Commons Licenses https://creativecommons.org/licenses/by-nc/4.0/ This article is distributed under the terms of the Creative Commons Attribution-NonCommercial 4.0 License ( https://creativecommons.org/licenses/by-nc/4.0/ https://us.sagepub.com/en-us/nam/open-access-at-sage Objectives: Multimodal deep learning models have the potential to significantly improve survival predictions and treatment planning for cancer patients. These models integrate diverse data modalities using early, intermediate, or late fusion techniques. However, many existing multimodal models either underperform or show only marginal improvements over unimodal models. To establish the true efficacy of multimodal survival prediction models, it is critical to demonstrate consistent and substantial advantages over unimodal counterparts. Methods: In this paper, we introduce the Robust Multimodal Survival Model (RMSurv), a novel discrete late fusion model that leverages synthetic data generation to compute time-dependent weights for various modalities. RMSurv utilizes up to 6 distinct data modalities from The Cancer Genome Atlas Program (TCGA) non-small cell lung cancer and the TCGA pan-cancer datasets to predict overall survival over a period of 10 years. The key innovations of RMSurv are the calculation of time-dependent late fusion weights using a synthetically generated dataset and a new statistical feature normalization technique to enhance the interpretability and accuracy of discrete survival predictions. We evaluate the performance of the proposed method and several alternatives with cross validation using the concordance index, and vary the number of modalities included. We also create a late fusion simulation to highlight the complex relationships of multimodal fusion. Results: In our experiments, RMSurv outperforms the best unimodal model’s Concordance index (C-Index) by 0.0273 on the 6-modal TCGA Lung Adenocarcinoma (LUAD) dataset. Existing late and early fusion methods improved the C-index by only 0.0143 and 0.0072, respectively. RMSurv also performs best on the combined TCGA non-small-cell lung cancer dataset and the TCGA pan-cancer dataset. Conclusions: These advancements underscore RMSurv’s potential as a powerful approach for survival prediction, establishing robust multimodal benefits, and setting a new benchmark for survival prediction models in pan-cancer settings. multimodal cancer survival prediction fusion pmc-status-qastatus 0 pmc-status-live yes pmc-status-embargo no pmc-status-released yes pmc-prop-open-access yes pmc-prop-olf no pmc-prop-manuscript no pmc-prop-legally-suppressed no pmc-prop-has-pdf yes pmc-prop-has-supplement yes pmc-prop-pdf-only no pmc-prop-suppress-copyright no pmc-prop-is-real-version no pmc-prop-is-scanned-article no pmc-prop-preprint no pmc-prop-in-epmc yes cover-date January-December 2025 typesetter ts1 Introduction Background Multimodal learning in oncology is an emerging research area with great potential to improve cancer research and patient care. Multimodality refers to various types of data, including but not limited to radiological and diagnostic imaging, clinical and demographic data, histopathology slides, or molecular information. Multi-omics analysis uses data from genomics, transcriptomics, and similar fields for medical research. Survival prediction, a critical aspect of cancer research, involves estimating how long a patient is likely to live after diagnosis or treatment, aiding in personalized treatment planning, resource allocation, and clinical trial design. Survival prediction models are best evaluated using the concordance index, or C-index, which measures the fraction of pairs of predicted risk scores that match the ground truth. Several existing fusion methods merge heterogeneous data modalities such as clinical records, -omics data, and histopathology images for survival prediction. 1 2  3  4  1  1 The key challenge for existing data fusion models is to consistently achieve a multimodal advantage, meaning performance for a given task that surpasses the best unimodal model. Even if the model produces a multimodal advantage for some modalities (eg, imaging, genomics, etc.), it won’t be helpful in real-world medical decision-making unless its performance clearly exceeds that of the unimodal model based on readily available data like a patient’s age, gender, or cancer stage. Therefore, studies that show a multimodal advantage for carefully selected modalities and exclude clinical data or other outlier high-performing modalities are limited in their potential for future clinical application. Existing intermediate and early multimodal fusion models often demonstrate a multimodal advantage when using the ideal combination of a maximum of 2 to 3 modalities, 5 8  4  8 A potential cause of the low robustness to weak modalities is the optimization strategy of early and intermediate fusion, which minimizes a combined loss function based on the training accuracy of the multimodal model. For small and noisy cancer cohort datasets, where the training-set cases and test-set cases will differ considerably, the overfitting of each modality will compound when they are all fused together as a single model. A promising solution proposed in a recent work  9  9 In this paper, we propose the Robust Multimodal Survival Model (RMSurv), which uses a synthetically generated dataset to empirically optimize the weighting for discrete late fusion. We further improve the model by using time-dependent weights to represent the performance of each modality over time and normalize the output to correct the distribution. We present multiple variations of late fusion methods and compare them to existing methods on 3 datasets with a varying number of data modalities. We also present a simulation to reveal the underlying correlation-based relationships of late fusion, and introduce a novel pathology report embedding modality, which shows promising results for a new class of text-based survival prediction modalities. Related Work Several machine learning methods for survival prediction are based on the Cox proportional hazards model.  3  3  10  4 Vale-Silva and Rohr  4  4  4 Intermediate fusion methods have the advantage of modeling rich cross-modal interactions.  1  11  8  11  8  12 Several improvements to unimodal architectures have been incorporated into intermediate fusion systems to further increase performance. Gomaa et al  6  6  6  5  5  5  7  7 One potential limitation of early and intermediate fusion approaches are the highly variable performance based on the dataset and number of modalities included. 4 8  9  13 1 9 1 14  4 Nikolaou et al  9  9  9  9 Methods Late Fusion Simulation Intuition suggests that the performance of a combination of 2 predictions depends on the accuracy of each prediction and the correlation between the 2. Combining nearly identical, highly correlated predictions will not add signal to the combined prediction. Likewise, linear combinations with low correlation can benefit from the independent signal of each modality. However, even with zero correlation, a survival prediction with very low C-index will just add noise to a highly accurate survival prediction. Therefore, an ad-hoc relationship that uses only the C-index as an input to calculate late fusion weights is not capable of modeling the true empirical relationship. Here we describe a fully synthetic dataset, distinct from RMSurv, to simulate late fusion and ground this intuition. We use the results of this simulation to explain the need for an empirical strategy like RMSurv, and to explain why adding more modalities to a model often decreases performance in multimodal fusion research. These results are shown in the “Late Fusion Simulation Results” Section. We also use this simulated dataset to calculate weights in our “synthetic weights” alternative weight calculation method, which we explain in the “Alternative Weight Calculation Options” Section. For this simulation, we generate synthetic risk scores and survival times with arbitrarily set C-indices and cross-modality correlations by sampling from a multivariate normal distribution. This method does not directly use C-index as an input but instead requires a positive semi-definite covariance matrix. To get around this, we need to model the non-linear C-index as a linear correlation. We achieve this by converting the C-index of each modality into a Pearson correlation between the modality and the survival times using analytical estimates. We run a binary search algorithm to repeatedly generate distributions to correct for errors in the analytical estimates and match the C-index to its corresponding correlation metric. This approximation of the C-index as a Pearson correlation results in negligeable error in a 2-dimensional simulation, but results in some small unavoidable error between the desired and actual C-indices and correlations when using 6 modalities within the simulation. After assigning a Pearson correlation to each modality, we add a new row and column to the existing Pearson correlation matrix to combine these into a unified matrix that represents cross-modality correlations between risk scores and correlations between risk scores and survival times. We then find the nearest positive semidefinite matrix and generate our normally distributed samples. We apply an iterative process to reduce the error between the desired and actual C-indices and correlations, then we can test the performance with varying weights given to each modality. Binary Search Procedure In the initialization step, we set the lower bound of Spearman’s correlation,  ρ s l o w ,  ρ s h i g h ,  t o l = 1 × 10 − 4 ,  ρ s = ρ s l o w + ρ s h i g h 2 , and convert  ρ s  ρ p = 2 sin ​ ( π 6 ρ s ) . We then set  ρ p  ρ p ,  c o b s e r v e d ,  c o b s e r v e d > c d e s i r e d ,  ρ s h i g h = ρ s .  c o b s e r v e d < c d e s i r e d  ρ s l o w = ρ s .  | c o b s e r v e d − c d e s i r e d | < t o l Generating Synthetic Data Using a Gaussian Copula We begin by constructing an initial symmetric Pearson correlation matrix,  P ,  M  M = 3 ,  P  3 × 3  ( M + 1 ) × ( M + 1 )  ∑ p  P = [ 1 ρ 12 ρ 13 ρ 21 1 ρ 23 ρ 31 ρ 32 1 ] → ∑ p = [ 1 ρ 12 ρ 13 ρ 1 T ρ 21 1 ρ 23 ρ 2 T ρ 31 ρ 32 1 ρ 3 T ρ T 1 ρ T 2 ρ T 3 1 ] , where  ρ i T  i  T Next, we verify that  ∑ p  ∑ p  15  Σ p  N  M After drawing these samples, we transform each normal variable  Z i  U i  Φ :  U i = Φ ( Z i ) , i = 1 , … , M , T . We then apply the desired marginal distributions. For each modality  i ,  U i  R i = Φ − 1 ( U i ) .  U T  λ  T = − ln ( 1 − U T ) λ . Optimizing Weights with Population-Based Search We define a combined risk score  R c o m b i n e d  R i ,  w i :  R c o m b i n e d = ∑ i = 1 M w i R i . Our objective is to maximize the C-index of  R c o m b i n e d  T :  max w c c o m b i n e d = C − i n d e x ( R c o m b i n e d , T ) . In a 2-dimensional simulation, we simply compute the combined C-index at 100 relative weights ranging from 0 to 1. However, in higher dimensions where local minima may appear, we use the differential evolution algorithm. We set a population size of 15, a tolerance of  10 − 6 , Data Pre-processing In our experiments, we use the non-small-cell lung cancer types LUAD and LUSC from the Cancer Genome Atlas (TCGA) database, a large public database of cancer data collected from 2006 to 2015.  16  17  17  17  17  17 We use 7 total input modalities to evaluate the performance of the fusion methods: clinical data, pathology reports, gene expression, miRNA, DNA methylation, protein expression, and somatic mutation. Gene expression (measuring mRNA) and miRNA are transcriptomic factors, which regulate the expression of genes in cancer cells.  16  18  19  16  20  21  22 Supplemental File 1 For the clinical data modality, we use the Multimodal Integration of Oncology Data System (MINDS) database  21 Table 1 Table 1. Discretization of Clinical Data Categories. Attribute Category Numeric value Age Integer Integer Gender Male 1 Female 2 Race White 1 Asian 2 Black or African American 3 Not reported 4 American Indian or Alaska Native 5 Stage Stage 0 1 Stage I 10 Stage IA 11 Stage IB 12 Stage IC 13 Stage II 20 Stage IIA 21 Stage IIB 22 Stage IIC 23 Stage III 30 Stage IIIA 31 Stage IIIB 32 Stage IIIC 33 Stage IV 40 Stage IVA 41 Stage IVB 42 Stage IVC 43 Not Reported 50 The pathology report PDF, also downloaded using MINDS, requires more preprocessing, and we use the HoneyBee framework  23  24 The remaining modalities are tabular-omics data downloaded from the UCSC Xena website.  20 Table 2 Table 2. Number of Features in Each Modality After Pre-Processing. Modality LUAD LUAD + LUSC PAN Clinical data 4 4 4 Pathology report 3584 3584 3584 Gene expression 16 829 16 829 192 958 miRNA 1012 1012 634 DNA methylation 4931 4931 38 943 Protein expression 210 Protein expression + somatic mutation 1204 1204 Although MRI images, whole slide images, and copy number information were available, we did not include these modalities in the final testing. TCGA LUAD has MRI images for fewer than 10% of patients, so this modality performed poorly. We used embeddings of slide images generated with the UNI pretrained vision transformer model,  25 Unimodal Architecture For a late fusion model, the ensemble can combine predictions from models with various different architectures. To simplify this study, we use the same architecture in all unimodal models used in late fusion. The unimodal model outputs used in late fusion are exactly the same for each late fusion strategy, but the linear combination weights vary depending on the method. This setup isolates the effect of the late fusion weight calculation method. Our unimodal discrete model uses twenty 6-month time periods and outputs a hazard score for each. This allows the model to account for non-proportional effects of individual features. The survival time of each case is converted into its respective time bin, and survival times exceeding 10 years are set to the final time bin. The negative log-likelihood loss function optimizes the model by increasing the hazard probability at the true time bin of the survival time and decreasing the hazard probability for the preceding time bins. In our preliminary experiments, we modified several existing models into discrete versions, including a self-normalizing network, a gradient boosting tree, a simplified fully connected network, and a modified version of the HFBSurv architecture.  12 An advantage of the late fusion approach is the ability to tune hyperparameters for unimodal models. We noticed that some unimodal models would experience more overfitting than others when using the same hyperparameters, so the unimodal models were manually tuned with cross-validation by modifying the learning rate  ( 5 × 10 − 5  1 . 2 × 10 − 4 ) , Robust Multimodal Survival Model (RMSurv) We develop a novel, robust multimodal data fusion approach to model the complex relationship between modalities and optimize the weight calculation strategy for discrete late fusion. The process uses nested cross-validation to estimate generalized C-indices, creates a synthetic dataset based on these estimates and the model outputs, and performs a grid search to find the optimal multimodal ensemble weights. Nested Cross-Validation One limitation of the existing method is the use of only a single validation set for calculating the C-index of each unimodal model.  9 Re-Training with Full Training Set After the nested cross-validation, the training set is combined without any held-out validation data, and the unimodal models are all trained again. The test set model inputs are passed through the model, and the outputs are recorded. This step is performed in the existing method,  9 Sampling Survival Times Next, we randomly sample ground truth survival times from the full training set, sampling as many survival times as there are test cases. Both censored and uncensored survival times were sampled in our experiments. We align each sampled survival time to a test set case, along with its unimodal model outputs, in a random permutation. This sampling approach perfectly models the actual cross-modality correlations and provides a strong estimate for the distribution of the test set survival times without leaking the actual test-set survival times. Optimize Survival Time Assignment Before this step, the distributions and correlations of the synthetic dataset are properly modeled, but the C-indices are randomly initialized and do not match our average validation C-indices calculated with the nested cross-validation. This step will augment the order of the sampled survival times such that the synthetic dataset will inherit the desired validation C-indices. We optimize how survival times are assigned by defining a total loss function based on the squared difference between achieved and desired C-indices:  L o s s = ∑ i = 1 M ( c a c h i e v e d , i − c d e s i r e d , i ) 2 , where  M  c d e s i r e d , i We iteratively improve the survival time assignment by swapping the rank of 2 randomly selected survival times, evaluating the loss after each swap, and accepting the new assignment whenever it reduces the loss. We stop early if the loss drops below a predefined threshold (10 −6 Optimize Weights via Population-Based Grid Search Now that the synthetic dataset is complete, we can empirically calculate the ideal weights with a grid search. This avoids the limitations of ad-hoc methods by implicitly considering correlations and number of modalities in addition to C-indices. The predictions for each modality are combined into 1 with a linear combination of model outputs. We optimize the linear combination weights via a population-based grid search. We define an objective function to maximize the C-index c combined R combined T  max w c c o m b i n e d = C − i n d e x ( R c o m b i n e d , T ) . Using the differential evolution algorithm,  26 Final Testing Finally, we test the model with the test set ground truth survival times, which are held out until this step. Figure 1 Algorithm 1 Figure 1. Overview of RMSurv weight calculation scheme. The process starts with a nested cross-validation on the training set (shown in blue) to calculate the average validation accuracy. This provides a representative accuracy for each modality, without introducing overfitting effects. Next, the unimodal models are re-trained on the full training set, and the model outputs are recorded. The survival times are randomly sampled from the training data. The synthetic dataset (shown in green) is generated using a binary search to match the average validation C-indices. Finally, ideal weights for the synthetic dataset are calculated with a grid search, and these weights are applied to the test set with the actual survival times (shown in pink). The diagram illustrates the RMSurv weight calculation process using nested cross-validation, sampling survival times, and re-training with unimodal outputs. It begins with training set evaluation, followed by model re-training, optimal weight determination, and concludes with testing. Time Dependent-RMSurv (TD-RMSurv) RMSurv and the other late fusion methods described in the “Alternative Weight Calculation Options” section all output a hazard for 20 discrete time bins, each representing a 6-month period over a 10-year time frame. In the baseline RMSurv scheme, the same  M  M × 20 We define the baseline RMSurv method as the following, where the same weight  w i  y c o m b , j = ∑ i = 1 M w i ⋅ y i , j , n o r m . For TD-RMSurv, each modality can have a distinct weight  w i , j  j .  y c o m b , j = ∑ i = 1 M w i j . y i , j , n o r m . Here,  M RMSurv Algorithm Algorithm 1. Pseudocode for RMSurv Algorithm. Require:  S ,  K ,  ϵ for  S do for do  D  T ( 20 % ) .  D for do end for  c d e s i r e d , m  D  T  D  | T | for  K do  L o s s = ∑ m ( c a c h i e v e d , m − c d e s i r e d , m ) 2 . end for  w ,  ∑ i w i = 1  T end for end for Normalization Strategy In our late fusion experiments we normalize both the unimodal outputs and the unified ensemble outputs, which gives 2 key benefits. First, unimodal models with higher training set C-indices will have greater variance in outputs, so they will have an outsize influence on the linearly combined result. The normalization before the linear combination ensures all unimodal model variances are equal such that there are no nonlinear effects, and the weights are interpretable as their true relative weight on the final output. Second, a linear combination of predictions will reduce the variance as compared to the unimodal outputs. By normalizing after the linear combination, we increase the variance, which avoids all survival predictions being very similar to the mean. One limitation of the C-index metric is that it only measures the accuracy of the rank, so outputs with biased means and standard deviations will not show any decrease in C-index. This normalization strategy does not significantly change the rank (C-index) of the output risk scores, but it does improve the error as measured by the Integrated Brier Score (IBS). IBS measures squared differences between observed outcomes and predicted survival probabilities over time.  27 Figure 2 Figure 2. Schematic layout of the proposed late fusion method is presented. Up to 6 unimodal models are separately trained and output unique survival predictions. Before the combination, the outputs are normalized to avoid non-linear influences from modalities with higher variance outputs. The modalities are combined with linear weighting, with the option for time-dependent weighting. The combined output is normalized again due to the inherent decrease in variance at the combination step. The statistics for the normalization are calculated by maximizing the Integrated Brier Score on the training set. Schematic layout of a late fusion method with unimodal models. Separate unimodal models’ survival predictions are normalized, combined with linear and/or time-dependent weighting. Final output is normalized again to adjust for variance reduction. Normalization stats are calculated by maximizing the Integrated Brier Score on the training set. We begin by computing the mean and standard deviation of the training set model outputs for each of the 20-time bins:  μ t r a i n , j = 1 N ∑ i = 1 N Y t r a i n , i , j , σ t r a i n , j = 1 N ∑ i = 1 N ( Y t r a i n , i , j − μ t r a i n , j ) 2 . These statistics are computed for each time bin independently. Next, we define a range of multipliers, for instance,  w s t d ∈ { 0 . 1 , 0 . 2 , … , 10 . 0 } .  w s t d , For test data, we normalize the predictions of each modality using the training set statistics and the optimized standard deviation multiplier  w std  y n o r m , i , j = ( y i , j − μ t e s t , j σ t e s t , j ) σ t r a i n , j w s t d + μ t r a i n , j . We then combine the normalized risk scores from all modalities using their respective weights  w i  y c o m b , j = ∑ i = 1 M w i y n o r m , i , j , where M  w std  y n o r m , i , j = ( y i , j − μ t e s t , j σ t e s t , j ) σ t r a i n , j w s t d + μ t r a i n , j . Once the combined score is normalized, we compute hazards and survival probabilities via the sigmoid function:  H j = S i g m o i d ( y c o m b , j ) , S j = ∏ k = 1 j ( 1 − H k ) . We use a single risk score per case for the C-index by defining:  R r i s k = − ∑ j = 1 T = 20 S j , where  S j  j .  R r i s k Alternative Weight Calculation Options In this section, we describe several alternative late fusion weight calculation methods which are used as a comparison to our proposed method in the “Late Fusion Experiment” Section. There are 5 main weight calculation strategies, and we test each with 1 validation set and with 5 nested cross-validation sets. The first strategy we test is the existing method proposed by Nikolaou et al,  9 Figure 3 Figure 4 Figure 3. Existing ad-hoc method with 1 validation set. This method was introduced in a previous work and uses simplified C-index estimation and weight calculation methods. By calculating the weight as the difference between the C-index and 0.5, the cross-correlation is not accounted for in either the model outputs or validation set outputs. This graph shows how different C-Index values, calculated using different weights, affect cross-correlation in three scenarios: with a correlation of 0.0, 0.2, and 0.5. Lines represent C-Index values of 0.590, 0.570, 0.550, and 0.530. As the relative weight for the second modality increases, C-Index generally decreases. 0.590 and 0.570 C-Index lines peak at around 0.2 relative weight, then decline. 0.550 and 0.530 C-Index lines peak around 0.1 relative weight, then decline. Figure 4. Improved ad-hoc method. This method is identical to the previous method except for the 5 nested validation sets. The averaging of the 5 validation C-indices decreases variance, which reduces the average difference between test set C-indices and validation set C-indices. Improvements in ad-hoc method by using 5 nested validation sets to average C-indices, reducing variance and enhancing accuracy comparison between test set C-indices and validation set C-indices. The second strategy empirically searches for the best weights for the validation set using a population-based grid search and then applies these weights to the test set outputs to generate the final ensemble output. This is described as the averaged weights method. We also test this method with 5 nested validation sets, and we average the calculated weights to give a more generalized estimate of the ideal test set weights. Figure 5 Figure 5. Averaged weights method with 5 nested validation sets. This method leverages a grid search for each validation set and then averages the calculated weights to apply on the test set. While this method does take advantage of the complex combination relationship, it suffers from the high variance in validation sets and does not account for the cross-correlation of the model outputs. Oversimplify, use plain text, and miss nuanced context The third strategy is the synthetic weights method. We calculate the average C-indices just as is done in the ad-hoc method, and then once the models are trained on the full training set, we calculate the Pearson correlation matrix based on the model outputs for the test set. These are used as inputs for the late fusion simulation described above, which generates a fully synthetic dataset and calculates the ideal weights to combine the synthetic risk scores. Figure 6 Figure 6. Synthetic weights method with 5 nested validation sets. This method is similar to RMSurv but uses a fully simulated dataset, just like the 1 used in the 2-D linear combination simulation shown above. This simulation uses only the test set correlations and average validation C-indices as inputs. This contrasts with RMSurv, which uses sampled training set survival times, test set model outputs, and average validation C-indices. The grid search is performed on the synthetic dataset to calculate the weights. Synthetic weights method with 5 nested validation sets. This method is similar to RMSurv but uses a fully simulated dataset, just like the 1 used in the 2-D linear combination simulation shown above. This simulation uses only the test set correlations and average validation C-indices as inputs. This contrasts with RMSurv, which uses sampled training set survival times, test set model outputs, and average validation C-indices. The grid search is performed on the synthetic dataset to calculate the weights. The fourth strategy is the RMSurv method. This data flow is similar to the synthetic weights method, but instead of simulating risk scores, the actual unimodal outputs are used with sampled and adjusted training set survival times. The weight search method is similar to the synthetic weights method, but for RMSurv, we use the full discrete survival calculation instead of a single simulated risk score. The fifth strategy, TD-RMSurv, uses the same data flow as RMSurv, but the search space is extended to calculate  M x 20  M Figure 7 Figure 7. RMSurv method with 5 nested validation sets. This method involves the same nested crossvalidation used in the other methods. Next, the models are trained with the full training set, and both test set outputs and training set survival times are recorded. The synthetic dataset is then generated using a binary search to give the randomly initialized dataset the average validation C-indices of the training set while maintaining the true cross-correlations without leaking the test set labels. A grid search is performed in the last step, and using the original model outputs allows for calculating independent weights for each time bin. RMSurv method using 5 nested validation sets for model training and testing with final testing for predictive performance. Early and Intermediate Fusion Models To create an early fusion model most analogous to our proposed late fusion model, we use an identical architecture to what is used in the unimodal models for TD-RMSurv. This architecture is the same as described in the “Unimodal Architecture” section, but all modalities are concatenated into 1 input vector which is used as the model input. We also create a Cox-based early fusion model for our high-level comparison. This model is also based on the same unimodal architecture, but the output layer consists of a single risk score, and we utilize the Cox partial likelihood loss function for optimization. In the 3-modal high-level comparison, we use the 3 best-performing modalities for each dataset. For LUAD, we use clinical data, gene expression, and miRNA. For LUAD + LUSC, we use clinical data, miRNA, and pathology reports. For pan-cancer, we use DNA methylation, miRNA, and protein expression. We train intermediate fusion models based on the HFBSurv architecture  12 In both early and intermediate fusion setups, hyperparameters were manually tuned to prevent overfitting. The lack of an automated hyperparameter search is a limitation of this comparison, since early and intermediate multimodal fusion models can be highly sensitive to hyperparameters.  2 Results Late Fusion Simulation Results To show the relationship between cross-modality correlation, unimodal C-index, and combined C-index, we create simulated datasets with 2 sets of risk scores with defined C-indices and Pearson correlations. To represent LUAD + LUSC, we set the first modality C-index to 0.59 and show curves with a varying second modality C-index. In our experiments, the cross-modality correlations usually varied between 0 and .5, with an average of about .2. Figure 8 Figure 8. 2-D linear combination simulation with varying Pearson correlation is presented. In these simulations, the first modality is held at 0.59 C-index, and 4 datasets are generated with the second C-index ranging from 0.53 to 0.59. The relative weights are calculated at 100 points to show the ideal weights at the peak of each curve. The figure on the left, with zero correlation, shows the greatest multimodal advantage. The central figure, with a correlation coefficient of .2, represents the average scenario for the LUAD + LUSC dataset. The figure on the right, with a 0.5 correlation, shows a much smaller multimodal advantage, and no advantage with second modalities below 0.55 C-index. This diagram illustrates a step-by-step guide to conducting multimodal analysis in medical datasets, focusing on breast cancer and lung squamous cell carcinoma (LUSC) from The Cancer Genome Atlas (TCGA). It begins with training unidimensional models across different dataset configurations and calculating C-indices for each validation set. The process continues with averaging these indices, training the models with full sets, and assessing them through Pearson correlation matrices. The aim is to identify the ideal weights for data integration, either through simulation or differential evolution. The final step involves testing the ensemble models with calculated weights to achieve optimal results. This structured approach helps in understanding the influence of correlation between modalities on model performance and in optimizing the multimodal analysis for better predictive accuracy. Unimodal Performance Figure 9 Figure 9. Unimodal performance with 95% confidence interval (CI) is shown for all 3 datasets tested. We train unimodal models using protein expression, miRNA, DNA methylation, gene expression, pathology report PDF embeddings, and clinical data (age, race, gender, stage). The dashed red line marks the minimum predictive performance at C-index = 0.50. The dashed blue line represents the best unimodal model performance. For LUAD and LUAD + LUSC, the strongest unimodal model is clinical data. For the pancancer dataset, which includes 33 cancer types, the strongest unimodal model is DNA methylation. Predictive accuracy of 95% confidence interval (CI) for various medical data types, including protein expression, miRNA, DNA methylation, gene expression, and clinical data like age, race, gender, and stage, with a strong clinical data model for LUAD and LUAD + LUSC, and DNA methylation for pancancer. Late Fusion Experiment Figure 10 Table 3 Figure 10. Comparison of the late fusion methods described above on the TCGA LUAD dataset using all 6 modalities. We test several models with both a single validation set and a full nested cross-validation for weight calculation. The use of 5 validation sets in the nested cross-validation consistently improved C-index by over 0.01. TD-RMSurv and Ad-Hoc (5-val) performed the best and are used in subsequent comparisons. This chart compares the performance of six late fusion methods on the TCGA LUAD dataset with all six modalities, testing various models with both a single validation set and a nested cross-validation for weight calculation. For each method, the 95% confidence interval of the test set C-index is depicted, showing the range within which the true C-index is likely to fall. The data points represent the average C-index values across multiple validation runs. Notably, using 5 validation sets in the nested cross-validation consistently improved the C-index by over 0.01, indicating a more robust and reliable model performance. TD-RMSurv and Ad-Hoc with 5 validation sets emerged as the best performers, and their results are used for further analysis. The chart highlights the impact of the number of validation sets on the accuracy and reliability of the calibration of weights in the model. Table 3. Statistical Comparison of Nested and Single Validation for 6-Modal LUAD. Late fusion strategy Nested cross-validation 1 Validation set Mean difference (bootstrap 95% CI) Paired t p TD-RMSurv 0.6735 0.6647 +0.0088 (+0.0031, +0.0148) .0054 RMSurv 0.6691 0.6597 +0.0093 (+0.0016, +0.0177) .0289 Ad-Hoc 0.6721 0.6601 +0.0120 (+0.0069, +0.0171) .0000 Synthetic weights 0.6658 0.6544 +0.0114 (+0.0032, +0.0200) .0119 Averaged weights 0.6602 0.6446 +0.0156 (+0.0075, +0.0237) .0005 Another surprising result was the relatively strong performance of the Ad-hoc method on LUAD. For this dataset and 6-modal configuration, it outperformed the “averaged weights,” “synthetic weights,” and baseline RMSurv strategies, and performed nearly as well as TD-RMSurv. This is unintuitive since these methods use empirical grid searches for weight calculation that will take correlation and number of modalities into account. One explanation for this is that the Ad-hoc weighting method can be more beneficial on a very small dataset like LUAD because of a lower sensitivity to small differences in C-index and correlation. LUAD can have as few as 30 uncensored test cases, so the C-indices can be highly variable and result in large differences between the validation and test C-indices. Additionally, the inclusion of more informative cases in either the training set or the testing set can result in an inverse relationship between the testing C-index and the average validation C-index. When these conditions are met, the reduced sensitivity of the ad-hoc approach could be more beneficial than the optimized weighting relationship. The baseline time-independent RMSurv method outperformed the ad-hoc method on the 2 larger datasets, which supports this conclusion. This small dataset phenomenon could also explain the poor performance of the “averaged weights” method. Since this approach uses a highly sensitive grid search that uses the model outputs and cross-correlations within each validation fold, instead of only using an average of the validation C-indices, more of the noise from the small dataset is likely preserved, decreasing performance compared to the other strategies. The RMSurv method outperformed the synthetic weights method by a wide margin despite the similar approach. There are a few likely explanations for this difference. First, the synthetic weights method models a single risk score per case using a normal distribution, instead of the 20 discrete outputs of the actual distribution, which maintain their exact time-dependent correlations in RMSurv. Second, the simulation assumes an exponential distribution for survival times, instead of sampling from the training distribution. Finally, the 6-dimensional simulation has small errors between the desired and actual C-indices and correlations. These were not possible to remove completely, likely because C-indices are non-linear parameters, which needed to be modeled as linear correlations and formed into a positive semi-definite covariance matrix. TD-RMSurv (5-val) and the Ad-hoc method (5-val) performed best for LUAD 6-modal, so these 2 strategies are compared in more detail in the “Comparison of TD-RMSurv and Ad-hoc Methods” Section below. Comparison of TD-RMSurv and Methods Figure 11 Tables 4 6 Figure 11. Comparison of the TD-RMSurv and 5 val. ad-hoc weight calculation methods on three datasets. This chart compares performance when using a varying number of modalities. TD-RMSurv outperformed the ad-hoc method overall. Comparative analysis of early fusion versus TD-RMSurv late fusion techniques applied to LUAD dataset. Table 4. Statistical Comparison of TD-RMSurv and Ad-Hoc Methods on LUAD. # of Modalities TD-RMSurv C-index Ad-Hoc mean C-index Mean Difference (bootstrap 95% CI) Paired t p 2 0.6714 0.6712 +0.0002 (−0.0033, +0.0036) .9174 3 0.6728 0.6696 +0.0033 (+0.0007, +0.0059) .0204 4 0.6833 0.6773 +0.0059 (+0.0016, +0.0101) .0091 5 0.6820 0.6747 +0.0073 (+0.0031, +0.0118) .0019 6 0.6735 0.6718 +0.0017 (−0.0029, +0.0063) .4733 Table 5. Statistical Comparison of TD-RMSurv and Ad-Hoc Methods on LUAD + LUSC. # of Modalities TD-RMSurv C-index Ad-Hoc mean C-index Mean Difference (bootstrap 95% CI) Paired t p 2 0.6115 0.6066 +0.0048 (+0.0, +0.0) .0002 3 0.6169 0.6118 +0.0051 (+0.0026, +0.0072) .0002 4 0.6172 0.6098 +0.0074 (+0.0026, +0.0077) .0001 5 0.6189 0.6082 +0.0107 (+0.0041, +0.0108) .0000 6 0.6124 0.6056 +0.0068 (+0.0070, +0.0107) .0010 Table 6. Statistical Comparison of TD-RMSurv and Ad-Hoc Methods on PAN. # of Modalities TD-RMSurv C-index Ad-Hoc mean C-index Mean difference (bootstrap 95% CI) Paired t p 2 0.7367 0.7374 −0.0007 (−0.0014, +0.0001) .1263 3 0.7400 0.7347 +0.0053 (+0.0034, +0.0072) .0005 4 0.7398 0.7353 +0.0045 (+0.0018, +0.0073) .0141 5 0.7526 0.7467 +0.0059 (+0.0036, +0.0080) .0007 6 0.7533 0.7458 +0.0074 (+0.0047, +0.00102) .0007 It is important to note that this is a comparison to an improved version of the existing method which uses fivefold nested cross validation, so the increased performance results solely from the novel weight calculation method. The strong results of TD-RMSurv in this experiment validate the theoretical arguments for correlation-sensitive weight calculation and time-dependent weighting. Both late fusion models in this comparison had a consistent multimodal advantage, meaning none of the multimodal models underperformed the best-performing unimodal models. Comparison of Baseline RMSurv and TD-RMSurv Methods To isolate the effect of time-dependent weighting, we compare the performance of the RMSurv method with and without time-dependent weighting enabled. Tables 7 9 Table 7. Statistical Comparison of TD-RMSurv and Baseline RMSurv Methods on LUAD. # of Modalities TD-RMSurv C-index RMSurv mean C-index Mean difference (bootstrap 95% CI) Paired t p 2 0.6714 0.6672 +0.0042 (−0.0033, +0.0092) .0952 3 0.6728 0.6689 +0.0039 (+0.0002, +0.0077) .0486 4 0.6833 0.6732 +0.0100 (+0.0037, +0.0166) .0042 5 0.6820 0.6712 +0.0109 (+0.0055, +0.0163) .0003 6 0.6735 0.6691 +0.0044 (−0.0019, +0.0110) .1894 Table 8. Statistical Comparison of TD-RMSurv and Baseline RMSurv Methods on LUAD + LUSC. # of Modalities TD-RMSurv C-index RMSurv mean C-index Mean difference (bootstrap 95% CI) Paired t p 2 0.6115 0.6059 +0.0056 (+0.0021, +0.0095) .0048 3 0.6169 0.6116 +0.0053 (+0.0018, +0.0089) .0058 4 0.6172 0.6124 +0.0049 (+0.0003, +0.0098) .0530 5 0.6189 0.6109 +0.0080 (+0.0042, +0.0118) .0002 6 0.6124 0.6057 +0.0067 (+0.0018, +0.0116) .0108 Table 9. Statistical Comparison of TD-RMSurv and Baseline RMSurv Methods on PAN. # of Modalities TD-RMSurv C-index RMSurv mean C-index Mean difference (bootstrap 95% CI) Paired t p 2 0.7367 0.7372 −0.0005 (−0.0013, +0.0003) .3231 3 0.7400 0.7391 +0.0009 (+0.0026, +0.0014) .0092 4 0.7398 0.7456 −0.0058 (−0.0112, −0.0011) .0645 5 0.7526 0.7525 +0.0001 (−0.0014, +0.0012) .9415 6 0.7533 0.7528 +0.0005 (−0.0003, +0.0013) .2762 Interpretation of Calculated Weights A comparison of the calculated weights of these models can help explain some of the differences in performance. The increased sensitivity of RMSurv is visible in the calculated weights shown in Figure 12 Figure 12. Comparison of calculated weights is shown for LUAD + LUSC seed 10 fold 5. Comparative heatmap of weights over time for multi-omic data in a study on LUAD + LUSC, highlighting contributions and changes across five time points. The weights of the TD-RMSurv model allow the user to interpret the influence of each modality over time. The model assigned a 90% weight to the clinical data for the first time bin and disregarded most of the other modalities. The clinical weighting then decreased to near zero until years 7 to 10. Since the survival prediction is calculated as the cumulative sum of 1-hazard, each subsequent survival prediction will depend on the prediction of the first time bin, which represents the likelihood of survival in the first 6 months. A likely explanation for this is the cancer stage feature, which will be highly predictive for short-term survival. Once the patient survives the first 6 months, other modalities and features become more predictive of the conditional survival. Another interesting change is that the protein modality is now included at certain time bins, where it can improve performance without introducing noise in years 0 to 3. The time-variant relationships were much more subtle on the larger pan-cancer dataset. The calculated weights for this dataset are shown below in Figure 13 Figure 13. Calculated Weights (TD-RMSurv) for the TCGA pan-cancer dataset for seed 1 fold 5. Calculated Weights (TD-RMSurv) for the TCGA pan-cancer dataset for seed 1 fold 5. Early Fusion Comparison In this section, we compare our TD-RMSurv model to an early fusion model with a range of modalities. For our early fusion model, the inputs for each modality are concatenated into 1 vector, and the model uses the same discrete architecture as the unimodal models used in our late fusion models. TD-RMSurv late fusion shows a dramatic improvement in performance and robustness compared to the discrete early fusion model. Figure 14 Figure 14. Comparison between early fusion (left) and TD-RMSurv late fusion (right) results for the LUAD dataset. Comparison between early fusion (left) and TD-RMSurv late fusion (right) results for the LUAD +LUSC dataset. Figure 15 Figure 15. Comparison between early fusion (left) and TD-RMSurv late fusion (right) results for the LUAD + LUSC dataset. Comparison between early fusion (left) and TD-RMSurv late fusion (right) results for the pancancer dataset. 16 words Figure 16 Figure 16. Comparison between early fusion (left) and TD-RMSurv late fusion (right) results for the pan-cancer dataset. This is a comparative analysis of four different multimodal fusion methods applied to Long Usable Cancer Diagram (LUAD). The graphs compare the performance of these methods, ranking them based on the minimum 5 modalities on the left and considering all 6 modalities on the right. Two key lines are marked: a red dashed line indicating the minimum predictive performance with a Concordance Index (C-index) of 0.50, and a blue dashed line showing the best performance of unimodal models. Each point on the graph represents the average C-index from 10 separate cross-validation trials, accompanied by a 95% confidence interval. High-Level Fusion Method Comparison In this section, we provide a broader comparison to demonstrate the differences in performance between Cox and discrete models, and early, intermediate, and late fusion models. TD-RMSurv outperforms these alternative methods by a wide margin. The discrete early and intermediate fusion models were competitive with late fusion when using the best 3 modalities; however, they sometimes underperformed the unimodal clinical model when using all 6 modalities. The Cox-based models underperformed the discrete models significantly across all 3 datasets. Figure 17 Figure 17. Comparison of multimodal fusion strategies on LUAD. Left: Best 3 modalities. Right: all 6 modalities. The dashed red line indicates the minimum predictive performance at a C-index of 0.50, while the dashed blue line represents the optimal unimodal model performance. The C-index is calculated with 10 cross-validation runs and shown with a 95% confidence interval. Compare fusion modes: 5 vs. 24 on diagnostic tests for brain tumors. Use 5 or 29 modes? 5-vs-59, 24-vs-59 C-indices: Red dashed is predictive threshold C-index: 0.50. Blue dashed line refers to C-indices for separate modality, 5 and 24, alone. For LUAD + LUSC, as shown in Figure 18 Figure 18. Comparison of multimodal fusion strategies on LUAD + LUSC. Left: Best 3 modalities. Right: all 6 modalities. The dashed red line marks the minimum predictive performance at C-index = 0.50, while the dashed blue line represents the best unimodal model performance. The C-index is calculated with 10 crossvalidation runs and shown with a 95% confidence interval. Comparison of multimodal fusion strategies on LUAD + LUSC. Left: Best 3 modalities. Right: all 6 modalities. The dashed red line marks the minimum predictive performance at C-index = 0.50, while the dashed blue line represents the best unimodal model performance. The C-index is calculated with 10 crossvalidation runs and shown with a 95% confidence interval. The Cox-based models underperformed for this dataset as well, and the TD-RMSurv outperformed early and intermediate fusion by a wide margin in the 3- modal and 6-modal settings. Finally, Figure 19 Figure 19. Comparison of multimodal fusion strategies on the pan-cancer dataset. Left: Best 3 modalities. Right: all 6 modalities. The dashed red line indicates the minimum predictive performance at a C-index of 0.50, and the dashed blue line represents the optimal unimodal model performance. The C-index is calculated with a single cross-validation and shown with a 95% confidence interval. The image compares three multimodal fusion strategies (Late Fusion, Early Fusion, and Information Fusion) using two tests (Test Set C-Index - PAN 3-Modal and Test Set C-Index - PAN 6-Modal) across the pan-cancer dataset with 3 and 6 modalities respectively. The dashed red line indicates the minimum predictive performance at a C-index of 0.50, while the dashed blue line represents the optimal unimodal model performance. The C-index is calculated with a single cross-validation and is shown with a 95% confidence interval. Kaplan-Meier Analysis We validate the robustness of this system through the Kaplan Meier analysis shown in Figure 20 Figure 20. Kaplan Meier Curves showing risk terciles for the 6-modal configuration of TD-RMSurv on the pan-cancer dataset for the test set of seed 1, fold 1 (C-index = 0.7459). This image of Kaplan-Meier Curves illustrates the survival probabilities over 30 years since baseline for patients classified into three categories: low risk, medium risk, and high risk. Discussion We found that the TD-RMSurv late fusion method consistently outperformed all unimodal models and multimodal fusion alternatives. We also noticed a consistent improvement by using 5 nested validation sets instead of just 1 validation set for late fusion. Furthermore, other late fusion methods like synthetic weights, ad-hoc, and baseline RMSurv also outperformed the early and intermediate fusion models. Early and intermediate fusion methods necessarily weight modalities based on the combined training-set accuracy, and therefore often overfit to weaker modalities. Late fusion can correct for this, because the errors from individual models tend to be uncorrelated in an ensemble.  1 14 19  16 The increased performance of time-dependent modeling is demonstrated in both the discrete multimodal advantage and the time-dependent weighting advantage. The discrete survival models outperformed the Cox Proportional Hazards models across the datasets, and TD-RMSurv also outperformed baseline RMSurv across all datasets. The weights for TD-RMSurv shown in Figure 12 Our late fusion simulation proves that the modality combination relationship is much more complicated than simply comparing modalities based on their C-index. The true relationship is dependent on the C-index, correlation, and number of modalities. The RMSurv and TD-RMSurv strategies take advantage of this complex relationship, which is likely why they perform better than the ad-hoc method overall. The pathology report modality was one of the weaker modalities, but its inclusion modestly increased performance on the LUAD + LUSC and pan-cancer datasets when using TD-RMSurv. It is a promising area of research, especially as language models continue to improve. RMSurv provides a robust multimodal advantage over unimodal models, which is an important step toward the clinical relevance of multimodal survival models. The late fusion approach also allows for easy integration of 6+ modalities, which may require different architectures. For the pan-cancer dataset, TD-RMSurv performed best when using all 6 modalities, which is a step toward including even more modalities on larger datasets. For the LUAD and LUAD + LUSC datasets, performance peaked when including 4 and 5 modalities, respectively. This lack of perfect robustness can be explained by our simulation results, which show that very low performing modalities fundamentally cannot add any signal to a combined prediction for datasets with non-zero correlations. In a very small dataset with high variance, these modalities will occasionally receive some weight when they should be assigned no weight, and the combined performance will decrease. Despite this, TD-RMSurv showed a robust multimodal advantage in all configurations, contrasting the unpredictable performance of the early and intermediate fusion methods. There is significant potential to improve on this work in the future. This study provides a strong proof of concept with 3 datasets of various sizes, but a broader comparison with many more cancer types is needed to better understand the limitations, especially on very small datasets. Future implementations could also add histopathology slides, MRI scans, and treatment regimes to combine with existing modalities in late fusion. The pathology report modality introduced in this study also presents an opportunity to add several new text-based modalities such as clinical notes, laboratory tests, and more clinical data features. The architecture of TD-RMSurv could also be improved by varying or increasing the resolution of time bins. By adding 1-month time bins for the first 6 months, for example, we could replace the large jumps in modality weighting between time bins with a more gradual and accurate representation. The multimodal performance of this method, and the clinical utility, is still limited by unimodal performance, so much larger datasets and optimal unimodal architectures for each modality will be needed to outperform traditional prognoses. Future applications should also consider cases where interactions between features across modalities are important. Late fusion cannot model these interactions, so combining certain modalities into early or intermediate fusion sub-models could be beneficial. Beyond model performance, several other challenges remain for prospective clinical application. Improved datasets or corrective adjustments to survival time sampling will be necessary to account for censoring, which can bias the model toward lower or higher survival probability depending on if the censored cases are included in the training set. Model interpretability for a clinical setting is significantly improved with the proposed method, which can show the normalized survival predictions and relative weights assigned to each modality, but each unimodal model is still a black box in this setup. A future architecture with interpretability at both the unimodal feature level and late fusion output level could be a valuable clinical tool. Finally, cohorts of cases, which would be used as the training set in prospective studies, will change significantly over time as the laboratory tests, recording procedures, environment, treatment methods, and mean overall survival shift. The RMSurv approach will allow for the modeling of the true cross-modality correlations and feature distributions of the prospective test-set, but the underlying C-indices of each modality in the training set would be based on potentially outdated cohorts with stronger or weaker modalities. A system to interpret the changes and uncertainty of modalities could improve the robustness significantly. Conclusions In summary, this study highlights the complex relationships within multimodal cancer survival prediction, and introduces the RMSurv model, which uses synthetic data generation, time-dependent weighting, and a novel normalization process. This robust and interpretable system advances the progress toward clinical use of machine learning based survival prediction, even with small datasets. Supplemental Material sj-pdf-1-cix-10.1177_11769351251376192 – Supplemental material for Robust Multimodal Fusion for Survival Prediction in Cancer Patients Supplemental material, sj-pdf-1-cix-10.1177_11769351251376192 for Robust Multimodal Fusion for Survival Prediction in Cancer Patients by Dominic Flack, Aakash Tripathi, Asim Waqas, Ghulam Rasool and Dimah Dera in Cancer Informatics ORCID iDs: https://orcid.org/0009-0006-4083-5709 Dimah Dera https://orcid.org/0000-0002-7168-5858 Ethical Considerations: Consent to Participate: Consent for Publication: Author Contributions: Funding: The authors declared the following potential conflicts of interest with respect to the research, authorship, and/or publication of this article: The views expressed are those of the authors and do not reflect the official guidance or position of the United States Government, the Department of Defense, the United States Air Force, or the United States Space Force. Data Availability Statement: https://xenabrowser.net/datapages/ https://github.com/lab-rasool/MINDS Supplemental Material: References 1 Lipkova J Chen RJ Chen B et al Artificial intelligence for multimodal data integration in oncology Cancer Cell 2022 40 1095 1110 36220072 10.1016/j.ccell.2022.09.012 PMC10655164 2 Waqas A Tripathi A Ahmed S. SeNMo: a self-normalizing deep learning model for enhanced multi-omics data analysis in oncology arXiv: 2405.08226 2024 3 Cox D. Regression models and life-tables J R Stat Soc Ser B 1972 34 187 220 4 Vale-Silva LA Rohr K. Long-term cancer survival prediction using multimodal deep learning Sci Rep 2021 11 13505 34188098 10.1038/s41598-021-92799-4 PMC8242026 5 Luo H Huang J Ju H Zhou T Ding W. Multimodal multi-instance evidence fusion neural networks for cancer survival prediction Sci Rep 2025 15 10470 40140434 10.1038/s41598-025-93770-3 PMC11947308 6 Gomaa A Huang Y Hagag A et al Comprehensive multimodal deep learning survival prediction enabled by a transformer architecture: a multicenter study in glioblastoma Neurooncol Adv 2024 6 10.1093/noajnl/vdae122 PMC11327617 39156618 7 Yang H Wang J Wang W et al MMsurv: a multimodal multi-instance multi-cancer survival prediction model integrating pathological images, clinical information, and sequencing data Brief Bioinform 2025 26 10.1093/bib/bbaf209 PMC12077396 40366860 8 Chen RJ Lu MY Williamson DF et al Pan-cancer integrative histology-genomic analysis via interpretable multimodal deep learning Cancer Cell 2022 40 10.1016/j.ccell.2022.07.004 PMC10397370 35944502 9 Nikolaou N Salazar D RaviPrakash H et al A machine learning approach for multimodal data fusion for survival prediction in cancer patients NPJ Precis Oncol 2025 9 128 40325104 10.1038/s41698-025-00917-6 PMC12053085 10 Ching T Zhu X Garmire LX. Cox-nnet: an artificial neural network method for prognosis prediction of high-throughput omics data PLoS Comput Biol 2018 14 10.1371/journal.pcbi.1006076 PMC5909924 29634719 11 Chen RJ Lu MY Wang J et al Pathomic fusion: an integrated framework for fusing histopathology and genomic features for cancer diagnosis and prognosis IEEE Trans Med Imaging 2022 41 757 770 32881682 10.1109/TMI.2020.3021387 PMC10339462 12 Li R Wu X Li A Wang M. HFBSurv: hierarchical multimodal fusion with factorized bilinear models for cancer survival prediction Bioinformatics 2022 38 2587 2594 35188177 10.1093/bioinformatics/btac113 PMC9048674 13 Steyaert S Pizurica M Nagaraj D et al Multimodal data fusion for cancer biomarker discovery with deep learning Nat Mach Intell 2023 5 4 351 362 37693852 10.1038/s42256-023-00633-5 PMC10484010 14 Stahlschmidt SR Ulfenborg B Synnergren J. Multimodal deep learning for biomedical data fusion: a review Brief Bioinform 2022 23 2 10.1093/bib/bbab569 PMC8921642 35089332 15 Higham NJ. Computing the nearest correlation matrix–a problem from finance IMA J Numer Anal 2002 22 329 343 16 Weinstein JN Collisson EA Mills GB et al The Cancer Genome Atlas Pan-Cancer analysis project Nat Genet 2013 45 1113 1120 24071849 10.1038/ng.2764 PMC3919969 17 Liu J Lichtenberg T Hoadley KA et al An integrated TCGA pan-cancer clinical data resource to drive high-quality survival outcome analytics Cells 2018 173 10.1016/j.cell.2018.02.052 PMC6066282 29625055 18 Moore L Le T Fan G. DNA methylation and its basic function Neuropsychopharmacology 2013 38 23 38 22781841 10.1038/npp.2012.112 PMC3521964 19 Akbani R Ng PK Werner HM et al A pan-cancer proteomic perspective on the Cancer Genome Atlas Nat Commun 2014 5 3887 24871328 10.1038/ncomms4887 PMC4109726 20 Goldman MJ Craft B Hastie M et al Visualizing and interpreting cancer genomics data via the Xena platform Nat Biotechnol 2020 38 675 678 32444850 10.1038/s41587-020-0546-8 PMC7386072 21 Tripathi A Waqas A Venkatesan K Yilmaz Y Rasool G. Building flexible, scalable, and Machine Learning-ready multimodal oncology datasets Sensors 2024 24 1634 38475170 10.3390/s24051634 PMC10933897 22 Moons K Collins G Reitsma J. TRIPOD+AI statement: updated guidance for reporting clinical prediction models that use regression or machine learning methods BMJ 2024 385 10.1136/bmj-2023-078378 PMC11019967 38626948 23 Tripathi A Waqas A Yilmaz Y Rasool G. HoneyBee: a scalable modular framework for creating multimodal oncology datasets with foundational embedding models arXiv: 2405.07460 2024 24 Yang X Chen A PourNejatian N. GatorTron: a large clinical language model to unlock patient information from unstructured electronic health records arXiv: 2203.03540 2022 25 Chen R Ding T Lu M A general-purpose self-supervised model for computational pathology arXiv: 2308.15474 2023 26 Storn R Price K. Differential evolution – a simple and efficient heuristic for global optimization over continuous spaces J Glob Optim 1997 11 341 359 27 Park S Park J Park S Kim H. Review of statistical methods for evaluating the performance of survival prediction models Korean J Radiol 2021 22 213 224 34269532 10.3348/kjr.2021.0223 PMC8484151 ",
  "metadata": {
    "Title of this paper": "Review of statistical methods for evaluating the performance of survival prediction models",
    "Journal it was published in:": "Cancer Informatics",
    "URL": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC12476512/"
  }
}