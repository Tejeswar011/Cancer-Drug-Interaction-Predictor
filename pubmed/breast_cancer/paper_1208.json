{
  "title": "Paper_1208",
  "abstract": "pmc Diagnostics (Basel) Diagnostics (Basel) 2841 diagno diagnostics Diagnostics 2075-4418 Multidisciplinary Digital Publishing Institute  (MDPI) PMC12468874 PMC12468874.1 12468874 12468874 41008751 10.3390/diagnostics15182379 diagnostics-15-02379 1 Article Improving the Detection Performance of Cardiovascular Diseases from Heart Sound Signals with a New Deep Learning-Based Approach https://orcid.org/0000-0001-8245-0117 Safak Ozgen Conceptualization Investigation Resources Project administration 1 Hekim Mehmet Tolga Conceptualization Validation Formal analysis Resources 1 https://orcid.org/0000-0002-4981-5521 Cakmak Tolga Conceptualization Formal analysis Data curation 2 https://orcid.org/0000-0003-3210-3664 Demir Fatih Methodology Software Writing – original draft Writing – review & editing 3 * https://orcid.org/0000-0003-3408-3505 Demir Kursat Methodology Software Writing – review & editing 4 Chen Dechang Academic Editor 1 ozgen_safak@yahoo.com tolgahekim@yahoo.com 2 tolgacakmak85@gmail.com 3 4 kursatdemir62@gmail.com * fatihdemir@firat.edu.tr 18 9 2025 9 2025 15 18 497628 2379 26 8 2025 15 9 2025 16 9 2025 18 09 2025 27 09 2025 29 09 2025 © 2025 by the authors. 2025 https://creativecommons.org/licenses/by/4.0/ Licensee MDPI, Basel, Switzerland. This article is an open access article distributed under the terms and conditions of the Creative Commons Attribution (CC BY) license ( https://creativecommons.org/licenses/by/4.0/ Background/Objectives Methods Results Conclusions cardiovascular diseases PCG signals RAMM model NRBMI algorithm Fırat University BAP Coordinatorship MF.25.70 This research was funded by the Fırat University BAP Coordinatorship with the project code MF.25.70. pmc-status-qastatus 0 pmc-status-live yes pmc-status-embargo no pmc-status-released yes pmc-prop-open-access yes pmc-prop-olf no pmc-prop-manuscript no pmc-prop-legally-suppressed no pmc-prop-has-pdf yes pmc-prop-has-supplement no pmc-prop-pdf-only no pmc-prop-suppress-copyright no pmc-prop-is-real-version no pmc-prop-is-scanned-article no pmc-prop-preprint no pmc-prop-in-epmc yes 1. Introduction According to WHO (2023), more than 70% of deaths worldwide are caused by noncommunicable diseases, such as cardiovascular disease. Over three-quarters of these deaths occur in low- and middle-income countries [ 1 2 Heart sound signals, produced when heart valves open and close during the cardiac cycle, carry rich physiological information [ 3 4 5 6 7 8 Researchers first used conventional techniques such as wavelet transforms and filters for feature learning. However, these methods have limitations in detecting complex heart sound patterns. Francesco Renna et al. [ 5 9 10 11 To create temporal and time–frequency features, Nia et al. [ 6 12 Researchers have started using CNN for heart sound feature extraction as deep learning has grown in popularity. A deep learning model that extracts special characteristics in the time axis was built by Christian Thomae et al. [ 13 14 15 16 A general review of the literature reveals numerous machine learning-based studies on the detection of cardiovascular diseases from PCG signals. The vast majority of these recent studies involve deep learning models. The purpose of using these models is to improve classification performance. The 2016 PhysioNet/CinC Challenge dataset, which contains PCG signals, was chosen for the present study. This dataset is a popular dataset with over 19,000 citations. The methodological contributions of the proposed approach are as follows: - By converting raw PCG signals into spectrogram images, the data’s representativeness is increased in the frequency and time domains. Furthermore, it becomes possible to work with two-dimensional deep learning models. - Strong deep features are extracted from a specialized MLP-Mixer structure, where attention and residual structures can work in parallel. - A hybrid feature selection algorithm combining the strengths of NCA and ReliefF structures is used, thus improving classification performance. The added value of the NCA- and ReliefF-Based Matching Indexing (NRBMI) lies not in introducing an entirely new algorithm but in its intersection-based validation strategy. By requiring features to be simultaneously important according to NCA and ReliefF, NRBMI minimizes noise and irrelevant variables, resulting in improved generalization and more balanced classification performance. Although spectrogram transformation, attention mechanisms, residual connections, MLP-Mixer structures, feature selection methods, and SVM classifiers have each been employed individually in prior studies, the novelty of this work lies in the systematic integration of these components into a single framework. By combining these complementary elements, our approach leverages both time–frequency representations and advanced deep feature extraction strategies, leading to a more robust and balanced classification performance compared to existing methods. 2. Materials and Methods Encouraging the creation of algorithms to categorize heart sound recordings taken from various clinical or nonclinical (such as in-home visits) settings is the goal of the 2016 PhysioNet/CinC Challenge [ 17 Figure 1 The proposed strategy includes five stages. Figure 2 Figure 3 A spectrogram is a two-dimensional representation of a signal’s frequency content, which varies over time. Time information is displayed on the horizontal axis, and frequency information is displayed on the vertical axis [ 18 19 Heart sounds such as S1, S2, and murmurs are short-lived signals with characteristic frequency components. While classical FFTs cannot show their time distribution, spectrograms can. This allows the following: - Time and frequency resolution can be achieved simultaneously. - Differences in duration, interval, and intensity of heart sounds can be visualized. - Pathological conditions such as murmurs can be distinguished by their frequency patterns. Deep learning models can process these 2D images for classification or anomaly detection. In Figure 3 Figure 4 Residual structures were first introduced with the ResNet architecture [ 20 21 The model may concentrate on significant portions of the input data thanks to the attention mechanism. This is an essential component of contemporary AI models like Vision Transformer (ViT), CNN, BERT, and Transformer. Deep learning models benefit greatly from the attention mechanism. Each input’s contribution is dynamically weighted in attention structures. For instance, the model focuses more on a keyword in a sentence or a particular object in a picture. Relationships between data can be efficiently modeled by the attention mechanism, particularly when dealing with sequential data. This offers a major benefit over LSTMs and RNNs. Attention structures, as opposed to RNNs, facilitate parallel processing, which enables quicker GPU training and inference. The interpretability of model decisions is improved by visualizing the attention weights, which makes it easier to see what the model is concentrating on. MLP-Mixer is a notable visual classification model proposed by Google in 2021. Unlike conventional CNN and Transformer structures, it uses only multi-layer perceptrons (MLPs). In this respect, it offers an innovative approach [ 22 23 The proposed RAMM model combines these three important structures into a single model, making significant contributions to improving classification performance. - Parallel and simultaneous training extracts both residual structural information and attention contextual information on the same input. This provides a richer representation. - Connecting the residual and attention outputs to the MLP-Mixer allows mixing of this rich feature set at both the spatial and intra-channel levels. - Because the features from the residual and attention models are activated by the ReLU layer, the model converges more stably and quickly. NCA- and ReliefF-Based Matching Indexing (NRBMI) Algorithm NCA is an algorithm developed by Jacob Goldberger and Geoffrey Hinton in 2005 [ 24 25 A ∈ R m × d m d j i (1) p i j = e − A x i − A x j 2 ∑ k ≠ i e − A x i − A x k 2 Here, k i (2) f A = ∑ i ∑ j  ∈  s a m e  c l a s s p i j Using feature weights, the ReliefF algorithm generates effective feature predictions. The convex optimization problem is solved to get the feature weights [ 26 27 28 (3) W ( x a ) = W ( x a ) − ∑ j = 1 k d i f f ( A , R i , H j ) m x k + ∑ c ≠ c l a s s R i P C 1 − P ( c l a s s ( R i ) ) x ∑ j = 1 k d i f f ( A , R i , M j ) m x k ( x a ) A R i H j k In the developed NCA- and ReliefF-Based Matching Indexing (NRBMI) algorithm, feature indices are first ranked according to the weights calculated by the ReliefF and NCA techniques. The index values of the feature data with the optimum “x” weights provided from the ReliefF and NCA methodologies are compared. The features with matching index values constitute the output of the NRBMI algorithm (see Algorithm 1). The strength of the NRBMI algorithm lies in its dual-perspective validation of feature importance. By combining NCA’s classification-driven feature ranking with ReliefF’s distance-based relevance assessment, NRBMI selects only the features deemed important by both methods. This intersection-based strategy reduces noise, prevents irrelevant feature inclusion, improves generalization, and yields a more compact yet highly informative feature subset. Algorithm 1. Input:  Dataset D with features F = {f1, f2, …, fn}  Labels Y  Parameter x //number of top features to select from each method Output:  Selected feature set S Steps: 1. Compute feature weights using NCA:  W_NCA = NCA_Weights(D, Y)  //W_NCA is an array of length n with importance scores 2. Sort features by W_NCA in descending order:  Sorted_NCA = sort_indices_by_weight(W_NCA, descending=True) 3. Select top x feature indices from NCA results:  Top_NCA_Indices = first_x_indices(Sorted_NCA, x) 4. Compute feature weights using ReliefF:  W_ReliefF = ReliefF_Weights(D, Y)  //W_ReliefF is an array of length n with importance scores 5. Sort features by W_ReliefF in descending order:  Sorted_ReliefF = sort_indices_by_weight(W_ReliefF, descending=True) 6. Select top x feature indices from ReliefF results:  Top_ReliefF_Indices = first_x_indices(Sorted_ReliefF, x) 7. Find matching feature indices between NCA and ReliefF selections:  Matching_Indices = intersection(Top_NCA_Indices, Top_ReliefF_Indices) 8. Select features corresponding to Matching_Indices from D:  S = { f_i | i Matching_Indices } 9. Return S 3. Results All coding was performed in MATLAB 2024a on a Windows 11 PC with an Intel i9 processor, 12 GB RAM, and an RTX 3080ti GPU. Spectrogram images were generated to train the RAMM model. Hamming was used for windowing to create the spectrogram images, and the size was set to 400. The overlap value and FFT size were set to 50. Normalization was performed only in the frequency domain and applied as pi./[samples]. Furthermore, all images were resized to 200 × 200. The total number of learnable parameters of the RAMM model is 582k, and the parameter memory size of the model is 2.13 MB. This indicates that the RAMM model is approximately seven times lighter than MobileNetV2, one of the lightest CNN models. The proposed RAMM model was trained for feature extraction. For training settings, the optimizer, epoch, and learning rate were set to SGDM, 50, and 0.001, respectively. The validation method employed was 10-fold cross-validation, and the loss function was cross-entropy. The accuracy and loss change graphs of the RAMM model during the 9900 iteration training process are given in Figure 5 Figure 6 Figure 5 Figure 6 Next, 1000 features were extracted from the last ReLU layer of the RAMM model. Their importance weights were calculated with both the NCA and ReliefF algorithms, and the NRBMI algorithm was applied for feature selection. The importance weights of these extracted features were calculated by both the NCA and ReliefF algorithms. The results of the calculated importance weights are given in Figure 7 Figure 7 Figure 7 Figure 8 Figure 8 Table 1 Table 1 In the study, no resampling techniques were applied to address the class imbalance (2725 healthy vs. 816 unhealthy). Instead, 10-fold cross-validation was employed, and additional performance metrics such as sensitivity, specificity, precision, and F1-score were reported to mitigate the impact of imbalance. Furthermore, the NRBMI feature selection algorithm contributed to balanced performance across both classes by prioritizing highly discriminative features. Also, the confusion matrix results of many experiments are given to clearly show the imbalance between class numbers. To increase the reliability of the proposed approach, the 10-fold cross-validation technique was run 40 times. The validation accuracy results are given in Table 2 4. Discussion This section presents ablation studies to show the effectiveness of the proposed approach and compares it with other methods using the same dataset. The first ablation study was conducted to demonstrate the effectiveness of spectrogram images. In this study, training was conducted on the RAMM model using the training options. Because the raw data is a one-dimensional signal, the layers in the RAMM model were transformed to operate in one dimension. Under these conditions, the training and validation accuracy changes obtained during the 9900 training iterations are presented in Figure 9 Figure 10 The experimental results obtained in Figure 11 Table 2 Figure 11 Figure 11 Figure 11 Figure 11 Figure 11 Table 2 Together, Figure 11 Table 3 Table 4 29 30 1 31 32 33 34 Although the proposed method offers high accuracy, this study has some limitations. First, the 2016 PhysioNet/CinC Challenge dataset used was collected under controlled conditions, and performance may suffer from noisy, incomplete, or low-quality data in real-world scenarios. In the future, environmental noise, device variations, and patient motion—especially in heart sounds recorded at home or in busy clinical settings—may pose significant challenges to the model. Furthermore, the high computational requirements of deep learning-based models may limit their application on portable devices or low-cost hardware. In this context, the development of lighter models or model compression/optimization techniques is crucial. Furthermore, issues such as patient privacy, data security, and the ethical responsibility of AI-based decisions should be considered in the widespread use of clinical decision support systems. Future studies should focus on developing new methods that address these limitations and validate them with multicenter, real-world patient data. For the proposed approach to be effectively used in clinical applications, digital stethoscopes capable of transmitting recordings via radio waves are required. Data collected from these stethoscopes can be transmitted to AI servers. After evaluation on these servers, it can be sent to mobile and web applications via cloud-based systems. Device sensitivity and patient diversity during data acquisition may pose challenges to the general validity of the proposed model. To prevent this, training and testing with new datasets must be conducted with clinical validation. Experimental results of the proposed approach demonstrate that the main contribution of this study is not the introduction of entirely new modules but rather the effective integration of spectrogram-based representations, residual and attention mechanisms, MLP-Mixer structures, and a hybrid feature selection strategy within a unified pipeline. This integration allows the strengths of each component to complement one another, resulting in improved generalization and balanced performance across classes. Thus, the novelty of our approach lies in the synergy achieved through the combined use of these well-established techniques. 5. Conclusions Heart sounds are an important data source for diagnosing heart conditions. However, expert interpretation is needed for accurate interpretation of this data. Artificial intelligence-powered applications that automate these interpretations are needed for early diagnosis. Therefore, this study was conducted on the popular 2016 PhysioNet/CinC Challenge dataset. The proposed lightweight RAMM model extracted highly discriminatory features. Highly representative features were selected using the newly developed NRBMI algorithm. The popular and powerful SVM algorithm was used for classification. The proposed approach achieved over 98% success in all metrics: accuracy, sensitivity, specificity, precision, and F1-score. Detailed experimental studies were conducted to demonstrate the effectiveness of the techniques used in the proposed approach. Performance comparisons were also conducted with other studies using the PhysioNet/CinC Challenge dataset. While the proposed model achieved high accuracy within the PhysioNet/CinC dataset, this performance is limited to 10-fold cross-validation. Therefore, further validation on independent datasets and prospective clinical studies is necessary before the model can be translated into real-world clinical practice. As a result, a highly reliable decision support system has been developed. Future tests with real-world data are planned after obtaining the necessary ethics committee approvals. This software application may also be adapted to wearable technologies in the future. Disclaimer/Publisher’s Note: Author Contributions Conceptualization, F.D. and K.D.; methodology, F.D.; software, F.D.; validation, O.S., M.T.H. and T.C.; formal analysis, O.S.; investigation, T.C.; resources, M.T.H.; data curation, O.S.; writing—original draft preparation, F.D.; writing—review and editing, K.D.; visualization, T.C.; supervision, M.T.H.; project administration, O.S.; funding acquisition, F.D. All authors have read and agreed to the published version of the manuscript. Institutional Review Board Statement Not applicable. Informed Consent Statement Not applicable. Data Availability Statement The original data presented in the study are openly available in https://www.kaggle.com/datasets/swapnilpanda/heart-sound-database Conflicts of Interest The authors declare no conflicts of interest. References 1. Xiao F. Liu H. Lu J. A New Approach Based on a 1D + 2D Convolutional Neural Network and Evolving Fuzzy System for the Diagnosis of Cardiovascular Disease from Heart Sound Signals Appl. Acoust. 2024 216 109723 10.1016/j.apacoust.2023.109723 2. Sajeev J.K. Kalman J.M. Dewey H. Cooke J.C. Teh A.W. The Atrium and Embolic Stroke: Myopathy Not Atrial Fibrillation as the Requisite Determinant? Clin. Electrophysiol. 2020 6 251 261 10.1016/j.jacep.2019.12.013 32192674 3. Khan M.U. Mushtaq Z. Shakeel M. Aziz S. Naqvi S.Z.H. Classification of Myocardial Infarction Using MFCC and Ensemble Subspace KNN Proceedings of the 2nd International Conference on Electrical, Communication and Computer Engineering, ICECCE 2020 Istanbul, Turkey 12–13 June 2020 IEEE New York, NY, USA 2020 1 5 4. Demir F. Sengür A. Bajaj V. Polat K. Towards the Classification of Heart Sounds Based on Convolutional Deep Neural Network Health Inf. Sci. Syst. 2019 7 16 10.1007/s13755-019-0078-0 31428314 PMC6684704 5. Renna F. Oliveira J. Coimbra M.T. Deep Convolutional Neural Networks for Heart Sound Segmentation IEEE J. Biomed. Health Inform. 2019 23 2435 2445 10.1109/JBHI.2019.2894222 30668487 6. Sadeghi Nia P. Danandeh Hesar H. Abnormal Heart Sound Detection Using Time-Frequency Analysis and Machine Learning Techniques Biomed. Signal Process. Control 2024 90 105899 10.1016/j.bspc.2023.105899 7. Petmezas G. Haris K. Stefanopoulos L. Kilintzis V. Tzavelis A. Rogers J.A. Katsaggelos A.K. Maglaveras N. Automated Atrial Fibrillation Detection Using a Hybrid CNN-LSTM Network on Imbalanced ECG Datasets Biomed. Signal Process. Control 2021 63 102194 10.1016/j.bspc.2020.102194 8. Latifoğlu F. Zhusupova A. İnce M. Ertürk N.A. Özdet B. İçer S. Güven A. Avşaroğulları Ö.L. Keleşoğlu Ş. Kalay N. Preliminary Study Based on Myocardial Infarction Classification of 12-Lead Electrocardiography Images with Deep Learning Methods Eur. J. Res. Dev. 2024 4 42 54 10.56038/ejrnd.v4i1.421 9. Deperlioglu O. Heart Sound Classification with Signal Instant Energy and Stacked Autoencoder Network Biomed. Signal Process. Control 2021 64 102211 10.1016/j.bspc.2020.102211 10. Mei N. Wang H. Zhang Y. Liu F. Jiang X. Wei S. Classification of Heart Sounds Based on Quality Assessment and Wavelet Scattering Transform Comput. Biol. Med. 2021 137 104814 10.1016/j.compbiomed.2021.104814 34481179 11. Akram M.U. Shaukat A. Hussain F. Khawaja S.G. Butt W.H. Analysis of PCG Signals Using Quality Assessment and Homomorphic Filters for Localization and Classification of Heart Sounds Comput. Methods Programs Biomed. 2018 164 143 157 10.1016/j.cmpb.2018.07.006 30195422 12. Gamboa-Cruzado J. Crisóstomo-Castro R. Vila-Buleje J. López-Goycochea J. Valenzuela J.N. Heart Attack Prediction Using Machine Learning: A Comprehensive Systematic Review and Bibliometric Analysis J. Theor. Appl. Inf. Technol. 2024 102 1930 1944 13. Thomae C. Dominik A. Using Deep Gated RNN with a Convolutional Front End for End-to-End Classification of Heart Sound Proceedings of the Computing in Cardiology Vancouver, BC, Canada 11–14 September 2016 IEEE New York, NY, USA 2016 Volume 43 625 628 14. Chakraborty D. Bhattacharya S. Thakur A. Gosthipaty A.R. Datta C. Feature Extraction and Classification of Phonocardiograms Using Convolutional Neural Networks Proceedings of the 2020 IEEE International Conference for Convergence in Engineering, ICCE 2020—Proceedings Kolkata, India 5–6 September 2020 IEEE New York, NY, USA 2020 275 279 15. Li Y. Xia Y. Atrial Fibrillation Detection with Signal Decomposition and Dilated Residual Neural Network Physiol. Meas. 2023 44 105001 10.1088/1361-6579/acfa61 37714186 16. Riccio D. Brancati N. Sannino G. Verde L. Frucci M. CNN-Based Classification of Phonocardiograms Using Fractal Techniques Biomed. Signal Process. Control 2023 86 105186 10.1016/j.bspc.2023.105186 17. Goldberger A.L. Amaral L.A. Glass L. Hausdorff J.M. Ivanov P.C. Mark R.G. Mietus J.E. Moody G.B. Peng C.K. Stanley H.E. PhysioBank, PhysioToolkit, and PhysioNet: Components of a New Research Resource for Complex Physiologic Signals Circulation 2000 101 e215 e220 10.1161/01.CIR.101.23.e215 10851218 18. Tawhid M.N.A. Siuly S. Wang H. Whittaker F. Wang K. Zhang Y. A Spectrogram Image Based Intelligent Technique for Automatic Detection of Autism Spectrum Disorder from EEG PLoS ONE 2021 16 e0253094 10.1371/journal.pone.0253094 34170979 PMC8232415 19. Demir F. Sengur A. Lu H. Amiriparian S. Cummins N. Schuller B. Compact Bilinear Deep Features For Environmental Sound Recognition Proceedings of the 2018 International Conference on Artificial Intelligence and Data Processing, IDAP Malatya, Turkey 28–30 September 2018 1 5 20. Gour M. Jain S. Sunil Kumar T. Residual Learning Based CNN for Breast Cancer Histopathological Image Classification Int. J. Imaging Syst. Technol. 2020 30 621 635 10.1002/ima.22403 21. Kumar R.L. Kakarla J. Isunuri B.V. Singh M. Multi-Class Brain Tumor Classification Using Residual Network and Global Average Pooling Multimed. Tools Appl. 2021 80 13429 13438 10.1007/s11042-020-10335-4 22. Tolstikhin I. Houlsby N. Kolesnikov A. Beyer L. Zhai X. Unterthiner T. Yung J. Steiner A. Keysers D. Uszkoreit J. MLP-Mixer: An All-MLP Architecture for Vision Adv. Neural Inf. Process. Syst. 2021 29 24261 24272 23. Zhang H. Dong Z. Li B. He S. Multi-Scale MLP-Mixer for Image Classification Knowl.-Based Syst. 2022 258 109792 10.1016/j.knosys.2022.109792 24. Goldberger J. Roweis S. Hinton G. Salakhutdinov R. Neighbourhood Components Analysis Adv. Neural Inf. Process. Syst. 2005 17 4 25. Baygin M. Yaman O. Tuncer T. Dogan S. Barua P.D. Acharya U.R. Automated Accurate Schizophrenia Detection System Using Collatz Pattern Technique with EEG Signals Biomed. Signal Process. Control 2021 70 102936 10.1016/j.bspc.2021.102936 26. Robnik-Šikonja M. Kononenko I. Theoretical and Empirical Analysis of ReliefF and RReliefF Mach. Learn. 2003 53 23 69 10.1023/A:1025667309714 27. Tuncer T. Dogan S. Ozyurt F. An Automated Residual Exemplar Local Binary Pattern and Iterative ReliefF Based COVID-19 Detection Method Using Chest X-Ray Image Chemom. Intell. Lab. Syst. 2020 203 104054 10.1016/j.chemolab.2020.104054 PMC7233238 32427226 28. Demir K. Berna A.R.I. Demir F. Detection of Brain Tumor with a Pre-Trained Deep Learning Model Based on Feature Selection Using MR Images Firat Univ. J. Exp. Comput. Eng. 2023 2 23 31 10.5505/fujece.2023.36844 29. Xiao B. Xu Y. Bi X. Li W. Ma Z. Zhang J. Ma X. Follow the Sound of Children’s Heart: A Deep-Learning-Based Computer-Aided Pediatric CHDs Diagnosis System IEEE Internet Things J. 2020 7 1994 2004 10.1109/JIOT.2019.2961132 30. Qiao L. Gao Y. Xiao B. Bi X. Li W. Gao X. HS-Vectors: Heart Sound Embeddings for Abnormal Heart Sound Detection Based on Time-Compressed and Frequency-Expanded TDNN With Dynamic Mask Encoder IEEE J. Biomed. Health Inform. 2023 27 1364 1374 10.1109/JBHI.2022.3227585 37015522 31. Tian G. Lian C. Zeng Z. Integrated Res2Net Combined with Seesaw Loss for Long-Tailed PCG Signal Classification Proceedings of the 11th International Conference on Intelligent Control and Information Processing, ICICIP 2021 Dali, China 3–7 December 2021 IEEE New York, NY, USA 2021 53 58 32. Xiao B. Xu Y. Bi X. Zhang J. Ma X. Heart Sounds Classification Using a Novel 1-D Convolutional Neural Network with Extremely Low Parameter Consumption Neurocomputing 2020 392 153 159 10.1016/j.neucom.2018.09.101 33. Alkhodari M. Fraiwan L. Convolutional and Recurrent Neural Networks for the Detection of Valvular Heart Diseases in Phonocardiogram Recordings Comput. Methods Programs Biomed. 2021 200 105940 10.1016/j.cmpb.2021.105940 33494031 34. Duan L. Yang L. Guo Y. Paramps: Convolutional Neural Networks Based on Tensor Decomposition for Heart Sound Signal Analysis and Cardiovascular Disease Diagnosis Signal Process. 2025 227 109716 10.1016/j.sigpro.2024.109716 Figure 1 PCG signal samples from the 2016 PhysioNet/CinC Challenge dataset. Figure 2 The representation of the proposed strategy. Figure 3 Layer structure of the RAMM model. Figure 4 Spectrogram transformations illustrating differences between healthy and unhealthy PCG signals. Figure 5 Accuracy graph of the RAMM model with spectrogram images during the training process. Figure 6 Loss graph of the RAMM model with spectrogram images during the training process. Figure 7 Feature weights with NCA and ReliefF algorithms. Figure 8 Confusion matrix depicting the performance of the proposed RAMM model with the NRBMI algorithm. Figure 9 Accuracy graph of the RAMM model with raw data during the training process. Figure 10 Loss graph of the RAMM model with raw data during the training process. Figure 11 Confusion matrix results of ablation studies for the NRBMI algorithm: ( a b c d diagnostics-15-02379-t001_Table 1 Table 1 Performance metric values of the proposed approach. Class Sensitivity (%) Specificity (%) Precision (%) F1-Score (%) Healthy 98.90 98.28 99.48 99.19 Unhealthy 98.28 98.90 96.39 97.28 diagnostics-15-02379-t002_Table 2 Table 2 Accuracy scores of the proposed approach for 10-fold cross-validation. Number of Cross—Validation → 1–10 11–20 21–30 31–40 Results → 98.59% 99.44% 98.36% 99.52% 98.61% 98.22% 98.22% 99.21% 98.33% 99.50% 98.39% 98.11% 98.66% 99.04% 99.41% 99.24% 98.45% 99.52% 98.93% 98.03% 98.59% 97.89% 98.70% 98.70% 98.61% 98.81% 99.41% 98.53% 98.75% 98.11% 98.17% 98.19% 98.89% 98.75% 98.47% 99.01% 99.38% 99.21% 98.53% 99.18% diagnostics-15-02379-t003_Table 3 Table 3 Performance metric results of ablation studies for the NRBMI algorithm. Model Class Sensitivity (%) Specificity (%) Precision (%) F1-Score (%) RAMM + SVM Healthy 95.93 92.01 97.62 96.77  Unhealthy 92.01 95.93 86.94 89.42 RAMM + ReliefF + SVM Healthy 97.13 95.65 98.70 97.91  Unhealthy 95.65 97.13 90.75 93.12 RAMM + NCA + SVM Healthy 96.91 94.50 98.36 97.63  Unhealthy 94.50 96.91 90.01 92.19 RAMM + NRBMI Healthy 98.90 98.28 99.48 99.19  Unhealthy 98.28 98.90 96.39 97.28 diagnostics-15-02379-t004_Table 4 Table 4 Evaluation against existing techniques with the 2016 PhysioNet/CinC Challenge dataset. Methods Accuracy (%) Specificity (%) F1-Score (%) Sensitivity (%) CliqueCNN [ 29 94.01 96.81 85.13 83.21 DenseCNN [ 29 94.21 96.62 85.8 84.92 HS-based Vectors [ 30 95.62 97.72 89.2 87.61 1D CNN + 2D CNN [ 1 96.32 97.92 91.11 90.61 1D hand-crafted feature + 2D CNN [ 1 96.22 97.94 90.62 89.72 Res2Net-CNN [ 31 91.03 95.01 77.52 74.51 1D CNN [ 32 93.01 86.01 91.02 95.02 1D CNN and RNN [ 33 88.22 88.92 74.91 85.92 ParaCNN [ 34 94.61 94.22 86.33 85.13 ParaMPS [ 34 96.10 98.70 88.71 86.03 Params [ 34 96.40 99.10 89.30 86.50 Ours (RAMM + NRBMI + SVM) 98.80 98.30 99.20 98.90 ",
  "metadata": {
    "Title of this paper": "Paramps: Convolutional Neural Networks Based on Tensor Decomposition for Heart Sound Signal Analysis and Cardiovascular Disease Diagnosis",
    "Journal it was published in:": "Diagnostics",
    "URL": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC12468874/"
  }
}