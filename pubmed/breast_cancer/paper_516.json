{
  "title": "Paper_516",
  "abstract": "pmc ACS Sens ACS Sens 822 acssd se ACS Sensors 2379-3694 pubs.acs.org/acssensors pmc-is-collection-domain yes pmc-collection-title ACS AuthorChoice PMC12481578 PMC12481578.1 12481578 12481578 40892429 10.1021/acssensors.5c01058 1 Article Explainable Deep\nLearning Framework for SERS Bioquantification 7343829 Zaki Jihan K. 7343853 Tomasik Jakub 2829851 McCune Jade A. 71972 Bahn Sabine 6140381 Lió Pietro 269420 https://orcid.org/0000-0001-8032-7166 Scherman Oren A.  † Melville\nLaboratory for Polymer Synthesis, Yusuf Hamied Department of Chemistry 2152 University of Cambridge Lensfield Rd Cambridge CB2 1EW U.K.  ‡ Department\nof Chemical Engineering and Biotechnology 2152 University of Cambridge Philippa Fawcett Drive Cambridge CB3 0AS U.K.  § Department\nof Computer Science and Technology University\nof Cambridge 15 JJ Thomson\nAve Cambridge CB3 0FD U.K. * pl219@cam.ac.uk * oas23@cam.ac.uk 02 9 2025 26 9 2025 10 9 497980 6597 6606 31 3 2025 01 8 2025 24 7 2025 02 9 2025 30 09 2025 01 10 2025 01 10 2025 © 2025 The Authors. Published by American Chemical Society 2025 The Authors https://creativecommons.org/licenses/by/4.0/ This article is licensed under CC-BY 4.0 Surface-enhanced\nRaman spectroscopy (SERS) is rapidly\ngaining attention\nas a fast and inexpensive method of biomarker quantification, which\ncan be combined with deep learning to elucidate complex biomarker-disease\nrelationships. Current standard practices in SERS analysis are behind\nthe state-of-the-art machine learning approaches; however, the present\nchallenges of SERS analysis could be effectively addressed with a\nrobust computational framework. Furthermore, there is a need for improved\nmodel explainability for SERS analysis, which at present is insufficient\nin assessing the contexts in which confounding factors affect prediction\noutcomes. This study presents a framework for SERS bioquantification\nrooted in a three-step process, including spectral processing, quantification,\nand explainability. A serotonin quantification task in urine was assessed\nas a model task, with 682 SERS spectra measured in a micromolar range\nusing cucurbit[8]­uril chemical spacers. A denoising autoencoder was\nutilized for spectral enhancement, while convolutional neural networks\n(CNNs) and vision transformers were utilized for biomarker quantification.\nIn addition, a context representative interpretable model explanation\n(CRIME) method was developed to suit the current needs of SERS mixture\nanalysis explainability. Serotonin quantification was most efficient\nin denoised spectra analyzed using a CNN with a three-parameter logistic\noutput layer (mean absolute error = 0.15 μM, mean percentage\nerror = 4.67%). Subsequently, the CRIME method revealed the CNN model\nto present six unique prediction contexts, of which three were associated\nwith serotonin. The proposed framework could unlock a novel, untargeted\nhypothesis-generating method of biomarker discovery, considering the\nrapid and inexpensive nature of SERS measurements and the potential\nto identify biomarkers from CRIME contexts. SERS deep learning denoising autoencoder explainable AI serotonin biomarker quantification CRIME urine analysis Stanley Medical Research Institute 10.13039/100007123 O7R-1888 H2020 European Research Council 10.13039/100010663 726470 Engineering and Physical Sciences Research Council 10.13039/501100000266 EP/S009000/1 Oskar Huttunen Foundation NA NA pmc-status-qastatus 0 pmc-status-live yes pmc-status-embargo no pmc-status-released yes pmc-prop-open-access yes pmc-prop-olf no pmc-prop-manuscript no pmc-prop-legally-suppressed no pmc-prop-has-pdf yes pmc-prop-has-supplement yes pmc-prop-pdf-only no pmc-prop-suppress-copyright no pmc-prop-is-real-version no pmc-prop-is-scanned-article no pmc-prop-preprint no pmc-prop-in-epmc yes document-id-old-9 se5c01058 document-id-new-14 se5c01058 production-flag-MathML-config-version 3 production-flag-journal-citation-display-style acs-titles production-flag-journal-date-display-style dates-used-rcd-rvd-acc production-flag-si-avail yes document-id-alt-64 5d7d86231d94568d7962ffe4a945847f1529c2d8c817a2f0c49d4d360c1a4bb7 Introduction Deep learning methods are increasingly\nbeing used in biomarker\nresearch, as yet-to-be-discovered relationships between biomarkers\nand disease outcomes increase in complexity with the expanding number\nof biomarkers investigated.  in situ intra The SERS domain is far behind\ncurrent state-of-the-art practices\ndeveloped in the field of machine learning, and several promising\nmethodologies have yet to be integrated into SERS analyses. SERS analysis\nhas relied on traditional dimensionality reduction methods to reduce\nthe variations of the spectra and to account for the high noise levels\nof SERS spectra, particularly in biological samples. Principal component\nanalysis and discriminant analysis (PCA-DA) and partial least-squares\nregression (PLSR) have been the de facto     This study aims to develop computational methods to mitigate\nthe\ndescribed primary challenges of SERS. These are the variability between\nspectra, the effects of biological noise on measurements, and the\ndifficulty in identifying confounding factors that prevent models\nfrom differentiating target analyte signals. To this end, the present\nstudy proposes a complete and up-to-date SERS analysis framework enabling\nrobust bioquantification and explainability. The assessment of urinary\nserotonin was selected as a model task to develop our methodology.\nUrine is noninvasive, easy to obtain in large quantities, and shows\nsignificant potential as a biomarker source, with over 5000 analytes\nidentified to date.   Methods Data Set Preparation The study design is summarized\nin Figure  Figure  Supplementary Figure 1 Supplementary Table 1 Supplementary Figures 2 and 3 –1 Table p n 1 Added Concentrations and Number of\nSpectra for All Three Neurotransmitters in Both Water and Urine Backgrounds Sample  EPI  DA  5-HT  Water  Urine A 2 0 0 25 22 B 0 2 0 17 21 C 0 0 2 22 22 D 3 0 7 0 26 E 0 8 3 0 28 F 7 3 0 0 21 G 3 2 7 99 26 H 1 1 9 38 22 I 2 8 3 37 22 J 6 9 1 93 23 K 7 3 2 11 23 L 9 6 4 11 21 M 3 3 3 11 0 U 0 0 0 58 41 a EPI =\nepinephrine, DA = dopamine,\n5-HT = serotonin, and n b Samples D, E, and F were not present\nin the water dataset, and sample M was not present in the urine dataset.\nSample U represents a baseline measurement with no added or measured\nconcentrations of the neurotransmitters. 1 SERS deep learning framework development pipeline. Illustrated\nare the SERS measurement process applied (A) and the computational\nframework pipeline. Benchmark comparisons of alternative methodology\nare presented on the right. Preprocessing methods (B) are marked in\norange and light red, quantification methods (C) are marked in blue,\nand explainability methods (D) are marked in dark red. Asymmetric\nleast-squares (ALS) basislining is applied to all spectra prior to\nassessing the framework or the benchmarks. SERS = surface-enhanced\nRaman spectroscopy, AuNP = gold nanoparticle, CB[8] = cucurbit[8]­uril,\nCNN = convolutional neural network, XGBoost = extreme gradient boosting\ntrees, PLSR = partial least-squares regression, SVM = support vector\nmachines, CRIME = context representative interpretable model explanations,\nLEN = logic explained networks, SHAP = Shapley additive explanations. Denoising Autoencoder Following\nbaseline correction\nand normalization, the spectra were denoised by using a denoising\nautoencoder. For conventional autoencoders, an encoder neural network\nis trained to convolute input data into a latent space, and simultaneously,\na decoder neural network is trained to restructure the original data\nfrom the latent transformation. A denoising autoencoder differs by\nattempting to reconstruct clean outputs from a latent space formed\nby encoding noisy data, Table Quantification Models The quantification of serotonin\nwas primarily evaluated using state-of-the-art neural network models,\nas shown in Figure Supporting Information The scale-adjusting CNN\nmodel was developed with two unique scaling layers implemented. These\nwere a multiscale assessing layer and a local scaling layer. Both\nlayers were utilized prior to the half-peak ReLU layer in the core\nCNN architecture. The multiscale layer captures features from the\ninput X  C i ( X ) = W i × X + b i W b s  j  a j , b j  S j ( X ) = X a j : b j ⊙ s j  ⊙ Supplementary Figure 4 Each model was evaluated in raw, Savitzky–Golay-filtered,\nand denoised data. These evaluations incorporated unseen spectra as\nwell as repeat spectra, with spectra defined as repeat if separate\nmeasurements of a specific sample were used in training either the\ndenoising autoencoder or the quantification models. Repeat spectra\nwere split into training and validation sets with a 90:10 split, and\nfurthermore, measurements taken from an unseen serotonin-free sample\n(sample F) were included in the validation set. The remaining unseen\nsamples (D and E) were included exclusively in the test set. Final\nspectra counts for both data sets consisted of 218 training spectra,\nwith a validation set of 46 and a test set of 54 spectra. Hyperparameter\ntuning and architecture search for both the CNN variants and the ViT\nwere conducted iteratively, guided by the model’s performance\non the validation set. Each model variant for both the CNNs and the\nViT was trained 100 times, with an ensemble average used for evaluation.\nModels exceeding 1 μM mean absolute error (MAE) in training\nwere dropped from the ensemble to minimize the inclusion of outlier\nmodels. Both model types were optimized using the adaptive moment\nestimation (Adam) algorithm with a learning rate of 0.001, a batch\nsize of 64, and 256 epochs, and compiled with an MAE loss function.\nAdditional evaluation metrics included the mean squared error (MSE)\nand mean percentage error (MPE). Early stopping with a patience of\n64 was employed to mitigate overfitting, and model checkpoints were\nsaved for epochs that minimized validation loss. Reproducibility was\nensured by setting random seeds for TensorFlow, NumPy, and the train-test\nsplit. Of the 100 trained models in the ensemble, the model with the\nlowest MAE in the validation set was selected as the final model,\nwhich was assessed in the holdout test set. Context Representative\nInterpretable Model Explanations The reliability and explainability\nof the final quantification model\nwere assessed using the context representative interpretable model\nexplanations (CRIME) framework developed in this study for machine\nlearning interpretations of data with expected contextual prediction\nclusters. The CRIME framework expands on the widely applied local\ninterpretable model-agnostic explanations (LIME) framework The CRIME framework attempts to identify all prediction\ncontexts of the input data space through the latent space of a variational\nautoencoder (VAE) trained on the LIME predictions of all instances\nin the available data. The LIME predictions are flattened with regard\nto perturbation limits and weights prior to input and are subsequently\nprojected to the two-dimensional latent space. The VAE architecture\nused in this study consisted of a simple encoder, sampler, and decoder.\nNotably, the architecture can be fine-tuned depending on the individual\nrequirements of the CRIME framework in future applications. Details\nregarding the VAE of the CRIME method are described in the Supporting Information Following the identification of the most relevant context prediction\nregions, the highlighted regions of the mean context spectra are assessed\nagainst measured clean spectra of the neurotransmitters known to be\npresent in the mixture. To emphasize the explanation weights in the\nspectra, both the reference clean spectra and the mean context spectra\nare scaled according to the explanation weights in the specific feature\nlocation. To determine the cause or identity of the recognized context\nclusters, the final mean context indicators are compared to the weighted\nreference spectra using cosine similarity S cos eq 1 S cos = A · B ∥ A ∥ ∥ B ∥ Benchmarking Each\nsegment of the framework presented\nin this study is carefully benchmarked against alternative models\nor methods, previously established benchmarks, or common practices\nin the SERS domain. The utility of the denoising autoencoder\nwas assessed by measuring performance in the raw and denoised data\nand, additionally, comparing it with fifth-order polynomial second\nSavitzky–Golay derivative processing with a window length of\n33, et al Supporting Information For comparison with CRIME,\nfeature importance and model explainability\nwere assessed using logic explained networks (LENs) x Supporting Information Results Denoising Autoencoder In this work, the utility of\ndeep learning methods was assessed for identifying target serotonin\nconcentrations from SERS measurements with CB[8] additives as chemical\nspacers. To this end, a denoising autoencoder and neural network quantification\nmodels were developed using 682 spectral measurements taken from water-\nand artificial urine-based samples, with concentrations of serotonin\nranging from 0 to 9 μM. The denoising autoencoder was implemented\nto augment the urinary SERS spectra by reintroducing serotonin-based\nsignals from biological noise arising from the urine matrix. The denoising\nautoencoder was primarily evaluated through its influence on the downstream\nmodel predictions, compared to Savitzky–Golay denoised spectra\nand unprocessed raw spectra. Following training, the denoising autoencoder\nwas able to robustly reconstruct the clean data from noisy inputs\nin the test set (MSE = 0.025). Examples of input noisy data and subsequently\ndenoised spectra are presented in Supplementary Figure 5A–C Supplementary Figure 5D–F Quantification Models Four different neural network\nmodels were evaluated in raw as well as Savitzky–Golay and\nautoencoder-denoised data sets. These included the ViT model, the\nlinear output layer CNN model (CNN L 3PL L 3PL L 3PL 3PL L Figure Supplementary Figure 6 Supplementary Figure 7A, B Supplementary Table 3 2 Results of the final models in the validation and test\nsets for\nthe four model types in both raw (A) and denoised data sets (B). Validation\nset results are shown in gray, and test set results are shown in color:\nthe linear CNN model is shown in yellow (diamond), the vision transformer\nmodel in blue (circle), the scale-adjusting CNN in green (triangle),\nand the three-parameter logistic output layer CNN model in red (square).\nA dashed line ( y x Supporting Information Table 3 CRIME Framework The CRIME framework was fit on a VAE\nby using the LIME explanations of the CNN 3PL Figure Figure Supplementary Figure 8A–F cos cos cos cos cos Supplementary Table 4 3 Results for\ncontext representative interpretable model explanations\n(CRIME) analysis. Six distinct contexts were identified, which are\nvisualized across mean spectra in subfigures A–F. Positive\nprediction weights are presented in green, negative prediction weights\nin yellow, and perturbation limits have been shaded in teal. Red regions\nin the mean spectra correspond to average perturbation limits at either\nthe top or bottom of the feature weight range, for the simplicity\nof the plot. Latent spaces are visualized by context and concentrations,\nand compound similarity matching was done by using cosine similarity.\nThe highest similarity score is presented alongside that of the matched\ncompound. Benchmarking The\nneural network models were benchmarked\nacross different architectures and against other machine learning\nmodels, with the results summarized in Table Supplementary Figure 9 Supplementary Table 2 2 Comparison of Test-Set\nMean Absolute\nErrors Across Different Machine Learning Models for Serotonin Quantification\nfrom SERS Spectra Data Set XGB (μM) PLSR (μM) RF (μM) SVM (μM) CNN 3PL CNN L sCNN (μM) ViT (μM) Denoising Autoencoder 0.78 0.70 0.93 0.96 0.15* 0.30  0.11* 0.30 Raw Spectra 0.82 2.05 0.88 1.26 1.14  0.70 0.95 1.17 Savitzky–Golay 1.15 2.25 1.46 1.37 1.72 1.30 1.27 + Kasera et al. -  0.52 - - - - - - a Best-performing\nmodel MAEs within\neach data set have been bolded, and the two best models overall have\nbeen marked with an asterisk (*). Additionally, for baseline comparison,\nthe mean absolute error of the previously published PLSR model has\nbeen presented. sCNN = convolutional neural network with scaling layers\nand three-parameter logistic (3PL) output layer, CNN3PL = convolutional\nneural network with 3PL output layer, CNNL = convolutional neural\nnetwork with linear output layer, SVM = support vector machine, RF\n= random forests, PLSR = partial least squares regression, XGB = extreme\ngradient boosting, ViT = vision transformer. + indicates that the\nViT model could not converge in training using a 1 MAE cutoff using\nSavitzky–Golay denoising. To compare the context explanations to methods of\nglobal explainability,\nthe LEN and SHAP frameworks were evaluated as a reference standard.\nThe mean feature activations of the CNN 3PL Supplementary Figure 10 Supplementary Figures 11–14 –1 Supplementary Figure 15 Discussion Within\nthe present study, a comprehensive\nframework of spectral\nquantification from complex biological media was developed, consisting\nof data preprocessing and denoising, bioquantification, and model\nexplanation through the CRIME framework. To this end, data from 318\nspectra from lyophilized urine media, as well as 364 spectra from\nwater media, were utilized for the development of neural network models\nfor denoising of urine backgrounds and quantification of serotonin.\nThe trained denoising autoencoder improved prediction outcomes near-universally\nacross all model types and enabled robust quantification compared\nwith the raw and Savitzky–Golay-processed spectra. The assessed\nstate-of-the-art neural network models substantially outperformed\ntraditional machine learning methods commonly used in the SERS domain,\nwith the CNN 3PL It can be assessed that the custom layers developed\nin this study\nfor the sCNN and CNN 3PL The CRIME\nframework within this study was able to effectively explain\nthe CNN model, exhibiting a significant improvement in the understanding\nof the model decisions. The found contexts were associated with the\nneurotransmitters present in the mixture, and it could be assessed\nthat the two largest contexts were accurately representing serotonin,\nwhile two contexts were associated with unwanted signals, one context\nwas ambiguous in its associations, and last, an outlier context was\nobserved. Regarding the outlier context, it can be attributed to a\nnumber of possible measurement errors resulting in null spectra. Laser\nmalfunctions, improper sample loading, lack of aggregation, or other\ntechnical factors could result in a high-noise, low-signal spectrum,\nwhich, following scaling, would resemble the observed pattern. The\ndopamine- and epinephrine-associated contexts reveal the imbalances\npresent within the data set. The misidentified contexts were revealed\nto consist exclusively of samples with low or absent serotonin concentrations.\nFollowing this observation, it can be concluded that within the present\ndata set, a correlation existed between a lack of serotonin and the\npresence of other neurotransmitters. Therefore, expanding the data\nset to include samples with low concentrations of all neurotransmitters\ncould remedy the apparent inability of the model to generalize to\nlower serotonin concentrations. To illustrate this point, a small\ndata-augmentation-based supplementary analysis is presented in the Supporting Information It must be highlighted\nthat the CRIME framework combined with SERS\ncould see clinically relevant use through acting as the first step\nin biomarker discovery trials. Instead of assessing individual biomarkers\nof disease through established hypotheses, a biomarker discovery study\ncould be initiated in a nontargeted, hypothesis-generating fashion.\nApplying a machine learning model on raw spectra presently is not\nadvisable due to the lack of confidence in the model assessing true\nbiomarkers as opposed to confounding factors. The exact identification\nof the signaling biomarkers is challenging when global explainability\nmethods are used for peak detection, as the spectral signals could\nbe a result of multiple overlapping compounds. However, were the CRIME\nframework applied, individual target biomarkers could be identified\nthrough contexts uniquely and subsequently assigned to the likely\nbiomarkers through a complete library of present compounds, as well\nas hypothesized biomarkers. With the advent of computational hypothesis-generating\nmethodologies such as Mendelian randomization, There are several limitations to\nconsider in this study. The development\nof a denoising autoencoder in patient urine samples as opposed to\nartificial urine samples could prove to be more challenging. While\nit could be explained by the CRIME framework, the neural network models\nwere not always able to assess the association of the peaks to the\ntarget serotonin compound directly and instead assessed the presence\nof dopamine or epinephrine as a predictor of the absence of serotonin.\nThe CRIME framework in turn presents limitations inherent in LIME\nexplanations, as the explanations are dependent on a simpler model\nfit to complex model predictions and, as such, do not completely represent\nan explanation of the actual model. Additionally, it could prove challenging\nto identify the true reasoning behind CRIME contexts if there were\nmore potential confounding compounds or effects present. Similarly,\nwhile in the present task it was feasible to calculate the LIME explanations\nfor all instances, this might not be scalable to larger data sets.\nFinally, although the inherent structure of SERS spectra effectively\nreduces data dimensionality, the data set size in this study remains\nmodest. Further validation is therefore necessary on larger and more\ndiverse data sets to fully assess the generalizability of the developed\nmodels, especially in more complex tasks such as multiplexing. In conclusion, the present study set out to develop an interpretable\ndeep learning framework that was capable of achieving three main aims:\nto perform enhanced single analyte detection from a high-variance,\nconfounder-rich biomarker matrix in urine; to recognize and adjust\nfor method-based variation in SERS measurements; and last, to identify\nall confounders that interfered with the correct prediction logic\nof the quantification model. A denoising autoencoder was developed\nto improve the targeting of relevant neurotransmitter peaks. To assess\nserotonin quantification in raw and denoised spectra, three different\nstate-of-the-art neural network models were developed: a CNN with\na three-parameter logistic output layer, a scale-adjusting CNN, and\na ViT model. In addition, all models were compared with other machine\nlearning methods. Finally, a novel model explainability framework,\nCRIME, was built around LIME explanations through the assessment of\nprediction contexts by using a combination of VAE and clustering algorithms.\nThe model interpretability was compared between the novel framework\nand global prediction methods: LEN and SHAP. Within this study, it\nwas shown that the denoising autoencoder substantially improved the\npredictive capabilities of applied machine learning models, of which\nthe developed three-parameter logistic output layer CNN outperformed\nother models assessed. Moreover, model explainability was strongly\nenhanced by the CRIME framework. To our knowledge, this marks the\nfirst instance where an autoencoder has been successfully applied\nto biological “noise” within the SERS domain. Within\nthe chemical spectral domain, the CRIME framework promises to enable\nthe deployment of spectral quantification methods to directly identify\ndisease features in biological fluids, which could be further refined\ninto specific biomarkers through the identification of relevant contexts. Supplementary Material The authors thank Dr. Setu Kasera for their detailed\nand elaborate data collection, enabling the repurposing of previously\nmeasured SERS spectra for the present study. The developed\ncode for the CRIME framework can be found in the following GitHub\nrepository: https://github.com/jkz22/CRIME The Supporting\nInformation is\navailable free of charge at https://pubs.acs.org/doi/10.1021/acssensors.5c01058 Supplementary sections\nfor experimental methods, neural\nnetwork architectures, AI explainability, benchmark hyperparameter\nsearch, and retrospective model development. Supplementary figures\nfor pure compound spectra, neural network architectures, denoising\nautoencoder performance, validation set ensemble predictions, CRIME\ncontext relevance cluster visualization, quantification model benchmarking,\nfeature activation maps for the final CNN model, visualized LEN explanations,\nand visualized SHAP explanations ( PDF Conceptualization:\nJ.K.Z., P.L., O.A.S.; methodology: J.K.Z., P.L.; data analysis: J.K.Z.;\nresources: S.B., O.A.S.; writingoriginal draft: J.K.Z.; writingreview\n& editing: all coauthors; supervision: P.L., S.B., O.A.S., J.T.;\nfunding acquisition: O.A.S., J.K.Z. S.B. thanks the\nStanley Medical Research Institute (grant number: O7R-1888), J.K.Z.\nthanks the Oskar Huttunen Foundation, and O.A.S. thanks the ERC Consolidator\nGrant CAM RIG (726470) and the EPSRC IRC in Hard-to-Treat Cancers\n(EP/S009000/1). A preprint of this article\nwas posted on arXiv: Zaki, J.; Tomasik, J.; McCune, J.; Bahn, S.;\nLió, P.; Scherman, O. Explainable Deep Learning Framework for\nSERS Bioquantification. arXiv preprint arXiv:2411.08082 The authors\ndeclare no competing financial interest. Mathema V. B. Sen P. Lamichhane S. Orešič M. Khoomrung S. Deep learning\nfacilitates multi-data type analysis and predictive biomarker discovery\nin cancer precision medicine Comput. Struct.\nBiotechnol. J. 2023 21 1372 1382 10.1016/j.csbj.2023.01.043 36817954 PMC9929204 Langer J. de Aberasturi D. J. Aizpurua J. Alvarez-Puebla R. A. Auguié B. Baumberg J. J. Bazan G. C. Bell S. E. Boisen A. Brolo A. G. Present and future of\nsurface-enhanced Raman scattering ACS Nano 2020 14 28 117 10.1021/acsnano.9b04224 31478375 PMC6990571 Pilot Signorini Durante Orian Bhamidipati Fabris A Review on Surface-Enhanced Raman\nScattering Biosensors 2019 9 57 10.3390/bios9020057 30999661 PMC6627380 Kasera S. Herrmann L. O. Barrio J. D. Baumberg J. J. Scherman O. A. Quantitative\nmultiplexing with nano-self-assemblies in SERS Sci. Rep. 2014 4 1 6 10.1038/srep06785 PMC4213794 25354650 Xiong M. Ye J. Reproducibility in\nsurface-enhanced Raman spectroscopy J. Shanghai\nJiaotong Univ. 2014 19 681 690 10.1007/s12204-014-1566-7 Zong C. Xu M. Xu L. J. Wei T. Ma X. Zheng X. S. Hu R. Ren B. Surface-Enhanced Raman\nSpectroscopy for Bioanalysis:\nReliability and Challenges Chem. Rev. 2018 118 4946 4980 10.1021/acs.chemrev.7b00668 29638112 Lussier F. Thibault V. Charron B. Wallace G. Q. Masson J. F. Deep learning\nand artificial intelligence methods for Raman and surface-enhanced\nRaman scattering TrAC, Trends Anal. Chem. 2020 124 115796 10.1016/j.trac.2019.115796 Kim S. Kim T. G. Lee S. H. Kim W. Bang A. Moon S. W. Song J. Shin J. H. Yu J. S. Choi S. Label-Free Surface-Enhanced Raman\nSpectroscopy Biosensor for On-Site\nBreast Cancer Detection Using Human Tears ACS\nAppl. Mater. Interfaces 2020 12 7897 7904 10.1021/acsami.9b19421 31971765 Czaplicka M. Kowalska A. A. Nowicka A. B. Kurzydłowski D. Gronkiewicz Z. Machulak A. Kukwa W. Kamińska A. Raman spectroscopy\nand surface-enhanced Raman spectroscopy (SERS) spectra of salivary\nglands carcinoma, tumor and healthy tissues and their homogenates\nanalyzed by chemometry: Towards development of the novel tool for\nclinical diagnosis Anal. Chim. Acta 2021 1177 338784 10.1016/j.aca.2021.338784 34482902 Cao D. Lin H. Liu Z. Qiu J. Ge S. Hua W. Cao X. Qian Y. Xu H. Zhu X. PCA-TLNN-based SERS\nanalysis platform for label-free detection and identification of cisplatin-treated\ngastric cancer Sens. Actuators, B 2023 375 132903 10.1016/j.snb.2022.132903 Akbar S. Majeed M. I. Nawaz H. Rashid N. Tariq A. Hameed W. Shakeel S. Dastgir G. Bari R. Z. A. Iqbal M. Surface-Enhanced\nRaman Spectroscopic (SERS)\nCharacterization of Low Molecular Weight Fraction of the Serum of\nBreast Cancer Patients with Principal Component Analysis (PCA) and\nPartial Least Square-Discriminant Analysis (PLS-DA) Anal. Lett. 2022 55 1588 1604 10.1080/00032719.2021.2017948 Tahir F. Kamran A. Majeed M. I. Alghamdi A. A. Javed M. R. Nawaz H. Iqbal M. A. Tahir M. Tariq A. Rashid N. Surface-Enhanced Raman\nScattering (SERS) in Combination\nwith PCA and PLS-DA for the Evaluation of Antibacterial Activity of\n1-Isopentyl-3-pentyl-1H-imidazole-3-ium Bromide against Bacillus subtilis ACS Omega 2024 9 6861 6872 10.1021/acsomega.3c08196 38371792 PMC10870359 Le\nCun Y. Bottou L. Bengio Y. Haffner P. Gradient-based learning\napplied to document recognition Proc. IEEE 1998 86 2278 2323 10.1109/5.726791 Tang J. W. Liu Q. H. Yin X. C. Pan Y. C. Wen P. B. Liu X. Kang X. X. Gu B. Zhu Z. B. Wang L. Comparative\nAnalysis of Machine Learning Algorithms on Surface Enhanced Raman\nSpectra of Clinical Staphylococcus Species Front. Microbiol. 2021 12 696921 10.3389/fmicb.2021.696921 34531835 PMC8439569 Lussier F. Missirlis D. Spatz J. P. Masson J. F. Machine-Learning-Driven\nSurface-Enhanced Raman Scattering Optophysiology Reveals Multiplexed\nMetabolite Gradients Near Cells ACS Nano 2019 13 1403 1411 10.1021/acsnano.8b07024 30724079 Huang T. Y. Yu J. C. C. Development of crime scene intelligence\nusing a hand-held\nraman spectrometer and transfer learning Anal.\nChem. 2021 93 8889 8896 10.1021/acs.analchem.1c01099 34134486 Thrift W. J. Ragan R. Quantification of Analyte\nConcentration in the Single Molecule Regime\nUsing Convolutional Neural Networks Anal. Chem. 2019 91 13337 13342 10.1021/acs.analchem.9b03599 31589030 Dosovitskiy A. Beyer L. Kolesnikov A. Weissenborn D. Zhai X. Unterthiner T. Dehghani M. Minderer M. Heigold G. Gelly S. An Image is\nWorth\n16 × 16 Words: Transformers for Image Recognition at Scale arXiv 2020 Li B. Zappalá G. Dumont E. Boisen A. Rindzevicius T. Schmidt M. N. Alstrøm T. S. Nitroaromatic explosives’\ndetection and quantification using an attention-based transformer\non surface-enhanced Raman spectroscopy maps Analyst 2023 148 4787 4798 10.1039/D3AN00446E 37602485 Tseng Y. M. Chen K. L. Chao P. H. Han Y. Y. Huang N. T. Deep Learning-Assisted\nSurface-Enhanced Raman Scattering for Rapid Bacterial Identification ACS Appl. Mater. Interfaces 2023 15 26398 26406 10.1021/acsami.3c03212 37216401 Ciloglu F. U. Caliskan A. Saridag A. M. Kilic I. H. Tokmakci M. Kahraman M. Aydin O. Drug-resistant\nStaphylococcus aureus\nbacteria detection by combining surface-enhanced Raman spectroscopy\n(SERS) and deep learning techniques Sci. Rep. 2021 11 1 18444 10.1038/s41598-021-97882-4 34531449 PMC8446005 Ciloglu F. U. Hora M. Gundogdu A. Kahraman M. Tokmakci M. Aydin O. SERS-based sensor with\na machine learning based effective feature\nextraction technique for fast detection of colistin-resistant Klebsiella\npneumoniae Anal. Chim. Acta 2022 1221 340094 10.1016/j.aca.2022.340094 35934394 Wishart D. S. Guo A. C. Oler E. Wang F. Anjum A. Peters H. Dizon R. Sayeeda Z. Tian S. Lee B. L. HMDB 5.0: the Human\nMetabolome Database for 2022 Nucleic Acids\nRes. 2022 50 D622 D631 10.1093/nar/gkab1062 34986597 PMC8728138 Meijer W. G. Kema I. P. Volmer M. Willemse P. H. B. de\nVries E. G. E. Discriminating Capacity of Indole Markers in the Diagnosis\nof Carcinoid Tumors Clin. Chem. 2000 46 1588 1596 10.1093/clinchem/46.10.1588 11017936 Kałuzny M. Bolanowski M. Sukiennik-Kujawa M. Ponikowski P. Handkiewicz-Junak D. Jarzab B. Jawiarczyk A. Syrycka J. Long-term survival\nand nearly asymptomatic course of\ncarcinoid tumour with multiple metastases (treated by surgery, chemotherapy,\n(90)­Y-DOTATATE, and LAR octreotide analogue): a case report Endokrynol. Pol. 2009 60 401 406 19885812 Lin S. H. Lee L. T. Yang Y. K. Serotonin and Mental Disorders: A\nConcise Review on Molecular Neuroimaging Evidence Clin. Psychopharmacol. Neurosci. 2014 12 196 10.9758/cpn.2014.12.3.196 25598822 PMC4293164 Coppen A. The biochemistry\nof affective disorders Br. J. Psychiatry. 1967 113 1237 1264 10.1192/bjp.113.504.1237 4169954 Jauhar S. Cowen P. J. Browning M. Fifty years\non: Serotonin and depression J.Psychopharmacol. 2023 37 237 10.1177/02698811231161813 36938996 PMC10076339 Gordon J. A. Hen R. The serotonergic system\nand anxiety Neuromolecular\nMed. 2004 5 27 40 10.1385/NMM:5:1:027 15001810 Eggers A. E. A serotonin\nhypothesis of schizophrenia Med. Hypotheses. 2013 80 791 794 10.1016/j.mehy.2013.03.013 23557849 Taylor R. W. Lee T.-C. Scherman O. A. Esteban R. Aizpurua J. Huang F. M. Baumberg J. J. Mahajan S. Precise Subnanometer\nPlasmonic Junctions for SERS within Gold Nanoparticle Assemblies Using\nCucurbit­[n]­uril “Glue” ACS Nano 2011 5 3878 3887 10.1021/nn200250v 21488693 Mahajan S. Lee T. C. Biedermann F. Hugall J. T. Baumberg J. J. Scherman O. A. Raman and SERS spectroscopy\nof cucurbit­[n]­urils Phys. Chem. Chem. Phys. 2010 12 10429 10433 10.1039/c0cp00071j 20582367 Kasera S. Biedermann F. Baumberg J. J. Scherman O. A. Mahajan S. Quantitative\nSERS Using the Sequestration of Small Molecules Inside Precise Plasmonic\nNanoconstructs Nano Lett. 2012 12 5924 5928 10.1021/nl303345z 23088754 Grys D.-B. Chikkaraddy R. Kamp M. Scherman O. A. Baumberg J. J. de Nijs B. Eliminating\nirreproducibility in SERS substrates J. Raman\nSpectrosc. 2021 52 412 419 10.1002/jrs.6008 Eilers P.\nH. C. Parametric\nTime Warping Anal. Chem. 2004 76 404 411 10.1021/ac034800e 14719890 Vincent P. Larochelle H. Bengio Y. Manzagol P.-A. Extracting and Composing\nRobust Features with Denoising Autoencoders Proc. 25th Int. Conf. Mach. Learn. 2008 1096 1103 10.1145/1390156.1390294 Ribeiro M. T. Singh S. Guestrin C. “Why\nShould\nI Trust You?”: Explaining the Predictions of Any Classifier arXiv 2016 Ciravegna G. Barbiero P. Giannini F. Gori M. Lió P. Maggini M. Melacci S. Logic Explained Networks Artif. Intell 2023 314 103822 10.1016/j.artint.2022.103822 Lundberg S. M. Lee S. I. A Unified Approach\nto Interpreting Model Predictions arXiv 2017 Zaki J. K. Tomasik J. McCune J. Scherman O. A. Bahn S. Discovery\nof Urinary Metabolite Biomarkers of Psychiatric Disorders Using Two-Sample\nMendelian Randomization medRxiv 2023 10.1101/2023.09.26.23296078 ",
  "metadata": {
    "Title of this paper": "Discovery\nof Urinary Metabolite Biomarkers of Psychiatric Disorders Using Two-Sample\nMendelian Randomization",
    "Journal it was published in:": "ACS Sensors",
    "URL": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC12481578/"
  }
}