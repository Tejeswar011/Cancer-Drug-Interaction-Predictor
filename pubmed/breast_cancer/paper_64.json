{
  "title": "Paper_64",
  "abstract": "pmc J Contemp Brachytherapy J Contemp Brachytherapy 1978 jcbrachy JCB Journal of Contemporary Brachytherapy 1689-832X 2081-2841 Termedia Publishing PMC12489543 PMC12489543.1 12489543 12489543 10.5114/jcb.2025.153913 56613 1 Original Paper Deep learning-based auto-segmentation model for clinical target volume delineation in brachytherapy after parotid cancer surgery Li Zhen-Yu MD 1 Yue Jing-hua PhD 2 Wu Wen-Jie MD 3 Liu Bo PhD 2 4 Zhang Jie MD 3 1 2 3 4 Address for correspondence: zhangjie06@126.com bo.liu@buaa.edu.cn 28 8 2025 8 2025 17 4 498172 232 241 24 5 2025 30 7 2025 01 08 2025 03 10 2025 03 10 2025 Copyright © 2025 Termedia 2025 https://creativecommons.org/licenses/by-nc-sa/4.0/ This is an Open Access article distributed under the terms of the Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International (CC BY-NC-SA 4.0). License ( http://creativecommons.org/licenses/by-nc-sa/4.0/ Purpose Timely and accurate delineation of the clinical target volume (CTV) in brachytherapy after parotid cancer surgery plays a crucial role in tailored delivery of radiation doses. This study aimed to develop and evaluate a deep learning-based model for auto-segmentation of the CTVs in postoperative adjuvant brachytherapy for patients with parotid gland cancer, addressing the challenge of achieving consistent, high-quality CTV delineations efficiently. Material and methods Using clinical imaging data from 326 patients with parotid gland carcinoma treated at Peking University School and Hospital of Stomatology between 2017 and 2023, we established a training dataset of 213 cases, a validation set of 53 cases, and a test set of 60 cases. The CTVs on the images were segmented using 3D Res-UNet, a deep learning model, and compared against manual delineations performed by experienced radiation oncologists. The performance of 3D Res-UNet was optimized through a comprehensive preprocessing and training process tailored to the dataset’s characteristics. Results The deep learning model yielded a significant improvement in segmentation efficiency. The deep learning model generated initial CTV contours in 9.4 seconds of computational time. Subsequent expert review and minor adjustments required an average of 11.9 minutes, substantially shorter than the 46.7 minutes needed for fully manual delineation. Quantitative analysis showed that the Dice similarity coefficient (DSC) of automatic segmentation by 3D Res-UNet was 0.709, which improved to 0.924 after expert review. Qualitative evaluation by senior oncologists further affirmed the clinical acceptability of the automatically segmented CTVs. Conclusions Automatic contouring with physician review enabled high-accuracy and rapid CTV generation, reducing the overall delineation workload by more than 30 minutes. Consequently, the proposed deep-learning model functions as a useful support tool that streamlines postoperative adjuvant brachytherapy planning for parotid gland cancer and lessens the burden on radiation oncologists, thereby contributing to improved patient care. brachytherapy clinical target volume auto-segmentation parotid gland cancer pmc-status-qastatus 0 pmc-status-live yes pmc-status-embargo no pmc-status-released yes pmc-prop-open-access yes pmc-prop-olf no pmc-prop-manuscript no pmc-prop-legally-suppressed no pmc-prop-has-pdf yes pmc-prop-has-supplement no pmc-prop-pdf-only no pmc-prop-suppress-copyright no pmc-prop-is-real-version no pmc-prop-is-scanned-article no pmc-prop-preprint no pmc-prop-in-epmc yes Purpose Adjuvant radiation therapy plays a key role in the postoperative management of parotid gland cancer [ 1 2 125 3 4 5 The use of automated segmentation methodologies in radiotherapy can alleviate the burden of labor-intensive tasks traditionally performed by radiation oncologists. Furthermore, this innovation can enhance the accuracy, consistency, and reproducibility of delineating CTVs [ 6 8 9 et al 10 Alongside the rapid advancements in deep learning within the realm of medical imaging, auto-segmentation algorithms based on deep learning paradigms have shown noteworthy advancements in tasks associated with medical imaging segmentation. Compared with nnU-Net or TransUNet, a 3D Res-UNet was selected because its residual connections stabilize gradient propagation and help recover blurred postoperative boundaries, while deep supervision refines irregular cavities across multiple scales. Even in cases showing significant variations in the size or shape of organs in the CT images to be segmented, deep learning can yield excellent segmentation results by increasing the number of training cases [ 11 et al 12 13 14 et al 4 Material and methods Clinical data This study was conducted with a cohort of 326 patients diagnosed with carcinoma of the parotid gland. Patient selection was based on inclusion-exclusion criteria ( Table 1 125 15 Table 2 Table 1 Inclusion and exclusion criteria Item Description Inclusion criteria 1. Unilateral parotid malignant tumors with a clinical stage of T1-T3 2. Tumors not invading the deep lobe of the parotid 3. Pathological type as low or moderate malignancy of adenogenic origin 4. Complete preoperative CT or MRI data 5. Clear tumor boundaries on preoperative CT or MRI 6. No clinical evidence of lymph node metastasis 7. Age ≥ 12 years Exclusion criteria 1. History of radiation treatment prior to brachytherapy 2. History of multiple operations for parotid gland cancer 3. Prior local recurrence of parotid malignancy or any re-operation before the planning/post-implant CT Table 2 Baseline characteristics of the study cohort ( n Variable Category n Age (years) < 40 128 (39.3) 40-49 65 (19.9) 50-59 71 (21.8) 60-69 42 (12.9) > 69 20 (6.1) Sex Male 181 (55.5) Female 145 (44.5) T stage T1 102 (31.3) T2 152 (46.6) T3 72 (22.1) Histologic subtype Adenoid cystic carcinoma 81 (24.8) Mucoepidermoid carcinoma 135 (41.4) Acinic cell carcinoma 54 (16.6) Secretory carcinoma 24 (7.4) Others* 32 (9.8) * “Others” include papillary cystadenocarcinoma, basal cell adenocarcinoma, and other rare histologies. Postoperative CT was performed 3-4 weeks after surgery to permit resolution of early edema and artefacts still remaining within the standard timeframe for adjuvant planning. The CT images were obtained with a matrix size of 512 × 512 and a slice thickness of 2 mm. The post-operative therapeutic strategy for each patient was devised using a brachytherapy planning system (BTPS; Beijing Astro Technology Ltd. Co., Beijing, China) on the basis of these CT images. Each acquired image was delineated in the axial plane. Subsequently, the aggregated datasets were subjected to random division, with 65.3% ( n n n The study protocol was approved by the Medical Ethical Committee of Peking University School and Hospital of Stomatology (No. PKUSSIRB-202385019). Due to the retrospective nature of the study, the need to obtain informed consent and approval was waived by the committee. All methods were performed in accordance with relevant guidelines and regulations. CTV delineation in the training and validation sets For each patient, the tumor bed was first identified on postoperative CT/MRI – supplemented by surgical reports – and then uniformly expanded by 1 cm, an approach analogous to postoperative breast brachytherapy, to define the clinical target volume (CTV). The CTVs of the primary tumor were manually delineated on CT images by two radiation oncologists with five and 16 years’ experience in parotid cancer treatment planning. Before delineation, both radiation oncologists underwent consistency training, which involved delineating the brachytherapy CTVs of five cases not related to this study. During the training, the radiation oncologists discussed the delineation procedures and standards to reduce the variations in target volume dimensions. In the first phase, radiation oncologist A, with five years’ experience, delineated the CTVs over the post-surgical parotid bed on the TPS system while using the preoperative images for reference. In the second phase, all contours were reviewed by the more senior radiation oncologist B and were modified when necessary. A total of 7780 layers of CTV contours from 266 cases of postoperative brachytherapy for parotid gland cancer were delineated for the training and validation sets of the deep learning model. Construction of an automatic CTV segmentation model The 3D Res-UNet network structure is shown in Figure 1 16 17 Figure 2 Figure 2A Figure 2B D Figure 2D Fig. 1 Architecture of the 3D Res-UNet-based model Fig. 2 Schematic diagram of the decoder and encoder paths. A B, D C During the model construction phase, CT data from 266 patients were used for training and validation. All images were preprocessed before being input into the Res-UNet model, including resampling, normalization, data augmentation (mirroring, rotation, scaling), and cropping. Loss calculation The model was trained using a standard deep supervision scheme [ 18 Equation 1 L = ∑ d = 1 5 1 2 d − 1 ⋅ L d L d = α d ⋅ L dice + β d ⋅ L ce  1 Where α d d L d th The loss function ( L d L dice 19 L ce 20 Equation 2 L dice = − 2 N ∑ n ∈ N ∑ i ∈ I y i n p i n ∑ i ∈ I y i n + ∑ i ∈ I p i n L ce = 1 I ∑ i ∈ I − p i ⋅ ln y i + 1 − p i ln 1 − y i  2 Where y i n p i n th th Optimization of the model was conducted using a Stochastic Gradient Descent (SGD) optimizer augmented with Nesterov momentum for enhanced convergence properties. The commencement learning rate was calibrated to 1e-2 to balance the trade-off between convergence speed and stability. Furthermore, the optimization process was characterized by a batch size of 2, with an epoch delineated by 250 iterations of training. To ensure comprehensive learning, the termination criterion for the optimization process was established at a maximum of 1000 epochs. This computational endeavor was performed using a 24GB GeForce RTX 3090 graphics processing unit (NVIDIA), which offered substantial computational capacity. The software framework underpinning these operations was Python 3.10.13, with PyTorch 2.1.1 serving as the deep learning platform, thus providing a robust environment for model development and evaluation. Test set delineation and automatic segmentation Using preoperative images for reference, radiation oncologist A delineated the CTVs for the 60 cases in the test set using a commercially available brachytherapy planning system (BTPS; Beijing Astro Technology Ltd. Co., Beijing, China). Subsequently, radiation oncologist B reviewed the delineations and modified them as necessary, recording the time required for both delineation and modification. After training and validation of the deep learning model, the model with the best validation performance was applied to the 60 cases in the test set, and the time required for segmentation was recorded. Subsequently, the resulting CTVs were reviewed and modified by radiation oncologist B when necessary. The time required to complete the session, including the auto-segmentation and the modifications, was recorded. Quantitative evaluation metrics The output accuracy of the deep learning model was compared with the gold-standard manual delineations using an array of metrics, including the Dice similarity coefficient (DSC), Jaccard index, 95% Hausdorff distance (95HD), precision, and recall. Specifically, the DSC was used to articulate the volumetric congruence between the ground truth (A) and the segmentation achieved through deep learning methodology (B). This measure is mathematically represented in the literature as Equation 3 21 D S C A , B = 2 A ∩ B A + B  3 The Jaccard index is a pivotal metric for evaluating the congruence between datasets within the realm of algorithmic performance assessment. It is determined as the ratio of the intersection’s cardinality to the union’s cardinality concerning the sets A and B, as encapsulated in Equation 4 22 J A , B = A ∩ B A ∪ B  4 The Hausdorff distance (HD) is a distance-centric metric that is fundamentally designed to quantify the dissimilarity between two distinct datasets [ 23 Assessment of precision and recall was based on measurement of true positives (TPs), false negatives (FNs), and false positives (FPs) [ 24 Equation (5) P r e c i s i o n = T P T P + F P  5 Recall was determined as the fraction of TP relative to the sum of TP and FN (TP + FN) and served as a measure of the model’s capacity to correctly identify all actual positives. This relationship is formalized in Equation (6) Re c a l l = T P T P + F N  6 Subjective validation For the qualitative assessment, datasets from the test group were evaluated by two experienced senior oncologists, each with over 20 years of clinical practice, following a blinded allocation to ensure impartiality. The quality of segmentation was appraised using a 4-point scale: 0 points indicated a severe defect characterized by large and conspicuous errors; 1 point was assigned for a moderate defect, where minor correctable errors were observed; 2 points denoted a mild defect with the presence of clinically negligible errors; and 3 points signified precise segmentation, necessitating no further modifications. Segmentation quality achieving a score of 2 or higher was classified as adequate for clinical utilization. Data availability statement The datasets used and analyzed during the current study are available from the corresponding author on reasonable request. Results Accuracy of CTV segmentation Axial CT images of a representative case from the test dataset with manually and automatically delineated contours of the CTV are shown in Figure 3 Table 3 Fig. 3 Comparison of CTV delineation performed by a radiation oncologist and the deep learning model. A, E, I B, F, J C, G, K D, H, L Table 3 Quantitative statistical results (mean ± SD) of the deep learning model DSC 95HD (mm)* Jaccard* Precision Recall 3D Res-UNet 0.709 ±0.105 18.117 ±9.310 0.517 ±0.114 0.724 ±0.089 0.694 ±0.101 Expert refinement of 3D Res-UNet 0.924 ±0.031 10.284 ±3.019 0.788 ±0.080 0.851 ±0.039 0.892 ±0.034 DSC – Dice similarity coefficient, 95HD – 95% Hausdorff distance, Jaccard – Jaccard index Subjective validation The qualitative evaluation was conducted by presenting the results of manual and automatic segmentation to two senior radiation oncologists, with the statistical results shown in Table 4 Table 4 Expert ratings for the three delineation methods Mean of scores assigned by radiation oncologist C Mean of scores assigned by radiation oncologist D Time Manual delineation 2.90 ±0.06 2.92 ±0.05 46.7 min 3D Res-UNet 2.54 ±0.11 2.65 ±0.09 9.4 s Expert refinement of 3D Res-UNet 2.89 ±0.06 2.92 ±0.04 11.9 min Although automatically generated contours received reasonably high subjective ratings, the automatic segmentations alone were not considered directly suitable for clinical use without expert refinement. In clinical practice at our institution, automatic segmentations serve as preliminary contours, always requiring subsequent physician review and modification prior to clinical implementation or dose distribution planning. Segmentation time The average time needed for CTV segmentation was 9.4 s using the deep learning model, while the average time for expert review after automatic segmentation was 11.9 min. In comparison, the traditional expert manual segmentation required 46.7 min. Manual refinements mainly extended thin lobulated margins at low-contrast scar-fat interfaces and trimmed occasional spill-over into adjacent bone/air spaces; residual edits involved minor smoothing and adjustment of superior-inferior limits. Discussion Deep learning algorithms have recently emerged as useful tools for medical image segmentation, which plays an essential role in medical image processing, particularly in applications such as radiation therapy planning, and is a critical task in many diagnostic and analytical workflows. The majority of research on medical image segmentation has focused on developing and employing automated segmentation tools, such as deep learning models, to reduce the workload of clinical doctors, expedite the delineation process, and enhance segmentation quality [ 25 Several studies have described the application of deep learning to radiotherapy of head and neck cancer, and automatic segmentation of CTVs is often discussed as one of the main applications. Li et al 26 et al 27 et al 28 In previous research, Li et al 4 29 30 To provide a more comprehensive evaluation, this study also incorporated qualitative expert evaluations. According to the evaluations by two experts, the target areas segmented solely using the deep learning model were still clinically applicable with slight modifications. Thus, this study assessed the feasibility of using a deep learning model to assist manual CTVs delineation for postoperative brachytherapy of parotid gland cancer. The CTVs obtained with the assistance of the deep learning model showed good consistency with those obtained by radiation oncologists (DSC = 0.924 ±0.031), while significantly reducing the time required for delineation. In comparison with the traditional method, this approach reduced the delineation time by an average of 74.5%. From the patient’s perspective, faster and more standardized contours can shorten the interval to treatment initiation, reduce additional visits or repeat imaging, and lessen anxiety and indirect costs associated with prolonged planning. In expert qualitative evaluations, it also achieved scores similar to the traditional method. However, it should be noted that although the automatic contours achieved mean scores of approximately 2.6, they still required expert verification and minor edits before clinical adoption, underscoring that automatic CTVs should serve as decision-support tools rather than fully autonomous inputs. The discrepancy between the raw automatic contours (Dice 0.709 ±0.105) and the expert-refined contours (Dice 0.924 ±0.031) is chiefly attributable to two predictable factors: postoperative target beds show scar-fat replacement and loss of a discrete tumor boundary, producing low-contrast and semantically ambiguous interfaces that can lead the model to local under- or over-segmentation, and systematic boundary deviations cluster at anatomically complex multi-tissue junctions such as the parapharyngeal fat-medial pterygoid transition, the fascia along the masseteric space and the peri-external auditory canal bone/soft tissue interface where intensity heterogeneity and geometric variability are greatest. These concentrated and interpretable deficits account for most of the residual error corrected during rapid expert review and indicate clear targets for future optimization. However, this study still had several limitations. First, by serving as the main reference data for CTV delineation, the preoperative imaging data indirectly participated in the training of the deep learning model by influencing the radiation oncologist’s delineations in the training dataset. In future studies, attempts will be made to input preoperative imaging data into the neural network model in hopes of achieving better automatic segmentation quality. Second, this was a single-center retrospective cohort with strict inclusion criteria (T1-T3, node-negative) and relatively uniform surgical approaches and imaging parameters, which may introduce selection bias and limit generalizability. As our cohort was dominated by low–intermediate grade tumors, external validation in high-grade and rarer histologic subtypes is planned, since these cases may require broader margins or exhibit more distorted postoperative beds, potentially affecting auto-segmentation performance. Thirdly, this study did not include a dose-distribution comparison between manual and physician-reviewed automatic contours, which remains a limitation; a prospective dosimetric evaluation is planned to assess whether the two approaches yield clinically equivalent treatment plans. Lastly, the segmentation of target volumes not only depends on medical imaging but can also integrate multiple types of information such as functional imaging, surgical records, and pathological diagnoses. Conclusions Automatic contouring, followed by physician review, enabled rapid and clinically acceptable CTV generation for postoperative brachytherapy in parotid-gland cancer. This workflow reduced the average delineation time from 46.7 minutes (fully manual) to 11.9 minutes per case after expert review, while maintaining contour quality comparable with manual delineation. Accordingly, the proposed deep-learning model functions as a useful support tool that streamlines physician-led radiation-treatment planning. Funding This work was supported by Clinical Research Foundation of Peking University School and Hospital of Stomatology (PKUSS-2024CRF302). Disclosures The study was approved by the Bioethics Committee of the Peking University School and Hospital of Stomatology (Approval No. PKUSSIRB-202385019). The authors declare no conflict of interest. 1 Wu WJ Gao Y Liu SM et al Subcutaneous injection of hyaluronic acid to decrease acute skin toxicity after adjuvant interstitial brachytherapy in parotid gland cancer patients: A nonrandomized controlled trial J Oral Maxillofac Surg 2020 78 167 172 31604061 10.1016/j.joms.2019.09.005 2 Yu G Peng X Conservative and functional surgery in the treatment of salivary gland tumours Int J Oral Sci 2019 11 22 31413317 10.1038/s41368-019-0059-9 PMC6802653 3 van der Veen J Gulyban A Nuyts S Interobserver variability in delineation of target volumes in head and neck cancer Radiother Oncol 2019 137 9 15 31048235 10.1016/j.radonc.2019.04.006 4 Li ZY Yue JH Wang W et al Deep learning-based two-step organs at risk auto-segmentation model for brachytherapy planning in parotid gland carcinoma J Contemp Brachytherapy 2022 14 527 535 36819465 10.5114/jcb.2022.123972 PMC9924151 5 Mukesh M Benson R Jena R et al Interobserver variation in clinical target volume and organs at risk segmentation in post-parotidectomy radiotherapy: can segmentation protocols help Br J Radiol 2012 85 e530 536 22815423 10.1259/bjr/66693547 PMC3587102 6 Hou Z Gao S Liu J et al Clinical evaluation of deep learning-based automatic clinical target volume segmentation: a single-institution multi-site tumor experience Radiol Med 2023 128 1250 1261 37597126 10.1007/s11547-023-01690-x 7 Jin D Guo D Ge J et al Towards automated organs at risk and target volumes contouring: Defining precision radiation therapy in the modern era J Natl Cancer Cent 2022 2 306 313 39036546 10.1016/j.jncc.2022.09.003 PMC11256697 8 Dei D Lambri N Crespi L et al Deep learning and atlas-based models to streamline the segmentation workflow of total marrow and lymphoid irradiation Radiol Med 2024 129 515 523 38308062 10.1007/s11547-024-01760-8 9 Delpon G Escande A Ruef T et al Comparison of automated atlas-based segmentation software for postoperative prostate cancer radiotherapy Front Oncol 2016 6 178 27536556 10.3389/fonc.2016.00178 PMC4971890 10 Hirotaki K Tomizawa K Moriya S et al Impact of anatomical position errors on dose distribution in head and neck radiotherapy and robust image registration against anatomical changes Anticancer Res 2023 43 1827 1834 36974799 10.21873/anticanres.16336 11 Men K Dai J Li Y Automatic segmentation of the clinical target volume and organs at risk in the planning CT for rectal cancer using deep dilated convolutional neural networks Med Phys 2017 44 6377 6389 28963779 10.1002/mp.12602 12 Lin L Dou Q Jin YM et al Deep learning for automated contouring of primary tumor volumes by MRI for nasopharyngeal carcinoma Radiology 2019 291 677 686 30912722 10.1148/radiol.2019182012 13 Smine Z Poeta S De Caluwé A et al Automated segmentation in planning-CT for breast cancer radiotherapy: A review of recent advances Radiother Oncol 2025 202 110615 39489430 10.1016/j.radonc.2024.110615 14 Walter A Hoegen-Saßmannshausen P Stanic G et al Segmentation of 71 anatomical structures necessary for the evaluation of guideline-conforming clinical target volumes in head and neck cancers Cancers (Basel) 2024 16 0 10.3390/cancers16020415 PMC11154560 38254904 15 Safigholi H Chamberland MJP Taylor REP et al Update of the CLRP TG-43 parameter database for low-energy brachytherapy sources Med Phys 2020 47 4656 4669 32436344 10.1002/mp.14249 16 Falk T Mai D Bensch R et al U-Net: deep learning for cell counting, detection, and morphometry [published correction appears in Nat Methods. 2019 Apr 16(4):351. doi: 10.1038/s41592-019-0356-4] Nat Methods 2019 16 67 70 30559429 10.1038/s41592-018-0261-2 17 He K Zhang X Ren S Sun J “Deep Residual Learning for Image Recognition” 2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), Las Vegas, NV, USA 2016 770 778 18 Lee CY Xie S Gallagher P et al Deeply-supervised nets[C]//Artificial intelligence and statistics PMLR 2015 562 570 19 Sudre CH Li W Vercauteren T et al Generalised dice overlap as a deep learning loss function for highly unbalanced segmentations[M]//Deep learning in medical image analysis and multimodal learning for clinical decision support Springer, Cham 2017 240 248 10.1007/978-3-319-67558-9_28 PMC7610921 34104926 20 Sukhbaatar S Fergus R Learning from noisy labels with deep neural networks arXiv preprint arXiv:1406 2080 2014 2 4 21 Zou KH Warfield SK Bharatha A et al Statistical validation of image segmentation quality based on a spatial overlap index Acad Radiol 2004 11 178 189 14974593 10.1016/S1076-6332(03)00671-8 PMC1415224 22 Jaccard P Nouvelles recherches sur la distribution florale Bull Soc Vaud Sci Nat 1908 44 223 270 23 Huttenlocher DP Klanderman GA Rucklidge WJ “Comparing images using the Hausdorff distance” IEEE Transactions on Pattern Analysis and Machine Intelligence 1993 15 850 863 24 Hosny KM Kassem MA Foaud MM Skin melanoma classification using ROI and data augmentation with deep convolutional neural networks Multimed Tool Appl 2020 79 24029 24055 25 Isaksson LJ Summers P Bhalerao A et al Quality assurance for automatically generated contours with additional deep learning Insights Imaging 2022 13 137 35976491 10.1186/s13244-022-01276-7 PMC9385913 26 Li Q Xu Y Chen Z et al Tumor segmentation in contrast-enhanced magnetic resonance imaging for nasopharyngeal carcinoma: Deep learning with convolutional neural network Biomed Res Int 2018 2018 9128527 30417017 10.1155/2018/9128527 PMC6207874 27 Cardenas CE Mccarroll RE Court LE et al Deep learning algorithm for auto-delineation of high-risk oropharyngeal clinical target volumes with built-in dice similarity coefficient parameter optimization function Int J Radiat Oncol Biol Phys 2018 101 468 478 29559291 10.1016/j.ijrobp.2018.01.114 PMC7473446 28 Kihara S Koike Y Takegawa H et al Clinical target volume segmentation based on gross tumor volume using deep learning for head and neck cancer treatment Med Dosim 2023 48 20 24 36273950 10.1016/j.meddos.2022.09.004 29 Li ZY Wu ZY Wu WJ et al Image fusion technique for target volume delineation in 125I seed implant brachytherapy for parotid gland cancers J Cancer Res Ther 2022 18 470 475 35645116 10.4103/jcrt.jcrt_266_21 30 Schmidt P Gaser C Arsic M et al An automated tool for detection of FLAIR-hyperintense white-matter lesions in multiple sclerosis Neuroimage 2012 59 3774 3783 22119648 10.1016/j.neuroimage.2011.11.032 ",
  "metadata": {
    "Title of this paper": "An automated tool for detection of FLAIR-hyperintense white-matter lesions in multiple sclerosis",
    "Journal it was published in:": "Journal of Contemporary Brachytherapy",
    "URL": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC12489543/"
  }
}