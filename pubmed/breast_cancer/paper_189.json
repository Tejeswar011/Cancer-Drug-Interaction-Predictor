{
  "title": "Paper_189",
  "abstract": "pmc Health Data Sci Health Data Sci 4547 hds HDS Health Data Science 2097-1095 2765-8783 AAAS Science Partner Journal Program PMC12489180 PMC12489180.1 12489180 12489180 10.34133/hds.0340 0340 1 Research Article Unsupervised Transformer Learning for Rapid and High-Quality MRI Data Acquisition Sui Yao  1  2  3  * Afacan Onur  4  5 Jaimes Camilo  4  6 Gholipour Ali  7 Warfield Simon K.  4  5 1 National Institute of Health Data Science Peking University China 2 Institute of Medical Technology Peking University China 3 Institute for Artificial Intelligence Peking University China 4 Harvard Medical School USA 5 Boston Children’s Hospital USA 6 Massachusetts General Hospital USA 7 Department of Radiological Sciences, School of Medicine University of California USA * yaosui@pku.edu.cn 02 10 2025 2025 5 478758 0340 06 1 2025 25 4 2025 21 7 2025 02 10 2025 02 10 2025 03 10 2025 03 10 2025 Copyright © 2025 Yao Sui et al. 2025 Yao Sui et al. https://creativecommons.org/licenses/by/4.0/ Exclusive licensee Peking University Health Science Center. No claim to original U.S. Government Works. Distributed under a Creative Commons Attribution License (CC BY 4.0) Background: Methods: Results: Conclusions: Major Program of National Natural Science Foundation of China 62394310, 62394312 Yao Sui National Institutes of Health http://dx.doi.org/10.13039/100000002 R01 NS133228, R01 NS121657 Onur Afacan National Institutes of Health http://dx.doi.org/10.13039/100000002 R01NS124212, R01LM013608, R01EB019483, R01NS106030 Simon Warfield National Institutes of Health http://dx.doi.org/10.13039/100000002 R01HD109395, R01EB031849 Ali Gholipour National Institutes of Health http://dx.doi.org/10.13039/100000002 R21EB036105 Camilo Jaimes pmc-status-qastatus 0 pmc-status-live yes pmc-status-embargo no pmc-status-released yes pmc-prop-open-access yes pmc-prop-olf no pmc-prop-manuscript no pmc-prop-legally-suppressed no pmc-prop-has-pdf yes pmc-prop-has-supplement no pmc-prop-pdf-only no pmc-prop-suppress-copyright no pmc-prop-is-real-version no pmc-prop-is-scanned-article no pmc-prop-preprint no pmc-prop-in-epmc yes Introduction Magnetic resonance imaging (MRI) holds substantial significance due to its various applications in scientific research and clinical investigations, such as neuroimaging [ 1 5 6 10 11 15 16 21 22 23 Many efforts have been made to address the aforementioned challenge. Parallel imaging [ 24 25 26 27 Super-resolution reconstruction utilizes multiple low-resolution images as input to produce a single high-resolution image as output. Consequently, this approach is compatible with fast imaging techniques, as low-resolution images can be acquired in shorter scan times. Moreover, the larger voxel size in low-resolution images results in an improved SNR, because each voxel accumulates a greater signal strength while maintaining a constant noise level [ 28 29 30 31 32 Over the past decade, substantial advances in deep learning have been made, particularly in enhancing MRI super-resolution reconstruction, achieving promising results in the context of scientific research MRI [ 33 38 39 40 41 Currently, most super-resolution reconstruction architectures are centered around convolutional neural networks (CNNs) [ 38 42 43 44 44 47 22 48 49 In this study, we introduced a new transformer-based architecture to address the challenge of super-resolution reconstruction. We developed an unsupervised learning strategy for the super-resolution reconstruction, allowing us to train the architecture directly on image data acquired from individual patients. With our proposed super-resolution reconstruction algorithm, we successfully reconstructed high-resolution images with T2 contrast at a 500-μm isotropic resolution in just 4 min of imaging. Figure 1 Fig. 1. Overview of our approach with an unsupervised transformer learning strategy. The contributions of this study are summarized below. • We propose a new methodology that enables rapid and high-quality MRI data acquisition through super-resolution technique. We develop a novel super-resolution approach that utilizes transformers to exploit long-range spatial dependencies present in images, allowing for an unsupervised learning framework tailored to individual subjects. • We demonstrate that the integration of long-range spatial dependencies significantly improves super-resolution reconstruction. We validate that our approach provides a clinically practical imaging duration for acquiring T2-weighted images with sub-millimeter resolution. Our results indicate that only 4 min of imaging are required to generate an image with T2 contrast and an isotropic spatial resolution of 500 μm, while in parallel, SNR and contrast-to-noise ratio (CNR) are increased by 13.23% and 18.45%, respectively, when compared to state-of-the-art super-resolution techniques. Methods This study seeks to establish an innovative methodology capable of acquiring high-quality MRI images within time frames suitable for clinical application on a patient-specific basis. To accomplish this goal, we devise an unsupervised deep learning technique for super-resolution reconstruction. Our approach encompasses the design of acquisition protocols, modeling of the acquisition process, and the creation of a super-resolution reconstruction algorithm. The subsequent sections present a detailed account of our method. Acquisition protocol The primary goal of this study is to acquire multiple low-resolution images, subsequently reconstructing them into a high-resolution image through a super-resolution reconstruction technique. The time taken for imaging is crucial in obtaining these low-resolution images, especially in the context of clinical applications. Consequently, our acquisition strategy incorporates high in-plane resolution coupled with thick slices. The elevated in-plane resolution helps mitigate the aliasing of Fourier encoding [ 30 31 50 Research has indicated that the use of multiple low-resolution images enhances the effectiveness of super-resolution reconstruction compared to relying on a single low-resolution image [ 51 52 In light of the preceding discussion, we develop a T2 turbo spin echo (TSE) sequence specifically for brain imaging on a 3-T MRI system. The imaging protocol specifies an in-plane resolution of 500 μm and a slice thickness of 2 mm. Parameters include a repetition time of 13,100 ms, an echo time of 93 ms, a flip angle of 160°, a bandwidth of 195 Hz/pixel, an echo train length of 16, and an echo spacing of 9.8 ms. We employ GRAPPA parallel imaging [ 25 Acquisition model The acquisition model characterizes the imaging process that can be systematically represented in the following steps. A high-resolution observation of the brain undergoes a transformation within its spatial coordinate system due to the varying head positions and orientations across different scans. Subsequently, the transformed image is subjected to blurring effects resulting from slice excitation, as well as phase and frequency encoding. The low-resolution image is then generated by downsampling the blurred image. Hence, the acquisition model is expressed as y i = b i ∗ m i ∘ x ↓ i + e , i = 1 , 2 , … , N , (1) x y i i e m i i b i i ↓ i i ∗ ∘ We collectively register all low-resolution images to determine the transformation matrices m i i = 1 N b i i = 1 N Unsupervised transformer learning Our goal is to estimate the high-resolution image x y i Eq. 1 e 53 min x ∑ i = 1 N y i − b i ∗ m i ∘ x ↓ i 2 2 . (2) Unfortunately, this is an inherent ill-posed problem, as the observations (the number of voxels in y i x 27 50 54 55 56 57 58 59 60 min θ ∑ i = 1 N y i − b i ∗ m i ∘ T θ y i i = 1 N ↓ i 2 2 , s . t . x = T θ y i i = 1 N . (3) The transformer network T θ y i i = 1 N θ 1 27 Eq. 1 ℓ 2 61 Eq. 3 θ 62 63 θ x = T θ y i i = 1 N . (4) Experimental setup We conduct comprehensive experiments to rigorously assess the effectiveness of our proposed method. Through these experiments, we aim to demonstrate the advantages of our approach in super-resolution reconstruction when compared to current leading methods. Datasets Simulated dataset To validate the accuracy of our proposed approach for super-resolution reconstruction, the inclusion of ground-truth images is essential. Nevertheless, acquiring high-resolution MRI images with adequate SNR poses a substantial challenge, making the acquisition of such high-quality ground-truth images unattainable for validation purposes. As a result, synthetic data are often employed to carry out experiments requiring ground-truth images. The fundamental concept involves using a high-quality image as the ground truth, from which corresponding low-resolution images are generated in accordance with the acquisition model outlined in Eq. 1 Using the Dryad package [ 39 Phantom dataset To evaluate the effectiveness of our proposed approach in practical imaging settings, we carried out phantom scans to investigate the image quality provided by our super-resolution reconstruction approach. A benefit of conducting phantom studies is the ability to obtain reference images at high spatial resolution while avoiding motion artifacts; however, a notable drawback is that high-resolution scans can result in a decreased SNR. An ACR phantom was scanned utilizing a T2 TSE sequence. Three low-resolution images were obtained, each with an in-plane resolution of 1 mm × 1 mm and a slice thickness of 4 mm across the axial, coronal, and sagittal orientations. Additionally, a high-resolution image was acquired at an isotropic resolution of 1 mm, functioning as a reference. The aim of employing this dataset is to reconstruct high-resolution phantom images at an isotropic resolution of 1 mm using these 3 low-resolution images. T2 TSE dataset To assess practical applicability, it is essential to examine our proposed method within routine clinical scenarios. Therefore, the behavior of all participants during imaging sessions remains unmanageable and unpredictable in this context. In order to evaluate the practical effectiveness of our proposed approach, gold-standard images are required, serving as reference images in each dataset acquired from individual subjects. It should be noted that the overall quality of these reference images might be inferior compared to the images generated through super-solution reconstruction methods. This quality discrepancy arises because direct high-resolution acquisitions suffer from reduced SNR, whereas super-solution reconstruction methods enhance both resolution and SNR simultaneously. This represents the fundamental distinction between the ground-truth images in the simulated datasets and the reference images acquired for the real datasets. We enrolled 12 volunteers to participate in our study. Using a 3-T Siemens scanner (Siemens Healthcare, Erlangen, Germany), we performed scans on these participants. We instructed them to keep their heads still during the imaging sessions to minimize motion artifacts. A total of 36 T2 image scans were collected for our real datasets. Each participant underwent the acquisition of an axial and a coronal low-resolution T2 TSE image for reconstruction, as well as a high-resolution sagittal T2 SPACE image as a reference image. The reference images possessed an isotropic spatial resolution of 900 μm. The in-plane resolution of the low-resolution T2 TSE images was 500 μm, while the through-plane resolution was 2 mm. Acquiring a low-resolution T2 TSE image took approximately 2 min, whereas the acquisition of a T2 SPACE high-resolution image required about 6 min. All scanning procedures were in compliance with the local institutional review board (IRB) guidelines. We achieved reconstruction of the high-resolution image at an isotropic resolution of 500 μm from the 2 low-resolution T2 TSE images for each dataset. Assessment criteria The effectiveness of our method was extensively assessed using specific metrics to gauge reconstruction accuracy, SNR, and image sharpness. For the simulated datasets with available ground-truth images, we opted for metrics allowing voxel-wise comparisons (structural similarity index [SSIM] [ 64 65 66 29 29 67 Structural similarity index In addition to the mean squared error, the SSIM metric [ 64 Normalized mutual information Mutual information serves as a frequently utilized measure to assess the similarity between 2 images, focusing on the probability density of voxel intensities, especially when the images have varying contrasts. A widely recognized variant is the NMI metric [ 65 Jensen–Shannon divergence The JSD metric [ 66 p q d p q = ∑ i = 1 N p i log 2 p i p i + q i + q i log 2 q i p i + q i , (5) p i q i i p q N p q Sharpness The clarity of boundaries between different tissues or lesions in brain MRI images is of paramount importance. A common way to evaluate this characteristic is by assessing the sharpness of image edges. In this study, we utilized the average edge strength (AES) measure [ 67 AES = 1 ∑ k E k ∑ k E k G k 2 2 , (6) E k k 68 G k k 69 Signal-to-noise ratio SNR substantially influences the quality of MRI images. For the computation of SNR values, we followed the methodology outlined in Ref. [ 29 SNR = s σ , (7) s σ 70 71 72 Contrast-to-noise ratio CNR emphasizes the distinction between various tissue types within the imaging context. To evaluate brain MRI images, we determined the CNR between gray matter and white matter. Adopting the approach delineated in [ 29 CNR = s GM − s WM σ , (8) s GM s WM σ Baseline methods Given that our learning approach is unsupervised, it eliminates the need for extensive auxiliary training datasets to train the network. As a result, we did not perform comparisons with supervised methods, but instead focused on evaluating against methods that utilize unsupervised frameworks exclusively. To this end, we incorporated 2 baseline methods in our study. SSGNN The SSGNN method employs an unsupervised learning framework to produce an enhanced super-resolution reconstruction model utilizing CNNs [ 49 49 TV Methods based on TV regularization are extensively employed in super-resolution reconstruction tasks [ 27 27 Results Our super-resolution reconstruction method was executed on an NVIDIA Quadro RTX 8,000 GPU, achieving the reconstruction of a high-resolution image with an isotropic resolution of 500 μm in under 3 h. In the report detailing our experimental results, we termed our method Reconformer to emphasize its use of transformer learning for the purpose of reconstruction. On simulated datasets Figure 2 Fig. 2. Quantitative comparisons on the simulated datasets at different upscale factors. Our approach (Reconformer) outperformed the 2 baseline methods consistently at all upscale factors. This was evidenced by the superior values in terms of (A) SSIM (↑), (B) NMI (↑), (C) SNR (↑), and (D) CNR (↑). In this context, (↑) indicates that higher values are deemed more favorable. Figure 3 2 Fig. 3. Qualitative comparisons on the simulated datasets. The rows, arranged from top to bottom, depict low-resolution scans alongside the corresponding high-resolution reconstructions obtained via TV, SSGNN, and Reconformer methods, respectively. These images are presented in the axial, coronal, and sagittal planes from left to right. The expanded sections on the far right provide detailed views of the areas highlighted by red boxes to facilitate enhanced visualization. The qualitative analysis indicates that our approach, the Reconformer, successfully produced high-resolution images characterized by superior edge sharpness, improved SNR, and enhanced contrast between gray and white matter in comparison to direct acquisition and the 2 baseline techniques. Figure 4 Fig. 4. Segmentation of brain tissues on the simulated datasets. The top panel illustrates the segmentation outputs, distinguishing gray matter, white matter, and cerebrospinal fluid (CSF) through various colorizations. The middle and bottom panels depict the segmented gray matter and white matter, respectively, with voxel intensity values extending from 0 to 1, indicating the probability of membership in the respective segmented tissues. It is important to highlight that the inclusion of certain tissues, such as the cerebellum and brain stem, in either the gray matter or white matter categories is inconsequential, since the segmentation was primarily employed for calculating SNR and CNR, rather than for precise morphological assessment. In summary, our Reconformer method exhibited strong performance when tested on the simulated datasets, showcasing its advantages over the 2 baseline techniques. On phantom datasets Table 1 5 Table 1. Quantitative evaluations on the phantom datasets, measured using NMI, JSD, sharpness, and SNR. The results indicate that our proposed approach, Reconformer, surpassed the baseline methods, TV and SSGNN, across all metrics on the phantom datasets. The most favorable results, highlighted by the relevant metrics, are emphasized in bold type. Metric TV SSGNN Reconformer (ours) Reference NMI 1.138 1.143  1.147 - JSD 0.685 0.581  0.561 - Sharpness 1.032 1.068  1.074 - SNR 26.935 27.638  28.724 20.718 Fig. 5. Qualitative comparisons on the phantom datasets. Our method evidently achieved the highest-quality image. In contrast, the reference image showed considerable noise, the TV approach led to excessive smoothing, and SSGNN resulted in artifacts, as indicated by the yellow arrows. On T2 TSE datasets Figure 6 73 2 Fig. 6. Quantitative comparisons on the T2 TSE datasets. Violin plots were utilized to illustrate the statistical characteristics of the results. Each plot depicts the minimum, mean, maximum, and the rotated empirical distribution of the metrics on either side. The results reveal that our method, Reconformer, substantially surpassed the baseline techniques, TV and SSGNN, regarding (A) SSIM (↑), (B) NMI (↑), (C) JSD (↓), (D) Sharpness (↑), (E) SNR (↑), and (F) CNR (↑). Here, (↑) denotes that higher values are preferable, while (↓) signifies that lower values are favorable. Table 2. Quantitative assessment on the T2 TSE datasets, evaluated using SSIM, NMI, JSD, sharpness, SNR, and CNR, yielding mean and standard deviation values. The analysis indicates that our proposed approach, Reconformer, consistently outperformed the baseline methods, TV and SSGNN, across all metrics on the T2 TSE datasets. The best results, as determined by the corresponding metrics, are highlighted by numbers in bold font. Metric TV SSGNN Reconformer (ours) SSIM 0.5593 ± 0.0249 0.7014 ± 0.0304 0.7432 NMI 1.0078 ± 0.0317 1.1030 ± 0.0234 1.1276 JSD 0.1555 ± 0.2858 0.0554 ± 0.0406 0.0389 Sharpness 1.1302 ± 0.0971 1.3132 ± 0.1004 1.4372 SNR 22.0243 ± 1.2101 25.7661 ± 2.3579 29.1738 CNR 14.3238 ± 1.3097 18.2133 ± 2.5278 21.5744 Two-sample t P = 5.9 × 10 − 3 P = 2.5 × 10 − 2 P = 2.7 × 10 − 2 P = 1.7 × 10 − 2 P = 1.6 × 10 − 2 Figure 7 Fig. 7. Qualitative comparisons on the T2 TSE datasets. The row sections, arranged from top to bottom, display the axial, coronal, and sagittal slices of a representative subject. In the first 2 columns, the acquired low-resolution T2 TSE and the high-resolution T2 SPACE reference images are shown. The last 3 columns present the high-resolution images reconstructed by TV, SSGNN, and Reconformer, respectively. Among these methods, our approach, Reconformer, demonstrated superior image quality for this subject. In contrast, the reference image and the high-resolution reconstruction using TV exhibit blurred edges and low image contrast, whereas SSGNN introduced subtle artifacts into its high-resolution reconstruction, marked by the orange arrows. In summary, when assessed on the T2 TSE datasets, our Reconformer method demonstrated improved image quality relative to direct high-resolution T2 SPACE acquisitions and the 2 baseline techniques. Parameter investigation The size of tokenization patches from the input image is a crucial parameter that affects the performance of our method. Thus, we conducted an analysis to determine the optimal patch size setting in our model. We selected 3 typical patch size values: 8 × 8 × 8, 16 × 16 × 16, and 32 × 32 × 32 pixels. The performance of our approach was assessed using phantom datasets, focusing on reconstruction accuracy (NMI and JSD) and image quality metrics (sharpness and SNR). As shown in Table 3 Table 3. Quantitative evaluations on the phantom datasets across various configurations concerning the size of tokenization patches from the input image for our proposed model. This assessment employed metrics such as NMI, JSD, sharpness, and SNR. The results show that our proposed approach, Reconformer, achieved optimal performance with a patch size of 16 × 16 × 16 pixels. The most favorable results, according to the assessed metrics, are emphasized in bold type. Metric Patch size 8 × 8 × 8 16 × 16 × 16 32 × 32 × 32 NMI 1.140  1.147 1.139 JSD 0.577  0.561 0.584 Sharpness 1.073  1.074 1.073 SNR 27.387  28.724 27.037 Discussion Our methodology has been extensively assessed via detailed experiments using both simulated and real datasets. This section discusses the study, focusing on its limitations, possible applications, and directions for future exploration. Applications Our super-resolution reconstruction technique facilitates various applications; for example, it aids in the compression of clinical image data to conserve storage space, enhances clinical imaging to improve diagnostic quality, and allows for quantitative imaging while maintaining clinically acceptable scan durations. The routine clinical use of MRI generates a large amount of images every day. These images must have sufficiently high resolutions to ensure diagnostic precision. Consequently, maintaining and storing the image data presents a substantial challenge. To conserve storage space, it is desirable to minimize the image data size as much as possible. Our super-resolution reconstruction method offers a potential solution to this issue. This method enables the acquisition of only a limited number of low-resolution images per subject and can reconstruct high-resolution images from these low-resolution scans as needed. Thus, with our technique, only low-resolution images need to be stored for each patient, substantially lowering data storage and maintenance costs. A further direct application of our methodology is in the domain of neonatal brain imaging [ 3 74 76 The literature demonstrates that quantitative MRI methodologies enhance the detection of brain lesions [ 77 80 Limitations Super-resolution reconstruction techniques, especially those leveraging deep learning, have frequently faced criticism due to the possibility that the improved resolution could result in visually appealing but artificial enhancements, often referred to as hallucinations. This problem is particularly substantial in the reconstruction of medical images, where maintaining accurate anatomical structures is vital for clinical applications. Our method, distinct from earlier deep learning approaches, depends solely on low-resolution data obtained from an individual patient. By not incorporating insights gained from other subjects, such as through transfer learning with large external datasets, our method reduces the risk of hallucinations. Moreover, employing an explainable model for super-resolution reconstruction can yield reliable results, making it a promising area for future exploration. Conclusion We have developed a new methodology that enables rapid and high-quality MRI data acquisition through a novel super-resolution approach. We have proposed an innovative network architecture grounded in transformers incorporating an unsupervised learning method for super-resolution reconstruction, which facilitates the creation of high-quality images customized for individual subjects. This methodology has allowed us to generate high-resolution images with T2 contrast at an isotropic spatial resolution of 500 μm, requiring merely 4 min of scanning. Our approach has been evaluated using both simulated datasets and clinical data comprising 40 scans using a 3-T MRI scanner. The results demonstrated that incorporating long-range spatial dependencies considerably enhanced the super-resolution reconstruction tasks. The conducted experiments revealed that our technique produced superior results compared to both direct high-resolution imaging and the leading super-resolution reconstruction techniques. Ethical Approval All scans were performed in accordance with the local IRB protocol. Acknowledgments Funding: Author contributions: Competing interests: Data Availability The datasets used in the simulated experiments are accessible through the URL provided in Ref. [ 39 References 1. Lerch J van der Kouwe A Raznahan A Paus T Johansen-Berg H Miller KL Smith SM Fischl B Sotiropoulos SN Studying neuroanatomy using MRI Nat Neurosci 2017 20 314 326 28230838 10.1038/nn.4501 2. Nichols T Das S Sea E Best practices in data analysis and sharing in neuroimaging using MRI Nat Neurosci 2017 20 3 299 303 28230846 10.1038/nn.4500 PMC5685169 3. Sui Y Afacan O Gholipour A Warfield SK Fast and high-resolution neonatal brain MRI through super-resolution reconstruction from acquisitions with variable slice selection direction Front Neurosci 2021 15 1 15 10.3389/fnins.2021.636268 PMC8242183 34220414 4. Cumplido-Mayoral I Sánchez-Benavides G Vilor-Tejedor N López-Martos D Brugulat-Serrat A Milà-Alomà M Falcon C Cacciaglia R Minguillón C Fauria K et al. Neuroimaging-derived biological brain age and its associations with glial reactivity and synaptic dysfunction cerebrospinal fluid biomarkers Mol Psychiatry 2025 30 8 3718 3728 40221600 10.1038/s41380-025-02961-x PMC12240798 5. Muetzel RL Enhancing consistency in brain imaging research for population neuroimaging Nat Protoc 2024 20 5 1099 1100 10.1038/s41596-024-01117-5 39672918 6. Esteban O Ciric R Kea F Analysis of task-based functional MRI data preprocessed with fMRIPrep Nat Protoc 2020 15 7 2186 2202 32514178 10.1038/s41596-020-0327-3 PMC7404612 7. Cohen J Daw N Bea E Computational approaches to fMRI analysis Nat Neurosci 2017 20 3 304 313 28230848 10.1038/nn.4499 PMC5457304 8. Cai J Hadjinicolaou AE Paulk AC Soper DJ Xia T Wang AF Rolston JD Richardson RM Williams ZM Cash SS Natural language processing models reveal neural dynamics of human conversation Nat Commun 2025 16 1 3376 40204693 10.1038/s41467-025-58620-w PMC11982309 9. Lv M Wang L Huang R Wang A Li Y Zhang G Research on noise-induced hearing loss based on functional and structural MRI using machine learning methods Sci Rep 2025 15 1 3289 39865152 10.1038/s41598-025-87168-4 PMC11770180 10. Ren J An N Lin C Zhang Y Sun Z Zhang W Li S Guo N Cui W Hu Q et al. DeepPrep: An accelerated, scalable and robust pipeline for neuroimaging preprocessing empowered by deep learning Nat Methods 2025 22 3 473 476 39915693 10.1038/s41592-025-02599-1 PMC11903312 11. Hilabi BS Alghamdi SA Almanaa M Impact of magnetic resonance imaging on healthcare in low- and middle-income countries Cureus 2023 15 4 Article e37698 37081900 10.7759/cureus.37698 PMC10112545 12. van Beek EJR Kuhl C Anzai Y Desmond P Ehman RL Gong Q Gold G Gulani V Hall-Craggs M Leiner T et al. Value of MRI in medicine: More than just another test? J Magn Reson Imaging 2019 49 1 e14 e25 30145852 10.1002/jmri.26211 PMC7036752 13. Singh H Deshmukh M Awasthi L kumar. Secure healthcare data management using multimodal image fusion and dual watermarking Sci Rep 2025 15 1 9047 40090963 10.1038/s41598-025-93544-x PMC11911451 14. Kim J Chen ML Rezaei SJ et al. Artificial intelligence tools in supporting healthcare professionals for tailored patient care NPJ Digit Med 2025 8 1 210 40240489 10.1038/s41746-025-01604-3 PMC12003912 15. Fairbairn TA Mullen L Nicol ED Lip GYH Schmitt M Shaw M Tidbury L Kemp I Crooks J Burnside G et al. Implementation of a national AI technology program on cardiovascular outcomes and the health system Nat Med 2025 31 6 1903 1910 40186078 10.1038/s41591-025-03620-y PMC12176617 16. Mohsen F Ali H Nea EH Artificial intelligence-based methods for fusion of electronic health records and imaging data Sci Rep 2022 12 1 17981 36289266 10.1038/s41598-022-22514-4 PMC9605975 17. Wu Y Liu X Yea H An open relaxation-diffusion MRI dataset in neurosurgical studies Sci Data 2024 11 1 177 38326377 10.1038/s41597-024-03013-9 PMC10850093 18. Tibrewala R Dutt T Aea T Ginocchio L Lattanzi R Keerthivasan MB Baete SH Chopra S Lui YW Sodickson DK et al. FastMRI prostate: A public, biparametric MRI dataset to advance machine learning for prostate cancer imaging Sci Data 2024 11 1 404 38643291 10.1038/s41597-024-03252-w PMC11032332 19. van der Graaf JW van Hooff M Buckens CFM Rutten M van Susante JLC Kroeze RJ de Kleuver M van Ginneken B Lessmann N Lumbar spine segmentation in MR images: A dataset and a public benchmark Sci Data 2024 11 1 264 38431692 10.1038/s41597-024-03090-w PMC10908819 20. Salim M Liu Y Sorkhei M Ntoula D Foukakis T Fredriksson I Wang Y Eklund M Azizpour H Smith K et al. AI-based selection of individuals for supplemental MRI in population-based breast cancer screening: The randomized ScreenTrustMRI trial Nat Med 2024 30 9 2623 2630 38977914 10.1038/s41591-024-03093-5 PMC11405258 21. Aziz-Zadeh L Ringold SM Jayashankar A Kilroy E Butera C Jacobs JP Tanartkit S Mahurkar-Joshi S Bhatt RR Dapretto M et al. Relationships between brain activity, tryptophan related gut metabolites, and autism symptomatology Nat Commun 2025 16 1 Article 3465 40229237 10.1038/s41467-025-58459-1 PMC11997199 22. Afacan O Erem B Roby DP Roth N Roth A Prabhu SP Warfield SK Evaluation of motion and its effect on brain magnetic resonance image quality in children Pediatr Radiol 2016 46 12 1728 1735 27488508 10.1007/s00247-016-3677-9 PMC5083190 23. Sui Y Afacan O Gholipour A Warfield SK SLIMM: Slice localization integrated MRI monitoring NeuroImage 2020 223 Article 117280 32853815 10.1016/j.neuroimage.2020.117280 PMC7735257 24. Pruessmann KP Weiger M Scheidegger MB Boesiger P SENSE: Sensitivity encoding for fast MRI Magn Reson Med 1999 42 5 952 962 10542355 25. Griswold MA Jakob PM Heidemann RM Nittka M Jellus V Wang J Kiefer B Haase A Generalized autocalibrating partially parallel acquisitions (GRAPPA) Magn Reson Med 2002 47 6 1202 1210 12111967 10.1002/mrm.10171 26. Burkett BJ Fagan AJ Felmlee JP Black DF Lane JI Port JD Rydberg CH Welker KM Clinical 7-T MRI for neuroradiology: Strengths, weaknesses, and ongoing challenges Neuroradiology 2021 63 2 167 177 33388947 10.1007/s00234-020-02629-z 27. Plenge E Poot DH Bernsen M Kotek G Houston G Wielopolski P Van Der Weerd L Niessen WJ Meijering E Super-resolution methods in MRI: Can they improve the trade-off between resolution, signal-to-noise ratio, and acquisition time? Magn Reson Med 2012 68 6 1983 1993 22298247 10.1002/mrm.24187 28. Sijbers J Scheunders P Bonnet N Van Dyck D Raman E Quantification and improvement of the signal-to-noise ratio in a magnetic resonance image acquisition procedure Magn Reson Med 1996 14 10 1157 1163 10.1016/s0730-725x(96)00219-6 9065906 29. Dietrich O Raya J Reeder S Reiser M Schoenberg S Measurement of signal-to-noise ratios in MR images: Influence of multichannel coils, parallel imaging, and reconstruction filters J Magn Reson Imaging 2007 26 2 375 385 17622966 10.1002/jmri.20969 30. Scheffler K Superresolution in MRI? Magn Reson Med 2002 48 2 Article 408 10.1002/mrm.10203 12210953 31. Peled S Yeshurun Y Super-resolution in MRI—Perhaps sometimes Magn Reson Med 2002 48 2 Article 409 32. Greenspan H Oz G Kiryati N Peled S MRI inter-slice reconstruction using super resolution Magn Reson Med 2002 20 5 437 434 10.1016/s0730-725x(02)00511-8 12206870 33. Pham C, Ducournau A, Fablet R, Rousseau F. Brain MRI super-resolution using deep 3D convolutional networks. In: International Symposium on Biomedical Imaging 34. Chen Y, Xie Y, Zhou Z, Shi F, Christodoulou AG, Li D. Brain MRI super resolution using 3D deep densely connected neural networks. In: International Symposium on Biomedical Imaging 35. Chaudhari A Fang Z Kogan F Wood J Stevens KJ Gibbons EK Lee JH Gold GE Hargreaves BA Super-resolution musculoskeletal MRI using deep learning Magn Reson Med 2018 80 5 2139 2154 29582464 10.1002/mrm.27178 PMC6107420 36. Chen Y, Shi F, Christodoulou AG, Xie Y, Zhou Z, Li D. Efficient and accurate MRI super resolution using a generative adversarial network and 3D multi-level densely connected network. In: Medical Image Computing and Computer-Assisted Intervention (MICCAI) 37. Wang J, Chen Y, Wu Y, Shi J, Gee J. Enhanced generative adversarial network for 3D brain MRI super-resolution. In: IEEE Winter Conference on Applications of Computer Vision 38. Cherukuri V Guo T Schiff SJ Monga V Deep MR brain image super-resolution using spatio-structural priors IEEE Trans Image Process 2020 29 1368 1383 10.1109/TIP.2019.2942510 PMC7335214 31562091 39. Lüsebrink F Sciarra A Mattern H Yakupov R Speck O T1-weighted in vivo human whole brain MRI dataset with an ultrahigh isotropic resolution of 250 um Sci Data 2017 14 1 1 2 10.1038/sdata.2017.32 PMC5349250 28291265 40. Sui Y, Afacan O, Gholipour A, Warfield SK. Learning a gradient guidance for spatially isotropic MRI super-resolution reconstruction. In: Medical Image Computing and Computer Assisted Intervention (MICCAI) 10.1007/978-3-030-59713-9_14 PMC7643753 33163994 41. Sui Y, Afacan O, Gholipour A, Warfield SK. MRI super-resolution through generative degradation learning. In: Medical Image Computing and Computer-Assisted Intervention (MICCAI) 10.1007/978-3-030-87231-1_42 PMC8550564 34713277 42. Xue X Wang Y Li J Jiao Z Ren Z Gao X Progressive sub-band residual-learning network for MR image super-resolution IEEE J Biomed Health Inform 2020 24 2 377 386 31603805 10.1109/JBHI.2019.2945373 43. Zhao X Zhang Y Zhang T Zou X Channel splitting network for single MR image super resolution IEEE Trans Image Process 2019 28 11 5649 5662 31217110 10.1109/TIP.2019.2921882 44. Vaswani A, Shazeer N, Parmar N, Uszkoreit J, Jones L, Gomez AN, Kaiser Ł, Polosukhin I. Attention is all you need. In: Advances in neural information processing systems (NeurIPS) 45. Dosovitskiy A, Beyer L, Kolesnikov A, Weissenborn D, Zhai X, Unterthiner T, Dehghani M, Minderer M, Heigold G, Gelly S, et al. An image is worth 16x16 words: Transformers for image recognition at scale. In: International Conference on Learning Representations (ICLR) 46. Chen J, Lu Y, Yu Q, Luo X, Adeli E, Wang Y, Lu L, Yuille AL, Zhou Y. TransUNet: Transformers make strong encoders for medical image segmentation. arXiv. 2021. 10.48550/arXiv.2102.04306 47. Hatamizadeh A, Tang Y, Nath V, Yang D, Myronenko A, Landman B, Roth HR, Xu D. UNETR: Transformers for 3D medical image segmentation. In: IEEE/CVF Winter Conference on Applications of Computer Vision (WACV) 48. Ulyanov D Vedaldi A Lempitsky V Deep image prior IEEE/CVF Conf Comput Vis Pattern Recog 2018 2018 9446 9454 49. Sui Y Afacan O Jaimes C Gholipour A Warfield S Scan-specific generative neural network for MRI super-resolution reconstruction IEEE Trans Med Imaging 2022 41 6 1383 1399 35020591 10.1109/TMI.2022.3142610 PMC9208763 50. Gholipour A Estroff JA Warfield SK Robust super-resolution volume reconstruction from slice acquisitions: Application to fetal brain MRI IEEE Trans Med Imaging 2010 29 10 1739 1758 20529730 10.1109/TMI.2010.2051680 PMC3694441 51. Fiat D. Method of enhancing an MRI signal. US Patent 6,294,914. 2001. 52. Shilling RZ Robbie TQ Bailloeul T Mewes K Mersereau RM Brummer ME A super resolution framework for 3-D high-resolution and high-contrast imaging using 2-D multi slice MRI IEEE Trans Med Imaging 2009 28 5 633 644 19272995 10.1109/TMI.2008.2007348 53. Gudbjartsson H Patz S The Rician distribution of Noisy MRI data Magn Reson Med 1995 34 6 910 914 8598820 10.1002/mrm.1910340618 PMC2254141 54. Huber PJ Robust estimation of a location parameter Ann Stat 1964 53 73 101 55. Tourbier S Bresson X Hagmann P Thiran J Meuli R Cuadra M An efficient total variation algorithm for super-resolution in fetal brain MRI with adaptive regularization NeuroImage 2015 118 584 597 26072252 10.1016/j.neuroimage.2015.06.018 56. Farsiu S Robinson MD Elad M Milanfar P Fast and robust multiframe super resolution IEEE Trans Image Process 2004 13 10 1327 1344 15462143 10.1109/tip.2004.834669 57. Shi F Cheng J Wang L Yap P Shen D LRTV: MR image super-resolution with low rank and total variation regularizations IEEE Trans Med Imaging 2015 34 12 2459 2466 26641727 10.1109/TMI.2015.2437894 PMC5572670 58. Rousseau F, Kim K, Studholme C, Koob M, Dietemann JL. On super-resolution for fetal brain MRI. In: Medical Image Computing and Computer-Assisted Intervention (MICCAI) 10.1007/978-3-642-15745-5_44 PMC3319126 20879335 59. Sui Y, Afacan O, Gholipour A, Warfield SK. Isotropic MRI super-resolution reconstruction with multi-scale gradient field prior. In: Medical Image Computing and Computer-Assisted Intervention (MICCAI) 10.1007/978-3-030-32248-9_1 PMC7437607 32832937 60. Sui Y Afacan O Gholipour A Warfield SK Gradient-guided isotropic MRI reconstruction from anisotropic acquisitions IEEE Trans Comput Imaging 2021 7 1240 1253 35252479 10.1109/tci.2021.3128745 PMC8896514 61. Kingma DP, Ba J. Adam: A method for stochastic optimization. In: International Conference on Learning Representations (ICLR) 62. Paszke A, Gross S, Chintala S, Chanan G, Yang E, DeVito Z, Lin Z, Desmaison A, et al. Automatic differentiation in PyTorch. In: Neural Information Processing Systems (NIPS) Workshop 63. The MONAI Consortium. MONAI: An open-source framework for deep learning in healthcare. arXiv. 2022. https://doi.org/10.48550/arXiv.2211.02701 64. Wang Z Bovik AC Sheikh HR Simoncelli EP Image quality assessment: From error measurement to structural similarity IEEE Trans Image Process 2004 13 1 600 612 15376593 10.1109/tip.2003.819861 65. Studholme C Hill DLG Hawkes DJ An overlap invariant entropy measure of 3D medical image alignment Pattern Recogn 1999 32 1 71 86 66. Endres DM Schindelin JE A new metric for probability distributions IEEE Trans Inf Theory 2003 49 7 1858 1860 67. Zaca D Hasson U Minati L Jovicich J Method for retrospective estimation of natural head movement during structural MRI J Magn Reson Imaging 2018 48 4 927 653 29393987 10.1002/jmri.25959 68. Canny JF A computational approach to edge detection IEEE Trans Pattern Anal Mach Intell 1986 8 6 679 698 21869365 69. Prewitt JMS Object enhancement and extraction Picture Processing Psychopictorics 1970 10 1 15 19 70. Zhang Y Brady M Smith S Segmentation of brain MR images through a hidden Markov random field model and the expectation-maximization algorithm IEEE Trans Med Imaging 2001 20 1 45 57 11293691 10.1109/42.906424 71. Jenkinson M Beckmann C Behrens T Woolrich M Smith S FSL NeuroImage 2012 62 2 782 790 21979382 10.1016/j.neuroimage.2011.09.015 72. Smith S Fast robust automated brain extraction Hum Brain Mapp 2002 17 3 143 155 12391568 10.1002/hbm.10062 PMC6871816 73. Plot V NIST DataPlot National Institute of Standards and Technology 2015 74. Askin Incebacak NC Sui Y Gui Levy L Merlini L Sa de Almeida J Courvoisier S Wallace TE Klauser A Afacan O Warfield SK et al. Super-resolution reconstruction of T2-weighted thick slice neonatal brain MRI scans J Neuroimaging 2021 32 1 68 79 34506677 10.1111/jon.12929 PMC8752487 75. Zhang Y Yap PT Chen G Lin W Wang L Shen D Super-resolution reconstruction of neonatal brain magnetic resonance images via residual structured sparse representation Med Image Anal 2019 55 76 87 31029865 10.1016/j.media.2019.04.010 PMC7136034 76. Pham CH, Tor-Díez C, Meunier H, Bednarek N, Fablet R, Passat N, Rousseau F. Simultaneous super-resolution and segmentation using a generative adversarial network: Application to neonatal brain MRI. In: 2019 IEEE 16th International Symposium on Biomedical Imaging (ISBI) 77. Granziera C Wuerfel J Barkhof F Calabrese M de Stefano N Enzinger C Evangelou N Filippi M Geurts JJG Reich DS et al. Quantitative magnetic resonance imaging towards clinical application in multiple sclerosis Brain 2021 144 5 1296 1311 33970206 10.1093/brain/awab029 PMC8219362 78. Filippi M Horsfield MA Morrissey SP MacManus D Rudge P McDonald W Miller DH Quantitative brain MRI lesion load predicts the course of clinically isolated syndromes suggestive of multiple sclerosis Neurology 1994 44 4 635 635 8164816 10.1212/wnl.44.4.635 79. Petr J Hogeboom L Nikulin P Wiegers E Schroyen G Kallehauge J Chmelík M Clement P Nechifor RE Fodor LA et al. A systematic review on the use of quantitative imaging to detect cancer therapy adverse effects in normal-appearing brain tissue MAGMA 2021 35 1 163 186 34919195 10.1007/s10334-021-00985-2 PMC8901489 80. Aldawsari AM Al-Qaisieh B Broadbent DA Bird D Murray LJ Speight R The role and potential of using quantitative MRI biomarkers for imaging guidance in brain cancer radiotherapy treatment planning: A systematic review. Physics and imaging Radiat Oncol 2023 27 Article 100476 10.1016/j.phro.2023.100476 PMC10410581 37565088 ",
  "metadata": {
    "Title of this paper": "The role and potential of using quantitative MRI biomarkers for imaging guidance in brain cancer radiotherapy treatment planning: A systematic review. Physics and imaging",
    "Journal it was published in:": "Health Data Science",
    "URL": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC12489180/"
  }
}