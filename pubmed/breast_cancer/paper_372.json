{
  "title": "Paper_372",
  "abstract": "pmc Commun Biol Commun Biol 3495 commbiol Communications Biology 2399-3642 Nature Publishing Group PMC12484869 PMC12484869.1 12484869 12484869 41028333 10.1038/s42003-025-08810-5 8810 1 Article SpaCross deciphers spatial structures and corrects batch effects in multi-slice spatially resolved transcriptomics Fang Donghai http://orcid.org/0000-0002-2558-2911 Min Wenwen minwenwen@ynu.edu.cn https://ror.org/0040axw97 grid.440773.3 0000 0000 9342 2456 School of Information Science and Engineering, Yunnan University, 30 9 2025 2025 8 478257 1393 4 4 2025 28 8 2025 30 09 2025 02 10 2025 02 10 2025 © The Author(s) 2025 2025 https://creativecommons.org/licenses/by-nc-nd/4.0/ Open Access http://creativecommons.org/licenses/by-nc-nd/4.0/ Spatially Resolved Transcriptomics (SRT) has revolutionized tissue architecture analysis by integrating gene expression with spatial coordinates. However, existing spatial domain identification methods struggle with unsupervised learning constraints, lack of implicit supervision in latent space, and challenges in balancing local spatial continuity with global semantic consistency, particularly in multi-slice integration. To address these issues, we propose SpaCross, a comprehensive deep learning framework for SRT that enhances spatial pattern recognition and cross-slice consistency. SpaCross employs a cross-masked graph autoencoder to reconstruct gene expression features while preserving spatial relationships and mitigating identity mapping issues. A cross-masked latent consistency module reinforces implicit constraints on latent representations, improving feature robustness. More importantly, an adaptive spatial-semantic graph structure dynamically integrates local and global contextual information, enabling effective multi-slice integration. Extensive evaluations demonstrate that SpaCross outperforms thirteen state-of-the-art methods on single-slice datasets and achieves robust batch effect correction while preserving biologically meaningful spatial architectures in multi-slice integration. Notably, SpaCross integrates embryonic mouse tissues across developmental stages, identifying conserved regions and uncovering stage-specific structures such as the dorsal root ganglion. In the heart domain, it reconstructs developmental trajectories capturing key transcriptional transitions and gene programs associated with cardiac maturation. SpaCross uses a crossmasked graph autoencoder with adaptive spatialsemantic integration to advance multi-slice spatial transcriptomics and reveal conserved and stagespecific tissue structures. Subject terms Functional clustering 501100001809 National Natural Science Foundation of China (National Science Foundation of China) 62262069 pmc-status-qastatus 0 pmc-status-live yes pmc-status-embargo no pmc-status-released yes pmc-prop-open-access yes pmc-prop-olf no pmc-prop-manuscript no pmc-prop-legally-suppressed no pmc-prop-has-pdf yes pmc-prop-has-supplement yes pmc-prop-pdf-only no pmc-prop-suppress-copyright no pmc-prop-is-real-version no pmc-prop-is-scanned-article no pmc-prop-preprint no pmc-prop-in-epmc yes issue-copyright-statement © Springer Nature Limited 2025 Introduction The organizational function of multicellular organisms depends on the precise spatial coordination and regulation between cells 1 2 4 5 6 7 8 2 9 10 11 9 12 13 The spatial complexity of biological tissues arises from the differentiation of heterogeneous regions, which form spatial domains with specific biological characteristics. Therefore, interpreting spatial domains is a key challenge in the SRT field for understanding physiology and pathology 3 14 15 16 17 18 Among spatial clustering methods, graph neural network (GNN)-based approaches have emerged as a powerful framework to jointly model spatial topology and transcriptomic features. For example, SpaGCN 19 20 3 9 In recent years, the development of generative self-supervised learning frameworks based on masking mechanisms has rapidly advanced 21 23 24 25 26 Graph Contrastive Learning (GCL), as an emerging self-supervised learning framework, constructs positive and negative sample pairs to drive the model to learn discriminative low-dimensional embeddings, thus overcoming the impact of data noise and high dimensionality on clustering 27 29 5 30 31 9 Finally, multi-slice integration faces significant methodological challenges 23 32 19 30 33 34 35 20 To address these limitations, we propose SpaCross, a framework that integrates a cross-masked graph autoencoder with adaptive spatial-semantic fusion for robust spatial domain identification and multi-slice integration. SpaCross leverages a masking-enhanced graph autoencoder to reconstruct gene expression features through cross-masked inputs that explicitly preserve spatial relationships while mitigating identity mapping issues, and it employs a cross-masked latent consistency (CMLC) module to enforce implicit constraints between latent representations derived from dual-masking perspectives, thereby enhancing feature robustness. Importantly, an adaptive hybrid spatial-semantic graph (AHSG) structure dynamically integrates local spatial continuity and global semantic consistency, which further facilitates effective multi-slice integration. Our comprehensive evaluations demonstrate the superior performance of SpaCross across diverse spatial transcriptomic scenarios. On single-slice datasets, SpaCross outperforms thirteen state-of-the-art methods in spatial domain identification, showing strong robustness to technical variation. In multi-slice integration tasks-including human dorsolateral prefrontal cortex (DLPFC) and mouse hypothalamic preoptic area datasets-SpaCross effectively balances batch correction with the preservation of biologically coherent architectures. In developing mouse embryos, SpaCross reconstructs spatiotemporal tissue dynamics across stages E9.5 to E11.5, identifying both conserved domains such as the heart and brain, and stage-specific structures like the dorsal root ganglia. Additionally, SpaCross enables cross-platform integration of mouse olfactory bulb data, capturing shared laminar structures and resolving platform-specific variation. These results highlight SpaCross as a generalizable framework for spatial analysis across complex developmental and anatomical contexts. Results Overview of SpaCross SpaCross is a comprehensive analytical framework designed for spatial transcriptomics data, aiming to enhance the accuracy of spatial pattern recognition and cross-slice consistency. The approach comprises key modules including data preprocessing, masked-enhanced self-supervised learning, hybrid graph modeling, and cross-slice integration, utilizing graph neural networks and contrastive learning to jointly model spatial and semantic information (see Fig. 1 Fig. 1 Overview of the SpaCross framework for spatial transcriptomics analysis. A B C To support the integrative analysis of multi-slice spatial transcriptomics data, SpaCross performs data preprocessing by first integrating gene expression matrices from multiple slices along the spot dimension. The data is then filtered and normalized to remove low-quality genes, retaining only highly variable genes for subsequent modeling. Next, principal component analysis (PCA) is applied for dimensionality reduction to decrease computational complexity. Subsequently, SpaCross incorporates a 3D spatial registration method, utilizing the iterative closest point (ICP) 33 36 1 To enhance the model’s robustness against missing data and noise, SpaCross introduces a cross-masked self-supervised learning mechanism (Fig. 1 In the latent representation learning process, SpaCross further enhances the reliability of these representations through a cross-masked latent consistency (CMLC) mechanism (Fig. 1 To address the insufficient integration of local and global information in SRT data, SpaCross has developed an adaptive hybrid spatial-semantic graph (AHSG) modeling method (Fig. 1 In downstream tasks (Fig. 1 SpaCross enhances clustering and layer-specific identification in DLPFC We comprehensively assessed SpaCross’s performance in spatial domain identification by benchmarking it against thirteen state-of-the-art methods spanning diverse modeling paradigms, including classical probabilistic models, graph-based frameworks, generative architectures, and contrastive learning strategies. For clarity, we categorized these methods based on their core algorithmic principles, while acknowledging that some span multiple paradigms. Non-GNN-based models included CellCharter 17 18 19 20 3 37 26 25 38 30 9 5 28 All methods were evaluated on the human dorsolateral prefrontal cortex (DLPFC) dataset from the 10x Visium platform 39 39 To quantify clustering accuracy, we computed the Adjusted Rand Index (ARI) and clustering Accuracy (ACC), where higher values indicate better correspondence with manual annotations (Fig. 2 2 1 Fig. 2 SpaCross enables accurate and biologically consistent spatial domain identification in the human DLPFC. All ( B G A p p p B n n C D PLP1 NEFL ENC1 I E F G SpaCross significantly outperformed 11 out of 13 baseline methods in terms of ARI, and 10 out of 13 in terms of ACC, based on Wilcoxon signed-rank tests across all slices (Fig. 2 p p p 2 1 3 For in-depth evaluation, we analyzed DLPFC slice 151675. As illustrated in Fig. 2 19 2 4 6 To elucidate these discrepancies, we visualized latent embeddings using UMAP (Fig. 2 40 2 SpaCross’s ability to identify spatially variable genes (SVGs) was also evaluated using a SpaGCN-inspired pipeline 19 PLP1 NEFL ENC1 2 I I p Further analysis of slice 151675 revealed challenges shared across methods in resolving subtle boundaries, particularly between layers 1–2 and 3–4 (Fig. 2 The default configuration of SpaCross assigned seven domains per slice, matching the six annotated layers and white matter. This choice promotes consistency with manual labels but may restrict detection of finer-grained structures. Although SpaCross achieved the highest ARI and ACC under this constraint, spatial maps showed layer 1 split into two domains and layer 4 absent, suggesting over- and under-segmentation (Fig. 2 To probe whether these results stemmed from biological similarity or model limitations, we increased the number of domains to eight (Fig. 2 To investigate the biological basis of the inferred boundaries, we computed pairwise Pearson correlations of gene expression across domains (Fig. 2 This heterogeneity was further validated via differential expression analysis between Domain_1 and Domain_2. The volcano plot (Fig. 2 MALAT1 MGP MYH11 CXCL14 AQP4 2 SpaCross robustly delineates tissue structures across diverse experimental platforms To systematically validate the cross-platform robustness of the SpaCross algorithm, we first conducted performance evaluation using a complex human breast cancer (BRCA) dataset generated by the 10x Visium platform 20 20 3 3 1 7 Fig. 3 SpaCross robustly delineates tissue structures across diverse experimental platforms. A B I C C D E F G At the tissue topology resolution level, SpaCross effectively addressed segmentation biases observed in existing algorithms (including stDCL, DiffusionST, GraphST, and SEDR) towards IDC_2 and IDC_5 regions. As shown in Fig. 3 8 3 SVG analysis further confirmed SpaCross’s superiority. Since each method employs distinct criteria for identifying spatially variable genes (SVGs), the resulting gene sets differ in both content and size, violating the matched-sample assumption of the Wilcoxon signed-rank test. Therefore, we adopted the Mann-Whitney U test, which is more appropriate for comparing two independent distributions with potentially unequal sample sizes. On the BRCA dataset (Fig. 3 I p −10 −7 C Furthermore, we evaluated the spatial domain identification performance of SpaCross and baseline methods on a more complex mouse brain dataset from the 10x Visium platform, which contains 52 spatial domains. SpaCross achieved the highest accuracy among all methods, with an ARI of 0.52, and exhibited more spatially continuous domain segmentation. See Supplementary Fig. 9 1 Next, we conducted a systematic evaluation of anatomical structure delineation capabilities on the mouse primary visual cortex (MVC) 41 3 3 10 1 Consistent with previous findings, stDCL failed to separate the HPC and CC regions. GraphST and SpaGCN exhibited severe cell admixture across cortical layers (Supplementary Fig. 10 UMAP visualization of latent embeddings (Fig. 3 10 3 Finally, we conducted quantitative benchmarking on the mouse somatosensory cortex (MSC) 42 3 11 1 3 11 SpaCross corrects batch effects in consecutive tissue slices To comprehensively evaluate the cross-slice integration efficacy of SpaCross, we implemented it on independent DLPFC donor datasets and conducted comparative benchmarking against state-of-the-art multi-slice integration methods (SPIRAL 43 33 35 32 44 b a t c h d o m a i n α As demonstrated in Donor3 (Fig. 4 4 4 4 Fig. 4 Comparative evaluation of multi-slice integration methods on consecutive DLPFC tissue sections. A B C A detailed comparative evaluation of SpaCross against related contrastive learning-based methods (STMGAC, SpaMask, and GAAEST) across multi-slice datasets is provided in Supplementary Text 2 12 13 SpaCross balances developmental consistency and stage-specific variability To further explore the balance between developmental consistency (shared across stages) and stage-specific variability (regions emerging or regressing at particular stages) in embryonic tissue architecture, we applied the SpaCross algorithm to the mouse embryonic dataset 8 3 14 45 5 14 5 5 14 Fig. 5 SpaCross enables spatiotemporal trajectory reconstruction of mouse embryonic heart development. A B C D Nppb Ppp1r17 Hes5 E Nppb F G To validate the biological relevance of these domains, we examined the spatial expression of region-specific marker genes in representative domains (Fig. 5 14 Nppb Ppp1r17 Hes5 To further investigate transcriptional dynamics within the SpaCross-identified heart domain, we extracted all spots assigned to clusters 4 and 20-two clusters exhibiting high transcriptomic similarity in the inter-cluster correlation matrix (Fig. 5 5 To improve biological interpretability and avoid ambiguity in trajectory direction, we discretized pseudotime into bins of width 0.1, computed the centroid of each bin, and connected them to visualize the developmental trajectory in the middle panel of Fig. 5 Nppb Nppb To examine transcriptional changes along the trajectory, we stratified the heart-region spots based on pseudotime into an early-to-intermediate group (≤0.8) and a late-phase group (>0.8). Differential expression analysis revealed a cohort of late-upregulated genes, including canonical markers of cardiac maturation and contractility such as Myh7 Myl2 Nppa Nppb 5 5 SpaCross enables cross-platform integration of spatially resolved data We next investigated SpaCross’s cross-platform integration capability by applying it to spatially resolved transcriptomic datasets of mouse olfactory bulb (MOB) 8 7 20 6 Fig. 6 Cross-platform integration of mouse olfactory bulb (MOB) spatial transcriptomics datasets using SpaCross. A B C D Comparative analysis revealed distinct performance differences among integration methods. While SPIRAL demonstrated effective batch mixing in UMAP visualizations (Fig. 6 6 6 6 6 6 6 6 6 Notably, SpaCross enabled the robust delineation of the AOB and AOBgr regions-structures that were inconsistently resolved using either platform alone due to limitations in spatial resolution or coverage. This stable detection of AOB was further supported by distinct transcriptional signatures revealed in the integrated embedding space. Marker gene expression patterns validated spatial domain fidelity (Fig. 6 Gabra1 Pcp4 Cck Nrep Fabp7 Nrsn1 Kcnd2 Fxyd6 Tac1 To further characterize the AOB region, we performed differential gene expression analysis between AOB and all other spatial domains. The identified AOB-specific genes-including Ptgds Snca Uchl1 Stmn2 15 Experimental results demonstrate that SpaCross effectively mitigates cross-platform batch effects while preserving biologically coherent spatial domains. It accurately reconstructs the multilayered architecture and enables the stable delineation of platform-specific, histologically validated regions such as the accessory olfactory bulb and its granular layer, which are not reliably identified by either platform alone due to differences in resolution and coverage. SpaCross generalizes to complex multi-slice and multi-tissue contexts To further validate the generalization capability of SpaCross in complex multi-slice and multi-tissue scenarios, we applied it to MERFISH-derived mouse hypothalamic preoptic area datasets consisting of five consecutive slices (Bregma coordinates: -0.04 mm to -0.24 mm) 10 7 7 Fig. 7 Generalization of SpaCross to multi-slice and multi-tissue spatial transcriptomics datasets. A B C D E F As shown in Fig. 7 We further validated the integration performance of SpaCross on an adult mouse whole-brain (AMB) multi-slice dataset constructed using a ST platform 46 33 7 7 7 SpaCross ablation experiments validate the efficacy of individual modules To systematically assess the contributions of SpaCross’s architectural modules and loss function designs, we conducted a series of ablation studies. These experiments evaluated the impact of key components such as the cross-masked latent consistency module (CMLC), the adaptive hybrid spatial-semantic graph (AHSG), and associated training losses. Results confirmed that each component plays a distinct and essential role in maintaining spatial coherence and cross-slice alignment. Detailed ablation analyses are provided in Supplementary Text 4 16 17 Computational performance and scalability We also evaluated the computational performance and scalability of SpaCross to assess its applicability to large-scale spatial transcriptomics datasets. We conducted benchmarking experiments on the DLPFC dataset by systematically increasing the number of slices from 1 to 12 (covering up to 48,000 spots) and recorded multiple computational metrics including runtime, GPU memory usage, and memory cache. In addition, we compared SpaCross with six representative baseline methods across different algorithmic categories. Detailed benchmarking procedures and comparative results are provided in Supplementary Text 5 18 2 Discussion In this study, we propose SpaCross as a comprehensive deep learning framework that addresses critical limitations in multi-slice spatial transcriptomics integrated analysis. By integrating a masked graph autoencoder for reconstruction learning with a cross-masked latent consistency (CMLC) module, the approach provides dual-space supervision that combines explicit reconstruction loss in the raw feature space with implicit latent consistency constraints. This dual strategy effectively enhances the robustness and accuracy of the learned embeddings, overcoming the shortcomings of traditional unsupervised methods that often yield representations misaligned with pathological annotations. Conventional graph autoencoders typically rely solely on unsupervised learning, which can result in latent representations that lack biological interpretability. In contrast, SpaCross incorporates complementary masked views that simulate missing data, compelling the model to predict and reconstruct gene expression features while preserving spatial context. The inclusion of the CMLC module further enforces consistency across different masked perspectives, ensuring that the latent space remains stable and biologically meaningful even in the presence of noise. This methodological innovation not only improves the feature robustness but also facilitates the accurate delineation of spatial domains. A key innovation of SpaCross lies in its adaptive hybrid spatial-semantic graph (AHSG) structure, which harmoniously fuses local spatial continuity with global semantic coherence. By dynamically integrating information from spatial neighborhoods and semantic clusters, the framework adeptly balances fine-grained spatial details with overarching tissue architecture. This capability is particularly important for multi-slice integration, where traditional methods have struggled with batch effects and inter-slice variability. The adaptive graph construction allows SpaCross to effectively transfer information across slices, ensuring that both technical noise is minimized and true biological variations are preserved. Experimental evaluations reinforce the practical value of these innovations. Across multiple single-slice datasets, SpaCross consistently outperformed thirteen state-of-the-art methods in spatial domain identification, demonstrating superior clustering performance and enhanced robustness. Its application to human dorsolateral prefrontal cortex data and complex MERFISH datasets confirmed that the framework not only corrects batch effects but also maintains the integrity of tissue spatial organization. In developmental contexts, SpaCross revealed dynamic spatiotemporal patterns in embryonic mouse tissues by integrating data across stages E9.5 to E11.5. In particular, it reconstructed a continuous transcriptional trajectory within the cardiac region, capturing transitions from early to mature cardiomyocyte states. This was supported by stage-aligned pseudotime progression, sustained expression of cardiac markers such as Nppb Additionally, the cross-platform integration of mouse olfactory bulb data from Stereo-seq and Slide-seqV2 further illustrates the versatility of SpaCross. The framework successfully identified shared laminar structures and resolved platform-specific subdomains, providing biologically meaningful representations across distinct technologies. While SpaCross demonstrates many strengths, it is worth noting that the graph-based approach might require some further tuning when applied to extremely high-resolution datasets or in cases of uneven spatial sampling. Additionally, although the dual supervision mechanism significantly enhances robustness, exploring complementary strategies for latent space regularization could offer further improvements under particularly challenging data conditions. In summary, SpaCross represents a significant advancement in the field of spatial transcriptomics. Its innovative integration of cross-masked reconstruction learning, latent consistency enforcement, and adaptive hybrid graph modeling not only improves spatial domain identification and multi-slice integration but also provides valuable insights into tissue architecture across diverse biological contexts. The theoretical and practical implications of this work establish a solid foundation for future research and applications in developmental biology, neuroscience, oncology, and beyond. Methods Data preprocessing and spatial graph construction SpaCross takes gene expression data and spatial coordinates from multiple tissue slices as input (Fig 1 47 N p c \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$X\\in {{\\mathbb{R}}}^{N\\times {N}_{pc}}$$\\end{document} X ∈ R N × N p c N To fully incorporate spatial information, we first employ the Iterative Closest Point (ICP) 36 6 A j i A i j A j i It is important to note that in cross-platform data integration or data from different developmental stages, significant spatial topological variations between samples exist, and direct application of ICP registration may lead to coordinate distortion. To address this, we adopt a hierarchical modeling strategy: first, the adjacency matrices \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$${\\{{A}_{t}\\}}_{t = 1}^{T}$$\\end{document} { A t } t = 1 T A A 1 A 2 A T Data augmentation with spot masking Before training SpaCross, we generate a masked feature matrix X m X c m ρ \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$${{{\\mathcal{V}}}}_{m}$$\\end{document} V m \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$${{\\mathcal{V}}}$$\\end{document} V \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$${{{\\mathcal{V}}}}_{cm}$$\\end{document} V c m \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$${{{\\mathcal{V}}}}_{m}\\cup {{{\\mathcal{V}}}}_{cm}={{\\mathcal{V}}}$$\\end{document} V m ∪ V c m = V \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$${{{\\mathcal{V}}}}_{m}\\cap {{{\\mathcal{V}}}}_{cm}=\\varnothing $$\\end{document} V m ∩ V c m = ∅ Based on the spot masking mechanism, we construct a masked feature matrix \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$${X}_{m}\\in {{\\mathbb{R}}}^{N\\times {N}_{pc}}$$\\end{document} X m ∈ R N × N p c v i \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$${v}_{i}\\in {{{\\mathcal{V}}}}_{m}$$\\end{document} v i ∈ V m \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$${x}_{[M]}\\in {{\\mathbb{R}}}^{{N}_{pc}}$$\\end{document} x [ M ] ∈ R N p c x m i x [ M x m i x i Similarly, we construct a complementary masked feature matrix \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$${X}_{cm}\\in {{\\mathbb{R}}}^{N\\times {N}_{pc}}$$\\end{document} X c m ∈ R N × N p c \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$${v}_{i}\\in {{{\\mathcal{V}}}}_{cm}$$\\end{document} v i ∈ V c m x c m i x [ M x c m i x i Latent representation learning via masked reconstruction Graph encoding The graph encoder \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$${{{\\mathcal{F}}}}_{g}$$\\end{document} F g A X m \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$${Z}_{g}\\in {{\\mathbb{R}}}^{N\\times d}$$\\end{document} Z g ∈ R N × d d \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$${Z}_{g}={{{\\mathcal{F}}}}_{g}(A,{X}_{m})$$\\end{document} Z g = F g ( A , X m ) l \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$${H}_{f}^{(l-1)}$$\\end{document} H f ( l − 1 ) \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$${H}_{f}^{(l)}$$\\end{document} H f ( l ) 1 \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$${H}_{f}^{(l)}=\\,{{\\mbox{ELU}}}({{\\mbox{BN}}}\\,({W}_{f}^{(l)}{H}_{f}^{(l-1)}+{b}^{(l)}))$$\\end{document} H f ( l ) = ELU ( BN ( W f ( l ) H f ( l − 1 ) + b ( l ) ) ) \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$${H}_{f}^{(0)}={X}_{m}$$\\end{document} H f ( 0 ) = X m \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$${H}_{f}={H}_{f}^{(L)}$$\\end{document} H f = H f ( L ) L Then, utilizing the information propagation mechanism of GCNs, the masked nodes can learn features from their unmasked neighboring nodes. The mathematical representation is as follows: 2 \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$${Z}_{g}=\\widetilde{A}\\cdot \\,{{\\mbox{ReLU}}}({{\\mbox{BN}}}\\,(\\widetilde{A}{H}_{f}{W}_{g}^{(0)}))\\cdot {W}_{g}^{(1)}$$\\end{document} Z g = A ~ ⋅ ReLU ( BN ( A ~ H f W g ( 0 ) ) ) ⋅ W g ( 1 ) \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$${W}_{g}^{(l)}$$\\end{document} W g ( l ) l \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$\\widetilde{A}$$\\end{document} A ~ \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$\\widetilde{A}={D}^{-\\frac{1}{2}}A{D}^{-\\frac{1}{2}}$$\\end{document} A ~ = D − 1 2 A D − 1 2 Once the training phase is completed, we utilize raw feature matrix X A \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$${{{\\mathcal{F}}}}_{g}$$\\end{document} F g Z Representation predicting To improve self-supervised learning in mask-based graph representations, we propose a graph predictor, \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$${{{\\mathcal{F}}}}_{p}$$\\end{document} F p Z m A \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$${Z}_{p}\\in {{\\mathbb{R}}}^{N\\times d}$$\\end{document} Z p ∈ R N × d \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$${Z}_{p}={{{\\mathcal{F}}}}_{p}(A,{Z}_{m})$$\\end{document} Z p = F p ( A , Z m ) Z m \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$${{{\\mathcal{V}}}}_{m}$$\\end{document} V m v i \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$${v}_{i}\\in {{{\\mathcal{V}}}}_{m}$$\\end{document} v i ∈ V m \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$${z}_{[RM]}\\in {{\\mathbb{R}}}^{d}$$\\end{document} z [ R M ] ∈ R d z m i z [ R M z m i z g i The predicted representation, Z p W p 3 \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$${Z}_{p}=\\widetilde{A}\\cdot {Z}_{m}\\cdot {W}_{p}$$\\end{document} Z p = A ~ ⋅ Z m ⋅ W p Z p Feature decoding The feature decoder, \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$${{{\\mathcal{F}}}}_{d}$$\\end{document} F d Z p \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$\\hat{X}\\in {{\\mathbb{R}}}^{N\\times {N}_{pc}}$$\\end{document} X ^ ∈ R N × N p c W d 4 \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$\\hat{X}=\\widetilde{A}\\cdot \\,{{\\mbox{ReLU}}}({{\\mbox{BN}}}\\,({Z}_{p}))\\cdot {W}_{d}$$\\end{document} X ^ = A ~ ⋅ ReLU ( BN ( Z p ) ) ⋅ W d Reconstruction loss in the raw space One of the primary objectives is to reconstruct the masked feature of spots in \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$${{{\\mathcal{V}}}}_{m}$$\\end{document} V m γ 5 \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$${{{\\mathcal{L}}}}_{{{\\rm{SCE}}}}=\\frac{1}{| {{{\\mathcal{V}}}}_{m}| }{\\sum}_{{v}_{i}\\in {{{\\mathcal{V}}}}_{m}}{\\left(1-{{\\mbox{sim}}}\\left({x}_{i},{\\hat{x}}_{i}\\right)\\right)}^{\\gamma },\\quad \\gamma \\ge 1$$\\end{document} L SCE = 1 ∣ V m ∣ ∑ v i ∈ V m 1 − sim x i , x ^ i γ , γ ≥ 1 γ \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$| {{{\\mathcal{V}}}}_{m}| $$\\end{document} ∣ V m ∣ 6 \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$\\,{{\\mbox{sim}}}\\,(x,y)=\\frac{{x}^{\\top }y}{\\parallel x\\parallel \\parallel y\\parallel }$$\\end{document} sim ( x , y ) = x ⊤ y ∥ x ∥ ∥ y ∥ Latent space guidance via CMLC Complementary graph encoding In unlabeled self-supervised learning models, such as those based on autoencoder structures, there is a risk of overfitting to the training data. To address this limitation, we design a Cross-Masked Latent Consistency (CMLC) module that delivers persistent supervisory signals for each masked point in the latent space. The CMLC framework implements a complementary masking strategy through graph encoder \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$${{{\\mathcal{F}}}}_{g}$$\\end{document} F g X c m A \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$${Z}_{cg}\\in {{\\mathbb{R}}}^{N\\times d}$$\\end{document} Z c g ∈ R N × d \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$${Z}_{cg}={{{\\mathcal{F}}}}_{g}(A,{X}_{cm})$$\\end{document} Z c g = F g ( A , X c m ) Z c g Z p Consistency loss in the latent space To enforce semantic consistency between the predicted representation Z p X m Z c g X c m \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$${{{\\mathcal{V}}}}_{m}$$\\end{document} V m Formally, for each masked spot \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$${v}_{i}\\in {{{\\mathcal{V}}}}_{m}$$\\end{document} v i ∈ V m z p i z c g i z p i z c g i i Z p Z c g z p i \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$${\\{{z}_{cg,j}\\}}_{j\\in {{{\\mathcal{N}}}}_{i}}$$\\end{document} { z c g , j } j ∈ N i \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$${{{\\mathcal{N}}}}_{i}$$\\end{document} N i 7 \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$${{{\\mathcal{L}}}}_{{{\\rm{NCE}}}}=-\\frac{1}{| {{{\\mathcal{V}}}}_{m}| }{\\sum}_{{v}_{i}\\in {{{\\mathcal{V}}}}_{m}}\\log \\frac{\\exp \\left(\\,{{\\mbox{sim}}}\\,({z}_{p,i},{z}_{cg,i})/\\tau \\right)}{\\exp \\left(\\,{{\\mbox{sim}}}\\,({z}_{p,i},{z}_{cg,i})/\\tau \\right)+{\\sum }_{j\\in {{{\\mathcal{N}}}}_{i}}\\exp \\left(\\,{{\\mbox{sim}}}\\,({z}_{p,i},{z}_{cg,j})/\\tau \\right)}$$\\end{document} L NCE = − 1 ∣ V m ∣ ∑ v i ∈ V m log exp sim ( z p , i , z c g , i ) / τ exp sim ( z p , i , z c g , i ) / τ + ∑ j ∈ N i exp sim ( z p , i , z c g , j ) / τ τ Discriminative representation learning in AHSG Adaptive hybrid spatial-semantic graph (AHSG) construction For any target spot \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$${v}_{i}\\in {{\\mathcal{V}}}$$\\end{document} v i ∈ V \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$${{{\\mathcal{B}}}}_{i}$$\\end{document} B i \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$${{{\\mathcal{B}}}}_{i}^{intra}$$\\end{document} B i i n t r a \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$${{{\\mathcal{B}}}}_{i}^{inter}$$\\end{document} B i i n t e r 8 \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$${{{\\mathcal{B}}}}_{i}={{{\\mathcal{B}}}}_{i}^{intra}\\cup {{{\\mathcal{B}}}}_{i}^{inter}$$\\end{document} B i = B i i n t r a ∪ B i i n t e r T i t v i z i z i z j v i \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$${v}_{j}\\in {{\\mathcal{V}}}\\setminus \\{{v}_{i}\\}$$\\end{document} v j ∈ V \\ { v i } T j t \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$Z\\in {{\\mathbb{R}}}^{N\\times d}$$\\end{document} Z ∈ R N × d X \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$${{{\\mathcal{F}}}}_{g}$$\\end{document} F g A \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$Z={{{\\mathcal{F}}}}_{g}(A,X)$$\\end{document} Z = F g ( A , X ) K i n t r a v i 9 \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$${{{\\mathcal{B}}}}_{i}^{intra}=\\left\\{{v}_{j}| \\,{{\\mbox{Rank}}}({{\\mbox{sim}}}\\,({z}_{i},{z}_{j}))\\le {K}_{intra},\\forall j\\in {{\\mathcal{V}}}\\setminus \\{{v}_{i}\\},T(j)=t\\right\\}$$\\end{document} B i i n t r a = v j ∣ Rank ( sim ( z i , z j ) ) ≤ K i n t r a , ∀ j ∈ V \\ { v i } , T ( j ) = t For the inter-slice candidate set, we consider all spots from slices different from the slice T i v j T j t v i K i n t e r 10 \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$${{{\\mathcal{B}}}}_{i}^{inter}=\\left\\{{v}_{j}| \\,{{\\mbox{Rank}}}({{\\mbox{sim}}}\\,({z}_{i},{z}_{j}))\\le {K}_{inter},\\forall j\\in {{\\mathcal{V}}}\\setminus \\{{v}_{i}\\},T(j)\\ne t\\right\\}$$\\end{document} B i i n t e r = v j ∣ Rank ( sim ( z i , z j ) ) ≤ K i n t e r , ∀ j ∈ V \\ { v i } , T ( j ) ≠ t To ensure that the candidate spots are not only similar in the latent semantic space but also exhibit spatial continuity, we introduce a spatial constraint and define the spatially constrained neighborhood set \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$${{{\\mathcal{N}}}}_{i}^{S}$$\\end{document} N i S 11 \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$${{{\\mathcal{N}}}}_{i}^{S}={{{\\mathcal{B}}}}_{i}\\cap {{{\\mathcal{A}}}}_{i}$$\\end{document} N i S = B i ∩ A i \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$${{{\\mathcal{A}}}}_{i}$$\\end{document} A i v i \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$${{{\\mathcal{A}}}}_{i}=\\{{v}_{j}\\in {{\\mathcal{V}}}| {A}_{ij}=1\\}$$\\end{document} A i = { v j ∈ V ∣ A i j = 1 } To capture global semantic consistency, we employ the k-means clustering algorithm to the latent representation Z \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$${{{\\mathcal{N}}}}_{i}^{G}$$\\end{document} N i G 12 \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$${{{\\mathcal{N}}}}_{i}^{G}={{{\\mathcal{B}}}}_{i}\\cap {{{\\mathcal{C}}}}_{i}$$\\end{document} N i G = B i ∩ C i \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$${{{\\mathcal{C}}}}_{i}$$\\end{document} C i v i v i c \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$${{{\\mathcal{C}}}}_{i}=\\{{v}_{j}\\in {{\\mathcal{V}}}| {v}_{j}\\,{{\\mbox{is}}} \\, {{\\mbox{assigned}}}\\; {{\\mbox{to}}}\\; {{\\mbox{cluster}}}\\,c\\}$$\\end{document} C i = { v j ∈ V ∣ v j is assigned to cluster c } Finally, we fuse the spatially constrained neighborhood set \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$${{{\\mathcal{N}}}}^{S}$$\\end{document} N S \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$${{{\\mathcal{N}}}}^{G}$$\\end{document} N G \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$${{{\\mathcal{N}}}}^{F}$$\\end{document} N F 13 \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$${{{\\mathcal{N}}}}^{F}={{{\\mathcal{N}}}}^{S}\\cup {{{\\mathcal{N}}}}^{G}$$\\end{document} N F = N S ∪ N G \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$${{{\\mathcal{N}}}}^{F}$$\\end{document} N F Hybrid feature aggregation Leveraging the adaptive hybrid spatial-semantic nearest neighbor, we extract an integrated node embedding matrix \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$S\\in {{\\mathbb{R}}}^{N\\times d}$$\\end{document} S ∈ R N × d v i s i 14 \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$${s}_{i}=\\,{{\\mbox{Sigmoid}}}\\,\\left(\\frac{1}{\\left\\vert {{{\\mathcal{N}}}}_{i}^{F}\\right\\vert }{\\sum}_{{v}_{j}\\in {{{\\mathcal{N}}}}_{i}^{F}}{z}_{g,j}\\right)$$\\end{document} s i = Sigmoid 1 N i F ∑ v j ∈ N i F z g , j \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$\\left\\vert {{{\\mathcal{N}}}}_{i}^{F}\\right\\vert $$\\end{document} N i F Contrastive loss The summary vector s i z g i s i z g i s i \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$${\\tilde{Z}}_{g}$$\\end{document} Z ~ g \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$({\\tilde{z}}_{g,i},{s}_{i})$$\\end{document} ( z ~ g , i , s i ) By maximizing the mutual information between node embeddings and their corresponding summary vectors, we enhance their alignment in the embedding space while simultaneously mitigating the collapse phenomenon. This alignment is enforced via a contrastive objective formulated with the Binary Cross-Entropy (BCE) loss: 15 \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$${{{\\mathcal{L}}}}_{{{\\rm{BCE}}}}=-\\frac{1}{\\left\\vert {{{\\mathcal{V}}}}_{m}\\right\\vert }{\\sum}_{{v}_{i}\\in {{{\\mathcal{V}}}}_{m}}\\left[\\log {{\\mathcal{D}}}\\left({z}_{g,i},{s}_{i}\\right)+\\log \\left(1-{{\\mathcal{D}}}\\left({\\tilde{z}}_{g,i},{s}_{i}\\right)\\right)\\right]$$\\end{document} L BCE = − 1 V m ∑ v i ∈ V m log D z g , i , s i + log 1 − D z ~ g , i , s i \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$${{\\mathcal{D}}}(\\cdot ,\\cdot )$$\\end{document} D ( ⋅ , ⋅ ) 16 \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$${{\\mathcal{D}}}({z}_{g},s)=\\,{{\\mbox{Sigmoid}}}\\,\\left({z}_{g}^{\\top }Ws\\right)$$\\end{document} D ( z g , s ) = Sigmoid z g ⊤ W s z g i s i Comprehensive loss function The comprehensive loss function, regulated by the weight factors λ 1 2 3 \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$${{{\\mathcal{L}}}}_{{{\\rm{SCE}}}}$$\\end{document} L SCE \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$${{{\\mathcal{L}}}}_{{{\\rm{NCE}}}}$$\\end{document} L NCE \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$${{{\\mathcal{L}}}}_{{{\\rm{BCE}}}}$$\\end{document} L BCE 17 \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$${{\\mathcal{L}}}={\\lambda }_{1}{{{\\mathcal{L}}}}_{{{\\rm{SCE}}}}+{\\lambda }_{2}{{{\\mathcal{L}}}}_{{{\\rm{NCE}}}}+{\\lambda }_{3}{{{\\mathcal{L}}}}_{{{\\rm{BCE}}}}$$\\end{document} L = λ 1 L SCE + λ 2 L NCE + λ 3 L BCE Spatial clustering and visualization After training, we obtain the graph embedding Z To compute UMAP, we first build a neighbor graph with the s c p p n e i g h b o r s Z s c a n p y t l u m a p s c a n p y t l p a g a s c a n p y p l p a g a c o m p a r e Identification of SVGs and meta-genes We identify SVGs and meta-genes using the SpaGCN detection framework 19 P g e n e 0 e 0 e 0 Experimental details In the data preprocessing stage, we first extract the top 200 principal components from 2000 highly variable genes using PCA as input features. For datasets with fewer than 2000 but more than 200 genes, PCA is applied directly to the available genes; if the number of genes is below 200, all normalized gene expressions are used without PCA transformation. For spatial neighborhood graph construction, we set K K \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$${{{\\mathcal{F}}}}_{g}$$\\end{document} F g \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$${{{\\mathcal{F}}}}_{p}$$\\end{document} F p \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$${{{\\mathcal{F}}}}_{d}$$\\end{document} F d \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$${{\\mathcal{D}}}$$\\end{document} D The masking rate is fixed at ρ γ τ K i n t r a K i n t e r λ 1 λ 2 λ 3 A comprehensive investigation of hyperparameter selection-including neighborhood size, PCA dimensionality, and loss weighting-is provided in Supplementary Text 7 19 20 1 Evaluated metrics and criteria We evaluate the performance of our spatial domain identification model using a combination of metrics that assess both clustering accuracy and spatial continuity. First, to quantify clustering accuracy, we employ the Adjusted Rand Index (ARI) 48 18 \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$\\,{{\\mbox{ARI}}}\\,=\\frac{{\\sum }_{ij}\\left(\\begin{array}{c}{N}_{ij}\\\\ 2\\end{array}\\right)-\\frac{\\left[{\\sum }_{i}\\left(\\begin{array}{c}{N}_{i}\\\\ 2\\end{array}\\right)+{\\sum }_{j}\\left(\\begin{array}{c}{N}_{j}\\\\ 2\\end{array}\\right)\\right]}{\\left(\\begin{array}{c}N\\\\ 2\\end{array}\\right)}}{\\frac{1}{2}\\left[{\\sum }_{i}\\left(\\begin{array}{c}{N}_{i}\\\\ 2\\end{array}\\right)+{\\sum }_{j}\\left(\\begin{array}{c}{N}_{j}\\\\ 2\\end{array}\\right)\\right]-\\frac{\\left[{\\sum }_{i}\\left(\\begin{array}{c}{N}_{i}\\\\ 2\\end{array}\\right)+{\\sum }_{j}\\left(\\begin{array}{c}{N}_{j}\\\\ 2\\end{array}\\right)\\right]}{\\left(\\begin{array}{c}N\\\\ 2\\end{array}\\right)}}$$\\end{document} ARI = ∑ i j N i j 2 − ∑ i N i 2 + ∑ j N j 2 N 2 1 2 ∑ i N i 2 + ∑ j N j 2 − ∑ i N i 2 + ∑ j N j 2 N 2 N N i j i C i C j Y j Y N i N j C i Y j In addition, we utilize the Normalized Mutual Information (NMI) metric 49 40 19 \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$\\,{{\\mbox{NMI}}}\\,(Y,C)=\\frac{2\\,[H(Y)-H(Y| C)]}{H(Y)+H(C)}$$\\end{document} NMI ( Y , C ) = 2 [ H ( Y ) − H ( Y ∣ C ) ] H ( Y ) + H ( C ) H 20 \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$H(X)=-{\\sum}_{i}p({x}_{i})\\log p({x}_{i})$$\\end{document} H ( X ) = − ∑ i p ( x i ) log p ( x i ) Similarly, the HOM score measures whether each cluster contains data points from only one class, while the COM score evaluates whether all data points of a given class are assigned to the same cluster. They are defined as: 21 \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$\\,{{\\mbox{HOM}}}\\,=1-\\frac{H(Y| C)}{H(Y)},\\,\\,\\,{{\\mbox{COM}}}\\,=1-\\frac{H(C| Y)}{H(C)}$$\\end{document} HOM = 1 − H ( Y ∣ C ) H ( Y ) , COM = 1 − H ( C ∣ Y ) H ( C ) Both metrics range from 0 to 1, where higher values indicate better clustering quality in terms of purity (homogeneity) and completeness. We then define the overall accuracy score (ACC) as the average of NMI, HOM, and COM: 22 \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$\\,{{\\mbox{ACC}}}\\,=\\frac{1}{3}\\left(\\,{{\\mbox{NMI}}}+{{\\mbox{HOM}}}+{{\\mbox{COM}}}\\,\\right)$$\\end{document} ACC = 1 3 NMI + HOM + COM To assess spatial continuity, we introduce two metrics: the Spatial Chaos Score (CHAOS) and the Percentage of Anomalous Points (PAS). A lower CHAOS value signifies more coherent spatial domain continuity, while a lower PAS indicates fewer isolated or anomalous points within the spatial domains 40 d i j i j 23 \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$${w}_{kij}=\\left\\{\\begin{array}{ll}{d}_{ij}, \\hfill &{{\\mbox{if}}} \\; {{\\mbox{spots}}} \\; i \\; {{\\mbox{and}}} \\; j \\; {{\\mbox{are}}} \\; {{\\mbox{connected}}} \\; {{\\mbox{in}}} \\; {{\\mbox{the}}}\\; {{\\mbox{1-NN}}} \\; {{\\mbox{graph}}} \\; {{\\mbox{within}}} \\; {{\\mbox{cluster}}}\\,k \\\\ 0,\\quad &\\,{{\\mbox{otherwise}}}\\,\\hfill \\end{array}\\right.$$\\end{document} w k i j = d i j , if spots i and j are connected in the 1-NN graph within cluster k 0 , otherwise n k k N K 24 \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$\\,{{\\mbox{CHAOS}}}\\,=\\frac{1}{N}{\\sum }_{k=1}^{K}{\\sum }_{ij}^{{n}_{k}}{w}_{kij}$$\\end{document} CHAOS = 1 N ∑ k = 1 K ∑ i j n k w k i j Finally, we define the overall discreteness score (DIS) as the average of the CHAOS and PAS scores: 25 \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$\\,{{\\mbox{DIS}}}\\,=\\frac{1}{2}\\left(\\,{{\\mbox{CHAOS}}}+{{\\mbox{PAS}}}\\,\\right)$$\\end{document} DIS = 1 2 CHAOS + PAS In summary, higher ARI and ACC scores indicate better clustering accuracy, while lower DIS scores reflect improved spatial domain continuity. These metrics together provide a comprehensive evaluation of the spatial domain identification performance. To quantify the balance between batch effect correction and preservation of spatial domain structures in multi-slice spatial data integration, we use the F1LISI metric. This metric leverages the Local Inverse Simpson Index (LISI), which separately measures the mixing of batches within the same spatial domain (LISI batch domain \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$\\alpha =\\frac{{N}_{domain}}{{N}_{batch}+{N}_{domain}}$$\\end{document} α = N d o m a i n N b a t c h + N d o m a i n 44 26 \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$\\,{{\\mbox{F1LISI}}}=\\frac{(1+{\\alpha }^{2})(1-{{\\mbox{LISI}}}{{\\mbox{\\_}}}{{\\mbox{domain}}}_{norm})({{\\mbox{LISI}}}{{\\mbox{\\_}}}{{\\mbox{batch}}}_{norm})}{{\\alpha }^{2}(1-{{\\mbox{LISI}}}{{\\mbox{\\_}}}{{\\mbox{domain}}}_{norm})+{{\\mbox{LISI}}}{{\\mbox{\\_}}}{{\\mbox{batch}}}_{norm}}$$\\end{document} F1LISI = ( 1 + α 2 ) ( 1 − LISI _ domain n o r m ) ( LISI _ batch n o r m ) α 2 ( 1 − LISI _ domain n o r m ) + LISI _ batch n o r m α Comparison with other methods To benchmark SpaCross, we compared it with a diverse set of methods spanning five categories: non-GNN-based (CellCharter 17 18 19 20 37 3 25 26 38 28 30 5 9 43 33 35 32 8 Statistics and reproducibility All analyses were performed in Python using non-parametric tests (Wilcoxon signed-rank, Mann-Whitney U, Wilcoxon rank-sum), with p < 0.05 considered significant. Here, n denotes biologically independent tissue slices. Reproducibility was assessed by repeating analyses with different random seeds across datasets and averaging results across independent runs. A replicate is defined as an independent run under identical settings, and all baseline models used their default recommended parameters to ensure fairness. Reporting summary Further information on research design is available in the Nature Portfolio Reporting Summary Supplementary information  Supplementary Information Description of Additional Supplementary Files Supplementary Data 1 Reporting Summary Transparent Peer Review file Publisher’s note These authors contributed equally: Donghai Fang, Wenwen Min. Supplementary information The online version contains supplementary material available at 10.1038/s42003-025-08810-5. Acknowledgements This work was supported by the National Natural Science Foundation of China (62262069) and the Young Talent Program of Yunnan Province (C619300A067). Author contributions W.M. conceived and supervised the project. D.F. and W.M. developed and implemented the SpaCross algorithm. D.F. and W.M. validated the methods and wrote the manuscript. All authors read and approved the final manuscript. Peer review Peer review information Communications Biology Data availability All data sets used in this article are publicly available: (1) Human dorsolateral prefrontal cortex data 39 http://research.libd.org/spatialLIBD/ https://www.10xgenomics.com/datasets/human-breast-cancer-block-a-section-1-1-standard-1-1-0 https://github.com/JinmiaoChenLab/SEDR_analyses/tree/master/data https://singlecell.broadinstitute.org/single_cell/study/SCP815 8 https://db.cngb.org/stomics/mosta/ 41 https://www.starmapresources.com/data 42 http://linnarssonlab.org/osmFISH 50 46 https://www.ncbi.nlm.nih.gov/geo/query/acc.cgi?acc=GSE147747 3 https://zenodo.org/records/15090086 Code availability An open-source implementation of the SpaCross algorithm can be downloaded from https://github.com/wenwenmin/SpaCross Competing interests The authors declare no competing interests. References 1. Rao A Barkley D França GS Yanai I Exploring tissue architecture using spatial transcriptomics Nature 2021 596 211 220 10.1038/s41586-021-03634-9 34381231 PMC8475179 Rao, A., Barkley, D., França, G. S. & Yanai, I. Exploring tissue architecture using spatial transcriptomics. Nature 596 34381231 10.1038/s41586-021-03634-9 PMC8475179 2. Ståhl PL Visualization and analysis of gene expression in tissue sections by spatial transcriptomics Science 2016 353 78 82 10.1126/science.aaf2403 27365449 Ståhl, P. L. et al. Visualization and analysis of gene expression in tissue sections by spatial transcriptomics. Science 353 27365449 10.1126/science.aaf2403 3. Dong K Zhang S Deciphering spatial domains from spatially resolved transcriptomics with an adaptive graph attention auto-encoder Nat. Commun. 2022 13 1739 10.1038/s41467-022-29439-6 35365632 PMC8976049 Dong, K. & Zhang, S. Deciphering spatial domains from spatially resolved transcriptomics with an adaptive graph attention auto-encoder. Nat. Commun. 13 35365632 10.1038/s41467-022-29439-6 PMC8976049 4. Min W Shi Z Zhang J Wan J Wang C Multimodal contrastive learning for spatial gene expression prediction using histology images Brief. Bioinform. 2024 25 bbae551 10.1093/bib/bbae551 39471412 PMC11952928 Min, W., Shi, Z., Zhang, J., Wan, J. & Wang, C. Multimodal contrastive learning for spatial gene expression prediction using histology images. Brief. Bioinform. 25 39471412 10.1093/bib/bbae551 PMC11952928 5. Wang T Graph attention automatic encoder based on contrastive learning for domain recognition of spatial transcriptomics Commun. Biol. 2024 7 1351 10.1038/s42003-024-07037-0 39424696 PMC11489439 Wang, T. et al. Graph attention automatic encoder based on contrastive learning for domain recognition of spatial transcriptomics. Commun. Biol. 7 39424696 10.1038/s42003-024-07037-0 PMC11489439 6. Rao N Clark S Habern O Bridging genomics and tissue pathology: 10× genomics explores new frontiers with the Visium spatial gene expression solution Genet. Eng. Biotechnol. News 2020 40 50 51 10.1089/gen.40.02.16 Rao, N., Clark, S. & Habern, O. Bridging genomics and tissue pathology: 10× genomics explores new frontiers with the Visium spatial gene expression solution. Genet. Eng. Biotechnol. News 40 7. Rodriques SG Slide-seq: A scalable technology for measuring genome-wide expression at high spatial resolution Science 2019 363 1463 1467 10.1126/science.aaw1219 30923225 PMC6927209 Rodriques, S. G. et al. Slide-seq: A scalable technology for measuring genome-wide expression at high spatial resolution. Science 363 30923225 10.1126/science.aaw1219 PMC6927209 8. Chen A Spatiotemporal transcriptomic atlas of mouse organogenesis using DNA nanoball-patterned arrays Cell 2022 185 1777 1792 10.1016/j.cell.2022.04.003 35512705 Chen, A. et al. Spatiotemporal transcriptomic atlas of mouse organogenesis using DNA nanoball-patterned arrays. Cell 185 35512705 10.1016/j.cell.2022.04.003 9. Yu Z Accurate spatial heterogeneity dissection and gene regulation interpretation for spatial transcriptomics using dual graph contrastive learning Adv. Sci. 2025 12 2410081 10.1002/advs.202410081 PMC11744562 39605202 Yu, Z. et al. Accurate spatial heterogeneity dissection and gene regulation interpretation for spatial transcriptomics using dual graph contrastive learning. Adv. Sci. 12 10.1002/advs.202410081 PMC11744562 39605202 10. Chen KH Boettiger AN Moffitt JR Wang S Zhuang X Spatially resolved, highly multiplexed RNA profiling in single cells Science 2015 348 aaa6090 10.1126/science.aaa6090 25858977 PMC4662681 Chen, K. H., Boettiger, A. N., Moffitt, J. R., Wang, S. & Zhuang, X. Spatially resolved, highly multiplexed RNA profiling in single cells. Science 348 25858977 10.1126/science.aaa6090 PMC4662681 11. Shah S Dynamics and spatial genomics of the nascent transcriptome by intron seqFISH Cell 2018 174 363 376 10.1016/j.cell.2018.05.035 29887381 PMC6046268 Shah, S. et al. Dynamics and spatial genomics of the nascent transcriptome by intron seqFISH. Cell 174 29887381 10.1016/j.cell.2018.05.035 PMC6046268 12. Zhang C Dong K Aihara K Chen L Zhang S STAMarker: determining spatial domain-specific variable genes with saliency maps in deep learning Nucleic Acids Res. 2023 51 e103 e103 10.1093/nar/gkad801 37811885 PMC10639070 Zhang, C., Dong, K., Aihara, K., Chen, L. & Zhang, S. STAMarker: determining spatial domain-specific variable genes with saliency maps in deep learning. Nucleic Acids Res. 51 37811885 10.1093/nar/gkad801 PMC10639070 13. Li X Zhu F Min W SpaDiT: diffusion transformer for spatial gene expression prediction using scRNA-seq Brief. Bioinform. 2024 25 bbae571 10.1093/bib/bbae571 39508444 PMC11541600 Li, X., Zhu, F. & Min, W. SpaDiT: diffusion transformer for spatial gene expression prediction using scRNA-seq. Brief. Bioinform. 25 39508444 10.1093/bib/bbae571 PMC11541600 14. Li H-S Tan Y-T Zhang X-F Enhancing spatial domain detection in spatial transcriptomics with ensdd Commun. Biol. 2024 7 1358 10.1038/s42003-024-07001-y 39433947 PMC11494180 Li, H.-S., Tan, Y.-T. & Zhang, X.-F. Enhancing spatial domain detection in spatial transcriptomics with ensdd. Commun. Biol. 7 39433947 10.1038/s42003-024-07001-y PMC11494180 15. Blondel VD Guillaume J-L Lambiotte R Lefebvre E Fast unfolding of communities in large networks J. Stat. Mech. Theory Exp. 2008 2008 P10008 10.1088/1742-5468/2008/10/P10008 Blondel, V. D., Guillaume, J.-L., Lambiotte, R. & Lefebvre, E. Fast unfolding of communities in large networks. J. Stat. Mech. Theory Exp. 2008 16. Wang H Zhao J Nie Q Zheng C Sun X Dissecting spatiotemporal structures in spatial transcriptomics via diffusion-based adversarial learning Research 2024 7 0390 10.34133/research.0390 38812530 PMC11134684 Wang, H., Zhao, J., Nie, Q., Zheng, C. & Sun, X. Dissecting spatiotemporal structures in spatial transcriptomics via diffusion-based adversarial learning. Research 7 38812530 10.34133/research.0390 PMC11134684 17. Varrone M Tavernari D Santamaria-Martínez A Walsh LA Ciriello G Cellcharter reveals spatial cell niches associated with tissue remodeling and cell plasticity Nat. Genet. 2024 56 74 84 10.1038/s41588-023-01588-4 38066188 Varrone, M., Tavernari, D., Santamaria-Martínez, A., Walsh, L. A. & Ciriello, G. Cellcharter reveals spatial cell niches associated with tissue remodeling and cell plasticity. Nat. Genet. 56 38066188 10.1038/s41588-023-01588-4 18. Yuan Z Mender: fast and scalable tissue structure identification in spatial omics data Nat. Commun. 2024 15 207 10.1038/s41467-023-44367-9 38182575 PMC10770058 Yuan, Z. Mender: fast and scalable tissue structure identification in spatial omics data. Nat. Commun. 15 38182575 10.1038/s41467-023-44367-9 PMC10770058 19. Hu J SpaGCN: Integrating gene expression, spatial location and histology to identify spatial domains and spatially variable genes by graph convolutional network Nat. Methods 2021 18 1342 1351 10.1038/s41592-021-01255-8 34711970 Hu, J. et al. SpaGCN: Integrating gene expression, spatial location and histology to identify spatial domains and spatially variable genes by graph convolutional network. Nat. Methods 18 34711970 10.1038/s41592-021-01255-8 20. Xu H Unsupervised spatially embedded deep representation of spatial transcriptomics Genome Med. 2024 16 12 10.1186/s13073-024-01283-x 38217035 PMC10790257 Xu, H. et al. Unsupervised spatially embedded deep representation of spatial transcriptomics. Genome Med. 16 38217035 10.1186/s13073-024-01283-x PMC10790257 21. Hou, Z. et al. GraphMAE: Self-supervised masked graph autoencoders. in Proc. 28th ACM SIGKDD Conf. Knowledge Discovery and Data Mining (KDD) 22. Tu W RARE: Robust masked graph autoencoder IEEE Trans. Knowl. Data Eng. 2023 36 5340 5353 10.1109/TKDE.2023.3335222 Tu, W. et al. RARE: Robust masked graph autoencoder. IEEE Trans. Knowl. Data Eng. 36 23. Chen Y Zhen C Mo Y Liu J Zhang L Multiscale dissection of spatial heterogeneity by integrating multi-slice spatial and single-cell transcriptomics Adv. Sci. 2025 12 2413124 10.1002/advs.202413124 PMC12005799 39999288 Chen, Y., Zhen, C., Mo, Y., Liu, J. & Zhang, L. Multiscale dissection of spatial heterogeneity by integrating multi-slice spatial and single-cell transcriptomics. Adv. Sci. 12 10.1002/advs.202413124 PMC12005799 39999288 24. Lin L STMGraph: spatial-context-aware of transcriptomes via a dual-remasked dynamic graph attention model Brief. Bioinform. 2025 26 bbae685 10.1093/bib/bbae685 PMC11704419 39764614 Lin, L. et al. STMGraph: spatial-context-aware of transcriptomes via a dual-remasked dynamic graph attention model. Brief. Bioinform. 26 10.1093/bib/bbae685 PMC11704419 39764614 25. Fang, D., Zhu, F., Xie, D. & Min, W. Masked graph autoencoders with contrastive augmentation for spatially resolved transcriptomics data. In Proc. 2024 IEEE Int. Conf. Bioinform. Biomed. (BIBM) 26. Min W Fang D Chen J Zhang S SpaMask: Dual masking graph autoencoder with contrastive learning for spatial transcriptomics PLoS Comput. Biol. 2025 21 e1012881 10.1371/journal.pcbi.1012881 40179332 PMC11968113 Min, W., Fang, D., Chen, J. & Zhang, S. SpaMask: Dual masking graph autoencoder with contrastive learning for spatial transcriptomics. PLoS Comput. Biol. 21 40179332 10.1371/journal.pcbi.1012881 PMC11968113 27. Lee, N., Lee, J. & Park, C. Augmentation-free self-supervised learning on graphs. in Proc. AAAI Conf. on Artif. Intell 28. Li J Chen S Pan X Yuan Y Shen H-B Cell clustering for spatial transcriptomics data with graph neural networks Nat. Comput. Sci. 2022 2 399 408 10.1038/s43588-022-00266-5 38177586 Li, J., Chen, S., Pan, X., Yuan, Y. & Shen, H.-B. Cell clustering for spatial transcriptomics data with graph neural networks. Nat. Comput. Sci. 2 38177586 10.1038/s43588-022-00266-5 29. Nie W Yu Y Wang X Wang R Li SC Spatially informed graph structure learning extracts insights from spatial transcriptomics Adv. Sci. 2024 11 2403572 10.1002/advs.202403572 PMC11615819 39382177 Nie, W., Yu, Y., Wang, X., Wang, R. & Li, S. C. Spatially informed graph structure learning extracts insights from spatial transcriptomics. Adv. Sci. 11 10.1002/advs.202403572 PMC11615819 39382177 30. Long Y Spatially informed clustering, integration, and deconvolution of spatial transcriptomics with GraphST Nat. Commun. 2023 14 1155 10.1038/s41467-023-36796-3 36859400 PMC9977836 Long, Y. et al. Spatially informed clustering, integration, and deconvolution of spatial transcriptomics with GraphST. Nat. Commun. 14 36859400 10.1038/s41467-023-36796-3 PMC9977836 31. Zeng Y Identifying spatial domain by adapting transcriptomics with histology through contrastive learning Brief. Bioinform. 2023 24 bbad048 10.1093/bib/bbad048 36781228 Zeng, Y. et al. Identifying spatial domain by adapting transcriptomics with histology through contrastive learning. Brief. Bioinform. 24 36781228 10.1093/bib/bbad048 32. Zhou X Dong K Zhang S Integrating spatial transcriptomics data across different conditions, technologies and developmental stages Nat. Comput. Sci. 2023 3 894 906 10.1038/s43588-023-00528-w 38177758 Zhou, X., Dong, K. & Zhang, S. Integrating spatial transcriptomics data across different conditions, technologies and developmental stages. Nat. Comput. Sci. 3 38177758 10.1038/s43588-023-00528-w 33. Wang G Construction of a 3D whole organism spatial atlas by joint modelling of multiple slices with deep neural networks Nat. Mach. Intell. 2023 5 1200 1213 10.1038/s42256-023-00734-1 Wang, G. et al. Construction of a 3D whole organism spatial atlas by joint modelling of multiple slices with deep neural networks. Nat. Mach. Intell. 5 34. Zeira R Land M Strzalkowski A Raphael BJ Alignment and integration of spatial transcriptomics data Nat. Methods 2022 19 567 575 10.1038/s41592-022-01459-6 35577957 PMC9334025 Zeira, R., Land, M., Strzalkowski, A. & Raphael, B. J. Alignment and integration of spatial transcriptomics data. Nat. Methods 19 35577957 10.1038/s41592-022-01459-6 PMC9334025 35. Xu H SPACEL: deep learning-based characterization of spatial transcriptome architectures Nat. Commun. 2023 14 7603 10.1038/s41467-023-43220-3 37990022 PMC10663563 Xu, H. et al. SPACEL: deep learning-based characterization of spatial transcriptome architectures. Nat. Commun. 14 37990022 10.1038/s41467-023-43220-3 PMC10663563 36. Arun KS Huang TS Blostein SD Least-squares fitting of two 3-D point sets IEEE Trans. Pattern Anal. Mach. Intell. 1987 1 698 700 10.1109/TPAMI.1987.4767965 21869429 Arun, K. S., Huang, T. S. & Blostein, S. D. Least-squares fitting of two 3-D point sets. IEEE Trans. Pattern Anal. Mach. Intell. 1 10.1109/tpami.1987.4767965 21869429 37. Xu C DeepST: identifying spatial domains in spatial transcriptomics by deep learning Nucleic Acids Res. 2022 50 e131 e131 10.1093/nar/gkac901 36250636 PMC9825193 Xu, C. et al. DeepST: identifying spatial domains in spatial transcriptomics by deep learning. Nucleic Acids Res. 50 36250636 10.1093/nar/gkac901 PMC9825193 38. Cui Y DiffusionST: a deep generative diffusion model-based framework for enhancing spatial transcriptomics data quality and identifying spatial domains Brief. Bioinform. 2025 26 bbaf390 40794943 10.1093/bib/bbaf390 Cui, Y. et al. DiffusionST: a deep generative diffusion model-based framework for enhancing spatial transcriptomics data quality and identifying spatial domains. Brief. Bioinform. 26 40794943 10.1093/bib/bbaf390 39. Maynard KR Transcriptome-scale spatial gene expression in the human dorsolateral prefrontal cortex Nat. Neurosci. 2021 24 425 436 10.1038/s41593-020-00787-0 33558695 PMC8095368 Maynard, K. R. et al. Transcriptome-scale spatial gene expression in the human dorsolateral prefrontal cortex. Nat. Neurosci. 24 33558695 10.1038/s41593-020-00787-0 PMC8095368 40. Yuan Z Benchmarking spatial clustering methods with spatially resolved transcriptomics data Nat. Methods 2024 21 712 722 10.1038/s41592-024-02215-8 38491270 Yuan, Z. et al. Benchmarking spatial clustering methods with spatially resolved transcriptomics data. Nat. Methods 21 38491270 10.1038/s41592-024-02215-8 41. Wang X Three-dimensional intact-tissue sequencing of single-cell transcriptional states Science 2018 361 eaat5691 10.1126/science.aat5691 29930089 PMC6339868 Wang, X. et al. Three-dimensional intact-tissue sequencing of single-cell transcriptional states. Science 361 29930089 10.1126/science.aat5691 PMC6339868 42. Codeluppi S Spatial organization of the somatosensory cortex revealed by osmfish Nat. Methods 2018 15 932 935 10.1038/s41592-018-0175-z 30377364 Codeluppi, S. et al. Spatial organization of the somatosensory cortex revealed by osmfish. Nat. Methods 15 30377364 10.1038/s41592-018-0175-z 43. Guo T SPIRAL: integrating and aligning spatially resolved transcriptomics data across different experiments, conditions, and technologies Genome Biol. 2023 24 241 10.1186/s13059-023-03078-6 37864231 PMC10590036 Guo, T. et al. SPIRAL: integrating and aligning spatially resolved transcriptomics data across different experiments, conditions, and technologies. Genome Biol. 24 37864231 10.1186/s13059-023-03078-6 PMC10590036 44. Tran HTN A benchmark of batch-effect correction methods for single-cell RNA sequencing data Genome Biol. 2020 21 12 10.1186/s13059-019-1850-9 31948481 PMC6964114 Tran, H. T. N. et al. A benchmark of batch-effect correction methods for single-cell RNA sequencing data. Genome Biol. 21 31948481 10.1186/s13059-019-1850-9 PMC6964114 45. Richardson L EMAGE mouse embryo spatial gene expression database: 2014 update Nucleic Acids Res. 2014 42 D835 D844 10.1093/nar/gkt1155 24265223 PMC3965061 Richardson, L. et al. EMAGE mouse embryo spatial gene expression database: 2014 update. Nucleic Acids Res. 42 24265223 10.1093/nar/gkt1155 PMC3965061 46. Ortiz C Molecular atlas of the adult mouse brain Sci. Adv. 2020 6 eabb3446 10.1126/sciadv.abb3446 32637622 PMC7319762 Ortiz, C. et al. Molecular atlas of the adult mouse brain. Sci. Adv. 6 32637622 10.1126/sciadv.abb3446 PMC7319762 47. Wolf FA Angerer P Theis FJ SCANPY: large-scale single-cell gene expression data analysis Genome Biol. 2018 19 1 5 10.1186/s13059-017-1382-0 29409532 PMC5802054 Wolf, F. A., Angerer, P. & Theis, F. J. SCANPY: large-scale single-cell gene expression data analysis. Genome Biol. 19 29409532 10.1186/s13059-017-1382-0 PMC5802054 48. Rand WM Objective criteria for the evaluation of clustering methods J. Am. Stat. Assoc. 1971 66 846 850 10.1080/01621459.1971.10482356 Rand, W. M. Objective criteria for the evaluation of clustering methods. J. Am. Stat. Assoc. 66 49. Amelio A Pizzuti C Correction for closeness: adjusting normalized mutual information measure for clustering comparison Comput. Intell. 2017 33 579 601 10.1111/coin.12100 Amelio, A. & Pizzuti, C. Correction for closeness: adjusting normalized mutual information measure for clustering comparison. Comput. Intell. 33 50. Moffitt JR Molecular, spatial, and functional single-cell profiling of the hypothalamic preoptic region Science 2018 362 eaau5324 10.1126/science.aau5324 30385464 PMC6482113 Moffitt, J. R. et al. Molecular, spatial, and functional single-cell profiling of the hypothalamic preoptic region. Science 362 30385464 10.1126/science.aau5324 PMC6482113 ",
  "metadata": {
    "Title of this paper": "Molecular, spatial, and functional single-cell profiling of the hypothalamic preoptic region",
    "Journal it was published in:": "Communications Biology",
    "URL": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC12484869/"
  }
}