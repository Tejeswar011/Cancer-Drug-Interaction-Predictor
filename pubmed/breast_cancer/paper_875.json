{
  "title": "Paper_875",
  "abstract": "pmc Sci Rep Sci Rep 1579 scirep Scientific Reports 2045-2322 Nature Publishing Group PMC12475121 PMC12475121.1 12475121 12475121 41006381 10.1038/s41598-025-16980-9 16980 1 Article Optimized extreme learning machines with deep learning for high-performance network traffic classification Zhang Xi 1 Yin Jun Zx810588969@163.com 2 1 https://ror.org/04mkzax54 grid.258151.a 0000 0001 0708 1323 School of Design, Jiangnan University, 2 https://ror.org/04mkzax54 grid.258151.a 0000 0001 0708 1323 School of Digital Technology &Innovation Design, Jiangnan University, 26 9 2025 2025 15 478255 33199 4 5 2025 20 8 2025 26 09 2025 28 09 2025 29 09 2025 © The Author(s) 2025 2025 https://creativecommons.org/licenses/by-nc-nd/4.0/ Open Access http://creativecommons.org/licenses/by-nc-nd/4.0/ The exponential growth in network users and applications, coupled with increasing dependence on networked systems, has elevated network security to a paramount concern for service providers and organizations. Traffic analysis has emerged as a pivotal technique for identifying malicious activities, enabling critical functions such as bandwidth management, fault detection, quality assessment, pricing, and lawful security monitoring. We propose a novel framework for network traffic classification using an Improved Extreme Learning Machine (IELM). The proposed approach advances traditional extreme learning by incorporating a particle swarm optimization algorithm to optimize model parameters, alongside a deep learning-based feature selection mechanism to assess and prioritize input feature relevance, thereby enhancing classification precision. The framework’s performance was rigorously evaluated using the CICIDS 2017 dataset, a widely recognized benchmark in network traffic analysis. The results demonstrate the framework’s capability to accurately classify network traffic into secure and insecure categories, achieving a remarkable detection accuracy of 98.756%. These findings underscore the efficacy of the IELM-based approach in detecting malicious activities and mitigating security risks, offering a robust and scalable solution for strengthening network protection. Supplementary Information The online version contains supplementary material available at 10.1038/s41598-025-16980-9. Keywords Extreme learning machine (ELM) Particle swarm optimization (PSO) Network traffic classification Feature selection Network security Subject terms Engineering Mathematics and computing pmc-status-qastatus 0 pmc-status-live yes pmc-status-embargo no pmc-status-released yes pmc-prop-open-access yes pmc-prop-olf no pmc-prop-manuscript no pmc-prop-legally-suppressed no pmc-prop-has-pdf yes pmc-prop-has-supplement yes pmc-prop-pdf-only no pmc-prop-suppress-copyright no pmc-prop-is-real-version no pmc-prop-is-scanned-article no pmc-prop-preprint no pmc-prop-in-epmc yes issue-copyright-statement © Springer Nature Limited 2025 Introduction Enabling essential network security applications, IP traffic classification such as intrusion detection systems (IDS), firewalls, and quality of service (QoS) management poses a significant challenge for Internet service providers, as well as government and private organizations. By analyzing network traffic, it becomes possible to identify intrusive programs or anomalies that disrupt traffic patterns and compromise network stability. Traditional traffic classification methods, particularly in cellular networks, are increasingly being phased out due to their reliance on the statistical characteristics of network traffic packets 1 2 3 1 4 5 6 7 A primary challenge in traffic analysis lies in the absence of explicit relationships between inputs and outputs. Input data, derived from network monitoring, must be translated into actionable outputs—decisions regarding whether traffic is secure or malicious. However, no predefined equations exist for this conversion. Addressing this issue requires the use of machine learning methods, which aim to model these relationships by optimizing parameters. Nonetheless, several challenges persist in applying ML techniques to network traffic classification: 1-Training Speed: The slow training speed of many ML models makes their implementation time-intensive. Most models require optimization of a large number of network parameters. The Extreme Learning Machine (ELM), however, is known for requiring fewer parameters, allowing faster training 9 10 11 12 16 17 18 The primary goal of this research is to develop an efficient network traffic classification method based on an enhanced extreme learning machine framework, combining ELM with particle swarm optimization (PSO-ELM). A secondary goal is to improve processing speed by optimizing batch sizes and identifying the influence of parameters on batching efficiency. This paper is organized into five sections: Section \" Introduction Related works Proposed method Result and discussion Conclusion Related works Zhang et al. 19 11 20 21 22 This method is able to increase the accuracy and reduce the classification time compared to the traditional classification approaches. Lim et al. 9 23 24 25 26 17 27 28 29 30  Table 1 Comparison of traffic classification approaches including recent deep learning-based and swarm intelligence-enhanced methods. Works Method Advantages Disadvantages Ref 31 DFR Good accuracy with fewer resources required. Does not handle changes in the network environment. Ref 9 RecNet Good accuracy and quality of services in closed packet classification. Requires advanced technology for self-automated traffic classification. Ref 23 Aggregated Plan Improved performance of deep learning algorithms. Does not perform well in unstable environments like the internet. Ref 24 SDN-HGW Used in smart home networks. Lack of precise representation for classification. Ref 31 End-to-end Encrypted VPN Good accuracy in VPN encrypted traffic classification. Challenging in traditional traffic classification methods. Ref 32 Mobile Encrypted Traffic Higher accuracy using traditional MLP methods. Not compatible with some mobile applications. Ref 33 Hybrid Network Better performance in traffic classification with short-term memory neural networks. Classification relies on traditional traffic classification with short-term memory neural networks. Ref 34 Deep Packet Network Strong focus on a specific protocol. Does not integrate well into a broader framework. Ref 35 Seq2Img Simultaneous use of image and textual information. Depends on handcrafted features. Ref 36 Multi-feature Classifier High accuracy and resistance to unknown data. Requires fine-tuning of adjustable parameters. Ref 37 VMD-ELM Good accuracy and stability. High complexity in implementation. To provide a clearer perspective on the proposed method’s position within the current research landscape, we have incorporated comparisons with more recent state-of-the-art approaches. Chakravarthy and Rajaguru 7 43 34 35 1 Proposed method The classifier implementation method proposed is called PSO-ELM. In this approach, the ELM network structure is utilized for network traffic analysis, while Particle Swarm Optimization (PSO) is applied to fine-tune the network parameters. Additionally, deep learning techniques are employed for feature selection during the method’s implementation. Figure 1  Fig. 1 Step-by-step framework of the proposed PSO-ELM model with deep learning-based backward elimination. The pipeline includes data preprocessing, normalization, deep-learning feature reduction, PSO parameter optimization, and final classification. The proposed method consists of the following steps: Step One: The data is first preprocessed, followed by normalization. Step Two: A deep learning-based feature selection method is then applied to refine the dataset, preparing it for evaluation. The output from this stage is used as the training and testing datasets for the following steps. Step Three: The IELM method is implemented in this step to create a structure for PSO, which helps identify the optimal parameter values. This stage serves as the training routine, carried out using the training dataset. Step Four: The trained IELM model is applied to traffic classification, and the testing dataset is used for evaluation. Step Five: Lastly, the performance of the proposed method is assessed using the metrics, which will be introduced in the next chapter. The implementation used Python 3.8.10 ( https://www.python.org/downloads/release/python-3810/ https://pypi.org/project/keras/2.6.0/ https://pypi.org/project/scikit-learn/0.24.2/ https://www.mathworks.com https://www.unb.ca/cic/research/applications.html#CICFlowMeter Data set The dataset used is the CIC-IDS 2017, which includes traffic related to eight attacks in computer networks. This data is provided in eight separate files in CSV format. To construct this dataset, the B-Profile system was utilized to profile the behavior of network users and record secure and insecure network traffic 38 39 2  Table 2 Frequency of data records in the CICIDS2017 dataset. Type of record Number of record occurrences Benign Traffic 2,3580,36 DDOS Attack 41,835 DOS Hulk Attack 231,036 Port Scan Attack 158,930 DOS Golden Eye Attack 10,293 FTP Patator Attack 7,938 SSH Patator Attack 5,897 DOS Slow Loris Attack 5,796 DOS Slow HTTP Test Attack 5,499 Botnet Attack 1,966  Table 3 Explanation of some of the most important features of the CICIDS2017 dataset. Feature Name Description Source IP IP Address of the Source Computer Destination IP IP Address of the Destination Computer Source Port Source Port Number Destination Port Destination Port Number Protocol Protocol Number in Use Total Fwd Packets Total Number of Packets Sent Total Length of Fwd Packets Total Length of Sent Packets Flow Bytes/s Flow Rate in Bytes per Second min_seg_size_forward Minimum Size of Forwarded Segment Avg Fwd Segment Size Average Size of Forwarded Segment The dataset used focuses on DDOS attacks and includes 76 input features and one output label. Some of the most important features of this dataset are explained in Table 3 Data normalization Most machine learning methods utilize numerical data for learning operations. In the dataset in question, there are five features that are stored as non-numerical data. These features are converted into numerical data as shown in Supplementary material Code 1. The identification strings are read from a column of data and stored in the variable readcell using the Col function. For each string stored in the cell, it is compared with the values found in the previous variable saved_string. If it is new, it is added to this array, and a new number is used to replace it. If the new data is repetitive, the same previous number is used. Out of a total of 225,745 records in the initial dataset, 36 records had empty values and were deleted. Therefore, the total number of records in the dataset is 225,709. Additionally, 10 features in this dataset had completely zero values and, therefore, have no impact on classification and were deleted. As a result, the dataset consists of 74 features and 1 output label. Normalization improves the performance of machine learning methods and ensures that the input feature dimensions are evaluated fairly by the learning algorithm, preventing any single feature from having a greater impact than others. Here, the standard method is applied, as shown in Eq. ( 1 2 1 \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$x=\\frac{{x - \\hbox{min} }}{{\\hbox{max} - \\hbox{min} }}$$\\end{document} 2 \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$x=(ub - lb) \\cdot x+lb$$\\end{document} All experiments were conducted on a workstation equipped with an Intel Xeon Gold 6248R (24 cores, 3.0 GHz), 128 GB RAM, and an NVIDIA Tesla V100-SXM2 GPU (32 GB), running Ubuntu 20.04 LTS. Python 3.8.10 (with TensorFlow 2.6.0, Keras 2.6, and scikit-learn 0.24.2) and MATLAB R2021a were used for deep learning and optimization tasks. The deep neural network (DNN) used for feature selection consisted of three hidden layers with 64, 32, and 16 neurons, respectively, employing ReLU activation in hidden layers and sigmoid in the output. The model was optimized using the Adam optimizer with a learning rate of 0.001, batch size of 1, binary cross-entropy loss function, and early stopping (patience = 50). Features with Fisher scores below 0.3 were eliminated. For classification, Particle Swarm Optimization (PSO) was applied to optimize the ELM parameters. PSO settings included 100 particles, 1000 iterations, inertia weight linearly decaying from 0.9 to 0.4, and cognitive and social coefficients (c 1 2 Feature selection To ensure clarity and reproducibility, we have provided the algorithmic steps of the deep learning-based backward elimination method below. The process is visually summarized in Fig. 2 3  Fig. 2 Flowchart illustrating the deep learning-based backward elimination method for feature selection. Step 1: Initialize the dataset with all n features { F 1 F 2 F n Y Step 2: Train a deep neural network DNN ( F F Acc ( F Step 3: For each feature F i F F i F F F i DNN ( F Acc ( F 3 \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$\\Delta i=Acc(F) - Acc(F^{\\prime})$$\\end{document} Step 4: Identify the feature with the lowest Δ i The goal of feature selection is to describe the data with less and more useful information. The attack dataset initially had 85 features and one label, which was reduced to 74 input features and one DDOS output label after refinement and normalization. We performed feature selection on this dataset. The feature selection method in the proposed plan employs deep learning. The feature selection process is time-consuming and complex, and the deep learning approach has been relatively successful in its execution 40 41 42 Classification design In this section, the design of classification using the improved extreme machine learning method is addressed. First, the network structure is computed. The neural PSO (Particle Swarm Optimization) is created, and then its parameters are optimized using the optimization algorithm. Neural networks based on Extreme Learning Machine (ELM), unlike the backpropagation algorithm, do not require the adjustment of hidden layer parameters such as weights and biases. These parameters in ELM are randomly selected, and they demonstrate good learning speed. ELM has a structure similar to RBF (Radial Basis Function) networks, with the difference being that the weights between the input and hidden layers are fixed and assigned a constant value. In this network, at the beginning of the training process, random values are assigned to the weights, and these values do not change during the training process. ELM is a feedforward network and calculates the weights using the Moore-Penrose pseudoinverse method. These weights are computed only once, which significantly increases the learning speed of the network. Although this method has fewer adjustable parameters, it has still shown good performance in various problems. In Fig. 3  Fig. 3 Structure of the ELM network. The network contains an input layer (equal to number of selected features), a hidden layer with optimized neurons, and a single output neuron for binary classification. PSO for network parameter tuning The PSO-ELM’s superiority over GA-ELM emerges from its continuous optimization paradigm. Where GA-ELM’s binary crossover/mutation operators disrupt weight matrices (limiting fine-tuning), PSO’s velocity-based updates preserve gradient information. Figure 6 p 7 4 a b a b 5  Fig. 4 Training phase of the improved ELM using PSO, showing the initialization and optimization of neuron weights for performance enhancement.  Fig. 5 Testing phase of the PSO-optimized ELM model. The trained network is evaluated using unseen test data for performance validation. The optimal value of this parameter has been determined to be 117 through extensive training runs without using PSO. Therefore, considering the 51 input features and only 1 output, vector a b 4 6 a b  Fig. 6 Factors influencing PSO particle updates. Each particle is updated based on its personal best (pbest), global best (gbest), and current velocity.  Table 4 SO-ELM particle parameter matrix dimensions. Particle # Weights from Input to Hidden ( a Weights from Hidden to Output ( b Total Parameters ( a b 1 … … 6084 2 … … 6084 … … … … 100 … … 6084 This algorithm is executed in multiple iterations, here we have repeated it 1000 times. In each iteration, the population is updated, and ultimately, the best particle with the best fitness is selected. The update process is shown. These three factors include the current movement of a particle, which depends on three factors as shown in Fig. 6 4 5 4 \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$v_{{id}}^{{new}}=K.[v_{{id}}^{{old}}+{c_1}.ran{d_1}.({p_{id}} - {x_{id}})+{c_2}.ran{d_2}*({p_{gd}} - {x_{id}})]$$\\end{document} 5 \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$x_{{id}}^{{new}}=x_{{id}}^{{old}}+v_{{id}}^{{new}}$$\\end{document} To find the optimal values, each particle is given to the ELM network. That is, the weight values of the network are assigned. Then, all rows of the dataset are sequentially given to the network, and the MSE value (Mean Squared Error) is calculated for all the network outputs. This value is calculated as the fitness value of a particle (for all records in the dataset used for training). Then, all particles are sorted based on their fitness, and the best ones in each neighborhood are selected and stored in the variables pbest and gbest. Due to the length of this process, the pseudocode for this procedure is shown in Supplementary material Code 6. This procedure performs the network weight initialization and runs each record from the training dataset on the network. After the optimal weights are calculated, the testing phase is conducted. The test procedure involves running the same function F once with the optimal weight values. It is important to note that, instead of using the training dataset, the testing dataset is applied. In the execution of the PSO algorithm, the number of neurons in the hidden layer is considered fixed. This decision is based on the specific data structure required in this case. As shown in Table 4 To better evaluate the proposed method, we implemented two other important classification methods for the network traffic classification problem: Random Forest Classification (RFC) and Multi-Layer Perceptron (MLP). These methods are neural networks. These methods were implemented in MATLAB software. GA-ELM method: In this method, instead of using the PSO method described in 43 43 Result and discussion This research addresses two fundamental issues. Our first contribution is a novel traffic classification method based on an enhanced Extreme Learning Machine (ELM) network. The second issue is feature selection, which was solved using deep learning. In this section, both solutions are evaluated, and the results of the experiments are reported. Python’s operational environment has been used to implement deep learning networks for the feature selection problem. The classification algorithm is implemented using extreme machine learning, and the particle optimization algorithm has been implemented using MATLAB software. The dataset used, after modification and normalization, consists of 75 columns, including 74 features and one label, as well as 225,709 records of data. To assess the robustness and generalizability of the proposed PSO-ELM model, we performed 10 independent runs with random initializations and stratified 10-fold cross-validation on the dataset. The mean and standard deviation of classification accuracy across these runs were calculated. The PSO-ELM model achieved a mean accuracy of 98.75% ± 0.12, indicating strong stability and consistent performance. Similarly, the F1-score and precision metrics showed low variance across folds (F1-score: 0.989 ± 0.008, Precision: 0.985 ± 0.007). These statistical measures confirm the reliability of the proposed model under different random seeds and data splits, reinforcing its applicability for real-world traffic classification scenarios. To further validate the generalizability of the PSO-ELM framework, we conducted additional experiments on two benchmark datasets: CIC-IDS-2018 and CIC-DDoS-2019. These datasets include newer attack variants (e.g., Brute Force FTP, Web Attacks) and larger traffic volumes compared to CIC-IDS-2017. The model retained high accuracy (98.12% on CIC-IDS-2018 and 97.89% on CIC-DDoS-2019) with consistent training times (~ 29 min). Feature selection reduced input dimensions by 30–35% across all datasets, confirming its adaptability. Detailed results are summarized in Table 5  Table 5 Performance metrics of the proposed model across three benchmark datasets. The model achieves high accuracy, sensitivity, and specificity with reduced feature sets and acceptable training times. Dataset Accuracy (%) Sensitivity Specificity Training Time (min) Features Retained CIC-IDS-2017 98.756 0.992 0.980 27.616 51 / 74 CIC-IDS-2018 98.120 0.988 0.975 28.941 49 / 72 CIC-DDoS-2019 97.890 0.983 0.971 29.203 53 / 81 Of this total, 90% has been designated for training, and the remaining 10% for testing. To better compare and evaluate the network traffic classification problem using multi-layer perceptron neural networks, the proposed method (PSO-ELM) and the method proposed in 43 44 6  Table 6 Evaluation criteria for classification algorithm. Evaluation Metrics Equation Description TP - True Positive TN - True Negative FP - False Positive FN - False Negative Accuracy (5) The percentage of correctly classified instances. Sensitivity (TPR) (6) True Positive Rate Specificity (TNR) (7) True Negative Rate Precision (8) The degree of validity for positive responses. Recall (9) The classifier’s ability to detect unsafe traffic. F1-Measure (10) A combination of precision and recall. Training Time - The time it takes to train the classifier. Prediction Time - The time it takes to classify a single incoming traffic. 6 \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$Accuracy=\\frac{{TP{\\text{ }}+{\\text{ }}TN{\\text{ }}}}{{TP{\\text{ }}+{\\text{ }}FP{\\text{ }}+{\\text{ }}TN{\\text{ }}+{\\text{ }}FN}}$$\\end{document} 7 \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$Sensitivity=\\frac{{TP}}{{TP{\\text{ }}+{\\text{ }}FN}}$$\\end{document} 8 \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$Specificity=\\frac{{TN}}{{TN{\\text{ }}+{\\text{ }}FP}}$$\\end{document} 9 \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$Precision=\\frac{{TP}}{{TP{\\text{ }}+{\\text{ }}FP}}$$\\end{document} 10 \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$Recall=\\frac{{TP}}{{TP{\\text{ }}+{\\text{ }}FN}}$$\\end{document} 11 \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$F1 - score=2 \\times \\frac{{Precision \\times Recall}}{{Precision+Recall}}$$\\end{document} Accuracy is the most logical and effective metric for evaluating a predictive model. This metric, calculated using Eq. ( 6 Using feature selection, the number of input feature dimensions was reduced from 74 to 52. The method used for feature selection is backward elimination based on deep learning. This method was executed in a Python virtual environment using jupyter notebook, as presented in Supplementary material code 3. In each step of the backward elimination method, the training process is done on 90% of the data, while the testing process uses the remaining 10%. This process is performed using deep learning. The deep learning training process required several hours due to computational complexity and dataset size. However, this slowness does not affect the final performance of the proposed method, as it only needs to be executed once and won’t require rerunning. In Fig. 7 8  Fig. 7 Impact of each input feature on the output label.  Fig. 8 Calculated values ​​for the impact of the input characteristics on the output label. Experiments were conducted to evaluate the effect of feature selection; Once with the original dataset (without using PSO-ELM for feature selection) and once with the reduced dataset (with feature selection). The results of these two tests are shown in Table 7  Table 7 The impact of the feature selection method on the PSO-ELM classification performance. Evaluation metric Without feature selection With feature selection Precision 98.751 98.756 Teaching time (min) 28.333 27.616 Prediction time (microseconds) 15.289 14.740 Beyond accuracy, PSO-ELM shows fundamental advantages over GA-ELM: (1) 38% faster convergence (Fig. 11 in Supplement), (2) 2.4× lower variance in repeated runs (σ = 0.12 vs. 0.29), and (3) 61% fewer false positives on rare attack types. These improvements stem from PSO’s ability to maintain population diversity during optimization, whereas GA-ELM often converges prematurely to suboptimal regions of the solution space. In Table 8 9 10 11  Fig. 9 Comparison of prediction accuracy of four implemented methods.  Fig. 10 Comparison of training time of four implemented methods.  Fig. 11 Comparison of prediction time of four implemented methods.  Table 8 Comparison of implemented methods for classification. Evaluation Metrics RFC MLP GA-ELM PSO-ELM TP 10,813 10,272 11,007 10,992 FP 344 885 150 165 TN 8128 7913 8151 8391 FN 342 557 319 79 Accuracy (%) 96.504 92.653 97.610 98.756 Sensitivity 0.969 0.948 0.971 0.992 Specificity 0.959 0.899 0.981 0.980 Precision 0.969 0.920 0.986 0.985 Recall 0.969 0.948 0.971 0.992 F1 Score 0.969 0.934 0.979 0.989 Training time (minutes) 2.650 26.133 35.566 27.616 Prediction time (microseconds) 117.604 23.706 13.894 14.740 Prediction accuracy stability No No No Yes To contextualize the performance of our PSO-ELM model, we compare its accuracy with recently published models in intelligent traffic analysis. The fusion-based ML model for congestion control proposed by Ahmed et al. 20 21 22 Conclusion This paper presents a network traffic classification method that combines Extreme Learning Machines (ELM) with a Particle Swarm Optimization (PSO) algorithm. The network structure features a hidden layer that offers both strong prediction performance and fast learning speed. To enhance efficiency, PSO is employed to find the optimal network parameters, providing a smarter search than the genetic algorithm (GA-ELM). Due to the large dataset and high number of features, feature selection is applied to reduce dimensionality, significantly improving both the training speed and performance of the proposed method compared to others, including RFC and MLP. Moreover, PSO-ELM outperforms GA-ELM in terms of learning speed and training time. The main reason for this improvement is the use of PSO to optimize both the parameters and the number of neurons in the hidden layer. Feature selection positively affects prediction accuracy and also boosts learning and prediction speed. Although the accuracy only improved by 0.11%, it demonstrates that reducing input dimensions can enhance classification performance. In machine learning methods, reducing feature numbers aids in improving generalization and accelerating convergence. The implementation complexity of the PSO-ELM method is lower than that of GA-ELM, as the learning processes in PSO are executed simultaneously. Our PSO-ELM framework outperforms GA-ELM and other methods in classification accuracy. As a goal-oriented process, the PSO-ELM method directs learning based on the best particles, offering better optimization and faster convergence than the genetic algorithm, which randomly swaps genes. The PSO-ELM method outperforms RFC and MLP in network settings. Optimal values were empirically derived, though alternative configurations may yield further improvements. However, trial and error methods do not effectively identify optimal points. In some experiments, the accuracy of MLP fell below 50%. Limitations and future directions Limitations: 1- Dataset Scope: While PSO-ELM achieves high accuracy on CIC datasets, its performance on real-time, high-speed networks (e.g., 5G/6G) remains untested due to the lack of temporal granularity in benchmark datasets. 2- Computational Overhead: The PSO optimization phase, though efficient post-training, requires substantial resources (~ 30 min for 1,000 iterations), limiting deployability in edge devices with strict latency constraints. 3- Feature Selection Bias: The backward elimination process relies on Fisher scores, which may prioritize linear correlations and overlook nonlinear feature interactions in encrypted traffic. Future Work: 1- Real-Time Adaptation: Integrate lightweight PSO variants (e.g., Quantum PSO) to reduce training overhead for edge deployment. 2- Cross-Protocol Generalization: Extend evaluation to IoT-specific datasets (e.g., IoT-23) and protocols (MQTT, CoAP) to assess robustness in heterogeneous environments. 3- Explain ability: Enhance interpretability via SHAP (SHapley Additive Explanations) to trace feature contributions, critical for adversarial attack detection. 4- Hybrid Optimization: Combine PSO with metaheuristics (e.g., Grey Wolf Optimizer) to improve parameter search efficiency in high-dimensional spaces. Supplementary Information Below is the link to the electronic supplementary material.  Supplementary Material 1 Publisher’s note Springer Nature remains neutral with regard to jurisdictional claims in published maps and institutional affiliations. Author contributions Xi Zhang and Jun Yin wrote the main manuscript text. Xi Zhang and Jun Yin reviewed the manuscript. Data availability The datasets generated and/or analyzed during the current study are available in the https://www.unb.ca/cic/datasets/ids-2017.html Declarations Competing interests The authors declare no competing interests. References 1. Abbasi M Shahraki A Taherkordi A Deep learning for network traffic monitoring and analysis (NTMA): A survey Comput. Commun. 2021 170 19 41 10.1016/j.comcom.2021.01.021 Abbasi, M., Shahraki, A. & Taherkordi, A. Deep learning for network traffic monitoring and analysis (NTMA): A survey. Comput. Commun. 170 2. Kalwar, J. H. & Bhatti, S. Deep learning approaches for network traffic classification in the internet of things (IoT): A survey. arXiv preprint arXiv:2402.00920. (2024). 3. Wang P Wang Z Ye F Chen X Bytesgan: A semi-supervised generative adversarial network for encrypted traffic classification in SDN edge gateway Comput. Netw. 2021 200 108535 10.1016/j.comnet.2021.108535 Wang, P., Wang, Z., Ye, F. & Chen, X. Bytesgan: A semi-supervised generative adversarial network for encrypted traffic classification in SDN edge gateway. Comput. Netw. 200 4. Chakravarthy SS Rajaguru H Automatic detection and classification of mammograms using improved extreme learning machine with deep learning Irbm 2022 43 1 49 61 10.1016/j.irbm.2020.12.004 Chakravarthy, S. S. & Rajaguru, H. Automatic detection and classification of mammograms using improved extreme learning machine with deep learning. Irbm 43 5. Meenalochini G Ramkumar S A deep learning based breast cancer classification system using mammograms J. Electr. Eng. Technol. 2024 19 4 2637 2650 10.1007/s42835-023-01747-x Meenalochini, G. & Ramkumar, S. A deep learning based breast cancer classification system using mammograms. J. Electr. Eng. Technol. 19 6. Sannasi Chakravarthy SR Deep transfer learning with fuzzy ensemble approach for the early detection of breast cancer BMC Med. Imaging 2024 24 1 82 10.1186/s12880-024-01267-8 38589813 PMC11389118 Sannasi Chakravarthy, S. R. et al. Deep transfer learning with fuzzy ensemble approach for the early detection of breast cancer. BMC Med. Imaging 24 38589813 10.1186/s12880-024-01267-8 PMC11389118 7. Chakravarthy, S. S. & Rajaguru, H. Breast tumor classification using transfer learning with adaptive crow search optimization. In 2023 Third International Conference on Smart Technologies, Communication and Robotics (STCR) 8. Rajaguru, H. & Chakravarthy, S. S. Classification of wisconsin breast cancer data with extreme learning machine and osprey optimization algorithm. In 2023 Third International Conference on Smart Technologies, Communication and Robotics (STCR) 9. Pacheco F Exposito E Gineste M Baudoin C Aguilar J Towards the deployment of machine learning solutions in network traffic classification: A systematic survey IEEE Commun. Surv. Tutorials 2018 21 2 1988 2014 10.1109/COMST.2018.2883147 Pacheco, F., Exposito, E., Gineste, M., Baudoin, C. & Aguilar, J. Towards the deployment of machine learning solutions in network traffic classification: A systematic survey. IEEE Commun. Surv. Tutorials 21 10. Azab A Khasawneh M Alrabaee S Choo KKR Sarsour M Network traffic classification: techniques, datasets, and challenges Digit. Commun. Networks 2024 10 3 676 692 10.1016/j.dcan.2022.09.009 Azab, A., Khasawneh, M., Alrabaee, S., Choo, K. K. R. & Sarsour, M. Network traffic classification: techniques, datasets, and challenges. Digit. Commun. Networks 10 11. Ertam F Avcı E A new approach for internet traffic classification: GA-WK-ELM Measurement 2017 95 135 142 10.1016/j.measurement.2016.10.001 Ertam, F. & Avcı, E. A new approach for internet traffic classification: GA-WK-ELM. Measurement 95 12. Wang L Jones R Big data analytics in cyber security: network traffic and attacks J. Comput. Inform. Syst. 2021 61 5 410 417 Wang, L. & Jones, R. Big data analytics in cyber security: network traffic and attacks. J. Comput. Inform. Syst. 61 13. Duan, X., Zhou, Y. & Guan, J. Exploration on heterogeneous network security monitoring algorithm based on big data intelligent information technology. In 2023 IEEE 15th International Conference on Computational Intelligence and Communication Networks (CICN) 14. Tang F Mao B Kawamoto Y Kato N Survey on machine learning for intelligent end-to-end communication toward 6G: from network access, routing to traffic control and streaming adaption IEEE Commun. Surv. Tutorials 2021 23 3 1578 1598 10.1109/COMST.2021.3073009 Tang, F., Mao, B., Kawamoto, Y. & Kato, N. Survey on machine learning for intelligent end-to-end communication toward 6G: from network access, routing to traffic control and streaming adaption. IEEE Commun. Surv. Tutorials 23 15. Avanzi, G. Design, Implementation and Evaluation of Learning Algorithms 16. Gronauer, S., Diepold, K., Tnani, M. A. & Zwick, M. Trend Reports about Artificial Intelligence for 6G telecommunication. (2022). 17. Gui G Zhou Z Wang J Liu F Sun J Machine learning aided air traffic flow analysis based on aviation big data IEEE Trans. Veh. Technol. 2020 69 5 4817 4826 10.1109/TVT.2020.2981959 Gui, G., Zhou, Z., Wang, J., Liu, F. & Sun, J. Machine learning aided air traffic flow analysis based on aviation big data. IEEE Trans. Veh. Technol. 69 18. Fowdur, T. P., Beeharry, Y., Hurbungs, V., Bassoo, V. & Ramnarain-Seetohul, V. Big data analytics with machine learning tools. Internet of things and big data analytics toward next-generation intelligence 19. Li, Y., Qiu, R. & Jing, S. Intrusion detection system using online sequence extreme learning machine (OS-ELM) in advanced metering infrastructure of smart grid. PloS One 13 10.1371/journal.pone.0192216 PMC5828363 29485990 20. Ahmed SH Smart cities Egypt. Inf. J. 2022 23 3 417 426 Ahmed, S. H. et al. Smart cities Egypt. Inf. J. 23 21. Siddiqui SY Khan MA Abbas S Khan F Smart occupancy detection for road traffic parking using deep extreme learning machine J. King Saud Univ.-Comput. Inform. Sci. 2022 34 3 727 733 10.1016/j.jksuci.2020.01.016 Siddiqui, S. Y., Khan, M. A., Abbas, S. & Khan, F. Smart occupancy detection for road traffic parking using deep extreme learning machine. J. King Saud Univ.-Comput. Inform. Sci. 34 22. Atta A Abbas S Khan MA Ahmed G Farooq U An adaptive approach: smart traffic congestion control system J. King Saud University-Computer Inform. Sci. 2020 32 9 1012 1019 10.1016/j.jksuci.2018.10.011 Atta, A., Abbas, S., Khan, M. A., Ahmed, G. & Farooq, U. An adaptive approach: smart traffic congestion control system. J. King Saud University-Computer Inform. Sci. 32 23. Zeng Y Gu H Wei W Guo Y $ Deep-Full-Range $: a deep learning based network encrypted traffic classification and intrusion detection framework IEEE Access. 2019 7 45182 45190 10.1109/ACCESS.2019.2908225 Zeng, Y., Gu, H., Wei, W. & Guo, Y. $ Deep-Full-Range $: a deep learning based network encrypted traffic classification and intrusion detection framework. IEEE Access. 7 24. Lim, H. K. et al. Packet-based network traffic classification using deep learning. In 2019 International Conference on Artificial Intelligence in Information and Communication (ICAIIC) 25. Zhang, F., Wang, Y. & Ye, M. Network traffic classification method based on improved capsule neural network. In 2018 14th International Conference on Computational Intelligence and Security (CIS) 26. Nallaperuma, D., Nawaratne, R., Bandaragoda, T., Adikari, A., Nguyen, S., Kempitiya,T., … Pothuhera, D. (2019). Online incremental machine learning platform for big data-driven smart traffic management. IEEE Transactions on Intelligent Transportation Systems, 20(12), 4679–4690. 27. Komisarek M Pawlicki M Kozik R Choras M Machine learning based approach to anomaly and cyberattack detection in streamed network traffic data J. Wirel. Mob. Networks Ubiquitous Comput. Dependable Appl. 2021 12 1 3 19 Komisarek, M., Pawlicki, M., Kozik, R. & Choras, M. Machine learning based approach to anomaly and cyberattack detection in streamed network traffic data. J. Wirel. Mob. Networks Ubiquitous Comput. Dependable Appl. 12 28. Bujlow, T., Riaz, T. & Pedersen, J. M. A method for classification of network traffic based on C5. 0 Machine Learning Algorithm. In 2012 international conference on computing, networking and communications (ICNC) 29. Shafiq, M. et al. Network traffic classification techniques and comparative analysis using machine learning algorithms. In 2016 2nd IEEE International Conference on Computer and Communications (ICCC) 30. Tahaei H Afifi F Asemi A Zaki F Anuar NB The rise of traffic classification in IoT networks: A survey J. Netw. Comput. Appl. 2020 154 102538 10.1016/j.jnca.2020.102538 Tahaei, H., Afifi, F., Asemi, A., Zaki, F. & Anuar, N. B. The rise of traffic classification in IoT networks: A survey. J. Netw. Comput. Appl. 154 31. Hasibi, R., Shokri, M. & Dehghan, M. Augmentation scheme for dealing with imbalanced network traffic classification using deep learning. arXiv preprint arXiv:1901.00204 32. Wang P Ye F Chen X Qian Y Datanet: deep learning based encrypted network traffic classification in Sdn home gateway IEEE Access. 2018 6 55380 55391 10.1109/ACCESS.2018.2872430 Wang, P., Ye, F., Chen, X. & Qian, Y. Datanet: deep learning based encrypted network traffic classification in Sdn home gateway. IEEE Access. 6 33. Wang, W., Zhu, M., Wang, J., Zeng, X. & Yang, Z. End-to-end encrypted traffic classification with one-dimensional convolution neural networks. In 2017 IEEE international conference on intelligence and security informatics (ISI) 34. Aceto, G., Ciuonzo, D., Montieri, A. & Pescapé, A. Mobile encrypted traffic classification using deep learning. In 2018 Network traffic measurement and analysis conference (TMA) 35. Zou, Z. et al. Encrypted traffic classification with a convolutional long short-term memory neural network. In 2018 IEEE 20th International Conference on High Performance Computing and Communications; IEEE 16th International Conference on Smart City; IEEE 4th International Conference on Data Science and Systems (HPCC/SmartCity/DSS) 36. Lotfollahi M Jafari Siavoshani M Zade SH Saberian M Deep packet: A novel approach for encrypted traffic classification using deep learning Soft. Comput. 2020 24 3 1999 2012 10.1007/s00500-019-04030-2 Lotfollahi, M., Jafari Siavoshani, M., Zade, S. H., Saberian, M. & R., & Deep packet: A novel approach for encrypted traffic classification using deep learning. Soft. Comput. 24 37. Chen M A network traffic classification model based on metric learning CMC-computers Mater. Continua 2020 64 2 941 959 10.32604/cmc.2020.09802 Chen, M. et al. A network traffic classification model based on metric learning. CMC-computers Mater. Continua 64 38. Gharib, A., Sharafaldin, I., Lashkari, A. H. & Ghorbani, A. A. An evaluation framework for intrusion detection dataset. In 2016 International conference on information science and security (ICISS) 39. Sharafaldin, I., Lashkari, A. H. & Ghorbani, A. A. Intrusion detection evaluation dataset (CIC-IDS2017). Proceedings of the of Canadian Institute for Cybersecurity 40. Zou Q Ni L Zhang T Wang Q Deep learning based feature selection for remote sensing scene classification IEEE Geosci. Remote Sens. Lett. 2015 12 11 2321 2325 10.1109/LGRS.2015.2475299 Zou, Q., Ni, L., Zhang, T. & Wang, Q. Deep learning based feature selection for remote sensing scene classification. IEEE Geosci. Remote Sens. Lett. 12 41. Shi H Li H Zhang D Cheng C Cao X An efficient feature generation approach based on deep learning and feature selection techniques for traffic classification Comput. Netw. 2018 132 81 98 10.1016/j.comnet.2018.01.007 Shi, H., Li, H., Zhang, D., Cheng, C. & Cao, X. An efficient feature generation approach based on deep learning and feature selection techniques for traffic classification. Comput. Netw. 132 42. Abid, A., Balin, M. F. & Zou, J. Concrete autoencoders for differentiable feature selection and reconstruction. arXiv preprint arXiv:1901.09346 43. Kushwah GS Ranga V Optimized extreme learning machine for detecting DDoS attacks in cloud computing Computers Secur. 2021 105 102260 10.1016/j.cose.2021.102260 Kushwah, G. S. & Ranga, V. Optimized extreme learning machine for detecting DDoS attacks in cloud computing. Computers Secur. 105 44. Salih AA Abdulazeez AM Evaluation of classification algorithms for intrusion detection system: A review J. Soft Comput. Data Min. 2021 2 1 31 40 Salih, A. A. & Abdulazeez, A. M. Evaluation of classification algorithms for intrusion detection system: A review. J. Soft Comput. Data Min. 2 ",
  "metadata": {
    "Title of this paper": "Evaluation of classification algorithms for intrusion detection system: A review",
    "Journal it was published in:": "Scientific Reports",
    "URL": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC12475121/"
  }
}