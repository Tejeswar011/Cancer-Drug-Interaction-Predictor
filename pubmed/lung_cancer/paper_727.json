{
  "title": "Paper_727",
  "abstract": "pmc Front Artif Intell Front Artif Intell 3981 frontai Front. Artif. Intell. Frontiers in Artificial Intelligence 2624-8212 Frontiers Media SA PMC12479492 PMC12479492.1 12479492 12479492 41036253 10.3389/frai.2025.1644084 1 Artificial Intelligence Methods Privacy-, linguistic-, and information-preserving synthesis of clinical documentation through generative agents van Velzen Mark  1  2  † van der Willigen Robert F.  1  3  4  *  † de Beer Vincent J.  1  3 de Graaf-Waar Helen I.  1  2 Janssen Esther R. C.  5  6  7 van Leeuwen Sjemaine  8 van der Willigen Micha F.  1  4 van der Willigen Martijn J.  1  3  4 Renardus Gavin  1  4 El Maaroufi Rayan  1  4 Satimin Sven J.  1  4 Hartog Larissa M.  1 Hulsen Tim  1  9 van Meeteren Nico L. U.  2  10 Scheper Mark C.  1  4  11  12 1 Data Supported Healthcare: Data-Science Unit, Research Center Innovations in Care, Rotterdam University of Applied Sciences Rotterdam Netherlands 2 Department of Anesthesiology and Department of Cariothoracic Surgery, Erasmus Medical Center Rotterdam Netherlands 3 HR Datalab EAS, School of Engineering and Applied Science, Rotterdam University of Applied Sciences Rotterdam Netherlands 4 School of Communication, Media and Information Technology, Rotterdam University of Applied Sciences Rotterdam Netherlands 5 Department of Orthopedic Surgery, VieCuri Medical Centre Venlo Netherlands 6 Radboud Institute for Health Sciences, IQ Health, Radboud University Medical Center Nijmegen Netherlands 7 School of Allied Health, HAN University of Applied Sciences Nijmegen Netherlands 8 Medifit Bewegingscentrum Oss Netherlands 9 Data Science & AI Engineering, Philips Eindhoven Netherlands 10 Top Sector Life Sciences and Health (Health~Holland) The Hague Netherlands 11 Allied Health Professions, Faculty of Medicine and Science, Macquarrie University Sydney, NSW Australia 12 Solid Start Coalition, Erasmus Medical Center Rotterdam Netherlands Edited by: Tuan D. Pham Reviewed by: Ricardo Valentim Mahesh Kumar Goyal *Correspondence: Robert F. van der Willigen, r.f.van.der.willigen@hr.nl † 16 9 2025 2025 8 481073 1644084 09 6 2025 25 8 2025 16 09 2025 01 10 2025 02 10 2025 Copyright © 2025 van Velzen, van der Willigen, de Beer, de Graaf-Waar, Janssen, van Leeuwen, van der Willigen, van der Willigen, Renardus, El Maaroufi, Satimin, Hartog, Hulsen, van Meeteren and Scheper. 2025 van Velzen, van der Willigen, de Beer, de Graaf-Waar, Janssen, van Leeuwen, van der Willigen, van der Willigen, Renardus, El Maaroufi, Satimin, Hartog, Hulsen, van Meeteren and Scheper https://creativecommons.org/licenses/by/4.0/ This is an open-access article distributed under the terms of the Creative Commons Attribution License (CC BY). The use, distribution or reproduction in other forums is permitted, provided the original author(s) and the copyright owner(s) are credited and that the original publication in this journal is cited, in accordance with accepted academic practice. No use, distribution or reproduction is permitted which does not comply with these terms. The widespread adoption of generative agents (GAs) is reshaping the healthcare landscape. Nonetheless, broad utilization is impeded by restricted access to high-quality, interoperable clinical documentation from electronic health records (EHRs) due to persistent legal, ethical, and technical barriers. Synthetic health data generation (SHDG), leveraging pre-trained large language models (LLMs) instantiated as GAs, could offer a practical solution by creating synthetic patient information that mimics genuine EHRs. The use of LLMs, however, is not without issues; significant concerns remain regarding privacy, potential bias propagation, the risk of generating inaccurate or misleading content, and the lack of transparency in how these models make decisions. We therefore propose a privacy-, linguistic-, and information-preserving SHDG protocol that employs multiple context-aware, role-specific GAs. Guided by targeted prompting and authentic EHRs—serving as structural and linguistic templates—role-specific GAs can, in principle, operate collaboratively through multi-turn interactions. We theorized that utilizing GAs in this fashion permits LLMs not only to produce synthetic EHRs that are accurate, consistent, and contextually appropriate, but also to expose the underlying decision-making process. To test this hypothesis, we developed a no-code GA-driven SHDG workflow as a proof of concept, which was implemented within a predefined, multi-layered data science infrastructure (DSI) stack—an integrated ensemble of software and hardware designed to support rapid prototyping and deployment. The DSI stack streamlines implementation for healthcare professionals, improving accessibility, usability, and cybersecurity. To deploy and validate GA-assisted workflows, we implemented a fully automated SHDG evaluation framework—co-developed with GenAI technology—which holistically compares the informational and linguistic features of synthetic, anonymized, and real EHRs at both the document and corpus levels. Our findings highlight that SHDG implemented through GAs offers a scalable, transparent, and reproducible methodology for unlocking the potential of clinical documentation to drive innovation, accelerate research, and advance the development of learning health systems. The source code, synthetic datasets, toolchains and prompts created for this study can be accessed at the GitHub repository: https://github.com/HR-DataLab-Healthcare/RESEARCH_SUPPORT/tree/main/PROJECTS/Generative_Agent_based_Data-Synthesis healthcare data synthesis privacy generative agents linguistics information theory synthetic health data generation (SHDG) clinical natural language processing (NLP) The author(s) declare that no financial support was received for the research and/or publication of this article. pmc-status-qastatus 0 pmc-status-live yes pmc-status-embargo no pmc-status-released yes pmc-prop-open-access yes pmc-prop-olf no pmc-prop-manuscript no pmc-prop-legally-suppressed no pmc-prop-has-pdf yes pmc-prop-has-supplement no pmc-prop-pdf-only no pmc-prop-suppress-copyright no pmc-prop-is-real-version no pmc-prop-is-scanned-article no pmc-prop-preprint no pmc-prop-in-epmc yes section-at-acceptance Medicine and Public Health 1 Introduction While the use of GenAI in healthcare offers substantial promise and is expected to become an integral part of regular clinical practice, its widespread adoption is limited by several critical challenges ( Sai et al., 2024 Mons et al., 2017 Busch et al., 2024 Woisetschläger et al., 2024 Ibrahim et al., 2025 Liu et al., 2025 Sai et al. (2024) Reddy (2024) Real-world data as recorded in EHRs consists primarily of free-text narratives that often contain valuable clinical insights that are not captured by structured data formats ( Negro-Calduch et al., 2021 Seinen et al., 2024 Murtaza et al., 2023 Ibrahim et al., 2025 Loni et al., 2025 Rujas et al., 2025 Negro-Calduch et al., 2021 Seinen et al., 2024 Schut et al., 2025 Murtaza et al., 2023 Ibrahim et al., 2025 Rujas et al., 2025 High quality synthetic health data generation (SHDG) that emulates real-world clinical documents is emerging as a vital strategy to enable safe, scalable, and privacy-preserving GenAI implementation in health and care settings ( Smolyak et al., 2024 Loni et al., 2025 Murtaza et al., 2023 Drechsler and Haensch, 2024 Ibrahim et al., 2025 Rujas et al., 2025 Ibrahim et al., 2025 Rujas et al., 2025 The growing promise and pitfalls of SHDG is best understood in the context of major breakthroughs in natural language processing (NLP) and GenAI, spanning early statistical approaches to today’s transformer-based language models. Synthetic data generation gained momentum in the early 1990s exemplified by Rubin’s ( Rubin, 1993 Little, 1993 Eigenschink et al., 2023 Murtaza et al., 2023 Drechsler and Haensch, 2024 Goyal and Mahmoud, 2024 Pezoulas et al., 2024 LeCun et al., 2015 Goodfellow et al., 2018 The use of Generative Adversarial Networks (GANs) has led to significant advances in data synthesis and can be classified as both deep learning and GenAI approaches. GANs rely on adversarial training, in which two deep neural networks—the generator and the discriminator—compete with one another until the discriminator can no longer distinguish between real and synthetic data, reaching equilibrium ( Goodfellow et al., 2018 Baowaly et al., 2019 Ibrahim et al., 2025 Ibrahim et al., 2025 The advent of transformer-based architectures revolutionized NLP by significantly enhancing language understanding ( Vaswani et al., 2017 Alsentzer et al., 2019 Lee et al., 2020 Bommasani et al., 2021 Ibrahim et al., 2025 Cannon and Lucci, 2010 Doan et al., 2014 Meystre et al., 2017 Negro-Calduch et al., 2021 Seinen et al., 2024 Schut et al., 2025 The evolution of transformer-based architectures culminated in the development of Large Language Models (LLMs) that are not only capable of language understanding—like BERT—but are also capable of language generation—like OpenAI’s GPT3—, called foundational models ( Bommasani et al., 2021 Kaplan et al., 2020 Coveney and Succi, 2025 Li et al., 2023 Sengupta et al., 2025 Brown et al., 2020 The rapid development of efficient, fine-tunable Small Language Models (SLMs) and multimodal SLMs is rapidly transforming healthcare. Unlike their bigger LLM counterparts SLMs can operate on-premises servers supporting local deployment, which significantly reduces costs, carbon footprint, and privacy concerns. These advances—as well as techniques like quantization, which reduce model size and accelerate inference time—are making it feasible to bring powerful language understanding and generation capabilities directly to the point of care, enabling clinical decision support, documentation, and patient interaction without reliance on high-end cloud infrastructure ( Schick and Schütze, 2021 Dibia et al., 2024 Garg et al., 2025 Kim et al., 2025 Xie et al., 2025 However, as GenAI becomes increasingly integrated into clinical workflows, it faces unique challenges specific to the medical domain. One of the most persistent and technically demanding issues is the precise segmentation and representation of multi-word clinical terms—such as “low blood pressure” or “low back pain” as well as their common abbreviations like “LBP.” Language models, including both LLMs and SLMs, often struggle to consistently recognize and encode such terms as unified clinical concepts. Inconsistent tokenization or lack of domain-specific context can lead to fragmented or distorted semantic representations, which in turn may compromise the accuracy of clinical information extraction, decision support, or narrative synthesis. This underscores the ongoing need for the development of more sophisticated prompting strategies tailored for healthcare, and the integration of concept embeddings, clinical practice guidelines, and real-world sample data to improve the realism and utility of synthetic clinical data ( Beam et al., 2020 Chung et al., 2023 Han et al., 2023 Li et al., 2023 2 GA-assisted SHDG workflows To overcome the challenges of semantic fragmentation and context loss, recent research has shifted toward collaborative, multi-agent workflows to jointly tackle the complexity of clinical narratives and multimodal data. This new class of GenAI—known as Agentic AI or Generative Agents (GAs)—features multiple autonomous agents, each specializing in a particular task or sensory domain such as vision, language, audio, or touch ( Chan et al., 2023 Park et al., 2023 Qiu et al., 2024 Gridach et al., 2025 Hettiarachchi, 2025 Piccialli et al., 2025 Schneider, 2025 Unlike traditional GenAI, GAs can gather real-time data from various sources, use different tools, design custom workflows, and refine their strategies through feedback, making them highly flexible and context aware. This collaborative approach allows specialized agents to solve complex tasks—such as SHDG—within a single workflow ( Qiu et al., 2024 Daull et al., 2023 Barrault et al., 2024 Xie et al., 2024 Jin et al., 2025 Building on this flexible and context-aware foundation, role-specific GAs are able to distribute cognitive workloads and leverage the strengths of multiple specialized agents within a single workflow ( Xie et al., 2024 Jin et al., 2025 Abdurahman et al., 2025 Vasireddy et al., 2024 Ohse et al., 2024 Yang et al., 2025 Thandla et al., 2024 Low-code/no-code LLM platforms, such as Flowise, 1 2 3 Kumar, 2023 Jeong, 2025 Karpathy (2025) Karpathy, 2025 Mayo, 2025 In what follows, we present a protocolized GA-driven proof-of-concept for SHDG use cases aimed at creating novel synthetic clinical documents that emulate genuine EHRs while safeguarding patient privacy, preserving linguistic integrity, and maintaining informational accuracy under conditions of limited access to authentic EHR datasets. 3 Materials and methods The protocol described here aims to expand the responsible use and deployment of GenAI healthcare solutions to a broad spectrum of end-users—including those without specialized AI expertise—by providing clear, step-by-step guidance for designing workflows that leverage GAs for SHDG. To further support open-source adoption, reproducibility and practical application of our GA-assisted SHDG workflows we provide a GitHub repository. 4 At the heart of our methodology is a modular data science infrastructure (DSI) Stack ( Figure 1A 5 Figure 1 Data science infrastructure (DSI) stack. (A) https://www.designcouncil.org.uk/our-resources/the-double-diamond/ (B) Diagram comparing data science and data engineering roles. Panel A shows stages from warehousing to deployment, divided into data science and engineering tasks. Data science involves deployment, feature engineering, and model development. Data engineering includes warehousing, compute, and toolchain tasks. Coding infrastructure is central. Data science focuses on doing things right, while data engineering focuses on doing the right things. Panel B contrasts human-oriented data scientists with machine-oriented data engineers, emphasizing their differing involvement levels. 3.1 Data science infrastructure stack Synthesizing and validating EHRs requires a well-defined data science infrastructure. This involves designing a robust data pipeline, a systematic sequence of processes that transforms raw data into high-quality synthetic datasets and generates actionable insights ( Meng, 2021 Tuulos, 2022 Building a pipeline requires the seamless integration of diverse hardware and software components within a pre-defined DSI stack. In this architecture, each layer—from data ingestion to deployment—builds upon the previous one, creating a cohesive framework. This layered approach streamlines the transformation of real-world EHR samples and clinical practice guidelines into novel, synthesized datasets. By following this structured process, patient privacy and regulatory compliance are maintained, enabling the safe and effective use of synthetic data for research, analytics, and clinical decision support ( Priebe et al., 2021 Tuulos, 2022 Hechler et al., 2023 Our DSI stack—as depicted in Figure 1 Krishnakumar et al., 2023 Kochanowska et al., 2022 “Doing the right things,” “Doing things right.” 3.1.1 Pseudonymization Integrating real-world sample data into the synthesization process enhances the diversity of synthetic data, thereby improving its linguistic quality and informational characteristics to better reflect real-world EHR narratives ( Chung et al., 2023 Pseudonymization served as an essential data pre-processing step prior to warehousing (Section 3.1.2). This involved replacing the names of referring physicians and treating physiotherapists with fictive names, thereby restoring the natural structure of the EHRs. This procedure ensured that sample datasets destined for warehousing were thoroughly de-identified in accordance with Dutch and broader European privacy and regulatory standards. To achieve this, we developed a GenAI-based Named Entity Recognition (NER) workflow, customized for privacy categories, to systematically identify and replace personal identifiers in Markdown files derived from EHR sample PDF documents. Data entry fields for entities such as names, addresses, contact details, birth dates, “burgerservicenummers” (BSNs), insurance details, and financial data were detected and either removed or pseudonymized in compliance with privacy guidelines. A Jupyter notebook executed custom Python code [GitHub Repository (see text footnote 4): FLOW01] to configure the Azure OpenAI API SDK; submit each document to Azure OpenAI’s GPT-4.1; and apply a tailored system prompt to both identify and pseudonymize specified entities while preserving the Markdown format. Processed files were stored with their original formatting intact for subsequent analysis. 3.1.2 Warehousing Data warehousing serves as the foundational layer of the DSI stack, providing centralized aggregation and accessibility for static, unstructured datasets. It is crucial for storing both the generated synthetic data (output for developing and testing solutions) and the real-world sample data and clinical practice guidelines (as input knowledge bases for the synthesis process). Besides, the integration of anonymized real-world data from EHR systems, the inclusion of codebooks for labels and abbreviations, and clinical practice guidelines into data warehouses limits chance of hallucination but enhances the diversity, linguistic quality, and therefore the clinical relevance of synthetic data ( Chung et al., 2023 Li et al., 2023 Storing data in accessible formats such as markdown (MD), structured query language (SQL), comma-separated values (CSV), portable document format (PDF), JavaScript object notation (JSON), or images is integral to facilitating interoperability and data sharing within clinical environments. These widely used formats support the storage and exchange of both structured and unstructured data, making it easier for diverse health information systems to work together ( Hart et al., 2016 3.1.3 Compute The next DSI stack layer is compute, which refers to scalable data processing capacity or computational power. Its purpose is to manage and scale the performance of a predefined set of computational instructions—referred to as a computational workload or task. The type of data science use case dictates its compute requirements, including the need for CPUs, GPUs, TPUs, or internal memory. To assist the targeted end-users—non-AI specialists—, we decided to employ a hybrid compute solution, combining standard desktop computers or laptops (local computing) with powerful external computing resources available over the internet (public cloud services like Azure, AWS, or Google Cloud). The latter is essential for utilizing state-of-the-art LLMs. These models require specialized high-performance computing hardware and massive computational resources that far exceed the capabilities of standard desktops or laptops. Public cloud enables scalable LLM deployment with on-demand access to high-end GPUs/TPUs, large memory, and parallel computing, surpassing local infrastructure limits. Since state-of-the-art LLMs are only accessible via cloud-based APIs ( Table 1 Table 1 Key evaluation criteria for selecting LLMs. Consideration Explanation Importance for model selection Model architecture The underlying design of the model (e.g., transformer-based, LSTM, etc.). Influences model capabilities, efficiency, and suitability for specific NLP tasks. Model size & parameters Number of parameters indicating model complexity and capacity Larger models often perform better but require more computational resources; balance needed based on use case. Inference speed & latency Time taken to generate outputs during use. Critical for real-time applications and user experience; faster models enable scalable deployment. Performance metric scores Quantitative measures like accuracy, perplexity, BLEU, ROUGE on relevant benchmarks. Helps objectively compare models’ language understanding and generation quality. Context window size Maximum input length (tokens) the model can process at once. Larger context windows allow handling longer documents or conversations without losing coherence. Fine-tuning & customizability Ability to adapt the model to specific domains or tasks via additional training. Enables tailoring model behavior to unique organizational needs and improves task-specific performance. Pretraining data & knowledge cutoff The scope and recency of data the model was trained on. Determines how current and relevant the model’s knowledge is. Multimodal capabilities Support for inputs beyond text, such as images or video. Expands potential applications, enabling richer interactions and cross-modal understanding. Use case alignment Suitability of the model’s strengths to the specific application or domain. Ensures optimal performance and ROI by matching model capabilities with business goals. Safety, bias & ethical considerations Mechanisms to reduce harmful, biased, or inappropriate outputs. Ensures responsible AI use, compliance with regulations, and trustworthiness. Licensing & accessibility Terms of use, availability (open source vs. proprietary), and cost implications. Affects budget, deployment flexibility, and compliance with organizational policies. Ecosystem & integration Availability of APIs, developer tools, and compatibility with existing systems. Facilitates easier implementation, faster development cycles, and operational efficiency. Enterprise readiness Support for scalability, data privacy, user data control, and cloud provider support. Important for secure, compliant, and robust deployment in production environments. Listed are essential considerations—including usability, ethical implications, and enterprise requirements—compiled together to assist non-AI specialists in selecting an LLM that aligns with their specific needs. The selected criteria are based on a synthesis of recent expert analyses and practitioner frameworks. 3.1.4 Toolchain The toolchain layer ensures the correct functioning of the desired workflow orchestration. Our protocol leverages rapid prototyping platforms to synthesize and validate EHRs using state-of-the-art GA-assisted SHDG workflows. These platforms offer an intuitive drag-and-drop user interface, simplifying implementation by eliminating the need for data engineering expertise in LLM deployment. This makes GenAI-technology more accessible for non-AI specialists by facilitating browser-based access ( Kumar, 2023 Jeong, 2025 We implemented a Docker-based 6 Abhishek and Rao, 2021 Ait et al., 2025 Fu et al., 2025 Gupta, 2025 Hugging Face Spaces 7 Kumar, 2023 Jeong, 2025 8 The usefulness of Open-source LLMs like LLaMA, Qwen, DeepSeek, and Phi in clinical settings is hampered by the frequent production of unsupported facts, contradictions, and omissions—collectively known as hallucinations—which present a substantial safety risk. Evaluation of the MIMIC-IV dataset revealed that while these models can accurately capture up to 83% of admission reasons and key events, their performance dropped dramatically for critical follow-up recommendations, with comprehensive coverage as low as 29% ( Das et al., 2025 Considering both the above outlined limitations and the selection criteria presented in Table 1 OpenAI, 2025 Table 1 QuantSpark, 2023 Inoue, 2024 Ruczynski, 2024 Chojnacki, 2025 Morris et al., 2025 In addition, GPT-4.1 incorporates advanced domain adaptation, sophisticated fact-checking mechanisms, and alignment strategies to reduce hallucination rates and enhance faithful adherence to source texts. Here, “Advanced domain adaptation” Singhal et al., 2023 Walturn, 2025 3.1.5 Workflow orchestration To synthesize Dutch clinical narratives related to low back pain in physiotherapy using genuine EHRs, we developed a GA-assisted, no-code workflow built on a rapid prototyping platform that allows end users to quickly construct and test GenAI solutions ( Figure 2 Figure 2 Visual representation of a no-code, multi-agent workflow for synthesizing EHRs. Data flows through connected tools and agents, enabling an iterative, structured generation process without manual coding. The here shown GA-assisted SHDG workflow begins with a Recursive Character Text Splitter that divides the uploaded PDF file containing anonymized EHR data into manageable chunks. These chunks are processed using Azure OpenAI Embeddings and stored in an In-Memory Vector Store. A Retriever Tool (RAG) then queries the stored embeddings to provide relevant context. The Azure ChatOpenAI component, configured with the GPT-4.0-mini model, interacts with stored agent memory (SQLite Agent Memory) and coordinates with two agents: the Supervisor—acting as a senior physiotherapist specialized in low back pain—who manages task instructions and workflow control, and directs the Tech Researcher—acting as a practicing physiotherapist (general or specialized—who executes prompts to generate synthetic Dutch-language EHR notes). Note: The workflow—accessed via a web interface—maintains contextual memory across user queries for seamless, multi-turn interactions and stops automatically when the supervisor determines completion. This design enables rapid prototyping of SHDG solutions by healthcare researchers and practitioners without requiring advanced expertise in AI. For more information on the adopted technologies and their implementation, see the Toolchain Section (Section 3.1.4 of the DSI stack). No-code multi-agent EHR synthesizing workflow diagram showing interconnected modules. Key components include Recursive Character Text Splitter, Pdf File input, In-Memory Vector Store, Retriever Tool, Azure OpenAI Embeddings, Azure ChatOpenAI, SQLite Agent Memory, Supervisor, and Worker. Each module has specific input and output parameters, facilitating the processing and synthesis of electronic health record data. Central to our approach is a multi-agent architecture ( Figure 3 Chen et al., 2025a Figure 3 Example of a single-turn input/output interaction when applying the multi-agent workflow for generating realistic, structured EHRs, as described in Figure 2 Color coding: Graphic displaying a structured layout for creating realistic physiotherapeutic patient files in Dutch, addressing low back pain. It includes sections on anamnesis, diagnosis following ICF, SMART therapeutic goals, and treatment plans. Text boxes offer guidelines for language use, workflow examples, and specify that 20 unique patient files are to be generated. The graphic is divided into roles: End-user, supervisor, and tech researcher, with a patient dossier example detailed. A status box at the bottom-right corner indicates \"status: FINISHED.\" 3.1.5.1 Supervisor agent prompt The supervisor agent was equipped with a “system prompt” World Health Organization, 2001 Swart et al., 2021 The prompt further instructed the supervisor agent to restrict outputs solely to the requested EHR content, thereby enforcing compliance and preventing the inclusion of extraneous or sensitive information. Functionally, it mandated the supervisor agent to orchestrate the division of labor among worker agents, manage task handoff, establish execution priorities, consolidate contributions, and verify completion of all record elements in accordance with professional documentation standards. 3.1.5.2 Worker agent prompt Under the coordination of the supervisor agent, each worker agent received individualized “worker prompts” tailored to its specialized domain within the workflow. These prompts offered detailed, task-specific instructions for generating a single EHR taking into account the clinical nuances of physiotherapy care for (sub)acute or chronic low back pain, as well as relevant and documentation standards ( Driehuis et al., 2019 Swart et al., 2021 Table 2 Table 2 Targeted worker agent prompting. Consideration Explanation Anamnesis summary Craft a concise, professional account of the patient’s medical history, the impact of symptoms, coping mechanisms, and clinical context; ensure precise specification of symptom duration (acute, subacute, or chronic) and maintain professional standards of written Dutch. Physical therapy diagnosis Deliver a comprehensive, multidimensional diagnostic formulation, detailing impairments, activity limitations, participation restrictions, relevant contextual (personal and environmental) factors, risk/prognostic indicators, and a reformulation of the patient’s explicit help seeking question—all mapped to ICF domains. Treatment goals Articulate SMART (Specific, Measurable, Achievable, Relevant, Time-bound), patient-centered, and function-oriented short- and long-term goals, with reference to clinical metrics (e.g., NPRS, QLBDS) strictly as criteria, not as goals themselves. Target dates for each goal are specified according to best practice. Treatment plan Compose an intervention strategy, incorporating manual therapy, exercise programs, educational components, psychosomatic physiotherapy and other modalities, substantiated by the KNGF guidelines and explicitly related to the established treatment goals. SOEP progress notes Generate between three and eight detailed progress notes, each corresponding to an individual treatment session, structured in the SOEP (Subjective, Objective, Evaluation, Plan) format. These notes are intended to reflect realistic clinical variation, including both therapeutic progression and stagnation or need for adjustment. Language and style All documentation must be rendered in idiomatic, professional Dutch with expanded abbreviations (e.g., MT, NPRS, LBP), and maintain a narrative and tone that emulates authentic Dutch physiotherapy records as demonstrated in the reference examples. Referencing examples and output format Worker Agents are instructed to use pseudonymized sample EHRs solely as a stylistic and structural reference, ensuring every generated dossier remains unique. Detailed are the specific domains addressed by the worker agent, along with corresponding explanations, to guide the synthesis of clinically valid and contextually appropriate physiotherapy records for low back pain. 3.1.6 Software architecture and deployment Data product deployment is the final layer of our DSI stack, where prototype workflows transform into web-accessible applications. This layer ensures that data products—such as LLM GPT-4.1 and Hugging Face Spaces—are securely and reliably made available through Inference Endpoints secured with API key authorization (as was discussed in the Toolchain Section 3.1.4). This also protects patient privacy and complies with data management and regulatory standards, including the GDPR 9 10 Haug, 2018 Hoofnagle et al., 2019 European Parliament and Council, 2024 3.2 No-code proof-of-concept This section details a rapid-prototyping implementation to demonstrate the feasibility and effectiveness of generating synthetic EHRs using GA-assisted SHDG workflows ( Figures 2 3 Here, we outline the specific tools and configurations used, illustrating how the DSI stack layers translate a specific data science use case into a functional workflow. The protocol presented here serves as a practical step-by-step guide for replicating our approach and showcases the capabilities of the proposed architecture in addressing the challenges of clinical text synthesis. For demonstrative purposes, we utilized public Hugging Face Spaces infrastructure in combination with Flowise to facilitate deployment (see Section 3.1.4). This setup allows custom-made workflows to be shared publicly or privately, making them accessible via a web interface or API, and supports secure credential management for connecting to external LLMs and API services. The workflow ( Figure 2 Table 3 Figure 3 Günther et al., 2024 Table 3 Workflow stages, modules, and operational details for no-code GA-assisted synthetic EHR processing. Workflow stage Module Operational details Ingestion and preprocessing parsing A/B recursive character text splitter Function: Input: Output: PDF File Function: Input: Output: In-memoryvector store Function: Input: Output: Retriever tool Function: Input: Output: Embeddings Azure OpenAI embeddings Function: Input: Output: Agent memory management SQLite agent memory Function: Input: Output: Agent orchestration of multi-turn interactions Supervisor Function: Input: Output: Worker Function: Input: Output: User interaction and language model reasoning Azure ChatOpenAI Function: Input: Output: We employed GPT-4.1 LLMs—using Azure API key credentials—for supervised reasoning and text generation. A key model parameter for any LLM is temperature, which controls generative diversity: lower values (~0.2–0.4) yield deterministic, guideline-conform output, while higher values (~0.7–0.9) promote creative variability ( Peeperkorn et al., 2024 “agentflow” The supervisor agent represents an experienced physiotherapist who ensures that documentation conforms to ICF domains, linguistic plausibility, and overall fidelity ( Figure 3 Figure 3 Chung et al., 2023 Li et al., 2023 3.3 SHDG automation through GenAI-assisted co-development Here we describe how we automatized the entire synthetic EHR pipeline; using a novel engineering approach called: GenAI-assisted co-development. This technique fosters collaboration between human developers and GAs ( Park et al., 2023 Orru et al., 2023 Ulfsnes et al., 2024 Casper et al., 2025 Mayo, 2025 For instance, GAs like AlphaEvolve ( DeepMind, 2025 Novikov et al., 2025 3.3.1 GA-assisted SHDG workflow validation We started by confirming that our GA-assisted SHDG workflow (Section 3.2) was effective in generating meaningful synthetic EHRs. This preliminary validation step involved human specialists (authors MV, MS) assessing the synthetic EHR samples for realism, internal coherence, and adherence to professional clinical documentation standards. We confirmed that the generated records were representative for deployment in downstream healthcare applications and research. 3.3.2 PDF-to-Markdown conversion As a foundational step, we used Gemini 2.5 Flash as the core LLM in our GenAI-Assisted Software Development workflow to generate and refine Python code—contained in Jupyter notebooks—for automating PDF-to-Markdown conversion. Guided by natural language prompts written by human domain experts, Gemini 2.5 Flash authored code that extracts text from PDFs (via Python packages such as OpenAI, PyMuPDF, and glob), interfaces with Azure OpenAI’s GPT-4.1 for Markdown formatting, and supports batch processing of files. This collaborative approach enabled efficient, maintainable code development, combining Gemini 2.5 Flash’s reasoning and coding abilities with GPT-4.1’s language understanding to deliver scalable and accurate document conversion. Note, Human supervision— following a human-in-the-loop approach, in which humans remain actively involved in reviewing, verifying, and refining AI outputs—was essential to ensure that the AI-generated code functioned correctly. The code used is available online via our GitHub Repository (see text footnote 1) (FLOW01). 3.3.3 Pseudonymization We prompted Gemini 2.5 Flash to integrate a pseudonymization step using a second call. This involved a second call to the Azure OpenAI GPT-4.1 API with a tailored system prompt designed to identify and pseudonymize specified named entities while preserving the Markdown format. For details about the selected named entities, we refer to Section 3.1.1. The code used is available online via our GitHub Repository (see text footnote 1) (FLOW02). 3.3.4 EHR-synthesis co-developed with GenAI technology Subsequently, we instructed Gemini 2.5 Flash to generate Python code that implements the synthetic data generation process. This process used the pseudonymized Markdown files as contextual examples for GPT-4.1, guided by the natural language prompts previously specified for the supervisor agent and worker agents (see Section 3.1.5). A comprehensive explanation of the code is provided, and it is publicly available as a downloadable Jupyter notebook from our GitHub Repository (see text footnote 1) (FLOW03). 3.3.5 Benchmark framework & analysis Finally, Gemini 2.5 Flash was tasked with developing a programmatic approach to assess how closely synthetic data mirrors the informational and linguistic characteristics of pseudonymized real-world EHRs. This assessment strictly adheres to an evaluation framework comprising ten distinct metrics, as detailed in the next Section 3.4, to evaluate the indistinguishability of synthetic from real data. The code used is available online via our GitHub Repository (see text footnote 1) (FLOW04). 3.4 Quantitative assessment of synthetic data quality To systematically assess the fidelity of GA-assisted SHDG, we recognized that no single metric would suffice. Therefore, we selected ten distinct metrics to jointly evaluate both the informational and linguistic qualities of clinical documents on both the individual document and corpus levels. These metrics, summarized in Tables 4 5 Table 4 Metrics used to evaluate surface-level similarities. Metric Category Purpose Interpretation (desired score) Interpretation (undesired score) Average word count Structural fidelity Compares word count per document between datasets. Similar average word counts between synthetic and real data. Consistent divergence (higher/lower) in average word count, suggesting content over/under-generation. Average unique word count Linguistic Compares the diversity of vocabulary per document. Similar average unique word counts, indicating comparable linguistic richness. Significant differences, suggesting issues with vocabulary diversity. Average document length (characters) Structural fidelity Compares overall document size in characters. Similar average document lengths between synthetic and real data. Consistent divergence (higher/lower) in average document length, suggesting content over/under-generation. Structural and linguistic metrics for evaluating similarities between original, pseudonymized, and synthetic documents, with interpretation guidelines for desirable and undesirable results. Table 5 Metrics used to evaluate linguistic and information level similarities. Metric Category Purpose Interpretation (desired score) Interpretation (undesired score) Shannon’s entropy (characters) Textual diversity Quantifies richness and unpredictability at character level for the entire corpus. Similar entropy values to real data. Much lower entropy (overly repetitive) or much higher entropy (excessively random/incoherent). Shannon’s entropy (words) Textual diversity Quantifies richness and unpredictability at word level for the entire corpus. Similar entropy values to real data, indicating comparable vocabulary diversity. Much lower entropy (overly repetitive vocabulary) or much higher entropy (excessively random/incoherent word choice). Jensen-Shannon divergence Word distribution similarity Measures the statistical distance between word probability distributions of two corpora (range 0–1). Low JSD (closer to 0), implying similar word frequency patterns and vocabulary overlap. High JSD (closer to 1), indicating marked differences in vocabulary or word usage patterns. Average Bigram Pointwise Mutual Information(PMI) Naturalness of word associations Quantifies the average strength of association between adjacent words. Comparable PMI, indicates synthetic text mimics natural bigram. Significant differences, suggesting unnatural word pairings or phrasings. BLEU score Lexical similarity / surface-level overlap Quantifies n-gram overlap between synthetic and reference texts (range 0–100). Higher BLEU score (closer to 100), indicating greater literal overlap in n-grams. Lower BLEU score (e.g., 4.6), indicating very low literal overlap; suggests synthetic text does not closely replicate exact phrasing, potentially acceptable if novelty is a goal. BERTScore Semantic alignment Assesses semantic similarity using contextual embeddings (F1 typically 0–1). High F1 score (closer to 1), indicating strong semantic alignment and meaning preservation. Lower scores suggest synthetic data differs from the sample data. This indicates the newly generated data is not an exact replica of its origin Classifier performance (AUC)/(AUPRC) Inseparability Tests how easily a classifier can distinguish real (pseudonymized) from synthetic data. AUC/AUPRC approaches 0.5, implying classifier cannot effectively differentiate (high mimicry). AUC/AUPRC ≈ 1.0: Classifier easily separates classes; unrealistic synthetic data. Metrics assessing overall similarity between real and synthetic clinical text corpora—including diversity, vocabulary, semantic alignment, and machine discernibility—emphasizing that desired scores reflect close corpus-level resemblance across these dimensions. Our framework goes beyond surface-level resemblance—such as basic structure—by also examining deeper linguistic and semantic properties. Specifically, we evaluate whether synthetic texts authentically mirror genuine EHRs in their phrasing, stylistic features, and conveyed meanings. To ensure this, we analyzed pooled corpora of pseudonymized real and synthetic data ( Table 5 Detailed implementation notes, equations and code for each metric are available in our public GitHub Repository (see text footnote 1) (FLOW04). 3.4.1 Document level assessment Three different metrics —the original clinical documents, their pseudonymized counterparts, and synthetic documents generated through the GA-assisted SHDG process—were used to provide insight into the structural fidelity of the generated documents, ensuring that basic textual characteristics were faithfully reproduced in the synthetic samples. Assessment of averaged word count, average unique word count, and average document length (measured in characters) provided a straightforward means for comparing the overall size and composition of documents between the original, pseudonymized, and synthetic datasets. Table 4 Collectively, the document-level metrics of Table 4 3.4.2 Corpus level assessment The inherent heterogeneity in EHRs—stemming from both the variety in patients and the diversity in documentation by healthcare professionals—can greatly impact comparability between real and synthetic data. Furthermore, as the aim of synthetic data is often to generate more data than is originally available (thus overcoming limited data availability), metrics other than pairwise comparison of individual documents are needed to evaluate the linguistic and informational similarities between datasets. To assess the actual comparability between the real pseudonymized and the synthetic clinical text, we pooled the individual documents into two corpora. Table 5 3.5 Sample dataset description The original dataset comprised N = 13 EHRs in PDF format, all relating to Dutch patients suffering from lower back pain. These real-world documents featured a combination of structured and unstructured text, including clinical notes, reports, and other pertinent patient information. To characterize these EHRs in terms of linguistic quality and informational content, a custom Python script was developed through GenAI-assisted co-development (see Section 3.3 for a detailed description). For each file, various parameters were extracted and calculated, including storage size textual content size Structural elements Shannon entropy canonical Jensen-Shannon Divergence (JSD) average pointwise mutual information (PMI) van der Willigen et al. (2024) 4 Results We start by reporting on a document-level assessment (Section 4.1), examining whether the generated data are contextually and semantically consistent with real EHRs. This is followed by a corpus-level assessment (Section 4.2) to assess whether our GA-assisted SHDG protocol adhered to established clinical data standards and preserved the statistical properties of the sample dataset (for details, see Section 3.5). 4.1 Document level assessment The first 4 rows of Figure 4 Figure 4 Document level assessment using a holistic benchmark framework for quantitative evaluation of synthetic data quality (see Table 4 (A) N (B) N (C) N Violin plots comparing various metrics across three datasets: Real-World PDF, Pseudonymized Markdown, and Synthetic Markdown. Metrics shown are size in megabytes, word count, unique words, document length in characters, character entropy, word entropy, average pointwise mutual information, and Jensen-Shannon divergence distance. Each metric is color-coded and the plots illustrate distributions with density and outlier points. When converting the original, real-world sample data from PDF to pseudonymised Markdown format, file sizes dropped noticeably. This is because PDF files retain a large amount of information—including embedded fonts, images, and detailed layout instructions—to ensure consistent appearance across devices. In contrast, Markdown files contain only the essential textual content and minimal formatting information, omitting media and complex layout data, which makes them much more compact (first row, Figure 4 Figure 4 The overall structure of the synthetic data differed substantially from the pseudonymized data: on average, synthetic clinical notes were approximately 30% shorter in length (9,412 vs. 13,370). This reduction suggests that synthetic documents contained significantly less content per record, potentially omitting important clinical details or context. While real-world EHRs often include duplicate or redundant information ( Nijor et al., 2022 Steinkamp et al., 2022 At the per-document level, the mean bigram PMI was also slightly lower for synthetic documents (6.26) compared to pseudonymized documents (6.40); however, this difference was not statistically significant (Mann–Whitney U = 161.00, p 4.2 Corpus level assessment We compared our synthetic clinical text to the real-world, pseudonymized clinical notes at corpus level (Section 4.2) using informational and linguistic measures, including Shannon’s Entropy and average bigram PMI. The results are shown in Table 6 Table 6 Corpus level assessment: pseudonymized (Pseudo) versus synthetic (Synth) text corpora. Metric interpretation Pseudo mean Synth mean Mann-whitney U (U-stat) p Textual diversity metrics Corpus shannon entropy (character) Pseudo > Synth character diversity 4.8565 4.6936 — — Corpus shannon entropy (word) Synth > Pseudo word diversity 9.3543 9.9799 — — Mean per-document shannon entropy (character) Pseudo > Synth, significant difference 4.8449 4.6846 U = 260.00 p Mean per-document shannon entropy (word) Synth > Pseudo, significant difference 8.3075 8.6939 U = 0.00 p Distributional differences JSD (word dist. between corpora) Moderate divergence — 0.3770 — — Mean Per-Doc JSD (word-level) Synth more divergent, significant difference 0.2297 0.2618 U = 12.00 p Linguistic associations Corpus average bigram PMI (min freq=3) Pseudo > Synth word pair associations 6.9187 5.9833 — — Mean per-document bigram PMI Not statistically significant 6.4007 6.2604 U = 161.00 P Document structure Average document length (characters) Pseudonymized docs much longer 13,370.15 9,412.25 — — Surface & Semantic similarity BLEU score (synthetic vs. pseudonymized) Very low n-gram overlap, low surface similarity — 4.6179 — — BERTScore (synthetic vs. pseudonymized) Moderate similarity — 0.6447 — — Classification metrics Precision Semantic/textual discrimination — 0.6556 — — Recall pseudonymized—F1 Similarity measure — 0.6499 — — Classifier AUC (pseudo vs. synthetic) Perfectly distinguishes lower = better for synthetic — 1.0000 — — Classifier AUPRC (pseudo vs. synthetic) Perfectly distinguishes (lower = better for synthetic) — 1.0000 — — Evaluation metrics used—see Table 5, for detailed description—are character and word diversity (Shannon entropy), distributional differences (JSD), linguistic associations (Average Bigram PMI), document length, surface and semantic similarity (BLEU and BERTScore), and the ability of machine learning classifiers to distinguish the two types of documents (AUC and AUPRC). Note, the Mann–Whitney U-test—reporting both statistic and p-value—is used to determine whether observed differences between the corpora are statistically significant. This non-parametric test was chosen because it does not assume a normal distribution, making it suitable for text-derived metrics that often violate this assumption, and thereby provides a robust evaluation of whether differences reflect meaningful distinctions rather than random variation. The corpus-level Shannon entropy quantifies the diversity and unpredictability of character and word usage within a corpus. For character-level entropy, the pseudonymized corpus (4.8565) exhibited a higher value than the synthetic corpus (4.6936), indicating that texts in the pseudonymized set utilize a greater variety of characters or employ characters in a less predictable manner. This suggests that the process of synthetically generating text may introduce constraints or redundancies at the character level, resulting in reduced diversity. Conversely, word-level corpus entropy was higher in the synthetic corpus (9.9799) compared to the pseudonymized corpus (9.3543). This reflects a broader or less predictable word usage in the synthetic data, potentially attributable to the generative process introducing new combinations of words or emphasizing novelty. Thus, while synthetic data appears to be less varied at the character level, it is more varied at the word level than the original pseudonymized corpus. Beyond overall corpus-level entropy, per-document analysis further clarifies differences in diversity and distribution between the pseudonymized and synthetic corpora. Mean per-document Shannon entropy at the character level was higher for the pseudonymized documents (4.8449) than for synthetic ones (4.6846), and this difference was statistically significant (Mann–Whitney U = 260.00, p Moreover, mean per-document Shannon entropy at the word level was significantly higher for synthetic documents (8.6939) than for pseudonymized ones (8.3075) (Mann–Whitney U = 0.00, p For Average Bigram PMI, which quantifies the strength of association between word pairs by measuring how much more likely two words are to occur together than would be expected by chance, we observed that the synthetic corpus exhibited weaker word pair associations compared to the pseudonymized corpus. Specifically, the corpus-average bigram PMI was lower in the synthetic data (5.98) than in the pseudonymized data (6.92). This indicates that bigrams in synthetic texts are less strongly associated, or less conventional, than those present in the real-world clinical narratives. This finding likely reflects the inherent repetitiveness and predictability of authentic EHRs, in which common phraseology and co-occurring terms are documented repeatedly, thereby increasing the frequency and association strength of certain word pairs. In contrast, synthetically generated texts may introduce more varied or less natural co-occurrences, leading to overall weaker bigram associations. In contrast to Shannon’s Entropy and average bigram PMI, metrics such as JSD, BLEU score, BERTScore, and classifier performance directly provide a comparative value as output ( Table 6 The mean per-document Jensen-Shannon divergence (JSD) of word distributions relative to the combined corpus is higher in synthetic documents (0.2618) than in pseudonymized ones (0.2297), a statistically significant difference (Mann–Whitney U = 12.00, p In surface-level text analysis, an n-gram n Semantic similarity, as assessed by BERTScore, was moderate, with an F1 score of approximately 0.65 (precision: 0.64, recall: 0.66). Thus, although the synthetic data exhibits low surface-level overlap and increased lexical diversity compared to authentic EHR notes, it nonetheless preserves a substantial portion of the underlying clinical meaning and topical content. Such moderation in semantic overlap tells us that the sentences and phrases in the synthetic data are not directly copied or closely matched, word-for-word, with those in the original clinical records (authentic EHR notes). When we look at common sequences of words (n-grams), there is very little overlap between the two sets—meaning the synthetic data displays different combinations of words and sentences, rather than repeating those found in the real notes. In our use case of synthesizing clinical narratives, very high F1, precision, and recall measures would indicate exact copies of original data, whereas our aim was to increase textual diversity by adding real-world samples and clinical practice guidelines as knowledge bases for reasoning. A machine learning classifier trained to distinguish between synthetic and pseudonymized (real) documents attained perfect discrimination, with both AUC and AUPRC scores of 1.00. This result shows that there are clear, easily learnable feature differences between the two datasets—particularly those reflected in TF-IDF representations. Among these, document length emerged as a primary distinguishing characteristic. Consequently, while the synthetic dataset demonstrates advantages such as content novelty and satisfactory conceptual coverage, its inability to realistically replicate document length results in synthetic documents being consistently and trivially separable from real ones. This highlights the need for improved modeling of document-level properties to enhance the realism and utility of synthetic clinical text. It also provides a clear path forward: simply adjusting the length of synthetic documents to match that of authentic clinical notes, or by deleting redundant information from the authentic clinical notes, should eliminate the primary feature the classifier uses to tell them apart. In doing so, the synthetic texts would likely become much harder for automated classifiers to distinguish from real ones, substantially improving their realism and the utility of the synthetic dataset. Our corpus-level assessment—drawing on both Figure 4 Table 6 5 Discussion Our present work addresses a persistent barrier in digital health GenAI: the lack of accessible, interoperable, and privacy-preserving datasets that capture the diversity of real-world healthcare documentation ( Eigenschink et al., 2023 Murtaza et al., 2023 Hernandez et al., 2025 Ibrahim et al., 2025 Loni et al., 2025 van Velzen et al., 2023 Tischendorf et al., 2025 Echoing “ On the Dangers of Stochastic Parrots Bender et al., 2021 A viable solution is the adoption of compact, fine-tunable SLMs. These small LLM alternatives can be deployed directly within healthcare facilities. Running locally not only reduces reliance on external cloud services but also lowers operational costs, decreases energy demands, and enhances data privacy. SLMs are increasingly capable of powering point-of-care applications—from clinical decision support to patient communication—while ensuring sensitive information remains within institutional boundaries ( Schick and Schütze, 2021 Dibia et al., 2024 Garg et al., 2025 Kim et al., 2025 Xie et al., 2025 By establishing a no-code, protocol for creating GA-assisted SHDG workflows—enabled by rapid prototyping platforms and further enhanced through fully automated, GenAI-assisted co-development—it is achievable to significantly lower the technical threshold for GenAI engagement. Leveraging the DSI stack as a generic blueprint architecture ( Figure 1A In particular, the use of GA-assisted workflows to support clinical reasoning for nurse specialists—demonstrated through the “Nandalyse” 11 Kumar, 2023 Jeong, 2025 Tischendorf et al., 2025 A key aspect of our protocol for GA-assisted SHDG workflows is the explicit bridging of the gap between end users—such as clinicians, quality officers, and researchers—and the technical developers responsible for constructing and maintaining AI systems (as detailed in Figure 1B Alemohammad et al., 2024 Li et al., 2023 Chung et al., 2023 Notably, our methodology fosters closer collaboration between users and developers by providing open-source GitHub repositories (see text footnote 4), which make design choices, workflow logic, and evaluation criteria more transparent and verifiable. However, realizing the full promise of these platforms will require continued investment in user education, ongoing refinement of documentation and support resources, and the cultivation of communities of practice around open-source synthetic data generation. The successful adoption of privacy preserving GA-assisted SHDG workflows in clinical practice, healthcare professionals requires more than technical proficiency alone ( Kumar, 2023 Chew and Ngiam, 2025 Jeong, 2025 Drechsler and Haensch, 2024 Rujas et al., 2025 Alemohammad et al., 2024 Loni et al., 2025 Harnad (2025) Shojaee et al. (2025) Shannon, 1948 Post, 2018 Zhang et al., 2019 Importantly, working with GenAI in Healthcare mandates a clear understanding of evaluation metrics ( Eigenschink et al., 2023 Abdurahman et al., 2025 Ibrahim et al., 2025 Tables 4 5 Shannon, 1948 Post, 2018 Zhang et al., 2019 Table 6 Our work is not without limitations. We identified four main operational and technical challenges that must be addressed to advance GA-assisted SHDG workflows. First, comparative evaluation of on-premises versus cloud-based AI models ( Table 1 Schick and Schütze, 2021 Garg et al., 2025 Xie et al., 2025 Peeperkorn et al., 2024 Arts et al., 2016 Figure 3 Mei et al. (2025) Zheng et al. (2025) Zhao et al., 2021 Gallegos et al., 2024 Huang et al. (2025) Meinke et al. (2024) Gallegos et al. (2024) Suominen et al., 2013 U.S.-National-Library-of-Medicine, 2024 Eigenschink et al., 2023 Smolyak et al., 2024 Chen et al., 2025b Ibrahim et al., 2025 Scherr et al., 2025 6 Conclusion Based on our findings, we recommend prioritizing the continued development and refinement of GA-assisted SHDG-workflows, ensuring that these toolchains remain accessible, transparent, and customizable for a diverse range of clinical users and researchers through the provision of open-source GitHub repositories (see text footnote 4). Our recommendations align with ongoing efforts by the RUAS Healthcare DataLab to advance innovation in care through collaborative, technology-driven solutions that integrate open, adaptable tools into diverse healthcare contexts. 12 Mons et al., 2017 Huerta et al., 2023 Verhulst et al., 2025 Our protocolization of privacy-preserving, GA-assisted SHDG workflows underscores the critical importance of maintaining transparency by keeping humans actively involved in the process—a principle known as human-in-the-loop Figure 1A Our sincere thanks go to Maurice A.C. van den Dobbelsteen—innovation manager AI & eHealth at KCZI and HR-DataLab Healthcare coordinator—for his pivotal role in establishing our DataLab at RUAS. This project was truly a team effort, and his inspiring guidance, collaborative spirit, and insightful discussions were essential in enabling and shaping our research and Data Science talent program.  1 https://github.com/FlowiseAI/Flowise  2 https://github.com/langflow-ai/langflow  3 https://www.microsoft.com/en-us/research/project/autogen/  4 https://github.com/HR-DataLab-Healthcare/RESEARCH_SUPPORT/blob/main/PROJECTS/Generative_Agent_based_Data-Synthesis/  5 https://github.com/HR-DataLab-Healthcare/RESEARCH_SUPPORT/tree/main/PROJECTS/Generative_Agent_based_Data-Synthesis/AGENT-FLOWS  6 https://github.com/docker/roadmap  7 https://huggingface.co/spaces  8 https://docs.flowiseai.com/configuration/deployment/hugging-face  9 https://eur-lex.europa.eu/eli/reg/2016/679/oj/eng  10 https://digital-strategy.ec.europa.eu/en/policies/regulatory-framework-ai  11 https://github.com/HR-DataLab-Healthcare/RESEARCH_SUPPORT/tree/main/PROJECTS/Harnessing%20the%20Power%20of%20Gen-AI%20in%20Research  12 https://www.rotterdamuas.com/research/projects-and-publications/innovations-in-care/healthcare-innovation-with-technology/ruas-datalab-healthcare/ Data availability statement The sample datasets referenced in this article are not publicly available, as they are proprietary to MediFit Bewegingscentrum Oss and the University of Applied Sciences Rotterdam. At present, approval to use these datasets beyond the university has not been granted. Individuals interested in accessing the sample data are kindly asked to contact Mark van Velzen at m.van.velzen@hr.nl Ethics statement Ethical approval was not required for this study involving humans, in accordance with local legislation and institutional requirements. The data were initially collected for the purpose of providing care. Prior to data extraction, all participants provided written informed consent, in accordance with the Declaration of Helsinki ( World Medical Association, 2025 Author contributions MV: Writing – original draft, Formal analysis, Project administration, Methodology, Data curation, Writing – review & editing, Conceptualization, Investigation, Resources, Validation. RW: Writing – original draft, Formal analysis, Resources, Methodology, Software, Project administration, Visualization, Data curation, Writing – review & editing, Validation, Investigation, Conceptualization, Supervision. VB: Investigation, Validation, Writing – review & editing, Conceptualization, Methodology, Formal analysis, Writing – original draft. HG-W: Methodology, Conceptualization, Validation, Writing – review & editing, Writing – original draft, Investigation. EJ: Writing – review & editing, Conceptualization. SL: Resources, Writing – review & editing. MiW: Software, Writing – review & editing, Methodology, Validation, Conceptualization, Formal analysis. MaW: Writing – review & editing, Validation, Software, Methodology. GR: Software, Writing – review & editing. RM: Software, Writing – review & editing. SS: Software, Writing – review & editing. LH: Conceptualization, Writing – review & editing, Software, Methodology. TH: Conceptualization, Writing – review & editing. NM: Writing – review & editing, Conceptualization. MS: Conceptualization, Writing – review & editing. Conflict of interest The authors declare that the research was conducted in the absence of any commercial or financial relationships that could be construed as a potential conflict of interest. Generative AI statement The authors declare that Gen AI was used in the creation of this manuscript. Generative tools, specifically Gemini Advanced, Perplexity, and Deep Research Pro, were utilized in developing the manuscript drafts to enhance the quality of human-written text produced by non-native English-speaking authors. The use of these tools was fully in accordance with relevant legal requirements and ethical guidelines, including Article 12 GDPR (transparency regarding data processing), Article 5 GDPR (purpose limitation and data minimization), Article 13 AI ACT (informing users about interactions with AI systems), and Article 50 AI ACT (transparency requirements for AI providers and users). Furthermore, all AI-generated content was carefully reviewed and edited by human authors to ensure accuracy, relevance, and adherence to academic and ethical standards. Importantly, this process was conducted in compliance with the principles set forth in the “Nederlandse gedragscode wetenschappelijke integriteit” ( Knaw et al., 2018 Any alternative text (alt text) provided alongside figures in this article has been generated by Frontiers with the support of artificial intelligence and reasonable efforts have been made to ensure accuracy, including review by the authors wherever possible. If you identify any issues, please contact us. Publisher’s note All claims expressed in this article are solely those of the authors and do not necessarily represent those of their affiliated organizations, or those of the publisher, the editors and the reviewers. Any product that may be evaluated in this article, or claim that may be made by its manufacturer, is not guaranteed or endorsed by the publisher. References Abdurahman S. Salkhordeh Ziabari A. Moore A. K. Bartels D. M. Dehghani M. 2025 A primer for evaluating large language models in social-science research Adv. Methods Pract. Psychol. Sci. 8 25152459251325174 10.1177/25152459251325174 Abhishek M. K. Rao D. R. 2021 Framework to secure docker containers Fifth world conference on smart trends in systems security and sustainability (WorldS4) London, UK IEEE 152 156 10.1109/WorldS451998.2021.9514041 Ait A. Cánovas Izquierdo J. L. Cabot J. 2025 On the suitability of hugging face hub for empirical studies Empir. Softw. Eng. 30 1 48 10.1007/s10664-024-10608-8 Alemohammad S. Casco-Rodriguez J. Luzi L. Humayun A. I. Babaei H. LeJeune D. 2024 Self-consuming generative models go mad International conference on learning representations (ICLR) Vienna, AT 10.48550/arXiv.2307.01850 Alsentzer E. Murphy J. R. Boag W. Weng W.-H. Jin D. Naumann T. 2019 Publicly available clinical BERT embeddings Proceedings of the 2nd clinical natural language processing workshop Minneapolis, MN Association for Computational Linguistics 72 78 10.18653/v1/W19-1909 Arts D. L. Voncken A. G. Medlock S. Abu-Hanna A. van Weert H. C. 2016 Reasons for intentional guideline non-adherence: a systematic review Int. J. Med. Inform. 89 55 62 10.1016/j.ijmedinf.2016.02.009 26980359 Baowaly M. K. Lin C. C. Liu C. L. Chen K. T. 2019 Synthesizing electronic health records using improved generative adversarial networks J. Am. Med. Inform. Assoc. 26 228 241 10.1093/jamia/ocy142 30535151 PMC7647178 Barrault L. Duquenne P.-A. Elbayad M. Kozhevnikov A. Alastruey B. Andrews P. 2024 Large concept models: language modeling in a sentence representation space arXiv [Preprint] 10.48550/arXiv.2412.08821 Beam A.L. Kompa B. Schmaltz A. Fried I. Weber G. Palmer N. 2020 Clinical concept embeddings learned from massive sources of multimodal medical data Pacific symposium on Biocomputing 2020 Singapore World Scientific 25 295 306 PMC6922053 31797605 Bender E. M. Gebru T. McMillan-Major A. Shmitchell S. 2021 On the dangers of stochastic parrots: can language models be too big? Proceedings of the 2021 ACM conference on fairness, accountability, and transparency: Association for Computing Machinery 610 623 10.1145/3442188.3445922 Bommasani R. Hudson D. A. Adeli E. Altman R. Arora S. von Arx S. 2021 On the opportunities and risks of foundation models arXiv [Preprint] 10.48550/arXiv.2108.07258 Brown T. B. Mann B. Ryder N. Subbiah M. Kaplan J. Dhariwal P. 2020 Language models are few-shot learners Proceedings of the 34th international conference on neural information processing systems NY, USA Curran Associates Inc 10.5555/3495724.3495883 Busch F. Kather J. N. Johner C. Moser M. Truhn D. Adams L. C. 2024 Navigating the European union artificial intelligence act for healthcare NPJ Digit Med 7 210 10.1038/s41746-024-01213-6 39134637 PMC11319791 Cannon J. Lucci S. 2010 Transcription and EHRS. Benefits of a blended approach J. AHIMA 81 36 40 20218195 Casper S. Bailey L. Hunter R. Ezell C. Cabalé E. Gerovitch M. 2025 The AI agent index arXiv [Preprint] 10.48550/arXiv.2502.01635 Chan A. Salganik R. Markelius A. Pang C. Rajkumar N. Krasheninnikov D. 2023 Harms from increasingly agentic algorithmic systems 2023 ACM conference on fairness accountability and transparency New York, NY Association for Computing Machinery 651 666 10.1145/3593013.3594033 Chen Q. Hu Y. Peng X. Xie Q. Jin Q. Gilson A. 2025b Benchmarking large language models for biomedical natural language processing applications and recommendations Nat. Commun. 16 3280 10.1038/s41467-025-56989-2 40188094 PMC11972378 Chen B. Zhang Z. Langrené N. Zhu S. 2025a Unleashing the potential of prompt engineering for large language models Patterns 6 101260 10.1016/j.patter.2025.101260 40575123 PMC12191768 Chew B.-H. Ngiam K. Y. 2025 Artificial intelligence tool development: what clinicians need to know? BMC Med. 23 244 10.1186/s12916-025-04076-0 40275334 PMC12023651 Chojnacki B. 2025 The ultimate guide to selecting the right large language model for [Online] dsstream https://www.dsstream.com/post/the-ultimate-guide-to-selecting-the-right-large-language-model-for Chung J. Kamar E. Amershi S. 2023 Increasing diversity while maintaining accuracy: text data generation with large language models and human interventions Proceedings of the 61st annual meeting of the ACL (volume 1: Long papers) Cambridge, MA Association for Computational Linguistics (ACL) 575 593 10.18653/v1/2023.acl-long.34 Coveney P. V. Succi S. 2025 The wall confronting large language models arXiv [Preprint] 10.48550/arXiv.2507.19703 Das A. B. Ahmed S. Sakib S. K. 2025 Hallucinations and key information extraction in medical texts: a comprehensive assessment of open-source large language models arXiv [Preprint] 10.48550/arXiv.2504.19061 Daull X. Bellot P. Bruno E. Martin V. Murisasco E. 2023 Complex qa and language models hybrid architectures, survey arXiv [Preprint] 10.48550/arXiv.2302.09051 DeepMind 2025 Alphaevolve: A gemini-powered coding agent for designing advanced algorithms https://deepmind.google/discover/blog/alphaevolve-a-gemini-powered-coding-agent-for-designing-advanced-algorithms/ Dibia V. Chen J. Bansal G. Syed S. Fourney A. Zhu E. 2024 Autogen studio: a no-code developer tool for building and debugging multi-agent systems Proceedings of the 2024 conference on empirical methods in natural language processing: System demonstrations Stroudsburg, PA Association for Computational Linguistics 72 79 10.18653/v1/2024.emnlp-demo.8 Doan S. Conway M. Phuong T. M. Ohno-Machado L. 2014 Natural language processing in biomedicine; a unified system architecture overview Clinical bioinformatics. Methods in molecular biology Trent R. New York, NY Humana Press 275 294 10.1007/978-1-4939-0847-9_16 24870142 Drechsler J. Haensch A.-C. 2024 30 years of synthetic data Stat. Sci. 39 221 242 10.1214/24-STS927 Driehuis F. Woudenberg-Hulleman I. Verhof-van Westing I. M. Geurkink H. Hartstra L. Trouw M. 2019 Verantwoording en toelichting kngf-richtlijn fysiotherapeutische dossiervoering 2019 Amersfoort: Koninklijk Nederlands Genootschap voor Fysiotherapie (KNGF). https://www.kngf.nl/app/uploads/2024/09/fysiotherapeutische-dossiervoering-2019-verantwoording-en-toelichting-versie-1.1.pdf Eigenschink P. Reutterer T. Vamosi S. Vamosi R. Sun C. Kalcher K. 2023 Deep generative models for synthetic data: a survey IEEE Access 11 47304 47320 10.1109/ACCESS.2023.3275134 European Parliament and Council 2024 https://eur-lex.europa.eu/eli/reg/2024/1689/oj/eng Fu Y. Mai L. Ustiugov D. 2025 AI goes serverless: are systems ready? Sigops. https://www.sigops.org/2025/ai-goes-serverless-are-systems-ready/ Gallegos I. O. Rossi R. A. Barrow J. Tanjim M. M. Kim S. Dernoncourt F. 2024 Bias and fairness in large language models: a survey Comput. Linguist. 50 1097 1179 10.1162/coli_a_00524 Garg M. Raza S. Rayana S. Liu X. Sohn S. 2025 The rise of small language models in healthcare: a comprehensive survey arXiv [Preprint] 10.48550/arXiv.2504.17119 Goodfellow I. Bengio Y. Courville A. 2018 Deep learning Cambridge, MA MIT press Goyal M. Mahmoud Q. H. 2024 A systematic review of synthetic data generation techniques using generative AI Electronics 13 3509 https://www.mdpi.com/2079-9292/13/17/3509 Gridach M. Nanavati J. Abidine K. Z. E. Mendes L. Mack C. 2025 Agentic ai for scientific discovery: a survey of progress, challenges, and future directions arXiv [Preprint] 10.48550/arXiv.2503.08979 Günther M. Mohr I. Williams D. J. Wang B. Xiao H. 2024 Late chunking: contextual chunk embeddings using long-context embedding models arXiv [Preprint] 10.48550/arXiv.2409.04701 Gupta S. 2025 The rise of serverless AI: transforming machine learning deployment Eur. J. Comput. Sci. Inf. Technol. 13 45 67 10.37745/ejcsit.2013/vol13n54567 Han T. Adams L. C. Papaioannou J.-M. Grundmann P. Oberhauser T. Löser A. 2023 Medalpaca – an open-source collection of medical conversational AI models and training data arXiv [Preprint] 10.48550/arXiv.2304.08247 Harnad S. 2025 Language writ large: LLMs, chatgpt, meaning, and understanding Front. Artif. Intell. 7 1490698 10.3389/frai.2024.1490698 40013231 PMC11861094 Hart E. M. Barmby P. LeBauer D. Michonneau F. Mount S. Mulrooney P. 2016 Ten simple rules for digital data storage PLoS Comput. Biol. 12 e1005097 10.1371/journal.pcbi.1005097 27764088 PMC5072699 Haug C. J. 2018 Turning the tables – the new european general data protection regulation N. Engl. J. Med. 379 207 209 10.1056/NEJMp1806637 29874143 Hechler E. Weihrauch M. Wu Y. 2023 Evolution of data architecture Data fabric and data mesh approaches with AI Berkeley, CA Apress 3 15 10.1007/978-1-4842-9253-2_1 Hernandez M. Osorio-Marulanda P. A. Catalina M. Loinaz L. Epelde G. Aginako N. 2025 Comprehensive evaluation framework for synthetic tabular data in health: Fidelity, utility and privacy analysis of generative models with and without privacy guarantees Front. Digit. Health 7 1576290 10.3389/fdgth.2025.1576290 40343213 PMC12058740 Hettiarachchi I. 2025 Exploring generative AI agents: architecture, applications, and challenges J. Artif. Intell. Gen. Sci. 8 105 127 10.60087/jaigs.v8i1.350 Hoofnagle C. J. Van Der Sloot B. Borgesius F. Z. 2019 The European Union general data protection regulation: what it is and what it means Inf. Commun. Technol. Law 28 65 98 10.1080/13600834.2019.1573501 Huang Y. Zhan R. Wong D. F. Chao L. S. Tao A. 2025 Intrinsic model weaknesses: how priming attacks unveil vulnerabilities in large language models Assoc. Comput. Ling. 1405 1425 10.18653/v1/2025.findings-naacl.77 Huerta E. A. Blaiszik B. Brinson L. C. Bouchard K. E. Diaz D. Doglioni C. 2023 Fair for AI: an interdisciplinary and international community building perspective Sci Data 10 487 10.1038/s41597-023-02298-6 37495591 PMC10372139 Ibrahim M. Khalil Y. A. Amirrajab S. Sun C. Breeuwer M. Pluim J. 2025 Generative AI for synthetic data across multiple medical modalities: a systematic review of recent developments and challenges Comput. Biol. Med. 189 109834 10.1016/j.compbiomed.2025.109834 40023073 Inoue K. 2024 A practitioner’s guide to selecting large language models for your business needs Veritone https://www.veritone.com/blog/a-practitioners-guide-to-selecting-large-language-models-for-your-business-needs/ Jeong C. 2025 Beyond text: implementing multimodal large language model-powered multi-agent systems using a no-code platform J. Intell. Inf. Syst. 31 191 231 10.13088/jiis.2025.31.1.191 Jin M. Sang-Min C. Gun-Woo K. 2025 Comcare: a collaborative ensemble framework for context-aware medical named entity recognition and relation extraction Electronics 14 328 10.3390/electronics14020328 Kaplan J. McCandlish S. Henighan T. Brown T. B. Chess B. Child R. 2020 Scaling laws for neural language models arXiv [Preprint] 10.48550/arXiv.2001.08361 Karpathy A. 2025 Vibe coding https://x.com/karpathy/status/1886192184808149383 Kim H. Hwang H. Lee J. Park S. Kim D. Lee T. 2025 Small language models learn enhanced reasoning skills from medical textbooks npj Digital Medicine 8 240 10.1038/s41746-025-01653-8 40316765 PMC12048634 Knaw NFU, NWO, TO Federatie, Vereniging Hogescholen Vsnu 2018 10.17026/dans-2cj-nvwu Kochanowska M. Gagliardi W. R. with reference to Jonathan, B 2022 The double diamond model: in pursuit of simplicity and flexibility Perspectives on design ii Raposo D. Neves J. Silva J. Cham Springer International Publishing 19 32 Krishnakumar A. Ogras U. Marculescu R. Kishinevsky M. Mudge T. 2023 Domain-specific architectures: research problems and promising approaches ACM Trans. Embed. Comput. Syst. 22 1 26 10.1145/3563946 Kumar A. 2023 https://blog.fabrichq.ai/6-best-flowise-alternatives-in-2024-to-build-ai-agents-8af9cb572449 LeCun Y. Bengio Y. Hinton G. 2015 Deep learning Nature 521 436 444 10.1038/nature14539 26017442 Lee J. Yoon W. Kim S. Kim D. Kim S. So C. H. 2020 Biobert: a pre-trained biomedical language representation model for biomedical text mining Bioinformatics 36 1234 1240 10.1093/bioinformatics/btz682 31501885 PMC7703786 Li Z. Zhu H. Lu Z. Yin M. 2023 Synthetic data generation with large language models for text classification: potential and limitations Proceedings of the 2023 conference on empirical methods in natural language processing Bouamor H. Pino J. Bali K. Cambridge, MA Association for Computational Linguistics (ACL) 10443 10461 10.18653/v1/2023.emnlp-main.647 Little R. J. 1993 Statistical analysis of masked data J. Off. Stat. 9 407 426 https://www.imstat.org/publications/sts/sts_39_2/sts_39_2.pdf Liu Y. Acharya U. R. Tan J. H. 2025 Preserving privacy in healthcare: a systematic review of deep learning approaches for synthetic data generation Comput. Methods Prog. Biomed. 260 108571 10.1016/j.cmpb.2024.108571 39742693 Loni M. Poursalim F. Asadi M. Gharehbaghi A. 2025 A review on generative AI models for synthetic medical text, time series, and longitudinal data npj Digit. Med. 8 281 10.1038/s41746-024-01409-w 40374917 PMC12081667 Mayo M. 2025 Feel the vibe: Why AI-dependent coding isn’t the enemy (or is it?) https://www.kdnuggets.com/feel-the-vibe-why-ai-dependent-coding-isnt-the-enemy-or-is-it Mei L. Yao J. Ge Y. Wang Y. Bi B. Cai Y. 2025 A survey of context engineering for large language models arXiv [Preprint] 10.48550/arXiv.2507.13334 Meinke A. Schoen B. Scheurer J. Balesni M. Shah R. Hobbhahn M. 2024 Frontier models are capable of in-context scheming arXiv [Preprint] 10.48550/arXiv.2412.04984 Meng X.-L. 2021 Building data science infrastructures and infrastructural data science Harv. Data Sci. Rev. 3 10.1162/99608f92.abfa0e70 Meystre S. M. Lovis C. Burkle T. Tognola G. Budrionis A. Lehmann C. U. 2017 Clinical data reuse or secondary use: current status and potential future progress Yearb. Med. Inform. 26 38 52 10.15265/IY-2017-007 28480475 PMC6239225 Mons B. Neylon C. Velterop J. Dumontier M. da Silva Santos L. O. B. Wilkinson M. D. 2017 Cloudy, increasingly fair; revisiting the fair data guiding principles for the European open science cloud Inf. Serv. Use 37 49 56 10.3233/isu-170824 Morris J. X. Sitawarin C. Guo C. Kokhlikyan N. Suh G. E. Rush A. M. 2025 How much do language models memorize? arXiv [Preprint] 10.48550/arXiv.2505.24832 Murtaza H. Ahmed M. Khan N. F. Murtaza G. Zafar S. Bano A. 2023 Synthetic data generation: state of the art in health care domain Comput Sci Rev 48 100546 10.1016/j.cosrev.2023.100546 Negro-Calduch E. Azzopardi-Muscat N. Krishnamurthy R. S. Novillo-Ortiz D. 2021 Technological progress in electronic health record system optimization: systematic review of systematic literature reviews Int. J. Med. Inform. 152 104507 10.1016/j.ijmedinf.2021.104507 34049051 PMC8223493 Nijor S. Rallis G. Lad N. Gokcen E. 2022 Patient safety issues from information overload in electronic medical records J. Patient Saf. 18 e999 e1003 10.1097/PTS.0000000000001002 35985047 PMC9422765 Novikov A. Vu N. Eisenberger M. Dupont E. Huang P. Wagner A.Z. 2025 https://storage.googleapis.com/deepmind-media/DeepMind.com/Blog/alphaevolve-a-gemini-powered-coding-agent-for-designing-advanced-algorithms/AlphaEvolve.pdf Ohse J. Hadžić B. Mohammed P. Peperkorn N. Danner M. Yorita A. 2024 Zero-shot strike: testing the generalisation capabilities of out-of-the-box llm models for depression detection Comput. Speech Lang. 88 101663 10.1016/j.csl.2024.101663 OpenAI 2025 https://openai.com/index/gpt-4-1/ Orru G. Piarulli A. Conversano C. Gemignani A. 2023 Human-like problem-solving abilities in large language models using chatgpt Front Artif Intell 6 1199350 10.3389/frai.2023.1199350 37293238 PMC10244637 Park J. S. O'Brien J. Cai C. J. Morris M. R. Liang P. Bernstein M. S. 2023 Generative agents: interactive simulacra of human behavior Proceedings of the 36th annual ACM symposium on user Interface software and technology (UIST '23) San Francisco, CA ACM 1 22 10.1145/3586183.3606763 Peeperkorn M. Kouwenhoven T. Brown D. Jordanous A. 2024 Is temperature the creativity parameter of large language models? Proceedings of the 15th international conference on computational creativity (ICCC’24), (Coimbra, Portugal: Association for Computational Creativity) 10.48550/arXiv.2405.00492 Pezoulas V. C. Zaridis D. I. Mylona E. Androutsos C. Apostolidis K. Tachos N. S. 2024 Synthetic data generation methods in healthcare: a review on open-source tools and methods Comput. Struct. Biotechnol. J. 23 2892 2910 10.1016/j.csbj.2024.07.005 39108677 PMC11301073 Piccialli F. Chiaro D. Sarwar S. Cerciello D. Qi P. Mele V. 2025 Agentai: a comprehensive survey on autonomous agents in distributed AI for industry 4.0 Expert Syst. Appl. 291 128404 10.1016/j.eswa.2025.128404 Post M. 2018 A call for clarity in reporting bleu scores Proceedings of the 3rd conference on machine translation: Research papers Stroudsburg, PA Association for Computational Linguistics 186 191 10.18653/v1/W18-6319 Priebe T. Neumaier S. Markus S. 2021 Finding your way through the jungle of big data architectures 2021 IEEE international conference on big data (big data) New York, NY IEEE 5994 5996 10.1109/BigData52589.2021.9671862 Qiu X. Wang H. Tan X. Qu C. Xiong Y. Cheng Y. 2024 Towards collaborative intelligence: propagating intentions and reasoning for multi-agent coordination with large language models arXiv [Preprint] 10.48550/arXiv.2407.12532 QuantSpark 2023 https://quantspark.ai/blogs/2023/10/31/ai-comparison-guide Reddy S. 2024 Generative AI in healthcare: an implementation science informed translational path on application, integration and governance Implement. Sci. 19 27 10.1186/s13012-024-01357-9 38491544 PMC10941464 Rubin D. B. 1993 Statistical disclosure limitation J. Off. Stat. 9 461 468 https://ecommons.cornell.edu/server/api/core/bitstreams/dd0b63ff-4494-4491-96ba-a69811563dee/content Ruczynski K. 2024 Compare llms: a guide to finding the best large language models [online] Word https://www.wordware.ai/blog/compare-llms-a-guide-to-finding-the-best-large-language-models Rujas M. Gomez M. Del Moral Herranz R. Fico G. Merino-Barbancho B. 2025 Synthetic data generation in healthcare: a scoping review of reviews on domains, motivations, and future applications Int. J. Med. Inform. 195 105763 10.1016/j.ijmedinf.2024.105763 39719743 Sai S. Gaur A. Sai R. Chamola V. Guizani M. Rodrigues J. J. P. C. 2024 Generative AI for transformative healthcare: a comprehensive study of emerging models, applications, case studies, and limitations IEEE Access 12 31078 31106 10.1109/ACCESS.2024.3367715 Scherr R. Spina A. Dao A. Andalib S. Halaseh F. F. Blair S. 2025 Novel evaluation metric and quantified performance of chatgpt-4 patient management simulations for early clinical education: experimental study JMIR Form. Res. 9 e66478 10.2196/66478 40013991 PMC11884304 Schick T. Schütze H. 2021 It’s not just size that matters: small language models are also few-shot learners Proceedings of the 2021 conference of the north American chapter of the Association for Computational Linguistics (NAACL): Human language technologies Cambridge, MA Association for Computational Linguistics 2339 2352 10.18653/v1/2021.naacl-main.185 Schneider J. 2025 Generative to agentic AI: survey, conceptualization, and challenges arXiv [Preprint] 10.48550/arXiv.2504.18875 Schut M. C. Luik T. T. Vagliano I. Rios M. Helsper C. W. van Asselt K. M. 2025 Artificial intelligence for early detection of lung cancer in gps' clinical notes: a retrospective observational cohort study Br. J. Gen. Pract. 75 e316 e322 10.3399/BJGP.2023.0489 40044183 PMC12040367 Seinen T. M. Kors J. A. van mulligen E. M. Rijnbeek P. R. 2024 Structured codes and free-text notes: measuring information complementarity in electronic health records medRxiv [Preprint]. 10.1101/2024.10.28.24316294 PMC11887999 39946687 Sengupta A. Goel Y. Chakraborty T. 2025 How to upscale neural networks with scaling law? A survey and practical guidelines arXiv [Preprint] 10.48550/arXiv.2502.12051 Shannon C. E. 1948 A mathematical theory of communication Bcl. Syst. Tech. J. 27 379 423 10.1002/j.1538-7305.1948.tb01338.x Shojaee P. Mirzadeh I. Alizadeh K. Horton M. Bengio S. Farajtabar M. 2025 The illusion of thinking: understanding the strengths and limitations of reasoning models via the lens of problem complexity arXiv [Preprint] 10.48550/arXiv.2506.06941 Singhal K. Azizi S. Tu T. Mahdavi S. S. Wei J. Chung H. W. 2023 Large language models encode clinical knowledge Nature 620 172 180 10.1038/s41586-023-06291-2 37438534 PMC10396962 Smolyak D. Bjarnadóttir M. V. Crowley K. Agarwal R. 2024 Large language models and synthetic health data: progress and prospects JAMIA Open 7 ooae114 10.1093/jamiaopen/ooae114 39464796 PMC11512648 Steinkamp J. Kantrowitz J. J. Airan-Javia S. 2022 Prevalence and sources of duplicate information in the electronic medical record JAMA Netw. Open 5 e2233348 10.1001/jamanetworkopen.2022.33348 36156143 PMC9513649 Suominen H. Salanterä S. Velupillai S. Chapman W. W. Savova G. Elhadad N. 2013 Overview of the share/clef ehealth evaluation lab 2013 Information access evaluation. Multilinguality, multimodality, and visualization: 4th international conference of the CLEF initiative Heidelberg, Germany Springer 212 231 10.1007/978-3-642-40802-1_17 Swart N. M. Apeldoorn A. T. Conijn D. Meerhoff G. A. Ostelo R. W. J. G. 2021 Kngf-richtlijn lage rugpijn en lumbosacraal radiculair syndroom Amersfoort/ Utrecht: Koninklijk Nederlands Genootschap voor Fysiotherapie (KNGF) & Vereniging van Oefentherapeuten Cesar en Mensendieck https://vvocm.nl/Portals/2/kngf_richtlijn_lage_rugpijn_en_lrs_2021_verantwoording.pdf Thandla S. R. Armstrong G. Q. Menon A. Shah A. Gueye D. L. Harb C. 2024 Comparing new tools of artificial intelligence to the authentic intelligence of our global health students BioData Min. 17 58 10.1186/s13040-024-00408-7 39696442 PMC11656723 Tischendorf T. Hinsche L. Hasseler M. Schaal T. 2025 Genai in nursing and clinical practice: a rapid review of applications and challenges J. Public Health (Berl.). 10.1007/s10389-025-02523-z Tuulos V. 2022 Effective data science infrastructure: How to make data scientists productive Shelter Island, NY Manning U.S.-National-Library-of-Medicine 2024 https://www.nlm.nih.gov/research/umls/index.html Ulfsnes R. Moe N. B. Stray V. Skarpen M. 2024 Transforming software development with generative AI: empirical insights on collaboration and workflow Generative AI for effective software development Nguyen-Duc A. Abrahamsson P. Khomh F. Cham Springer Nature Switzerland 219 234 van der Willigen R. F. Versnel H. van Opstal A. J. 2024 Spectral-temporal processing of naturalistic sounds in monkeys and humans J. Neurophysiol. 131 38 63 10.1152/jn.00129.2023 37965933 PMC11305640 van Velzen M. de Graaf-Waar H. I. Ubert T. van der Willigen R. F. Muilwijk L. Schmitt M. A. 2023 21st century (clinical) decision support in nursing and allied healthcare. Developing a learning health system: a reasoned design of a theoretical framework BMC Med. Inform. Decis. Mak. 23 279 10.1186/s12911-023-02372-4 38053104 PMC10699040 Vasireddy I. Sriveni B. Prathyusha K. Kandi A. 2024 Sentiment analysis of web media using hybrid model with t5 and gpt-4 models 2nd international conference on recent trends in microelectronics, automation, computing and communications systems (ICMACC) New York, NY IEEE 634 639 10.1109/ICMACC62921.2024.10894040 Vaswani A. Shazeer N. Parmar N. Uszkoreit J. Jones L. Gomez A. N. 2017 Attention is all you need Advances in Neural Information Processing Systems 30 (31st NeurIPS, 2017) Guyon I. Luxburg U. V. Bengio S. Wallach H. Fergus R. Vishwanathan S. Curran Associates, Inc. 15 https://proceedings.neurips.cc/paper_files/paper/2017/file/3f5ee243547dee91fbd053c1c4a845aa-Paper.pdf Verhulst S. Zahuranec A. J. Chafetz H. 2025 Walturn 2025 https://www.walturn.com/insights/gpt-4-1-and-the-frontier-of-ai-capabilities-improvements-and-comparison-to-claude-3-gemini-mistral-and-llama Woisetschläger H. Erben A. Marino B. Wang S. Lane N. D. Mayer R. 2024 Federated learning priorities under the European Union artificial intelligence act arXiv [Preprint] 10.48550/arXiv.2402.05968 World Health Organization 2001 Icf: International classification of functioning, disability and health / world health organization Geneva World Health Organization World Medical Association 2025 World medical association declaration of Helsinki: ethical principles for medical research involving human participants JAMA 333 71 74 10.1001/jama.2024.21972 39425955 Xie C. Cai S. Wang W. Li P. Sang Z. Yang K. 2025 Infir: crafting effective small language models and multimodal small language models in reasoning arXiv [Preprint] 10.48550/arXiv.2502.11573 Xie J. Chen Z. Zhang R. Wan X. Li G. 2024 Large multimodal agents: a survey arXiv [Preprint] 10.48550/arXiv.2402.15116 Yang X. Xiao Y. Liu D. Deng H. Huang J. Zhou Y. 2025 Cross language transformation of free text into structured lobectomy surgical records from a multi center study Sci. Rep. 15 15417 10.1038/s41598-025-97500-7 40316625 PMC12048494 Zhang T. Kishore V. Wu F. Weinberger K. Q. Artzi Y. 2019 Bertscore: evaluating text generation with bert arXiv [Preprint] 10.48550/arXiv.1904.09675 Zhao Z. Wallace E. Feng S. Klein D. Singh S. 2021 Calibrate before use: improving few-shot performance of language models Proceedings of the 38th international conference on machine learning Marina M. Tong Z. PMLR 12697 12706 https://proceedings.mlr.press/v139/zhao21c.html Zheng Y. Li T. Huang H. Zeng T. Lu J. Chu C. 2025 Are all prompt components value-neutral? Understanding the heterogeneous adversarial robustness of dissected prompt in large language models arXiv [Preprint] 10.48550/arXiv.2508.01554 ",
  "metadata": {
    "Title of this paper": "Are all prompt components value-neutral? Understanding the heterogeneous adversarial robustness of dissected prompt in large language models",
    "Journal it was published in:": "Frontiers in Artificial Intelligence",
    "URL": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC12479492/"
  }
}