{
  "title": "Paper_54",
  "abstract": "pmc Acta Oncol Acta Oncol 4634 ao AO Acta Oncologica 0284-186X 1651-226X MJS Publishing PMC12490106 PMC12490106.1 12490106 12490106 40995989 10.2340/1651-226X.2025.44020 AO-64-44020 1 Original Article CNN-based prediction using early post-radiotherapy MRI as a proxy for toxicity in the murine head and neck https://orcid.org/0000-0001-5210-132X Huynh Bao Ngoc a https://orcid.org/0009-0003-6951-6910 Kakar Manish b https://orcid.org/0000-0002-2744-9663 Zlygosteva Olga c https://orcid.org/0000-0002-6317-5671 Juvkam Inga Solgård b d https://orcid.org/0000-0002-6995-131X Edin Nina c https://orcid.org/0000-0003-1595-9962 Tomic Oliver e https://orcid.org/0000-0001-7944-0719 Futsaether Cecilia Marie e https://orcid.org/0000-0002-1308-9871 Malinen Eirik b c a b c d e CONTACT baohuy@ous-hf.no Supplemental data for this article can be accessed online at https://doi.org/10.2340/1651-226X.2025.44020 25 9 2025 2025 64 479049 44020 31 5 2025 10 9 2025 25 09 2025 03 10 2025 03 10 2025 © 2025 The Author(s) 2025 https://creativecommons.org/licenses/by/4.0/ This is an Open Access article distributed under the terms of the Creative Commons Attribution 4.0 International License ( http://creativecommons.org/licenses/by/4.0/ Background and purpose Radiotherapy (RT) of head and neck cancer can cause severe toxicities. Early identification of individuals at risk could enable personalized treatment. This study evaluated whether convolutional neural networks (CNNs) applied to Magnetic Resonance (MR) images acquired early after irradiation can predict radiation-induced tissue changes associated with toxicity in mice. Patient/material and methods Twenty-nine C57BL/6JRj mice were included (irradiated: n n n Results The best-performing model (EfficientNet B3) achieved 83% slice-level accuracy (ACC) and correctly classified 28 of 29 mice. Higher predicted probabilities of the irradiated class were strongly associated with oral mucositis, dermatitis, reduced saliva production, late submandibular gland fibrosis and atrophy of salivary gland acinar cells. Explainability heatmaps confirmed that CNNs focused on irradiated regions. Interpretation The high CNN classification ACC, the regions highlighted by the explainability analysis and the strong correlations between model predictions and toxicity suggest that CNNs, together with post-irradiation magnetic resonance imaging, may identify individuals at risk of developing toxicity. KEYWORDS head and neck mice radiotherapy deep learning convolutional neural network toxicity early detection magnetic resonance imaging This work was supported by the South-Eastern Norway Regional Health Authority, grant number 2023107, and by UiO Life Science at the University of Oslo, grant reference 2018/10221. BIGART 2025 was financially supported by the Acta Oncologica Foundation. pmc-status-qastatus 0 pmc-status-live yes pmc-status-embargo no pmc-status-released yes pmc-prop-open-access yes pmc-prop-olf no pmc-prop-manuscript no pmc-prop-legally-suppressed no pmc-prop-has-pdf yes pmc-prop-has-supplement yes pmc-prop-pdf-only no pmc-prop-suppress-copyright no pmc-prop-is-real-version no pmc-prop-is-scanned-article no pmc-prop-preprint no pmc-prop-in-epmc yes Introduction Radiotherapy (RT) of head and neck cancer (HNC) patients can lead to acute and chronic toxicities, including radiation dermatitis, oral mucositis, dysphagia, hyposalivation, xerostomia, pain and weight loss [ 1 3 1 3 3 4 The growing availability of clinical data provides opportunities for developing machine learning models to identify HNC patients at higher risk of radiation-induced toxicity [ 4 5 4 6 6 4 7 8 Medical imaging, including computed tomography (CT), magnetic resonance imaging (MRI) and positron emission tomography (PET), provide anatomical and functional features that may support toxicity risk assessment [ 5 8 9 10 11 12 13 14 While clinical data from human patients are ideal for developing toxicity prediction models, preclinical studies using laboratory animals offer a controlled environment and allow experimental manipulations unfeasible in human studies [ 15 16 17 18 This study aimed to evaluate whether CNNs can detect early signs of radiation-induced tissue damage in mouse normal tissue using T2-weighted Magnetic Resonance (MR) images acquired 3–5 days post-irradiation. We hypothesized that CNN models could capture subtle image features associated with radiation-induced tissue changes. To test this, we compared multiple CNN architectures for their ability to distinguish control from irradiated mice, examined correlations between model predictions and five toxicity endpoints and applied explainability analysis as a model sanity check to identify image regions most influential for classification. Patients/material and methods Animal handling and datasets Nine-week-old female C57BL/6JRj mice (Janvier, France) were housed under pathogen-free conditions on a 12-hour light/dark cycle, with unrestricted access to standard commercial fodder and water. Standard housing included nesting material and refuge. Mice were 12 weeks old at the start of the experiments. The present study included 29 mice, which were randomly assigned to a control group ( n n n 19 20 21 22 n n n This study conforms with the ARRIVE guidelines [ 23 19 22 2 17 Supplementary Figure B1 n 24 25 Figure 1 Figure 1 Example results of Huang’s thresholding applied to normalized MR slices (top row), along with the two criteria used for selecting 2D MR slices for CNN model development (middle and bottom rows). The left slice, which did not meet either criterion, was excluded from the dataset. In contrast, the center and right slices satisfied both criteria and were included for model training. Blue and green regions show the background and foreground, respectively. The magenta region depicts the largest foreground area belonging to the reference slice of this particular mouse. MR: Magnetic Resonance; CNN: convolutional neural networks. The area of the foreground must cover more than 10% of the sagittal slice under consideration ( Figure 1 F R The foreground area of the slice under consideration must be at least 40% as large as the foreground area of the reference Figure 1 F N The selected sagittal MR slices, comprising 304 slices from control mice and 282 slices from irradiated mice, were used to create the dataset for developing CNN models for classifying MR slices into irradiated (class 1) or control (class 0) groups ( Supplementary Figure B1 Supplementary Table A1 CNN modelling workflow A total of 17 CNN models based on different architectures, namely VGG [ 26 27 28 29 P s 30 The selected MR slices were divided into five folds for nested five-fold cross-validation (CV) [ 31 Supplementary Figure B1 B2 32 P s P s The performance metrics ( Supplementary C The five models with the highest per-slice validation AvgScore were investigated further by calculating the per-mouse predictions and performance metrics. The per-mouse predicted class probability ( P m P ¯ s P m Supplementary Figure B1 Variance of Gradients, VarGrad [ 33 14 33 To analyze the explainability heatmaps, VarGrad values were calculated and compared across three different anatomical regions given in the MR images: the irradiated area (mouth and throat, approximated by the red boundary in Supplementary Figure B1 The irradiation field to the mouse head was previously assessed using planar X-ray imaging [ 17 Figure 1 Statistical analysis Spearman’s rank correlation [ 34 35 36 Technical information Development and evaluation of CNN models and the generation of the explainability heatmaps ( Supplementary Figure B1 https://github.com/huynhngoc/ous-mice Results Model performance Most CNN models achieved per-slice validation ACC over 75%, except for models in the VGG and MobileNet groups. The ResNet101 model (from the ResNet group) and all EfficientNet models achieved per-slice validation ACC over 80% and AUC over 85%. Detailed validation results are shown in Supplementary Table D1 Tables 1 and 2 show per-slice and per-mouse performance metrics, respectively, of the five models with the highest per-slice validation AvgScore. While the EfficientNet B1 model obtained the highest per-slice validation AvgScore, the EfficientNet B3 model outperformed the four remaining models across all per-slice test metrics on the test set ( Table 1 Table 2 Table 1 Per-slice performance metrics on validation and test sets of the five highest-performing models. Model Accuracy Scaled MCC AUC F1 irradiated F1 control AvgScore  Validation EfficientNet B1  0.823  0.827 0.892  0.808  0.834  0.837 EfficientNet B6 0.818 0.819  0.898 0.802 0.827 0.833 EfficientNet B0 0.816 0.818 0.894 0.804 0.820 0.831 EfficientNet S 0.816 0.818 0.890 0.799 0.828 0.830 EfficientNet B3 0.817 0.819 0.883 0.807 0.820 0.829  Test EfficientNet B1 0.778 0.778 0.870 0.760 0.794 0.796 EfficientNet B6 0.794 0.793 0.886 0.783 0.803 0.812 EfficientNet B0 0.805 0.807 0.888 0.807 0.804 0.822 EfficientNet S 0.783 0.783 0.889 0.771 0.794 0.804 EfficientNet B3  0.833  0.834  0.914  0.832  0.834  0.849 Highest values are highlighted in bold. MCC: Matthew’s correlation coefficient; AUC: area under the curve. Table 2 Per-mouse performance metrics on validation and test sets of the five highest-performing models. Model Accuracy Scaled MCC AUC F1 irradiated F1 control AvgScore  Validation EfficientNet B1 0.940 0.946 0.972 0.939 0.939 0.947 EfficientNet B6  0.957  0.961  0.994  0.946  0.961  0.964 EfficientNet B0 0.948 0.954 0.983 0.945 0.946 0.955 EfficientNet S 0.942 0.947 0.983 0.936 0.945 0.951 EfficientNet B3 0.933 0.940 0.989 0.930 0.931 0.945  Test EfficientNet B1 0.897 0.897 0.981 0.889 0.903 0.913 EfficientNet B6  0.966  0.967  1.000 0.963  0.968  0.973 EfficientNet B0 0.931 0.935 0.971 0.933 0.929 0.940 EfficientNet S  0.966  0.967 0.986  0.966 0.966 0.970 EfficientNet B3  0.966  0.967 0.995  0.966 0.966 0.972 Highest values are highlighted in bold. MCC: Matthew’s correlation coefficient; AUC: area under the curve. Since the EfficientNet B3 model achieved the highest per-slice test AvgScore and its per-mouse test performance was comparable with other top-performing models, it was selected for toxicity and explainability analysis. Early toxicity correlations All investigated toxicity endpoints were correlated with the predicted probability, with absolute phi-K and Spearman correlation coefficients exceeding 0.69 ( Figure 2 p Figure 2 Relationships between model-predicted probability of the irradiated class and toxicity endpoints. Spearman’s (R Spearman Phi-K Model explainability results VarGrad heatmaps showed that voxels within the mouth and throat (irradiated region) contributed more to the model predictions than non-irradiated regions (brain and nape), with substantially higher VarGrad values across most MR slices, particularly in the central slices ( Figure 3 Figure 3 Figure 4 p p Figure 3 Line plots showing changes in the mean VarGrad values within the brain & nape regions of interest (ROIs; blue) and the mouth & throat ROIs (red) across all image slices for each mouse in the control group (top row) and irradiated group (second row). The two bottom rows display two example T2-weighted (T2w) MR image slices (left), corresponding to the points marked by circles and triangles in the line plots. The corresponding explainability heatmaps, based on normalized VarGrad values (color bar), are shown both as standalone maps (center column) and overlaid on the corresponding T2w slices (right column). Pixels with higher VarGrad values indicate greater contribution to the model’s prediction. Two ROIs are highlighted: non-irradiated areas (brain and nape) in blue, and irradiated areas (mouth and throat) in red. MR: Magnetic Resonance. Figure 4 Mean VarGrad values for each mouse across three regions of interest: brain & nape (blue), mouth & throat (red) and background (green). Error bars represent the 25th and 75th percentiles. Statistical analysis using the Mann–Whitney U test confirmed significant differences in VarGrad values between the three regions (p < 0.00001), indicating clear distinctions in model prediction contribution across anatomical areas within the MR images. MR: Magnetic Resonance. Discussion and conclusion This study demonstrates that CNN models can distinguish between control and irradiated mice using MR images acquired 3–5 days post-irradiation. The best-performing model achieved a per-slice test ACC of 83% and correctly classified 28 out of 29 mice, indicating that subtle radiation-induced tissue changes, undetectable to the human eye but captured in T2w images, can be identified by deep learning. Furthermore, the model’s predicted class probabilities showed strong correlations with two early (8–35 days post-irradiation) and three late (105 days) toxicity endpoints, where higher probabilities of the irradiated class were associated with more severe toxicities. These findings indicate that the model’s predictions reflect tissue toxicity, suggesting that early post-irradiation MR images combined with deep learning may support future toxicity risk assessment. Explainability analyses further reinforced the model’s validity, as importance heatmaps revealed that the CNNs predominantly focused on irradiated regions, with VarGrad values consistently higher in these areas compared to non-irradiated tissue. This pattern suggests that the models learned biologically meaningful image features rather than relying on spurious correlations. This work builds upon a previous study [ 17 37 Supplementary Table D2 Various artificial intelligence models have been developed to predict radiation-induced toxicity [ 4 38 39 9 40 41 42 9 A few studies have explored changes in medical images during treatment. van Dijk et al. [ 43 44 45 The most apparent limitation of this study is the small sample size (29 mice), which required dividing the data into smaller units, sagittal slices, for model development and analysis. As a result, 2D CNN models were used instead of 3D models, despite the 3D structure of the MR images. However, the use of 2D models allowed for the application of transfer learning with pretrained models, which may have improved model performance given the limited dataset. Another limitation is that only a single explainability method (VarGrad) was investigated. Further investigation of additional model explainability techniques such as LIME [ 46 47 48 49 In conclusion, this study demonstrates the potential of CNN models to detect radiation-induced changes to normal tissue in early post-RT MR images. Strong correlations were found between model predictions and early and late toxicity endpoints, suggesting that early post-therapy MRI features could serve as a proxy for toxicity. These findings support the feasibility of using deep learning on post-treatment medical imaging for early toxicity risk assessment, with implications for future clinical translation. Supplementary Material Acknowledgements This work was supported by the South-Eastern Norway Regional Health Authority, grant number 2023107, and by UiO Life Science at the University of Oslo, grant reference 2018/10221. BIGART 2025 was financially supported by the Acta Oncologica Foundation. Disclosure statements The authors report there are no competing interests to declare. Data availability statement The data that support the findings of this study are available from Prof. Eirik Malinen ( eirik.malinen@fys.uio.no Ethics declarations & trial registry information All experimental procedures were approved by the Norwegian Food Safety Authority (approval ID 27931) and conducted in compliance with Directive 2010/63/EU on the protection of animals used for scientific purposes. Author contributions All authors conceptualized, validated, reviewed, edited and approved the final manuscript. BNH, MK, CMF, OT and EM designed the methodology. BNH prepared the datasets, implemented the models, analyzed and visualized the results and wrote the original draft. MK, OZ, ISJ and NE curated data. CMF, OT, EN and EM supervised and provided resources. EM acquired funding. References [1] Van den Bosch L van der Schaaf A van der Laan HP Hoebers FJP Wijers OB van den Hoek JGM et al Comprehensive toxicity risk profiling in radiation therapy for head and neck cancer: a new concept for individually optimised treatment Radiother Oncol 2021 157 147 54 10.1016/j.radonc.2021.01.024 33545258 [2] van der Laan HP Van den Bosch L Schuit E Steenbakkers RJHM van der Schaaf A Langendijk JA Impact of radiation-induced toxicities on quality of life of patients treated for head and neck cancer Radiother Oncol 2021 160 47 53 10.1016/j.radonc.2021.04.011 33892023 [3] Hunter M Kellett J Toohey K D’Cunha NM Isbel S Naumovski N Toxicities caused by head and neck cancer treatments and their influence on the development of malnutrition: review of the literature Eur J Investig Health Psychol Educ 2020 10 4 935 49 10.3390/ejihpe10040066 PMC8314324 34542427 [4] Isaksson LJ Pepa M Zaffaroni M Marvaso G Alterio D Volpe S et al Machine learning-based models for prediction of toxicity outcomes in radiotherapy Front Oncol 2020 10 790 10.3389/fonc.2020.00790 32582539 PMC7289968 [5] Pota M Scalco E Sanguineti G Farneti A Cattaneo GM Rizzo G et al Early prediction of radiotherapy-induced parotid shrinkage and toxicity based on CT radiomics and fuzzy classification Artif Intell Med 2017 81 41 53 10.1016/j.artmed.2017.03.004 28325604 [6] Kawamura M Yoshimura M Asada H Nakamura M Matsuo Y Mizowaki T A scoring system predicting acute radiation dermatitis in patients with head and neck cancer treated with intensity-modulated radiotherapy Radiat Oncol 2019 14 1 14 10.1186/s13014-019-1215-2 30665451 PMC6341605 [7] Samant P de Ruysscher D Hoebers F Canters R Hall E Nutting C et al Machine learning for normal tissue complication probability prediction: predictive power with versatility and easy implementation Clin Transl Radiat Oncol 2023 39 100595 10.1016/j.ctro.2023.100595 36880063 PMC9984444 [8] Carbonara R Bonomo P Di Rito A Didonna V Gregucci F Ciliberti MP et al Investigation of radiation-induced toxicity in head and neck cancer patients through radiomics and machine learning: a systematic review J Oncol 2021 2021 1 9 10.1155/2021/5566508 PMC8211491 34211551 [9] Khajetash B Mahdavi SR Nikoofar A Johnson L Tavakoli M Ensemble learning approach for prediction of early complications after radiotherapy for head and neck cancer using CT and MRI radiomic features Sci Rep 2025 15 1 14229 10.1038/s41598-025-93676-0 40274870 PMC12022137 [10] Lambin P Leijenaar RTH Deist TM Peerlings J de Jong EEC van Timmeren J et al Radiomics: the bridge between medical imaging and personalized medicine Nat Rev Clin Oncol 2017 14 12 749 62 10.1038/nrclinonc.2017.141 28975929 [11] Zwanenburg A Radiomics in nuclear medicine: robustness, reproducibility, standardization, and how to avoid data analysis traps and replication crisis Eur J Nucl Med Mol Imaging 2019 46 13 2638 55 10.1007/s00259-019-04391-8 31240330 [12] Afshar P Mohammadi A Plataniotis KN Oikonomou A Benali H From handcrafted to deep-learning-based cancer radiomics: challenges and opportunities IEEE Sig Process Mag 2019 36 4 132 60 10.1109/msp.2019.2900993 [13] Reyes M Meier R Pereira S Silva CA Dahlweid F-M von Tengg-Kobligk H et al On the interpretability of artificial intelligence in radiology: challenges and opportunities Radiol Artif Intell 2020 2 3 e190043 10.1148/ryai.2020190043 32510054 PMC7259808 [14] Hooker S Erhan D Kindermans PJ Kim B A benchmark for interpretability methods in deep neural networks Advances in neural information processing systems 2019 32 9737 9748 [15] Schlaak RA SenthilKumar G Boerma M Bergom C Advances in preclinical research models of radiation-induced cardiac toxicity Cancers 2020 12 2 415 10.3390/cancers12020415 32053873 PMC7072196 [16] Tillner F Thute P Bütof R Krause M Enghardt W Pre-clinical research in small animals using radiotherapy technology – a bidirectional translational approach Z Med Phys 2014 24 4 335 51 10.1016/j.zemedi.2014.07.004 25125191 [17] Kakar M Huynh BN Zlygosteva O Juvkam IS Edin N Tomic O et al Attention-based vision transformer enables early detection of radiotherapy-induced toxicity in magnetic resonance images of a preclinical model Technol Cancer Res Treat 2025 24 15330338251333018 10.1177/15330338251333018 40183426 PMC11970093 [18] Belgioia L Morbelli SD Corvò R Prediction of response in head and neck tumor: focus on main hot topics in research Front Oncol 2021 10 604965 10.3389/fonc.2020.604965 33489911 PMC7821385 [19] Juvkam IS Zlygosteva O Arous D Galtung HK Malinen E Søland TM et al A preclinical model to investigate normal tissue damage following fractionated radiotherapy to the head and neck J Radiat Res 2023 64 1 44 52 10.1093/jrr/rrac066 36253091 PMC9855321 [20] Zlygosteva O Juvkam IS Arous D Sitarz M Sørensen BS Ankjærgaard C et al Acute normal tissue responses in a murine model following fractionated irradiation of the head and neck with protons or X-rays Acta Oncol 2023 62 11 1574 80 10.1080/0284186x.2023.2254481 37703217 [21] Juvkam IS Zlygosteva O Sitarz M Sørensen BS Aass HCD Edin NJ et al Proton- compared to X-irradiation leads to more acinar atrophy and greater hyposalivation accompanied by a differential cytokine response Sci Rep 2024 14 1 22311 10.1038/s41598-024-73110-7 39333378 PMC11437014 [22] Zlygosteva O Juvkam IS Aass HCD Galtung HK Søland TM Malinen E et al Cytokine levels in saliva are associated with salivary gland fibrosis and hyposalivation in mice after fractionated radiotherapy of the head and neck Int J Mol Sci 2023 24 20 15218 10.3390/ijms242015218 37894899 PMC10607825 [23] Percie du Sert N Hurst V Ahluwalia A Alam S Avey MT Baker M et al The ARRIVE guidelines 2.0: updated guidelines for reporting animal research BMC Vet Res 2020 16 1 242 10.1186/s12917-020-02451-y 32660541 PMC7359286 [24] Huang L-K Wang M-JJ Image thresholding by minimizing the measures of fuzziness Pattern Recognit 1995 28 1 41 51 10.1016/0031-3203(94)e0043-k [25] Beare R Histogram-based thresholding – some missing methods Insight J 2011 Jan-Jun 3279 3284 10.54294/efycla [26] Diehl PU Neil D Binas J Cook M Liu S-C Pfeiffer M Fast-classifying, high-accuracy spiking deep networks through weight and threshold balancing 2015 International Joint Conference on Neural Networks (IJCNN) 2015 1 8 10.1109/ijcnn.2015.7280696 [27] Howard AG Zhu M Chen B Kalenichenko D Wang W Weyand T et al Mobilenets: efficient convolutional neural networks for mobile vision applications arXiv preprint arXiv 170404861 2017 [28] Wu Z Shen C van den Hengel A Wider or deeper: revisiting the ResNet model for visual recognition Pattern Recognit 2019 90 119 33 10.1016/j.patcog.2019.01.006 [29] Tan M Le Q Efficientnet: Rethinking model scaling for convolutional neural networks International conference on machine learning 2019 May 24 held in Long Beach, California, USA 6105 6114 PMLR 97 [30] Deng J Dong W Socher R Li L-J Kai L Li F-F ImageNet: a large-scale hierarchical image database 2009 IEEE Conference on Computer Vision and Pattern Recognition 2009. p. 248 55 10.1109/cvpr.2009.5206848 [31] Cawley GC Talbot NL On over-fitting in model selection and subsequent selection bias in performance evaluation J Machine Learn Res 2010 11 2079 107 [32] Huynh BN Groendahl AR Tomic O Liland KH Knudtsen IS Hoebers F et al Head and neck cancer treatment outcome prediction: a comparison between machine learning with conventional radiomics features and deep learning radiomics Front Med 2023 10 1217037 10.3389/fmed.2023.1217037 PMC10498924 37711738 [33] Adebayo J Gilmer J Muelly M Goodfellow I Hardt M Kim B Sanity checks for saliency maps Adv Neural Inform Process Syst 2018 31 9505 9515 [34] Spearman C The proof and measurement of association between two things Am J Psychol 1904 15 1 72 101 10.2307/1412159 3322052 [35] Baak M Koopman R Snoek H Klous S A new correlation coefficient between categorical, ordinal and interval variables with Pearson characteristics Comput Statist Data Anal 2020 152 107043 10.1016/j.csda.2020.107043 [36] McKnight PE Najab J Mann‐whitney U test The Corsini encyclopedia of psychology 2010 Jan 30 1 1 10.1002/9780470479216.corpsy0524 [37] Sagi O Rokach L Ensemble learning: a survey Wiley Interdiscipl Rev Data Mining Knowl Discov 2018 8 5 e1249 10.1002/widm.1249 [38] Zhen X Chen J Zhong Z Hrycushko B Zhou L Jiang S et al Deep convolutional neural network with transfer learning for rectum toxicity prediction in cervical cancer radiotherapy: a feasibility study Phys Med Biol 2017 62 21 8246 63 10.1088/1361-6560/aa8d09 28914611 [39] Araújo ALD Moraes MC Pérez-de-Oliveira ME da Silva VM Saldivia-Siracusa C Pedroso CM et al Machine learning for the prediction of toxicities from head and neck cancer treatment: a systematic review with meta-analysis Oral Oncol 2023 140 106386 10.1016/j.oraloncology.2023.106386 37023561 [40] van Dijk LV Noordzij W Brouwer CL Boellaard R Burgerhof JGM Langendijk JA et al 18F-FDG PET image biomarkers improve prediction of late radiation-induced xerostomia Radiother Oncol 2018 126 1 89 95 10.1016/j.radonc.2017.08.024 28951007 [41] Sheikh K Lee SH Cheng Z Lakshminarayanan P Peng L Han P et al Predicting acute radiation induced xerostomia in head and neck cancer using MR and CT radiomics of parotid and submandibular glands Radiat Oncol 2019 14 1): 131 10.1186/s13014-019-1339-4 31358029 PMC6664784 [42] van Dijk LV Thor M Steenbakkers RJHM Apte A Zhai T-T Borra R et al Parotid gland fat related magnetic resonance image biomarkers improve prediction of late radiation-induced xerostomia Radiother Oncol 2018 128 3 459 66 10.1016/j.radonc.2018.06.012 29958772 PMC6625348 [43] van Dijk LV Langendijk JA Zhai T-T Vedelaar TA Noordzij W Steenbakkers RJHM et al Delta-radiomics features during radiotherapy improve the prediction of late xerostomia Sci Rep 2019 9 1 12483 10.1038/s41598-019-48184-3 31462719 PMC6713775 [44] Liu Y Shi H Huang S Chen X Zhou H Chang H et al Early prediction of acute xerostomia during radiation therapy for nasopharyngeal cancer based on delta radiomics from CT images Quant Imaging Med Surg 2019 9 7 1288 302 10.21037/qims.2019.07.08 31448214 PMC6685806 [45] Kapoor R Sleeman W Palta J Weiss E 3D deep convolution neural network for radiation pneumonitis prediction following stereotactic body radiotherapy J Appl Clin Med Phys 2022 24 3 e13875 10.1002/acm2.13875 36546583 PMC10018674 [46] Ribeiro MT Singh S Guestrin C Why should I trust you? Proceedings of the 22nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining 2016. p. 1135 44 10.1145/2939672.2939778 [47] Lundberg SM Lee S-I A unified approach to interpreting model predictions Adv Neural Inform Process Syst 2017 30 4765 4774 [48] Kirillov A Mintun E Ravi N Mao H Rolland C Gustafson L et al Segment anything Proceedings of the IEEE/CVF international conference on computer vision Paris, France, on October 2-3 2023 4015 4026 IEEE [49] Zhang Y Shen Z Jiao R Segment anything model for medical image segmentation: current applications and future directions Comput Biol Med 2024 171 108238 10.1016/j.compbiomed.2024.108238 38422961 ",
  "metadata": {
    "Title of this paper": "Segment anything model for medical image segmentation: current applications and future directions",
    "Journal it was published in:": "Acta Oncologica",
    "URL": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC12490106/"
  }
}