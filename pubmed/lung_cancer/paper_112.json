{
  "title": "Paper_112",
  "abstract": "pmc NPJ Digit Med NPJ Digit Med 3605 npjdigitmed NPJ Digital Medicine 2398-6352 Nature Publishing Group PMC12488890 PMC12488890.1 12488890 12488890 41034564 10.1038/s41746-025-02004-3 2004 1 Article Large language models forecast patient health trajectories enabling digital twins Makarov Nikita 1 2 3 Bordukova Maria 1 2 3 Quengdaeng Papichaya 2 4 Garger Daniel 2 3 Rodriguez-Esteban Raul 5 Schmich Fabian fabian.schmich@roche.com 1 Menden Michael P. michael.menden@unimelb.edu.au 2 6 1 https://ror.org/00sh68184 grid.424277.0 Roche Innovation Center Munich (RICM), 2 3 https://ror.org/05591te55 grid.5252.0 0000 0004 1936 973X Department of Biology, Ludwig Maximilian University of Munich, 4 https://ror.org/02kkvpp62 grid.6936.a 0000 0001 2322 2966 TUM School of Computation, Information and Technology, Technical University of Munich, 5 https://ror.org/00by1q217 grid.417570.0 0000 0004 0374 1269 Roche Innovation Center Basel (RICB), 6 https://ror.org/01ej9dk98 grid.1008.9 0000 0001 2179 088X Department of Biochemistry and Pharmacology, Bio21 Molecular Science and Biotechnology Institute, The University of Melbourne, 1 10 2025 2025 8 478273 588 5 5 2025 13 9 2025 01 10 2025 03 10 2025 03 10 2025 © The Author(s) 2025 2025 https://creativecommons.org/licenses/by/4.0/ Open Access http://creativecommons.org/licenses/by/4.0/ Generative artificial intelligence is revolutionizing digital twin development, enabling virtual patient representations that predict health trajectories, with large language models (LLMs) showcasing untapped clinical forecasting potential. We developed the Digital Twin—Generative Pretrained Transformer (DT-GPT), extending LLM-based forecasting solutions to clinical trajectory prediction. DT-GPT leverages electronic health records without requiring data imputation or normalization and overcomes real-world data challenges such as missingness, noise, and limited sample sizes. Benchmarking on non-small cell lung cancer, intensive care unit, and Alzheimer’s disease datasets, DT-GPT outperformed state-of-the-art machine learning models, reducing the scaled mean absolute error by 3.4%, 1.3% and 1.8%, respectively. It maintained distributions and cross-correlations of clinical variables, and demonstrated explainability through a human-interpretable interface. Additionally, DT-GPT’s ability to perform zero-shot forecasting highlights potential advantages of LLMs as clinical forecasting platforms, proposing a path towards digital twin applications in clinical trials, treatment selection, and adverse event mitigation. Subject terms Computational biology and bioinformatics Computational models Data processing Machine learning Predictive medicine Biomarkers Outcomes research F. Hoffmann-La Roche AG European Union's Horizon 2020 Research and Innovation Programme 950293 - COMBAT-RES 950293 - COMBAT-RES pmc-status-qastatus 0 pmc-status-live yes pmc-status-embargo no pmc-status-released yes pmc-prop-open-access yes pmc-prop-olf no pmc-prop-manuscript no pmc-prop-legally-suppressed no pmc-prop-has-pdf yes pmc-prop-has-supplement yes pmc-prop-pdf-only no pmc-prop-suppress-copyright no pmc-prop-is-real-version no pmc-prop-is-scanned-article no pmc-prop-preprint no pmc-prop-in-epmc yes issue-copyright-statement © Springer Nature Limited 2025 Introduction Clinical forecasting involves predicting patient-specific health outcomes and clinical events over time, which is essential for patient monitoring, treatment selection, and drug development 1 2 3 3 4 2 4 5 Digital twins offer a comprehensive framework for patient modeling by integrating diverse data streams, which can include history of medical examinations, diagnoses and treatments, deep molecular profiling, lifestyle and environmental factors, as well as general biomedical knowledge 6 8 4 3 4 Generative artificial intelligence (AI) holds promise for creating digital twins due to its potential to produce synthetic yet realistic data, but this area of application is still in its infancy 4 9 13 14 15 Recent breakthroughs in generative AI have been achieved with foundation models, which are pre-trained AI models adaptable to various specific tasks involving different types of data. Most foundation models for patient forecasting focus on single-point predictions rather than comprehensive longitudinal patient trajectories, which are needed for clinical decision-making 16 17 18 19 20 22 LLM-based forecasting has made great progress in general forecasting. However, some common methods, such as LSTPrompt 20 21 22 23 We propose the creation of digital twins based on LLMs that leverage data from electronic health records (EHRs) from real world data (RWD) and observational studies. EHRs are a key source of training data for machine learning models in healthcare, as they record patient characteristics such as demographics, diagnoses, and lab results over time 24 16 10 13 We hypothesize that LLMs will empower the next generation of digital twins in healthcare. Here, we introduce the Digital Twin - Generative Pretrained Transformer (DT-GPT) model (Fig. 1 Fig. 1 The LLM-based DT-GPT framework enables forecasting patient trajectories, identifying key variables, and zero-shot predictions. Here exemplified, a b c d e f enables: (i) forecasting of clinical variable trajectories, (ii) zero-shot predictions of clinical variables not previously trained on, and (iii) preliminary interpretability utilizing chatbot functionalities. DT-GPT is an extension of previous LLM-based forecasting solutions, based on fine-tuning LLMs on clinical data using a straightforward data encoding scheme. The method is designed to solve clinically specific issues, be model-agnostic and to be applied to any text-focused LLM without any further architectural changes. Results We analyzed the performance of DT-GPT by forecasting various clinical values on diverse datasets, including on a short-term scale (next 24 h) for Intensive Care Unit (ICU) patients, a medium-term scale (up to 13 weeks) for non-small cell lung cancer (NSCLC) patients, as well as a long-term Alzheimer’s Disease dataset (next 24 months). The ICU dataset is based on Medical Information Mart for Intensive Care IV (MIMIC-IV) 25 1 4 1 1 5 1 DT-GPT achieved state-of-the-art forecasting performance DT-GPT achieved the lowest overall scaled mean absolute error (MAE) across benchmark tasks in comparison with state-of-the-art models (Table 1 26 27 28 Table 1 Benchmark of clinical variable forecasting across three datasets Scaled mean absolute error Model Non-small cell lung cancer (NSCLC) Intensive care unit Alzheimer’s disease Hemoglobin Leukocytes Lymphocytes/ Leukocytes Lymphocytes Neutrophils Lactate Dehydrogenase Magnesium Resp. Rate Oxygen Saturation MMSE CDR-SB ADAS11 Channel-Independent Input Copy Forward 0.698 0.969 0.731 0.569 0.974 0.433 0.681 0.769 0.746 0.654 0.539 0.519 PatchTST 0.684 0.968 0.719 0.560 0.959 0.447 0.671 0.635 0.646 0.654 0.540 0.506 Time-LLM 0.665 0.894 0.684 0.544 0.878 0.443 0.664 0.655 0.665 0.654 0.540 0.506 LLMTime 0.736 0.923 0.725 0.601 0.900 0.437 0.759 0.686 0.688 0.654 0.539 0.503 Channel-Dependent Input BioMistral-7B 0.984 1.097 0.756 0.997 1.953 0.600 0.790 0.770 0.945 2.064 0.883 0.728 Qwen3-32B 0.670 0.942 0.736 0.573 0.937 0.453 0.709 0.720 0.791 0.686 0.546 0.555 TCN 0.660 0.857 0.752 0.606 0.832 0.731 0.612 0.713 0.726 Not Applicable  Not Applicable  Not Applicable Linear Regression 0.486 0.782 0.668 0.506 0.778 0.475 0.606 0.680 0.681 0.551 0.449 0.457 RNN 0.529 0.806 0.671 0.511 0.801 0.433 0.597 0.647 0.674 0.545 0.463 0.465 Transformer 0.496 0.749 0.683 0.503 0.741 0.514 0.537 0.644 0.651 0.553 0.485 0.481 LSTM 0.526 0.781 0.665 0.495 0.764 0.441 0.567 0.643 0.642 0.545 0.468 0.475 Temporal Fusion Transformer 0.469 0.719 0.651 0.463 0.717 0.480 0.537 0.635 0.644 0.520 0.451 0.466 TiDE 0.464 0.737 0.655 0.465 0.740 0.453 0.534 0.635 0.652 0.578 0.498 0.506 LightGBM 0.453 0.727 0.644 0.456 0.734 0.425 0.520 0.634 0.644 0.540 0.455 0.462 DT-GPT (ours) 0.439 0.687 0.643 0.434 0.701 0.418 0.505 0.636 0.635 0.535 0.417 0.458 DT-GPT outperformed the baselines in the majority of cases of the non-small cell lung cancer (NSCLC), intensive-care unit (ICU), and Alzheimer’s disease dataset. All errors refer to mean absolute error (MAE; lower is better) scaled by standard deviation. We compared DT-GPT to 14 multi-step, multivariate baselines, ranging from a naïve model that copies over the last observed value to state-of-the-art forecasting models. These included linear regression model, time series LightGBM model, Temporal Fusion Transformer (TFT), Temporal Convolutional Network (TCN), Recurrent Neural Network (RNN), Long Short-Term Memory (LSTM), Transformer, and Time-series Dense Encoder (TiDE) model 12 29 30 31 32 33 34 21 22 35 On the NSCLC dataset, DT-GPT achieved an average scaled MAE of 0.55 ± 0.04, whilst LightGBM, the second best model, achieved an average scaled MAE of 0.57 ± 0.05, showing a relative improvement of 3.4% (Table 1 1 6 17 p −17 2 18 19 1 2 Channel-independent models, such as LLMTime, Time-LLM and PatchTST, perform worse with respect to scaled MAE on variables that are more sparse and correlate less with other time series. Inversely, we see that the channel-independent models perform relatively better on respiratory rate and oxygen saturation, which have generally more dense measurements and are less correlated to time series such as treatment, in comparison, for example, to neutrophils in NSCLC. The LLMs without fine-tuning performed significantly worse than DT-GPT, often incorrectly hallucinating results. DT-GPT outperformed BioMistral by 47.9%, 29.1% and 61.1%, and outperformed the larger Qwen3-32B model by 22.9%, 19.9% and 21.1% on NSCLC, ICU and Alzheimer’s disease datasets, respectively. To comprehensively evaluate DT-GPT, we assessed a range of metrics, including derived classification metrics (“Methods”). DT-GPT consistently performed well across various metrics, capturing trajectory trends effectively (Supplementary Tables 6 17 6 11 2 DT-GPT shows strong potential in capturing clinically relevant lab trends but has limitations in predicting specific critical events. For example, DT-GPT struggled with forecasting critically low hemoglobin levels ( < 7.5 g/dL; ROC AUC = 0.506), likely due to their low prevalence (1.2%; Methods; Supplementary Tables 6 11 2 Notably, DT-GPT demonstrated robust predictive performance across several routine yet clinically informative laboratory parameters. This includes detection of mild anemia (hemoglobin below reference; ROC AUC = 0.793) and elevated LDH (lactate dehydrogenase; >222 U/L; ROC AUC = 0.793), a marker of NSCLC progression 36 AUCs = 0.704/0.638) and rising leukocytes, lymphocytes, and neutrophils suggestive of inflammation (ROC AUCs = 0.65–0.68) 37 DT-GPT forecasts preserved inter-variable relationships. The correlations between the variables forecasted by DT-GPT aligned with the correlations between the variables in the test datasets with an R 2 2 3 2a, b 2 Fig. 2 DT-GPT achieves state-of-the-art performance for clinical trajectory forecasting. a b c d e DT-GPT can be further improved by utilising alternative trajectory aggregation methods. To inspect both low and high MAE predictions from DT-GPT, we visualized two sample individual-patient forecasts for the variable neutrophils (Fig. 2c, d 2e It is important to note that the final prediction was derived by averaging 30 generated trajectories and that, even in poor performing cases, individual non-averaged forecasted trajectories sometimes succeeded in capturing aspects of the true trajectory. To assess the impact of trajectory aggregation, we calculated the error given an optimal aggregation. To this end, we selected the individual trajectories with the lowest scaled MAE and recalculated the hypothetical scaled MAE on the NSCLC dataset, achieving a 26% improvement in error to 0.40 ± 0.02, without any further model training, noting that this is a theoretical lower bound. Finally, we observed that in the distribution of scaled MAE for neutrophils across all patients, most of the errors were right-skewed, indicating that high errors came from a small number of patients with likely uncommon trajectories (Fig. 2e DT-GPT preserves the overall distribution of target variables—a property that, while not sufficient, is arguably necessary for clinically meaningful forecasting. To assess this, we computed the Kolmogorov–Smirnov (KS) statistic across all target variables in the NSCLC cohort, comparing predicted and true distributions (Fig. 3a Fig. 3 DT-GPT resembles the distribution of the original data. a b c d e indicating the best distributional alignment. Notably, several recent baselines, including TiDE, TCN, and TFT, struggled with the distribution modeling. We also visualized the distributions of the ground truth (Fig. 3b 3c 3d 3e DT-GPT is robust to common RWD challenges DT-GPT is flexible and robust to common practical data challenges, exhibiting desired properties in a variety of ablation studies, here exemplified on the average performance on all six clinical variables of the NSCLC dataset. First, DT-GPT performance was competitive with baselines after training with data corresponding to 5000 patients and it further improved with the number of patients in the training dataset (Fig. 4a 1 20 4b 4c Fig. 4 DT-GPT is robust to common RWD issues in the long-term NSCLC dataset. a b c DT-GPT enables prediction insights and zero-shot forecasting DT-GPT retains its conversational capability post-fine-tuning for the forecasting task, facilitating user interaction and enabling the inquiries into the reasoning behind predictions. For each patient sample, 10 predicted trajectories were generated, accompanied by a set of explanatory variables elucidating these predictions (Fig. 5a 5b 21 4 9 3 Fig. 5 DT-GPT preserves its conversational ability after the fine-tuning, allowing inquiring into prediction rationale and zero-shot forecasting. a b c d e f g h i Therapy emerged as a key determinant of hemoglobin dynamics, aligning with existing literature 38 39 5c 4 40 ECOG status also played a significant role in shaping hemoglobin trajectories. The last recorded ECOG value in a patient’s medical history was predictive of future hemoglobin levels (Fig. 5d 41 42 43 9 DT-GPT enables zero-shot forecasting of non-target clinical variables, expanding its applicability beyond fine-tuned predictions. It can forecast 69 non-target clinical variables that are recorded in patient medical histories but were not explicitly included during model fine tuning. In our experiments, we forecasted each non-target variable separately (Fig. 5e To benchmark DT-GPT’s zero-shot performance, we compared it against a traditional machine learning approach. We extensively trained 69 LightGBM models, each using data from over 13,000 patients for individual target variables, and compared their performance to a single DT-GPT model that received no such additional training (i.e., zero-shot setting) and therefore was at a disadvantage. LightGBM was therefore anticipated to perform better than the zero-shot DT-GPT model. Surprisingly, zero-shot DT-GPT outperformed LightGBM on 13 out of 69 non-target variables (Fig. 5f 5g segmented neutrophils band form neutrophils neutrophils by automated count neutrophils 22 We identified that DT-GPT performs better in zero-shot predictions for variables highly correlated with the fine-tuned targets. Specifically, 11 of 13 non-target variables for which DT-GPT demonstrates equal or superior performance compared to LightGBM, exhibit a strong Spearman correlation coefficient ( | ρ | > 0.7) with at least one fine-tuned target variable (Supplementary Fig. 10 11 23 44 46 Discussion Our main finding is that a simple yet effective method allows training LLMs on EHRs and study data to generate detailed patient trajectories that preserve inter-variable correlations. This method achieves state-of-the-art performance in clinical forecasting, while closely reproducing the distribution of original data and outperforming baselines in predicting clinically meaningful events in the trajectory. This highlights the potential of using LLMs as a digital twin platform that can mimic individual patients, with applications such as treatment selection and clinical trial support. Building on past LLM research in general forecasting, DT-GPT outperforms existing baselines 20 21 18 19 The positive performance of LLMs for patient forecasting may stem from parallels between natural language and biomedical data, such as non-random missingness. For example, a doctor might skip measuring blood pressure if a patient appears healthy, indicating information by omission. Natural language implicitly handles such ambiguity; unspoken words can still convey meaning or none at all. Recent advancements suggest that LLMs can capture these complex relationships 47 DT-GPT addresses EHR challenges including noise, sparsity, and lack of data normalization 16 DT-GPT can be inquired about the rationale of predictions, which increases the interpretability of the model. This capability helps bridge the gap between medical expert and model, enabling the exploration of prediction rationales and alternative patient scenarios efficiently. We believe that this advancement could enhance human-computer interaction with AI predictions and may positively affect clinical practices in the near future. DT-GPT enables zero-shot predictions, demonstrating its ability to forecast variables not explicitly included in its fine-tuning phase by learning their dynamics and adapting to novel tasks. Remarkably, zero-shot DT-GPT outperforms a supervised, fully-trained machine learning model on a subset of clinical variables, highlighting the pioneering potential of LLM-based approaches in RWD forecasting. Applying the preliminary interpretability approach also on the zero shot variables, we hypothesize that the model is potentially able to capture latent clinical knowledge, such as the importance of the ferritin-to-hemoglobin ratio and parts of the Albumin-Bilirubin (ALBI) score, both which are emerging prognostic biomarkers in NSCLC 45 46 DT-GPT shows promise for clinical trajectory forecasting, with strong performance on standard metrics (e.g., MAE) and robust modeling of temporal dependencies. It effectively detects moderate abnormalities such as anemia, tracks inflammation-related trends, and predicts progression markers such as elevated LDH. However, performance declines for specific acute events—e.g., severe hemoglobin drops or high leukocyte counts—highlighting the challenge of forecasting low-prevalence, high-variance outcomes. Future improvements will require methods that enhance sensitivity to high-risk events, such as tailored loss functions, anomaly detection, and integration of unstructured clinical data. A challenge of LLM-based models is the restricted number of simultaneously forecasted variables. The current constraint on the number of forecasted variables is due to the limited sequence length of both input and output of the LLMs used in fine-tuning. Advances in extending the context length will enable modeling of additional patient variables, such as by using larger, more advanced models such as Qwen3-32B as the base model. Furthermore, we anticipate that transitioning from zero-shot to few-shot learning, where the model receives further training on a small subset of data, would enable a wider span of forecasted variables and extend DT-GPT’s applicability to broader clinical challenges. Future work can also take inspiration from developments in LLM-based forecasting. Specifically, ideas such as patching and prompt-as-a-prefix from Time-LLM 22 21 Another established shortcoming of LLM-based models is their tendency to hallucinate, as well as recreating the biases from the underlying data. In our case, the hallucination could be reflected in explainability results not necessarily providing true answers. This is a critical aspect for the medical domain, and we believe that a human-in-the-loop setup will be required, together with advanced training of clinicians on the use of LLM outputs. Regarding model biases, it is well established that models recreate the biases from the underlying data, which is especially pronounced in minority populations 48 Finally, we observe that high error predictions often occur due to the high variance between the multiple generated trajectories of each patient sample, with the mean aggregation into the final prediction not capturing key dynamics. It is thus an open challenge to develop improved aggregation methods, for example by using a second LLM as an arbiter or by having a human expert select the most realistic trajectory. In conclusion, DT-GPT highlights the utility of using LLMs as a digital twin forecasting platform, enabling state-of-the-art and stable predictions, exploratory interpretability via a natural-language interface, and forecasting of patient variables not used in fine-tuning. Whilst further advancements are needed for wide-scale deployment, DT-GPT exhibits digital twin behaviors, potentially reproducing many aspects of the patients it represents, and surpassing traditional AI methods optimized for individual variables. We believe that through further method development and extensive validation, patient-level digital twins will impact clinical trials by supporting biomarker exploration, trial design, and interim analysis. Additionally, future digital twins will assist doctors in treatment selection and patient monitoring. Overall, we envision LLM-powered digital twins becoming integral to healthcare systems. Methods DT-GPT is a method that employs pre-trained LLMs fine-tuned on clinical data (Fig. 6a Fig. 6 The DT-GPT framework transforms EHRs into text and subsequently fine-tunes an LLM on this data. a b c d NSCLC dataset For the US-based NSCLC dataset, we used the nationwide Flatiron Health EHR-derived de-identified database. The data are de-identified and subject to obligations to prevent re-identification and protect patient confidentiality. The Flatiron Health database is a longitudinal database, comprising de-identified patient-level structured and unstructured data, curated via technology-enabled abstraction 49 50 The study included 16,496 patients diagnosed with NSCLC from 01 January 1991 to 06 July 2023. The majority of patients in the database originate from community oncology settings; relative community/academic proportions may vary depending on the study cohort. Patients with a birth year of 1938 or earlier may have an adjusted birth year in Flatiron Health datasets due to patient de-identification requirements. To harmonize the data, we aggregated all values in a week based on the last observed value. We focused on the 50 most common diagnoses and 80 most common laboratory measurements, complemented by the Eastern Cooperative Oncology Group (ECOG) score, metastases, vitals, drug administrations, response, and mortality variables totaling 773,607 patient-days across 320 variables. For every NSCLC patient, we divided their trajectory into input and output segments based on the start date of each line of therapy to create each patient sample. All variables up to the start date were considered input data. The objective was to predict the weekly values up to 13 weeks after the start date of the following variables and their respective LOINC codes: hemoglobin (718-7), leukocytes (26464-8), lymphocytes/leukocytes (26478-8), lymphocytes (26474-7), neutrophils (26499-4) and lactate dehydrogenase (2532-0). These variables were selected due to their frequent measurement and relevance in reflecting key characteristics of NSCLC treatment response (Supplementary Tables 1 2 ICU dataset To demonstrate the generalizability of DT-GPT, we analyzed ICU trajectories from the publicly-accessible Medical Information Mart for Intensive Care IV (MIMIC-IV) dataset 25 51 Here, the objective was to predict a patient’s future hourly lab variables given their first 24 h in the ICU. Specifically, the patient history was considered as the first 24 h for all variables, and the task was to forecast the future 24 hourly values for the following variables: O2 saturation pulse oximetry, respiratory rate and magnesium. These variables were selected due to having the highest temporal variability, thus making the forecasting task more challenging, and the fact that at least 50% of patients had at least one measurement for each, highlighting their widespread clinical usage (Supplementary Tables 1 3 4 Alzheimer’s disease dataset To further demonstrate the generalizability of DT-GPT, we ran DT-GPT and the baseline models on the Alzheimer’s disease dataset, based on the Alzheimer’s Disease Neuroimaging Initiative (ADNI) database ( adni.loni.usc.edu We preprocessed the dataset, including 1140 patients. The task was to predict the 24 month trajectory of three cognitive variables, given the baseline measurements of the patients. Specifically, the variables were Mini Mental State Examination (MMSE), Clinical Dementia Rating sum of boxes (CDR-SB) and Alzheimer’s Disease Assessment Scale (ADAS11), which are key indicators of cognitive decline commonly measured in Alzheimer’s disease patients (Supplementary Tables 1 5 Data splitting and filtering The NSCLC and ICU datasets were split at the patient level into 80% training, 10% validation, and 10% test set. The splitting was performed randomly for the ICU dataset, whilst stratified by group stage, smoking status, number of observations per visit and number of visits with drug administrations to ensure a balanced evaluation. The Alzheimer’s disease dataset was randomly split into 80% training and 20% test, selected due to the small sample size, with all hyperparameters determined via a further splitting on the training set. Thus, each set comprised disjoint sets of patients to avoid data leakage. The test sets were solely used for final evaluation and to assess the model’s generalizability (Fig. 6b We applied a two-step outlier filtering procedure on all datasets: all target values below or above three standard deviations were filtered out first, then we calculated new standard deviation values on the filtered dataset and clipped target values below and above those values. This approach ensured that the noise present in the data was removed, while some of the outliers were replaced with reasonable low or high values to maintain the biological signal. The data for all of the baselines excluding DT-GPT were then also standardized using z-scores. Encoding We encoded patient trajectories by using templates that converted medical histories based on EHRs into a text format compatible with LLMs, as proposed by Xue et al. 19 19 20 6c, d 4 12 LLMs and fine-tuning We utilized the biomedical LLM BioMistral 7B DARE, since it is provided with an open source license and based on a recognized LLM 33 21 52 5 6 Handling of missing and noise data We investigated the ability of DT-GPT as a LLM-based model to handle missing data and misspelling in the input prompts. For the missing data study, we randomly masked between 0 and 80% of data, in addition to the already missing data in a dataset. Evaluation of the effect of missingness was performed on a randomly sampled 200 patients from the test set, which can potentially lead to higher variance in the results, but allowed for a more extensive exploration. For the noise study, we introduce a misspelling algorithm. This algorithm randomly performs either perturbation, insertion, deletion, or replacement, using all ASCII letters & digits, applied to the entire input text. This includes dates, variable names, values, baseline information, and prompts. One operation is considered one misspelling. For the evaluation of the effects of RWD missingness and noise we randomly sampled 200 patients of the test set, which can potentially lead to higher variance in the results, but allowed for a more extensive exploration. Chatbot and zero-shot learning We employed the DT-GPT model to run a chatbot based on patient histories for prediction explanation and zero-shot forecasting. For this, first we used DT-GPT to generate forecasting results from patient history and, consecutively, added a task-specific prompt surrounded by the respective instruction-indication tokens to the DT-GPT chat history for receiving a response. For prediction explanation, the prompt asked for the most important variables influencing the predicted trajectory. For zero-shot forecasting, the prompt specified the output format and days to predict new clinical variables that were not subject to optimization during training. Example prompts and chatbot interactions for both tasks are provided in Supplementary Note 7 5a, e Forecasting evaluation Forecasting metrics, i.e. Eqs. ( 1 5 8 \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$${{v}_{t}}^{(i)}$$\\end{document} v t ( i ) \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$v$$\\end{document} v \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$i$$\\end{document} i \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$i=1,\\cdots ,n$$\\end{document} i = 1 , ⋯ , n \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$n$$\\end{document} n \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$t$$\\end{document} t \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$t=1,\\cdots ,{T}_{i}$$\\end{document} t = 1 , ⋯ , T i \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$${T}_{i}$$\\end{document} T i \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$i$$\\end{document} i \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$${v}_{0}^{(i)}$$\\end{document} v 0 ( i ) \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$${t}_{0}$$\\end{document} t 0 \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$t=0$$\\end{document} t = 0 \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$${\\hat{v}}_{t}^{(i)}$$\\end{document} v ˆ t ( i ) 1 \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$${MAE}=\\frac{1}{n}\\mathop{\\sum }\\limits_{i=1}^{n}\\frac{1}{{T}_{i}}\\mathop{\\sum }\\limits_{t=1}^{{T}_{i}}|{v}_{t}^{(i)}-{\\hat{v}}_{t}^{(i)}|$$\\end{document} MAE = 1 n ∑ i = 1 n 1 T i ∑ t = 1 T i | v t ( i ) − v ˆ t ( i ) | 2 \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$${scaled\\; MAE}=\\frac{{MAE}}{\\sigma }$$\\end{document} scaled MAE = MAE σ \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$\\sigma$$\\end{document} σ 3 \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$${MASE}=\\frac{{MAE}}{\\,\\frac{1}{n}{\\sum }_{i=1}^{n}\\frac{1}{{T}_{i}}{\\sum }_{t=1}^{{T}_{i}}|{v}_{t}^{(i)}-{v}_{0}^{(i)}|}$$\\end{document} MASE = MAE 1 n ∑ i = 1 n 1 T i ∑ t = 1 i | v t ( i ) − v 0 ( i ) | 4 \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$${SMAPE}=\\frac{200}{n}\\mathop{\\sum }\\limits_{i=1}^{n}\\frac{1}{{T}_{i}}\\mathop{\\sum }\\limits_{t=1}^{{T}_{i}}\\frac{{|{{v}_{t}}^{(i)}\\,-{{\\,\\hat{v}}_{t}}^{(i)}|}}{|{v}_{t}^{(i)}|+|{\\hat{v}}_{t}^{(i)}|}{\\mathbb{1}_{\\{|v_t^{(i)}| + |\\hat{v}_t^{(i)}| \\neq 0\\}}}$$\\end{document} S M A P E = 200 n ∑ i = 1 n 1 T i ∑ t = 1 T i ∣ v t ( i ) − v ^ t ( i ) ∣ ∣ v t ( i ) ∣ + ∣ v ^ t ( i ) ∣ 1 { ∣ v t ( i ) ∣ + ∣ v ^ t ( i ) ∣ ≠ 0 } \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$${\\mathbb{1}}$$\\end{document} 1 5 \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$Spearman\\,\\rho =\\frac{{\\sum }_{i=1}^{n}\\,\\frac{1}{{T}_{i}}{\\sum }_{t=1}^{{T}_{i}}\\,(R[{v}_{t}^{(i)}]-\\underline{R[v]})(R[{\\widehat{v}}_{t}^{(i)}]-\\underline{R[\\widehat{v}]})}{\\sqrt{{\\sum }_{i=1}^{n}\\,\\frac{1}{{T}_{i}}{\\sum }_{t=1}^{{T}_{i}}{(R[{v}_{t}^{(i)}]-\\underline{R[v]})^{2}}\\,{\\sum }_{i=1}^{n}\\frac{1}{{T}_{i}}\\,{\\sum }_{t=1}^{{T}_{i}}\\,(R[{\\widehat{v}}_{t}^{(i)}]-\\underline{R[\\widehat{v}]})^{2}}}$$\\end{document} S p e a r m a n ρ = ∑ i = 1 n 1 T i ∑ t = 1 T i ( R [ v t ( i ) ] − R [ v ] _ ) ( R [ v ^ t ( i ) ] − R [ v ^ ] _ ) ∑ i = 1 n 1 T i ∑ t = 1 T i ( R [ v t ( i ) ] − R [ v ] _ ) 2 ∑ i = 1 n 1 T i ∑ t = 1 T i ( R [ v ^ t ( i ) ] − R [ v ^ ] _ ) 2 \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$R[.]$$\\end{document} R [ . ] \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$\\underline{R[v]}=\\frac{1}{n}{\\sum }_{i=1}^{n}\\,\\frac{1}{{T}_{i}}{\\sum }_{t=1}^{{T}_{i}}\\,R[{v}_{t}^{(i)}]$$\\end{document} R [ v ] _ = 1 n ∑ i = 1 n 1 T i ∑ t = 1 i R [ v t ( i ) ] \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$\\underline{R[\\widehat{v}]}=\\frac{1}{n}\\,{\\sum }_{i=1}^{n}\\,\\frac{1}{{T}_{i}}\\,{\\sum }_{t=1}^{{T}_{i}}\\,R[{\\widehat{v}}_{t}^{(i)}]$$\\end{document} R [ v ^ ] _ = 1 n ∑ i = 1 n 1 T i ∑ t = 1 i R [ v ^ t ( i ) ] We chose scaled MAE, i.e., Eq. ( 2 Classification evaluation Classification metrics assess the model’s clinical utility to capture events, such as abrupt changes in clinical variables indicative of acute conditions (e.g., sudden drops or increases) or prolonged trends in variable changes that are characteristic of a chronic condition (e.g., gradual increases or decreases over extended periods). Below, we provide detailed definitions of the metrics employed in our evaluation. An interpretation of introduced metrics is provided in Supplementary Note 8 First, we assess the model’s ability to detect values outside the normal range of clinical variables. Let \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$[{v}_{\\min \\,},\\,{v}_{\\max }]$$\\end{document} [ v min , v max ] \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$v$$\\end{document} v \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$${v}_{t}^{(i)}$$\\end{document} v t ( i ) \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$${v}_{t}^{(i)} < {v}_{\\min }$$\\end{document} v t ( i ) < v min \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$${v}_{t}^{(i)} > {v}_{\\max }$$\\end{document} v t ( i ) > v max \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$${v}_{\\min } < {v}_{t}^{(i)} < {v}_{\\max }$$\\end{document} v min < v t ( i ) < v max \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$${v}_{t}^{(i)}$$\\end{document} v t ( i ) \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$${\\hat{v}}_{t}^{(i)}$$\\end{document} v ˆ t ( i ) For the binary classification tasks “low” versus “not low”, “high” versus “not high”, and “normal” versus “not normal”, we calculate area under the receiver operating characteristic curve (AUC ROC) and denote it as \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$${AU}{C}_{{low}}$$\\end{document} AU C low \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$${AU}{C}_{{high}}$$\\end{document} AU C high \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$${AU}{C}_{{normal}}$$\\end{document} AU C normal 6 6 \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$\\text{AUC}_{\\text{weighted}} = \\frac{(\\text{AUC}_{\\text{low}} \\times \\#\\text{low}) + (\\text{AUC}_{\\text{normal}} \\times \\#\\text{normal}) + (\\text{AUC}_{\\text{high}} \\times \\#\\text{high})}{\\#\\text{low} + \\#\\text{normal} + \\#\\text{high}}$$\\end{document} AUC weighted = ( AUC low × # low ) + ( AUC normal × # normal ) + ( AUC high × # high ) # low + # normal + # high \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$${\\#low}$$\\end{document} #low \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$${\\#normal}$$\\end{document} #normal \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$${\\#high}$$\\end{document} #high \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$${{v}_{t}}^{(i)}$$\\end{document} v t ( i ) We evaluated the model’s trend forecasting performance by analyzing its predicted value trajectories over a specified time interval \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$s$$\\end{document} s \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$${v}_{t}^{(i)}$$\\end{document} v t ( i ) \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$${v}_{t+1}^{(i)} < {v}_{t}^{(i)}$$\\end{document} v t + 1 ( i ) < v t ( i ) \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$${v}_{t+1}^{(i)} > {v}_{t}^{(i)}$$\\end{document} v t + 1 ( i ) > v t ( i ) \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$t$$\\end{document} t \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$${v}_{t}^{(i)}$$\\end{document} v t ( i ) \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$${v}_{k+1}^{(i)} < {v}_{k}^{(i)}$$\\end{document} v k + 1 ( i ) < v k ( i ) \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$k$$\\end{document} k \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$[{time}(t)-s,{time}(t)]$$\\end{document} [ time ( t ) − s , time ( t ) ] \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$${v}_{k+1}^{(i)} > {v}_{k}^{(i)}$$\\end{document} v k + 1 ( i ) > v k ( i ) \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$k$$\\end{document} k \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$${time}(t)$$\\end{document} time ( t ) \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$${AU}{C}_{{trend}\\downarrow }$$\\end{document} AU C trend ↓ \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$${AU}{C}_{{trend}\\uparrow }$$\\end{document} AU C trend ↑ \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$${time}(t) < s$$\\end{document} time ( t ) < s 13 We performed the classification evaluation only on the NSCLC data. For this, we used parameters for the reference ranges \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$[{v}_{\\min },\\,{v}_{\\max }]$$\\end{document} [ v min , v max ] 53 9 54 54 9 55 9 55 36 We further address the model ability to detect a significant drop in hemoglobin associated with a bleeding by calculating \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$${AU}{C}_{{low}}$$\\end{document} AU C low \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$${v}_{\\min }$$\\end{document} v min \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$s=21$$\\end{document} s = 21 Supplementary information  Supplementary Information Publisher’s note These authors contributed equally: Nikita Makarov, Maria Bordukova. Supplementary information The online version contains supplementary material available at 10.1038/s41746-025-02004-3. Acknowledgements We would like to thank Anton Kraxner for providing crucial insights into NSCLC, as well as Ginte Kutkaite, Hugo Loureiro, Franziska Braun, Rudolf Kinder, Venus So, Guy Amster and Will Shapiro for their valuable input and discussions. This study was funded by F. Hoffmann-La Roche and the European Union's Horizon 2020 Research and Innovation Programme (Grant agreement No. 950293–COMBAT-RES). The funder played no role in study design, data collection, analysis and interpretation of data, or the writing of this manuscript. Data collection and sharing for the Alzheimer’s Disease Neuroimaging Initiative (ADNI) is funded by the National Institute on Aging (National Institutes of Health Grant U19AG024904). The grantee organization is the Northern California Institute for Research and Education. In the past, ADNI has also received funding from the National Institute of Biomedical Imaging and Bioengineering, the Canadian Institutes of Health Research, and private sector contributions through the Foundation for the National In-Institutes of Health (FNIH) including generous contributions from the following: AbbVie, Alzheimer’s Association; Alzheimer’s Drug Discovery Foundation; Araclon Biotech; BioClinica, Inc.; Biogen; BristolMyers Squibb Company; CereSpir, Inc.; Cogstate; Eisai Inc.; Elan Pharmaceuticals, Inc.; Eli Lilly and Company; EuroImmun; F. Hoffmann-La Roche Ltd and its affiliated company Genentech, Inc.; Fujirebio; GE Healthcare; IXICO Ltd.; Janssen Alzheimer Immunotherapy Research & Development, LLC.; Johnson & Johnson Pharmaceutical Research & Development LLC.; Lumosity; Lundbeck; Merck & Co., Inc.; Meso Scale Diagnostics, LLC.; NeuroRx Research; Neurotrack Technologies; Novartis Pharmaceuticals Corporation; Pfizer Inc.; Piramal Imaging; Servier; Takeda Pharmaceutical Company; and Transition Therapeutics. Author contributions N.M., M.B. and P.Q. performed data processing. N.M. and M.B. performed model implementation. N.M., M.B. and D.G. performed model evaluation. R.R.-E., F.S. and M.P.M. supervised, designed and directed the project. N.M and M.B. drafted the manuscript. N.M., M.B., D.G., R.R.-E., F.S. and M.P.M. substantially revised this manuscript. All authors have read and approved the manuscript. Funding Open Access funding enabled and organized by Projekt DEAL. Data availability The Flatiron Health data that support the findings of this study were originated by and are the property of Flatiron Health, Inc., which has restrictions prohibiting the authors from making the data set publicly available. Requests for data sharing by license or by permission for the specific purpose of replicating results in this manuscript can be submitted to PublicationsDataAccess@flatiron.com. The Medical Information Mart for Intensive Care IV (MIMIC-IV) is available online upon request under https://physionet.org/content/mimiciv https://adni.loni.usc.edu/data-samples/adni-data/ Code availability The code is available at https://github.com/MendenLab/DT-GPT Competing interests N.M., M.B., R.R.E. and F.S. are all employees of F. Hoffmann-La Roche. M.P.M. collaborates and is financially supported by GSK, F. Hoffmann-La Roche, and AstraZeneca. M.P.M. is supported by the European Union’s Horizon 2020 Research and Innovation Programme (Grant agreement No. 950293—COMBAT-RES). N.M., M.B., R.R.E., F.S. and M.P.M. are authors of an in-force patent entitled “Forecasting of subject-related attributes using generative machine-learning model” (patent publication number 2025/021719, patent application number EP2024070632) owned by F. Hoffmann-La Roche and Helmholtz Zentrum Munich. The patent covers application of large language models such as DT-GPT for forecasting of clinical trajectories of patients during a clinical trial. The authors have no other relevant affiliations or financial involvement with any organization or entity with a financial interest in or financial conflict with the subject matter or materials discussed in the manuscript apart from those disclosed. References 1. Schachter AD Ramoni MF Clinical forecasting in drug development Nat. Rev. Drug Discov. 2007 6 107 108 10.1038/nrd2246 17342862 Schachter, A. D. & Ramoni, M. F. Clinical forecasting in drug development. Nat. Rev. Drug Discov. 6 17342862 10.1038/nrd2246 2. Allen A A digital twins machine learning model for forecasting disease progression in stroke patients Appl. Sci. 2021 11 5576 10.3390/app11125576 Allen, A. et al. A digital twins machine learning model for forecasting disease progression in stroke patients. Appl. Sci. 11 3. Boulos MNK Zhang P Digital twins: From personalised medicine to precision public health J. Pers. Med. 2021 11 745 10.3390/jpm11080745 34442389 PMC8401029 Boulos, M. N. K. & Zhang, P. Digital twins: From personalised medicine to precision public health. J. Pers. Med. 11 34442389 10.3390/jpm11080745 PMC8401029 4. Bordukova M Makarov N Rodriguez-Esteban R Schmich F Menden MP Generative artificial intelligence empowers digital twins in drug discovery and clinical trials Expert Opin. Drug Discov. 2024 19 33 42 10.1080/17460441.2023.2273839 37887266 Bordukova, M., Makarov, N., Rodriguez-Esteban, R., Schmich, F. & Menden, M. P. Generative artificial intelligence empowers digital twins in drug discovery and clinical trials. Expert Opin. Drug Discov. 19 37887266 10.1080/17460441.2023.2273839 5. Coorey G The health digital twin to tackle cardiovascular disease—a review of an emerging interdisciplinary field npj Digit. Med. 2022 5 126 10.1038/s41746-022-00640-7 36028526 PMC9418270 Coorey, G. et al. The health digital twin to tackle cardiovascular disease—a review of an emerging interdisciplinary field. npj Digit. Med. 5 36028526 10.1038/s41746-022-00640-7 PMC9418270 6. Venkatesh KP Raza MM Kvedar JC Health digital twins as tools for precision medicine: Considerations for computation, implementation, and regulation. npj Digit Med 2022 5 150 10.1038/s41746-022-00694-7 PMC9500019 36138125 Venkatesh, K. P., Raza, M. M. & Kvedar, J. C. Health digital twins as tools for precision medicine: Considerations for computation, implementation, and regulation. npj Digit. Med 5 10.1038/s41746-022-00694-7 PMC9500019 36138125 7. Bordukova M Generative AI and digital twins: shaping a paradigm shift from precision to truly personalized medicine Expert Opin. Drug Discov. 2025 20 821 826 10.1080/17460441.2025.2507376 40375366 Bordukova, M. et al. Generative AI and digital twins: shaping a paradigm shift from precision to truly personalized medicine. Expert Opin. Drug Discov. 20 40375366 10.1080/17460441.2025.2507376 8. Moingeon P Chenel M Rousseau C Voisin E Guedj M Virtual patients, digital twins and causal disease models: Paving the ground for in silico clinical trials Drug Discov. Today 2023 28 103605 10.1016/j.drudis.2023.103605 37146963 Moingeon, P., Chenel, M., Rousseau, C., Voisin, E. & Guedj, M. Virtual patients, digital twins and causal disease models: Paving the ground for in silico clinical trials. Drug Discov. Today 28 37146963 10.1016/j.drudis.2023.103605 9. Nguyen M Predicting Alzheimer’s disease progression using deep recurrent neural networks NeuroImage 2020 222 117203 10.1016/j.neuroimage.2020.117203 32763427 PMC7797176 Nguyen, M. et al. Predicting Alzheimer’s disease progression using deep recurrent neural networks. NeuroImage 222 32763427 10.1016/j.neuroimage.2020.117203 PMC7797176 10. Jung, W., Mulyadi, A. W. & Suk, H. I. Unified Modeling of Imputation, Forecasting, and Prediction for AD Progression. in Lecture Notes in Computer Science 11. Wu, F. et al. Forecasting Treatment Outcomes Over Time Using Alternating Deep Sequential Models. IEEE Transactions on Biomedical Engineering PP 10.1109/TBME.2023.3331298 PMC11246606 37943640 12. Phetrittikun, R. et al. Temporal Fusion Transformer for forecasting vital sign trajectories in intensive care patients. in 2021 13th Biomed Eng Int Conf (BMEiCON) 13. Chang P A transformer-based diffusion probabilistic model for heart rate and blood pressure forecasting in Intensive Care Unit Comput. Methods Prog. Biomed. 2024 246 108060 10.1016/j.cmpb.2024.108060 PMC10940190 38350189 Chang, P. et al. A transformer-based diffusion probabilistic model for heart rate and blood pressure forecasting in Intensive Care Unit. Comput. Methods Prog. Biomed. 246 10.1016/j.cmpb.2024.108060 PMC10940190 38350189 14. Melnychuk, V., Frauen, D. & Feuerriegel, S. Causal Transformer for Estimating Counterfactual Outcomes. in International Conference on Machine Learning 15. Kaddour J Lynch A Liu Q Kusner MJ Silva R Causal machine learning: A survey and open problems. Foundations and Trendsr in Optimization 2025 9 1 247 10.1561/2400000052 Kaddour, J., Lynch, A., Liu, Q., Kusner, M. J. & Silva, R. Causal machine learning: A survey and open problems. Foundations and Trendsr in Optimization 9 16. Wornow M The shaky foundations of large language models and foundation models for electronic health records npj Digital Med. 2023 6 135 10.1038/s41746-023-00879-8 PMC10387101 37516790 Wornow, M. et al. The shaky foundations of large language models and foundation models for electronic health records. npj Digital Med. 6 10.1038/s41746-023-00879-8 PMC10387101 37516790 17. Renc P Zero shot health trajectory prediction using transformer. npj Digit Med 2024 7 256 10.1038/s41746-024-01235-0 PMC11412988 39300208 Renc, P. et al. Zero shot health trajectory prediction using transformer. npj Digit. Med 7 10.1038/s41746-024-01235-0 PMC11412988 39300208 18. Liang, Y. et al. Foundation Models for Time Series Analysis: A Tutorial and Survey. in Proceedings of the 30th ACM SIGKDD conference on knowledge discovery and data mining 19. Xue, H. & Salim, F. D. PromptCast: A New Prompt-based Learning Paradigm for Time Series Forecasting. IEEE Transactions on Knowledge and Data Engineering 20. Liu, H., Zhao, Z., Wang, J., Kamarthi, H. & Prakash, B. B. LSTPrompt: Large Language Models as Zero-Shot Time Series Forecasters by Long-Short-Term Prompting. in Association for Computational Linguistics Findings 2024 21. Gruver, N., Finzi, M., Qiu, S. & Wilson, A. G. Large Language Models Are Zero-Shot Time Series Forecasters. in Advances in Neural Information Processing Systems 22. Jin, M. et al. Time-LLM: Time Series Forecasting by Reprogramming Large Language Models. in International Conference on Learning Representations 23. Zhou, T., Niu, P., Wang, X., Sun, L. & Jin, R. One Fits All:Power General Time Series Analysis by Pretrained LM. arXiv (2023) 10.48550/arxiv.2302.11939. 24. Loureiro H Correlation between early trends of a prognostic biomarker and overall survival in non–small-cell lung cancer clinical trials JCO Clin. Cancer Inform. 2023 7 e2300062 10.1200/CCI.23.00062 37922432 PMC10730042 Loureiro, H. et al. Correlation between early trends of a prognostic biomarker and overall survival in non–small-cell lung cancer clinical trials. JCO Clin. Cancer Inform. 7 37922432 10.1200/CCI.23.00062 PMC10730042 25. Johnson AE MIMIC-IV, a freely accessible electronic health record dataset Sci. Data 2023 10 1 10.1038/s41597-022-01899-x 36596836 PMC9810617 Johnson, A. E. et al. MIMIC-IV, a freely accessible electronic health record dataset. Sci. Data 10 36596836 10.1038/s41597-022-01899-x PMC9810617 26. Tombaugh TN McIntyre NJ The mini-mental state examination: A comprehensive review J. Am. Geriatr. Soc. 1992 40 922 935 10.1111/j.1532-5415.1992.tb01992.x 1512391 Tombaugh, T. N. & McIntyre, N. J. The mini-mental state examination: A comprehensive review. J. Am. Geriatr. Soc. 40 1512391 10.1111/j.1532-5415.1992.tb01992.x 27. O’Bryant SE Validation of the new interpretive guidelines for the clinical dementia rating scale sum of boxes score in the national Alzheimer’s coordinating center database Arch. Neurol. 2010 67 746 749 10.1001/archneurol.2010.115 20558394 PMC2888493 O’Bryant, S. E. et al. Validation of the new interpretive guidelines for the clinical dementia rating scale sum of boxes score in the national Alzheimer’s coordinating center database. Arch. Neurol. 67 20558394 10.1001/archneurol.2010.115 PMC2888493 28. Kueper JK Speechley M Montero-Odasso M The Alzheimeras disease assessment scale-cognitive subscale (ADAS-Cog): modifications and responsiveness in pre-dementia populations. a narrative review Journal of Alzheimeras Disease 2018 63 423 444 10.3233/JAD-170991 PMC5929311 29660938 Kueper, J. K., Speechley, M. & Montero-Odasso, M. The Alzheimeras disease assessment scale-cognitive subscale (ADAS-Cog): modifications and responsiveness in pre-dementia populations. a narrative review. Journal of Alzheimeras Disease 63 10.3233/JAD-170991 PMC5929311 29660938 29. Lim B Arık S Loeff N Pfister T Temporal Fusion Transformers for interpretable multi-horizon time series forecasting Int. J. Forecast. 2021 37 1748 1764 10.1016/j.ijforecast.2021.03.012 Lim, B., Arık, S., Loeff, N. & Pfister, T. Temporal Fusion Transformers for interpretable multi-horizon time series forecasting. Int. J. Forecast. 37 30. Das, A. et al. Long-term Forecasting with TiDE: Time-series Dense Encoder. Transactions on Machine Learning Research 31. Nespoli L Medici V Multivariate Boosted Trees and Applications to Forecasting and Control J. Mach. Learn. Res. 2022 23 1 47 Nespoli, L. & Medici, V. Multivariate Boosted Trees and Applications to Forecasting and Control. J. Mach. Learn. Res. 23 32. Ke, G., Meng, Q., Finley, T., Wang, T., Chen, W., Ma, W., Ye, Q. & Liu, T. Y. Lightgbm: A highly efficient gradient boosting decision tree. In Advances in neural information processing systems. 33. Labrak, Y. et al. BioMistral: A collection of open-source pretrained large language models for medical domains. arXiv (2024). 34. Yang A Qwen3 technical report arXiv 2025 10.48550/arxiv.2505.09388 Yang, A. et al. Qwen3 technical report. arXiv 35. Nie, Y., Nguyen, N. H., Sinthong, P. & Kalagnanam, J. A Time Series is Worth 64 Words: Long-term Forecasting with Transformers. in International Conference on Learning Representations (2023). 36. Farhana, A. & Lappin, S. L. Biochemistry, Lactate Dehydrogenase 32491468 37. Margraf A Lowell CA Zarbock A Neutrophils in acute inflammation: current concepts and translational implications Blood 2022 139 2130 2144 10.1182/blood.2021012295 34624098 PMC9728535 Margraf, A., Lowell, C. A. & Zarbock, A. Neutrophils in acute inflammation: current concepts and translational implications. Blood 139 34624098 10.1182/blood.2021012295 PMC9728535 38. Groopman JE Itri LM Chemotherapy-induced anemia in adults: incidence and treatment J. Natl. Cancer Inst. 1999 91 1616 1634 10.1093/jnci/91.19.1616 10511589 Groopman, J. E. & Itri, L. M. Chemotherapy-induced anemia in adults: incidence and treatment. J. Natl. Cancer Inst. 91 10511589 10.1093/jnci/91.19.1616 39. Abdel-Razeq H Hashem H Recent update in the pathogenesis and treatment of chemotherapy and cancer induced anemia Crit. Rev. Oncol. Hematol. 2020 145 102837 10.1016/j.critrevonc.2019.102837 31830663 Abdel-Razeq, H. & Hashem, H. Recent update in the pathogenesis and treatment of chemotherapy and cancer induced anemia. Crit. Rev. Oncol. Hematol. 145 31830663 10.1016/j.critrevonc.2019.102837 40. Wang Y Probin V Zhou D Cancer therapy-induced residual bone marrow injury: Mechanisms of induction and implication for therapy Curr. Cancer Ther. Rev. 2006 2 271 279 10.2174/157339406777934717 19936034 PMC2779029 Wang, Y., Probin, V. & Zhou, D. Cancer therapy-induced residual bone marrow injury: Mechanisms of induction and implication for therapy. Curr. Cancer Ther. Rev. 2 19936034 10.2174/157339406777934717 PMC2779029 41. Cella D The functional assessment of cancer therapy-anemia (FACT-An) Scale: A new tool for the assessment of outcomes in cancer anemia and fatigue Semin. Hematol. 1997 34 13 19 9253779 Cella, D. The functional assessment of cancer therapy-anemia (FACT-An) Scale: A new tool for the assessment of outcomes in cancer anemia and fatigue. Semin. Hematol. 34 9253779 42. Pathak N Improving the performance status in advanced non-small cell lung cancer patients with chemotherapy (ImPACt trial): A phase 2 study J. Cancer Res. Clin. Oncol. 2023 149 6399 6409 10.1007/s00432-023-04617-1 36759393 PMC11797346 Pathak, N. et al. Improving the performance status in advanced non-small cell lung cancer patients with chemotherapy (ImPACt trial): A phase 2 study. J. Cancer Res. Clin. Oncol. 149 36759393 10.1007/s00432-023-04617-1 PMC11797346 43. Tas F Ciftci R Kilic L Karabulut S Age is a prognostic factor affecting survival in lung cancer patients Oncol. Lett. 2013 6 1507 1513 10.3892/ol.2013.1566 24179550 PMC3813578 Tas, F., Ciftci, R., Kilic, L. & Karabulut, S. Age is a prognostic factor affecting survival in lung cancer patients. Oncol. Lett. 6 24179550 10.3892/ol.2013.1566 PMC3813578 44. Lee S Jeon H Shim B Prognostic value of ferritin-to-hemoglobin ratio in patients with advanced non-small-cell lung cancer J. Cancer 2019 10 1717 1725 10.7150/jca.26853 31205527 PMC6548010 Lee, S., Jeon, H. & Shim, B. Prognostic value of ferritin-to-hemoglobin ratio in patients with advanced non-small-cell lung cancer. J. Cancer 10 31205527 10.7150/jca.26853 PMC6548010 45. Matsukane R Prognostic significance of pre-treatment ALBI grade in advanced non-small cell lung cancer receiving immune checkpoint therapy Sci. Rep. 2021 11 15057 10.1038/s41598-021-94336-9 34301991 PMC8302741 Matsukane, R. et al. Prognostic significance of pre-treatment ALBI grade in advanced non-small cell lung cancer receiving immune checkpoint therapy. Sci. Rep. 11 34301991 10.1038/s41598-021-94336-9 PMC8302741 46. Tomita M Shimizu T Hara M Ayabe T Onitsuka T Impact of preoperative hemoglobin level on survival of non-small cell lung cancer patients Anticancer Res 2008 28 1947 1950 18630486 Tomita, M., Shimizu, T., Hara, M., Ayabe, T. & Onitsuka, T. Impact of preoperative hemoglobin level on survival of non-small cell lung cancer patients. Anticancer Res 28 18630486 47. Sravanthi, S. L. et al. PUB: A Pragmatics Understanding Benchmark for Assessing LLMs’ Pragmatics Capabilities. in Findings of the Association for Computational Linguistics: ACL 2024 48. Cross JL Choma MA Onofrey JA Bias in medical AI: Implications for clinical decision-making PLOS Digit. Heal. 2024 3 e0000651 10.1371/journal.pdig.0000651 PMC11542778 39509461 Cross, J. L., Choma, M. A. & Onofrey, J. A. Bias in medical AI: Implications for clinical decision-making. PLOS Digit. Heal. 3 10.1371/journal.pdig.0000651 PMC11542778 39509461 49. Ma, X., Long, L., Moon, S., Adamson, B. & Baxi, S. Comparison of Population Characteristics in Real-World Clinical Oncology Databases in the US: Flatiron Health, SEER, and NPCR. medRxiv 2020 50. Birnbaum, B. et al. Model-assisted cohort selection with bias analysis for generating large-scale cohorts from the EHR for oncology research. arXiv preprint arXiv:2007.XXXX 51. Gupta, M. et al. An Extensive Data Processing Pipeline for MIMIC-IV. in Proceedings of Machine Learning Research PMC9854277 36686986 52. Wang, X. et al. Self-Consistency Improves Chain of Thought Reasoning in Language Models. in The Eleventh International Conference on Learning Representations 53. Billett, H. H., Walker, H. K., 1, W. D. H. & Hurst, J. W. Hemoglobin and Hematocrit. in Clinical Methods: The History, Physical, and Laboratory Examinations. 3rd Edition 21250045 54. Riley LK Rupert J Evaluation of patients with leukocytosis Am. Fam. physician 2015 92 1004 1011 26760415 Riley, L. K. & Rupert, J. Evaluation of patients with leukocytosis. Am. Fam. physician 92 26760415 55. Haematology reference ranges. https://www.gloshospitals.nhs.uk/our-services/services-we-offer/pathology/haematology/haematology-reference-ranges/ ",
  "metadata": {
    "Title of this paper": "Evaluation of patients with leukocytosis",
    "Journal it was published in:": "NPJ Digital Medicine",
    "URL": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC12488890/"
  }
}