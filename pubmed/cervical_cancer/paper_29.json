{
  "title": "Paper_29",
  "abstract": "pmc Sci Rep Sci Rep 1579 scirep Scientific Reports 2045-2322 Nature Publishing Group PMC12494869 PMC12494869.1 12494869 12494869 41044098 10.1038/s41598-025-17753-0 17753 1 Article Automated assessment and detection of third molar and inferior alveolar nerve relations using UNet and transfer learning models Klaib Ahmad F. 1 2 Saif Amal ama20219010@std.psut.edu.jo 3 Alhosanie Tasneem N. 2 Barakat Motaz 4 AbuHijleh Iyas 5 Khasawneh Rama 1 AlMadani Wa’ed 4 Alomari Saja 6 Alghanim Danah 4 Dabobash Bayan 4 Hussien Taimaa 4 Shalbak Jude 4 Darweesh Majd 4 AlHadidi Abeer 4 Abu Karaky Ashraf 4 1 https://ror.org/004mbaj56 grid.14440.35 0000 0004 0622 5497 Information Systems Department, Yarmouk University, 2 https://ror.org/01jy46q10 grid.29251.3d 0000 0004 0404 9637 Software Engineering Department, Princess Sumaya University for Technology, 3 https://ror.org/01jy46q10 grid.29251.3d 0000 0004 0404 9637 Computer Science Department, Princess Sumaya University for Technology, 4 https://ror.org/05k89ew48 grid.9670.8 0000 0001 2174 4509 Oral and Maxillofacial Surgery, Oral Medicine, and Periodontology Department, University of Jordan, 5 https://ror.org/0564xsr50 grid.419782.1 0000 0001 1847 1773 Head and Neck Surgery Department, King Hussein Cancer Center, 6 https://ror.org/004mbaj56 grid.14440.35 0000 0004 0622 5497 Computer Science Department, Yarmouk University, 3 10 2025 2025 15 478255 34529 10 6 2025 26 8 2025 03 10 2025 05 10 2025 05 10 2025 © The Author(s) 2025 2025 https://creativecommons.org/licenses/by-nc-nd/4.0/ Open Access http://creativecommons.org/licenses/by-nc-nd/4.0/ Panoramic radiographs (PRs) are widely used in assessing the relationship between the mandibular third molar (MM3) and the inferior alveolar nerve (IAN). The relationship of MM3 and IAN is a critical consideration in oral and maxillofacial surgery due to the risk of nerve injury that can lead to anesthesia in the lower lip or chin. This study aimed to evaluate the performance of different transfer learning models in classifying these relations into four classes after detecting and segmenting the MM3 and the IAN using a new method with the UNet model. 714 PRs from more than 500 patients, representing four classes, were utilized in a UNet model to annotate the MM3 and IAN. Then, the annotations were extracted and augmented to yield 1021 images, thereby achieving a more balanced distribution of samples in each class. Different transfer learning models were evaluated in classifying the images using 10-fold cross-validation. The UNet model achieves an accuracy of 0.97 in annotating the images. The transfer learning models performed well. The best model, DenseNet121, achieved an average accuracy of 0.84, precision of 0.86, recall of 0.84, and F1-score of 0.85 across all folds and classes. The proposed approach demonstrates high performance compared to other works, classifying four classes and achieving similar or better performance than other techniques. It can also benefit dentists at the annotation and classification stages. Based on our results, this approach holds promise for opening several research directions in the future. Trial registration Keywords Deep learning Transfer learning UNet Third molar Mandibular nerve Inferior alveolar nerve Subject terms Dental diseases Oral diseases Image processing Machine learning Computer science pmc-status-qastatus 0 pmc-status-live yes pmc-status-embargo no pmc-status-released yes pmc-prop-open-access yes pmc-prop-olf no pmc-prop-manuscript no pmc-prop-legally-suppressed no pmc-prop-has-pdf yes pmc-prop-has-supplement no pmc-prop-pdf-only no pmc-prop-suppress-copyright no pmc-prop-is-real-version no pmc-prop-is-scanned-article no pmc-prop-preprint no pmc-prop-in-epmc yes issue-copyright-statement © Springer Nature Limited 2025 Introduction Mandibular third molar (MM3) extraction is one of the most performed procedures in oral and maxillofacial surgery. Inferior alveolar nerve (IAN) damage and impairment of sensation in the lower lip and the chin regions are a significant potential complication of MM3 extractions. Nerve impairment could be temporary or permanent, with a reported incidence of 0.4-13.4% 1 2 3 4 5 6 7 8 The utility of deep learning (DL) models as a tool for assisting in interpreting medical imaging has been explored more widely in recent years 9 10 11 12 13 16 17 This study aims to assess the accuracy of using AI in determining the anatomical relation of MM3s with IAN canals in PRs by overcoming some previous shortages in similar works, such as focusing on dividing the classes based on whether there is a contact with mandibular canal or not (two classes) 18 21 22 23 Main Contributions Our study was conducted as a preliminary study to classify the degree of overlap between MM3 and IAN on PRs. The main contributions are summarized as follows: Develop a new method to detect and segment the MM3 and IAN using annotations. Our annotations and the steps before the segmentation will assist clinicians in highlighting the IAN and MM3 to examine their relationship. Employ the UNet model to annotate the PRs. Classify the degree of overlapping between the IAN and MM3 into four classes. Examine the performance of different transfer learning methods in classifying the MM3-IAN relations. Use 10-fold cross-validation to evaluate the whole process rather than depending on a few samples to test the proposed approach. Our data augmentation depends on getting different MM3-IAN combinations instead of rotation, flipping, and other common methods that do not generate new data. Background This section focuses on the works concerned with MM3 and IAN relationships in PRs, and these works are summarized in Table 1 Table 1 The summary of the related work. Ref. No. of samples No. of classes Accuracy Precision Recall F1-score Classification method 19 1279 and they used k-fold cross-validation 2 classes 0.86 0.81 0.791 0.800 ResNet50 26 1,478 (no details about splitting the data) 2 classes 0.85 0.98 0.86 0.92 ANN 24 Training: 6073 Validation: 896 Testing: 1751 3 classes 0.81 - - 0.75 R50+ViT-L/32 25 Training: 407 Validation: 30 Testing: 50 3 classes 0.78 - - - Xception 23 Training: 5385 Validation: 1794 Testing: 1794 2 classes / 3 classes 0.90 / 0.83 0.84 / 0.81 0.79 / 0.71 0.81 / 0.75 An algorithm that checks the intersections 27 Training: 1504 Testing: 376 4 classes 0.81 0.78 0.77 0.78 AlexNet To get high-performance results, detection and segmentation are essential steps to classify the relationship between MM3 and IAN. An algorithm was used to check the intersections of MM3 with the IAN to classify their relation into two classes (contact, no contact), and into three classes (no, partial, and complete contact) 23 Another approach that classifies the MM3-IAN relations into three classes (no, partial, and complete contact) achieved 0.81 accuracy using the R50+ViT-L/32 hybrid model containing a visual transformer and ResNet50 model. The model was trained using 250 epochs. The same previous issue, class 2 is much larger than classes 1 and 3 24 19 Several aspects of studying the MM3 were studied. For example, the classification of the MM3 is based on its position, angulation, and relation to the IAN 25 The extraction of the IAN and MM3 from the PRs was performed through a combination of expert manual annotations and image processing techniques. Trained radiologists annotated the structures using polygons with variable nodes via the Colabeler AI Labelling Tool, allowing for precise, pixel-level labels of the IAN and MM3 boundaries. These polygonal annotations served as the foundation for further processing: the skeletons of the IAN and roots were computed through morphological operations, enabling a simplified representation of their course and morphology. For the IAN, a piecewise linear model was fitted to its skeleton to quantify deviations such as deflection or narrowing. Similarly, root skeletons were assessed to measure such characteristics as deflection of roots, narrowing, and proximity to the canal. Skeleton-to-borders distances were calculated to estimate space-related characteristics, such as the narrowing of canals or roots. These attributes, which were mined from the annotated and skeletonized structures, were then used to quantify the radiological indications of contact between the MM3 and the IAN as inputs into future machine learning classification models and ANN 26 A research paper 27 Therefore, in our study, we have utilized 714 PRs to be trained using the UNet model to annotate the IAN and MM3. Then, the segmented PRs were augmented using random combinations of IAN and the MM3 instead of just rotating or flipping the images to give some balancing to the classes. We have examined six transfer learning models to classify the PRs into four classes for an accurate description of the relationships between MM3 and IAN based on 10-fold cross-validation to overcome the limited number of samples. Methods This section proposes a detailed description of the methodology steps. All these steps are summarized in Fig. 1 Fig. 1 The sequence of the methodology steps. Ethical approval and data collection Due to the retrospective nature of this study, internal review boards (IRB) from the Jordan University Hospital (JUH) (Ref. No. 10/2025/3202) waived the need to obtain informed consent. Additionally, the study aligns with the principles of the Declaration of Helsinki. Preoperative PRs were retrospectively collected from the Department of Oral and Maxillofacial Surgery database at JUH between January 2014 and June 2024 for more than 500 patients who presented for the extraction of MM3. Using CCD sensors, CS8100 acquired the PRs, operating at 73 kV and 12 mA. The data was collected and classified by OMFS residents and verified by OMFS specialists, which contained 714 PRs after extracting MM3 from the left and right sides of the PRs. PRs inclusion and exclusion criteria Fully diagnostic PRs showing the whole mandible with the concerning lower third molars were chosen based on the following criteria: patients who had a complete set of mandibular teeth with MM3 roots more than 2/3s formed and no associated pathology with the MM3 or the surrounding teeth and structures. Images with fixation plates were excluded. Analysis of the PRs PRs were analyzed by multiple examiners as follows: five maxillofacial surgery residents analyzed and classified the whole sample into different classes, which were assigned to them. Board-certified maxillofacial surgeons reanalyzed all samples based on these classes. Conflicting samples were finally analyzed and approved by a board-certified maxillofacial radiologist. The relationship between MM3s and IAN canals was grouped into four classes 1 27 2 Data preparation This step aims to prepare the data for training, including the previous steps, as well as resizing the PRs and cropping the area of the MM3 and IAN based on the labels (left/right). The images were cropped by choosing a large area that definitely includes the desired region. The dentists annotated the cropped PRs twice: once for the IAN and the second for the MM3. The annotation approach of Ariji et al. inspired our method to annotate the IAN and MM3 28 UNet model This model is known for its high accuracy in segmenting medical images as the encoder learns the critical features. At the same time, the decoder attempts to reconstruct these features, and the skip connections preserve the spatial information during the image decoding process. This model takes the original and annotated cropped PRs with a shape of \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$224\\times 224\\times 3$$\\end{document} 3 Fig. 2 Samples from the four classes. Fig. 3 UNet architecture. Postprocessing the data This process cleans the output of the UNet model by combining the IAN and MM3 results, extracting these annotations using MATLAB, and then cropping, centering, and resizing the images that contain the IAN and MM3 annotations. The images were augmented by randomly taking IAN and MM3 from different images to construct new images. For example, random IAN and MM3 from classes 2, 3, and 4 construct new combinations, representing class 1 and ignoring others. The same procedure was followed to augment other classes. Classification models and evaluation metrics The data was split using stratified 10-fold cross-validation. Six transfer learning models were evaluated for each fold by classifying the data that was generated from the UNet model, plus the data generated from the augmentation, which had a shape of \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$256\\times 256\\times 3$$\\end{document} Results and evaluation UNet model The evaluation of this model was based on its ability to preserve the class when annotating the data. It achieved 97% accuracy, and in some cases, it outperformed the ground truth annotations by capturing details about the nerve or MM3 that humans cannot easily detect. This result is valuable to dentists as it enables them to highlight the differences between their decisions and those made by AI. As a result, the UNet participates in determining the features alongside the dentists’ vision and does not eliminate their intervention. As shown in Fig. 4 Fig. 4 UNet results samples. Transfer learning The DeneNet121 outperforms all models in terms of accuracy, precision, recall, and F1-score, with averages of 0.84, 0.86, 0.84, and 0.85, respectively. The second model that achieved near results was VGG16. However, ResNet50 was the worst model in terms of classification, as evidenced by the training and testing results. This could be due to the fact that ResNet50 was designed for complex and high-dimensional inputs and large datasets, making the dataset unsuitable for its use. Other transfer learning models, such as Xception, InceptionV3, and MobileNet, performed similarly according to all evaluation metrics. Figures 5 6 7 8 Fig. 5 Accuracy of 10-fold for each model. Fig. 6 Precision of 10-fold for each model. Fig. 7 Recall of 10-fold for each model. Fig. 8 F1-score of 10-fold for each model. Table 2 9 Table 2 DenseNet121 results in details. Class Metric Fold number 1 2 3 4 5 6 7 8 9 10 Average 1 Precision 0.88 0.95 0.87 0.85 0.94 0.88 0.86 1.00 1.00 1.00 0.92 Recall 0.88 0.72 0.80 0.68 0.68 0.92 0.76 0.92 0.88 0.88 0.81 F1-score 0.88 0.82 0.83 0.76 0.79 0.90 0.81 0.96 0.94 0.93 0.86 2 Precision 0.79 0.61 0.63 0.67 0.68 0.91 0.67 0.89 0.86 0.86 0.76 Recall 0.85 0.73 0.85 0.85 0.88 0.84 0.88 0.96 0.96 0.92 0.87 F1-score 0.81 0.67 0.72 0.75 0.77 0.88 0.76 0.92 0.91 0.98 0.82 3 Precision 0.72 0.68 0.94 0.83 0.84 0.84 0.91 0.82 0.92 0.79 0.83 Recall 0.72 0.76 0.60 0.76 0.84 0.81 0.77 0.88 0.92 0.76 0.78 F1-score 0.72 0.72 0.73 0.79 0.84 0.82 0.83 0.85 0.92 0.78 0.80 4 Precision 0.84 0.96 0.93 0.92 0.96 0.86 0.96 0.96 0.96 0.83 0.92 Recall 0.78 0.88 1.00 0.92 0.92 0.92 0.92 0.88 0.96 0.89 0.91 F1-score 0.81 0.92 0.96 0.92 0.94 0.89 0.94 0.92 0.96 0.86 0.91 Fig. 9 Confusion matrix of DenseNet121. Since the related work focused on two or three classes, and some of them used a similar number of samples as in our study. We have conducted more experiments on classifying the PRs into two and three classes using DenseNet121, as it achieved the best performance in classifying the four classes. In the case of three classes, classes two and three were merged to represent partial contact, class one represents no contact, and class four represents complete contact. And in the case of two classes, classes two, three, and four were merged to represent the contact class, while class one represents the no-contact class. As shown in Table 3 Table 3 Performance metrics for DenseNet121 using 10-fold cross-validation for two and three classes. Classes Accuracy Precision Recall F1-score 2 classes 0.94 0.94 0.89 0.91 3 classes 0.89 0.90 0.88 0.89 Discussion MM3 extraction is a standard procedure performed by general dentists and oral and maxillofacial specialists. However, it is frequently associated with inferior alveolar nerve injury (IANI), with an incidence ranging from 0.35% to 8.4% 29 30 MM3s pose a considerable risk due to their proximity to the IAN canal, which requires careful assessment and investigation to address this risk. Several radiographic techniques can be employed to evaluate nerve proximity or position 31 32 The relationship between the MM3 and IAN has received attention from researchers, as some have focused on MM3 detection 33 34 35 18 23 27 Our new approach of annotating the PRs and letting the UNet learn what to annotate without our direct control over the exact annotations enables the model to perform well in capturing complex features. It adds valuable information that will help dentists in the diagnosis process. Additionally, this model can work with annotations of any color, making the segmentation process easier. Then, the transfer learning models, except for the ResNet50, provide good accuracy, F1-score, precision, and recall results. However, the UNet is affected by the quality of PRs. The better the quality is, the more accurate the provided annotations are. The quality of PRs depends on multiple factors. Errors are also quite common, and they could be classified into positioning errors (related to the position of the maxilla and mandible, patient movement, and cervical spine angle), errors associated with the radiographic unit, and other mechanical errors (irregularity in exposure, error in the sensor or reader), pre-and post-processing errors (noise, contrast, abnormal density), errors related to the anatomy (jaw malformation, congenital anomalies) 36 In our study, positioning errors during image acquisition were most common, followed by errors in pre- and post-processing. However, processing errors, primarily affecting image density, sharpness, and contrast, had a greater impact on image quality and classification difficulty than positioning mistakes. The proposed methodology’s overall performance and robustness are promising in this field. Conclusion MM3 extraction and its relation with the IAN hold a high risk in the oral and maxillofacial area. Therefore, it was necessary to provide this area with accurate explanations of these relations. The proposed model integrates the UNet model with various transfer learning models, using PRs to detect and annotate the MM3 and IAN, and classify their relations into four distinct classes. Among several experiments, the combination of UNet with DenseNet121 yielded the highest accuracy in 10-fold cross-validation, demonstrating its effectiveness. The UNet model provides dentists with initial annotations of MM3 and IAN, a step that is arguably more critical than the classification itself, as it reveals features that are not easily detectable otherwise. Although the analysis based on the proposed methodology can assist in clinical decision-making and surgical planning, it cannot replace the crucial role of surgeon expertise. PRs are still the most commonly used screening radiographic tool; however, they still fall short compared to CBCT in accurately detecting anatomical relations and informing treatment plans. Therefore, incorporating 3D imaging and comparing the classification accuracy with the operator’s evaluation of 3D imaging could further improve performance and enhance future results. This will be our future direction, alongside the integration of optimization algorithms that can significantly refine outcomes in subsequent work. Publisher’s note Springer Nature remains neutral with regard to jurisdictional claims in published maps and institutional affiliations. These authors contributed equally: Ahmad F. Klaib and Amal Saif. Author contributions A. F. K.: Methodology, Software, Investigation, Data Curation, Writing - Review & Editing, Visualization, Supervision; A. S.: Conceptualization, Methodology, Software, Validation, Investigation, Data Curation, Writing - Original Draft, Visualization; T. N. A.: Methodology, Software, Investigation, Data Curation, Writing - Original Draft, Project administration; M. B. and I. A.: Methodology, Validation, Investigation, Data Curation, Writing - Original Draft, Supervision; R. K.: Methodology, Software, Investigation, Data Curation; W. A.: Methodology, Validation, Investigation, Data Curation; S. A.: Methodology, Software, Investigation, Data Curation; D. A., B. D., T. H., J. S., and M. D.: Methodology, Validation, Investigation, Data Curation; A. A.: Validation, Data Curation, Writing - Review & Editing, Supervision; A. A.: Validation, Writing - Review & Editing, Supervision. Data availability This data is not publicly available due to JUH regulations, as it requires JUH approval each time. For more details on how to get the data, contact Tasneem N. Ahhosanie (tas20238052@std.psut.edu.jo). Declarations Competing interests The authors declare no competing interests. References 1. Szalma J Lempel E Jeges S Szabó G Olasz L The prognostic value of panoramic radiography of inferior alveolar nerve damage after mandibular third molar removal: Retrospective study of 400 cases Oral Surgery, Oral Medicine, Oral Pathology, Oral Radiology, and Endodontology 2010 109 294 302 10.1016/j.tripleo.2009.09.023 19846324 Szalma, J., Lempel, E., Jeges, S., Szabó, G. & Olasz, L. The prognostic value of panoramic radiography of inferior alveolar nerve damage after mandibular third molar removal: Retrospective study of 400 cases. Oral Surgery, Oral Medicine, Oral Pathology, Oral Radiology, and Endodontology 109 19846324 10.1016/j.tripleo.2009.09.023 2. Wang D Radiographic features of anatomic relationship between impacted third molar and inferior alveolar canal on coronal cbct images: Risk factors for nerve injury after tooth extraction Archives of Medical Science 2018 14 532 540 10.5114/aoms.2016.58842 29765439 PMC5949900 Wang, D. et al. Radiographic features of anatomic relationship between impacted third molar and inferior alveolar canal on coronal cbct images: Risk factors for nerve injury after tooth extraction. Archives of Medical Science 14 29765439 10.5114/aoms.2016.58842 PMC5949900 3. Rood J Shehab BN The radiological prediction of inferior alveolar nerve injury during third molar surgery British Journal of Oral and Maxillofacial Surgery 1990 28 20 25 10.1016/0266-4356(90)90005-6 2322523 Rood, J. & Shehab, B. N. The radiological prediction of inferior alveolar nerve injury during third molar surgery. British Journal of Oral and Maxillofacial Surgery 28 2322523 10.1016/0266-4356(90)90005-6 4. Su N Predictive value of panoramic radiography for injury of inferior alveolar nerve after mandibular third molar surgery Journal of Oral and Maxillofacial Surgery 2017 75 663 679 10.1016/j.joms.2016.12.013 28041843 Su, N. et al. Predictive value of panoramic radiography for injury of inferior alveolar nerve after mandibular third molar surgery. Journal of Oral and Maxillofacial Surgery 75 28041843 10.1016/j.joms.2016.12.013 5. Fukuda M Comparison of 3 deep learning neural networks for classifying the relationship between the mandibular third molar and the mandibular canal on panoramic radiographs Oral Surgery, Oral Medicine, Oral Pathology and Oral Radiology 2020 130 336 343 10.1016/j.oooo.2020.04.005 32444332 Fukuda, M. et al. Comparison of 3 deep learning neural networks for classifying the relationship between the mandibular third molar and the mandibular canal on panoramic radiographs. Oral Surgery, Oral Medicine, Oral Pathology and Oral Radiology 130 32444332 10.1016/j.oooo.2020.04.005 6. Bell G Use of dental panoramic tomographs to predict the relation between mandibular third molar teeth and the inferior alveolar nerve: Radiological and surgical findings, and clinical outcome British Journal of Oral and Maxillofacial Surgery 2004 42 21 27 10.1016/S0266-4356(03)00186-4 14706294 Bell, G. Use of dental panoramic tomographs to predict the relation between mandibular third molar teeth and the inferior alveolar nerve: Radiological and surgical findings, and clinical outcome. British Journal of Oral and Maxillofacial Surgery 42 14706294 10.1016/s0266-4356(03)00186-4 7. Faadiya AN Widyaningrum R Arindra PK Diba SF The diagnostic performance of impacted third molars in the mandible: A review of deep learning on panoramic radiographs The Saudi Dental Journal 2024 36 404 412 10.1016/j.sdentj.2023.11.025 38525176 PMC10960107 Faadiya, A. N., Widyaningrum, R., Arindra, P. K. & Diba, S. F. The diagnostic performance of impacted third molars in the mandible: A review of deep learning on panoramic radiographs. The Saudi Dental Journal 36 38525176 10.1016/j.sdentj.2023.11.025 PMC10960107 8. Barreiro-Torres J Evaluation of the surgical difficulty in lower third molar extraction Med Oral Patol Oral Cir Bucal 2010 15 e869 74 10.4317/medoral.15.e869 20526272 Barreiro-Torres, J. et al. Evaluation of the surgical difficulty in lower third molar extraction. Med Oral Patol Oral Cir Bucal 15 20526272 10.4317/medoral.15.e869 9. Khanagar SB Developments, application, and performance of artificial intelligence in dentistry-a systematic review Journal of Dental Sciences 2021 16 508 522 10.1016/j.jds.2020.06.019 33384840 PMC7770297 Khanagar, S. B. et al. Developments, application, and performance of artificial intelligence in dentistry-a systematic review. Journal of Dental Sciences 16 33384840 10.1016/j.jds.2020.06.019 PMC7770297 10. Ekert T Deep learning for the radiographic detection of apical lesions Journal of Endodontics 2019 45 917 922 10.1016/j.joen.2019.03.016 31160078 Ekert, T. et al. Deep learning for the radiographic detection of apical lesions. Journal of Endodontics 45 31160078 10.1016/j.joen.2019.03.016 11. Murata M Deep-learning classification using convolutional neural network for evaluation of maxillary sinusitis on panoramic radiography Oral Radiology 2019 35 301 307 10.1007/s11282-018-0363-7 30539342 Murata, M. et al. Deep-learning classification using convolutional neural network for evaluation of maxillary sinusitis on panoramic radiography. Oral Radiology 35 30539342 10.1007/s11282-018-0363-7 12. Vranckx M Artificial intelligence (ai)-driven molar angulation measurements to predict third molar eruption on panoramic radiographs International Journal of Environmental Research and Public Health 2020 17 3716 10.3390/ijerph17103716 32466156 PMC7277237 Vranckx, M. et al. Artificial intelligence (ai)-driven molar angulation measurements to predict third molar eruption on panoramic radiographs. International Journal of Environmental Research and Public Health 17 32466156 10.3390/ijerph17103716 PMC7277237 13. Vinayahalingam S Xi T Bergé S Maal T De Jong G Automated detection of third molars and mandibular nerve by deep learning Scientific Reports 2019 9 9007 10.1038/s41598-019-45487-3 31227772 PMC6588560 Vinayahalingam, S., Xi, T., Bergé, S., Maal, T. & De Jong, G. Automated detection of third molars and mandibular nerve by deep learning. Scientific Reports 9 31227772 10.1038/s41598-019-45487-3 PMC6588560 14. Banar N Towards fully automated third molar development staging in panoramic radiographs International Journal of Legal Medicine 2020 134 1831 1841 10.1007/s00414-020-02283-3 32239317 Banar, N. et al. Towards fully automated third molar development staging in panoramic radiographs. International Journal of Legal Medicine 134 32239317 10.1007/s00414-020-02283-3 15. Chen S-L Detection of various dental conditions on dental panoramic radiography using faster r-cnn IEEE Access 2023 11 127388 127401 10.1109/ACCESS.2023.3332269 Chen, S.-L. et al. Detection of various dental conditions on dental panoramic radiography using faster r-cnn. IEEE Access 11 16. Naufal MF Fatichah C Astuti ER Putra RH Deep learning for mandibular canal segmentation in digital dental radiographs: A systematic literature review IEEE Access 2024 12 76794 76815 10.1109/ACCESS.2024.3406342 Naufal, M. F., Fatichah, C., Astuti, E. R. & Putra, R. H. Deep learning for mandibular canal segmentation in digital dental radiographs: A systematic literature review. IEEE Access 12 17. Yoo J Deep learning based prediction of extraction difficulty for mandibular third molars Science Reports 2021 11 1954 1963 10.1038/s41598-021-81449-4 PMC7820274 33479379 Yoo, J. et al. Deep learning based prediction of extraction difficulty for mandibular third molars. Science Reports 11 10.1038/s41598-021-81449-4 PMC7820274 33479379 18. Zhu T Chen D Wu F Zhu F Zhu H Artificial intelligence model to detect real contact relationship between mandibular third molars and inferior alveolar nerve based on panoramic radiographs Diagnostics 2021 11 1664 10.3390/diagnostics11091664 34574005 PMC8465495 Zhu, T., Chen, D., Wu, F., Zhu, F. & Zhu, H. Artificial intelligence model to detect real contact relationship between mandibular third molars and inferior alveolar nerve based on panoramic radiographs. Diagnostics 11 34574005 10.3390/diagnostics11091664 PMC8465495 19. Sukegawa S Deep learning model for analyzing the relationship between mandibular third molar and inferior alveolar nerve in panoramic radiography Scientific Reports 2022 12 16925 10.1038/s41598-022-21408-9 36209283 PMC9547920 Sukegawa, S. et al. Deep learning model for analyzing the relationship between mandibular third molar and inferior alveolar nerve in panoramic radiography. Scientific Reports 12 36209283 10.1038/s41598-022-21408-9 PMC9547920 20. Jeon KJ Choi H Lee C Han S-S Automatic diagnosis of true proximity between the mandibular canal and the third molar on panoramic radiographs using deep learning Scientific Reports 2023 13 22022 10.1038/s41598-023-49512-4 38086921 PMC10716248 Jeon, K. J., Choi, H., Lee, C. & Han, S.-S. Automatic diagnosis of true proximity between the mandibular canal and the third molar on panoramic radiographs using deep learning. Scientific Reports 13 38086921 10.1038/s41598-023-49512-4 PMC10716248 21. Soltani P A two-stage deep-learning model for determination of the contact of mandibular third molars with the mandibular canal on panoramic radiographs BMC Oral Health 2024 24 1373 10.1186/s12903-024-04850-1 39538183 PMC11562527 Soltani, P. et al. A two-stage deep-learning model for determination of the contact of mandibular third molars with the mandibular canal on panoramic radiographs. BMC Oral Health 24 39538183 10.1186/s12903-024-04850-1 PMC11562527 22. Kempers S Positional assessment of lower third molar and mandibular canal using explainable artificial intelligence Journal of Dentistry 2023 133 104519 10.1016/j.jdent.2023.104519 37061117 Kempers, S. et al. Positional assessment of lower third molar and mandibular canal using explainable artificial intelligence. Journal of Dentistry 133 37061117 10.1016/j.jdent.2023.104519 23. Joo Y Moon S-Y Choi C Classification of the relationship between mandibular third molar and inferior alveolar nerve based on generated mask images IEEE Access 2023 11 81777 81786 10.1109/ACCESS.2023.3302271 Joo, Y., Moon, S.-Y. & Choi, C. Classification of the relationship between mandibular third molar and inferior alveolar nerve based on generated mask images. IEEE Access 11 24. Lee J Park J Moon SY Lee K Automated prediction of extraction difficulty and inferior alveolar nerve injury for mandibular third molar using a deep neural network Applied Sciences 2022 12 475 10.3390/app12010475 Lee, J., Park, J., Moon, S. Y. & Lee, K. Automated prediction of extraction difficulty and inferior alveolar nerve injury for mandibular third molar using a deep neural network. Applied Sciences 12 25. Achararit P Impacted lower third molar classification and difficulty index assessment: Comparisons among dental students, general practitioners, and deep learning model assistance BMC Oral Health 2025 25 152 10.1186/s12903-025-05425-4 39875882 PMC11776253 Achararit, P. et al. Impacted lower third molar classification and difficulty index assessment: Comparisons among dental students, general practitioners, and deep learning model assistance. BMC Oral Health 25 39875882 10.1186/s12903-025-05425-4 PMC11776253 26. Ulusoy AC Toprak T Selver MA Güneri P İlhan B Panoramic radiographic features for machine learning based detection of mandibular third molar root and inferior alveolar canal contact Scientific Reports 2025 15 4178 10.1038/s41598-024-82915-5 39905034 PMC11794476 Ulusoy, A. C., Toprak, T., Selver, M. A., Güneri, P. & İlhan, B. Panoramic radiographic features for machine learning based detection of mandibular third molar root and inferior alveolar canal contact. Scientific Reports 15 39905034 10.1038/s41598-024-82915-5 PMC11794476 27. Buyuk C A fused deep learning architecture for the detection of the relationship between the mandibular third molar and the mandibular canal Diagnostics 2022 12 2018 10.3390/diagnostics12082018 36010368 PMC9407570 Buyuk, C. et al. A fused deep learning architecture for the detection of the relationship between the mandibular third molar and the mandibular canal. Diagnostics 12 36010368 10.3390/diagnostics12082018 PMC9407570 28. Ariji Y Mori M Fukuda M Katsumata A Ariji E Automatic visualization of the mandibular canal in relation to an impacted mandibular third molar on panoramic radiographs using deep learning segmentation and transfer learning techniques Oral Surgery, Oral Medicine, Oral Pathology and Oral Radiology 2022 134 749 757 10.1016/j.oooo.2022.05.014 36229373 Ariji, Y., Mori, M., Fukuda, M., Katsumata, A. & Ariji, E. Automatic visualization of the mandibular canal in relation to an impacted mandibular third molar on panoramic radiographs using deep learning segmentation and transfer learning techniques. Oral Surgery, Oral Medicine, Oral Pathology and Oral Radiology 134 36229373 10.1016/j.oooo.2022.05.014 29. Sarikov, R. & Juodzbalys, G. A literature review 10.5037/jomr.2014.5401 PMC4306319 25635208 30. Li Y Association of the inferior alveolar nerve position and nerve injury: A systematic review and meta-analysis In Healthcare 2022 10 1782 10.3390/healthcare10091782 PMC9498832 36141394 Li, Y. et al. Association of the inferior alveolar nerve position and nerve injury: A systematic review and meta-analysis. In Healthcare 10 10.3390/healthcare10091782 PMC9498832 36141394 31. Lim H-K Jung S-K Kim S-H Cho Y Song I-S Deep semi-supervised learning for automatic segmentation of inferior alveolar nerve using a convolutional neural network BMC Oral Health 2021 21 1 9 10.1186/s12903-021-01983-5 34876105 PMC8650351 Lim, H.-K., Jung, S.-K., Kim, S.-H., Cho, Y. & Song, I.-S. Deep semi-supervised learning for automatic segmentation of inferior alveolar nerve using a convolutional neural network. BMC Oral Health 21 34876105 10.1186/s12903-021-01983-5 PMC8650351 32. Izzetti R Basic knowledge and new advances in panoramic radiography imaging techniques: A narrative review on what dentists and radiologists should know Applied Sciences 2021 11 7858 10.3390/app11177858 Izzetti, R. et al. Basic knowledge and new advances in panoramic radiography imaging techniques: A narrative review on what dentists and radiologists should know. Applied Sciences 11 33. Celik ME Deep learning based detection tool for impacted mandibular third molar teeth Diagnostics 2022 12 942 10.3390/diagnostics12040942 35453990 PMC9025752 Celik, M. E. Deep learning based detection tool for impacted mandibular third molar teeth. Diagnostics 12 35453990 10.3390/diagnostics12040942 PMC9025752 34. Kim J-Y The efficacy of supervised learning and semi-supervised learning in diagnosis of impacted third molar on panoramic radiographs through artificial intelligence model Dentomaxillofacial Radiology 2023 52 20230030 10.1259/dmfr.20230030 37192043 PMC10461259 Kim, J.-Y. et al. The efficacy of supervised learning and semi-supervised learning in diagnosis of impacted third molar on panoramic radiographs through artificial intelligence model. Dentomaxillofacial Radiology 52 37192043 10.1259/dmfr.20230030 PMC10461259 35. Lo Casto A Artificial intelligence for classifying the relationship between impacted third molar and mandibular canal on panoramic radiographs Life 2023 13 1441 10.3390/life13071441 37511816 PMC10381483 Lo Casto, A. et al. Artificial intelligence for classifying the relationship between impacted third molar and mandibular canal on panoramic radiographs. Life 13 37511816 10.3390/life13071441 PMC10381483 36. Choi B-R Clinical image quality evaluation for panoramic radiography in korean dental clinics Imaging Science in Dentistry 2012 42 183 190 10.5624/isd.2012.42.3.183 23071969 PMC3465761 Choi, B.-R. et al. Clinical image quality evaluation for panoramic radiography in korean dental clinics. Imaging Science in Dentistry 42 23071969 10.5624/isd.2012.42.3.183 PMC3465761 ",
  "metadata": {
    "Title of this paper": "Clinical image quality evaluation for panoramic radiography in korean dental clinics",
    "Journal it was published in:": "Scientific Reports",
    "URL": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC12494869/"
  }
}