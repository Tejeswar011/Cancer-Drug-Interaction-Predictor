{
  "title": "Paper_133",
  "abstract": "pmc Front Oncol Front Oncol 1755 frontonco Front. Oncol. Frontiers in Oncology 2234-943X Frontiers Media SA PMC12488436 PMC12488436.1 12488436 12488436 10.3389/fonc.2025.1640685 1 Oncology Original Research Innovative patient-specific delivered-dose prediction for volumetric modulated arc therapy using lightweight Swin-Transformer Zhou Yongqiang  1 Gong Changfei  2  3 Jian Junming  2  3 Zhang Yun  2  3  *  1 Department of Radiation and Medical Oncology, First Affiliated Hospital of Wenzhou Medical University, WenZhou Radiation Oncology and Translational Research Key Laboratory Wenzhou, Zhejiang China  2 Department of Radiation Oncology, Jiangxi Cancer Hospital & Institute, Jiangxi Clinical Research Center for Cancer Nanchang, Jiangxi China  3 NHC Key Laboratory of Personalized Diagnosis and Treatment of Nasopharyngeal Carcinoma (Jiangxi Cancer Hospital) Nanchang, Jiangxi China Edited by: Abdul K. Parchur, University of Maryland Medical Center, United States Reviewed by: Djamel Eddine Chouaib Eddine Chouaib Belkhiat  Takaaki Matsuura *Correspondence: Yun Zhang, zhangyun_1983@sohu.com 18 9 2025 2025 15 480898 1640685 04 6 2025 03 9 2025 18 09 2025 03 10 2025 03 10 2025 Copyright © 2025 Zhou, Gong, Jian and Zhang. 2025 Zhou, Gong, Jian and Zhang https://creativecommons.org/licenses/by/4.0/ This is an open-access article distributed under the terms of the Creative Commons Attribution License (CC BY). The use, distribution or reproduction in other forums is permitted, provided the original author(s) and the copyright owner(s) are credited and that the original publication in this journal is cited, in accordance with accepted academic practice. No use, distribution or reproduction is permitted which does not comply with these terms. Background Volumetric modulated arc therapy (VMAT) necessitates rigorous pre-treatment patient-specific quality assurance (PSQA) to ensure dosimetric accuracy, yet conventional manual verification methods encounter time and labor constraints in clinical workflows. While deep learning (DL) models have advanced PSQA by automating metrics prediction, existing approaches relying on convolutional neural networks struggle to reconcile local feature extraction with global contextual awareness. This study aims to develop a novel lightweight DL framework that synergizes hierarchical spatial feature learning and computational efficiency to enhance VMAT-delivered dose (VTDose) prediction. Methods We propose a hybrid architecture featuring a novel hierarchical fusion framework that synergizes shifted-window self-attention with adaptive local-global feature interaction. (termed “STQA”). Specially, strategic replacement of Swin-Transformer blocks with ResNet residual modules in deep layers, coupled with depthwise separable attention mechanisms, enables 40% parameter reduction while preserving spatial resolution. The model was trained on multimodal inputs and evaluated against state-of-the-art methods using structural similarity index (SSIM), mean absolute error (MAE), root mean square error (RMSE), and gamma passing rate (GPR). Results Visual evaluation of VTDose and discrepancy maps across axial, coronal, and sagittal planes demonstrated enhanced fidelity of STQA to ground truth (GT). Quantitative analysis revealed superior performance of STQA across all evaluation metrics: SSIM=0.978, MAE=0.163, and RMSE= 0.416. GPR analysis confirmed clinical applicability, with STQA achieving 95.43%±3.41% agreement with GT (94.63%±2.84%). Conclusions STQA establishes a paradigm for efficient and accurate VTDose prediction. Its lightweight design, validated through multi-site clinical data, addresses critical limitations in current DL-based PSQA, offering a clinically viable solution to enhance radiotherapy PSQA workflows. deep learning Swin-Transformer volumetric modulated arc therapy pre-treatment specific quality assurance multimodal The author(s) declare financial support was received for the research and/or publication of this article. The authors acknowledge the supported by the National Natural Science Foundation of China (No.82360357), WenZhou Radiation oncology and translational research key lab, and “Five-level Progressive” talent cultivation project of Jiangxi Cancer Hospital & Institute (WCDJ2024YQ04). pmc-status-qastatus 0 pmc-status-live yes pmc-status-embargo no pmc-status-released yes pmc-prop-open-access yes pmc-prop-olf no pmc-prop-manuscript no pmc-prop-legally-suppressed no pmc-prop-has-pdf yes pmc-prop-has-supplement no pmc-prop-pdf-only no pmc-prop-suppress-copyright no pmc-prop-is-real-version no pmc-prop-is-scanned-article no pmc-prop-preprint no pmc-prop-in-epmc yes section-in-acceptance Radiation Oncology 1 Introduction Volumetric modulated arc therapy (VMAT) has emerged as a cornerstone of precision radiotherapy, achieving superior dose conformity through synchronized dynamic multi-leaf collimator (MLC) modulation and gantry rotation ( 1 2 3 Over the past decade, machine learning (ML) has driven advancements in PSQA, particularly in gamma passing rate (GPR) prediction. Early ML approaches, including Poisson regression with Lasso regularization for binary classification ( 4 5 6 7 8 9 10 11 12 13 14 15 18 Extensive studies have validated the potential of ML/DL models in terms of predicting PSQA without performing real measurements ( 4 18 19 20 The remarkable success of Transformers in natural language processing ( 21 22 23 24 27 28 29 30 To address the critical limitations in existing PSQA methodologies, we propose STQA (Swin Transformer-based Quality Assurance) - a novel lightweight network that synergizes hierarchical feature learning with adaptive global-local attention for volumetric dose prediction in VMAT-PSQA. Departing from conventional Transformer adaptations, our architecture introduces three key innovations: 1) A depth-aware hierarchical encoder-decoder framework employing parameter-shared shifted window attention across scales, enabling efficient cross-resolution feature interaction while preserving spatial fidelity; 2) A dual-path feature extraction mechanism combining depth-wise separable local attention with global context modeling through lightweight transformer blocks, effectively capturing both fine-grained dose carving patterns and long-range anatomical dependencies; 3) Bottleneck-adapted skip connections with channel-wise excitation modules that dynamically recalibrate multi-scale features during spatial resolution recovery. Extensive experiments demonstrate STQA’s capability to predict 3D dose distributions closely matching actual VTDose, enabling patient-specific VTDose acquisition. Our method not only demonstrates superior overall prediction performance but also consistently outperforms comparative models across multiple cancer sites (head & neck, chest, abdomen). Significantly, STQA achieves a 40% parameter reduction versus Swin Transformer through depth-wise separable attention in shallow layers, hierarchical parameter-shared window processing, and bottleneck adapters within skip connections that strategically compress and reactivate channels, thereby maintaining performance while eliminating architectural redundancy. 2 Methods 2.1 Data collection and preprocessing The study cohort comprised 200 patients treated with volumetric modulated arc therapy (VMAT) between 2020 and 2024 (  Table 1 Table 1 Clinical characteristics of cancer patients enrolled in this study. Characteristics Sample number Percentage Gender, no. (%) Male 120 60.0% Female 80 40.0% Age (years) <20y 15 7.5% 20y-60y 100 50.0% >60y 85 42.5% Cancer sites H&N 38 19.0% Chest 116 58.0% Abdomen 46 23.0% To ensure spatial consistency across all data types, both the measured and TPS-planned dose distributions were extracted directly from DICOM RT Dose files and converted into 32-bit floating-point arrays ( 3 2.2 The overall network structure The overall architecture of the STQA network proposed in this study, as illustrated in  Figure 1  Figure 1 Figure 1 Flow chart of the proposed STQA. Diagram of a deep learning model for predicting VT Dose from CT and planned VMAT dose images. The encoder consists of patch partitioning, linear embedding, and Swin Transformer blocks with patch merging, reducing dimensions from \\(W/4 \\times H/4 \\times 48\\) to \\(W/32 \\times H/32 \\times 8C\\). The bottleneck uses Swin Transformer blocks. The decoder reverses this process with patch expanding and Swin Transformer blocks, resulting in the predicted VT Dose. Skip connections exist at multiple stages. 2.3 Swin-Transformer-based feature extraction The Swin Transformer architecture employs two distinct attention mechanisms as its core feature extraction components: the Window Multihead Self-Attention (W-MSA) module that processes localized image regions through fixed window partitioning, and the Shifted Window Multihead Self-Attention (SW-MSA) module that enables cross-window information exchange through strategic window shifting operations, with their hierarchical arrangement and interaction patterns visually detailed in  Figure 2 Figure 2  (A) (B) Diagram comparing two neural network architectures labeled A and B. A shows a sequence of LN, MSA, and MLP layers with residual connections. B includes W-MSA and SW-MSA layers in addition to LN and MLP, also with residual connections. Both feature inputs and outputs at different stages, with a dashed line separating them. SwinUNet utilizes Swin-Transformer layers for feature extraction, Patch Merging and Patch Expanding layers for downsampling and upsampling respectively and incorporates skip connections inspired by U-Net to fuse encoder features in the decoder. (1) z ^ l = W − MSA ( LN ( z l − 1 ) ) + z l − 1 (2) z l = MLP ( LN ( z ^ l ) ) + z ^ l (3) z ^ l + 1 = SW − MSA ( LN ( z l ) ) + z l (4) z l + 1 = MLP ( LN ( z ^ l + 1 ) ) + z ^ l + 1 (5) A t t e n t i o n ( Q , K , V ) = S o f t M a x ( Q K T d + B ) V In Equations 1 4  z ^ l  z l  l − t h Equation 5  Q , K , V ∈ R M 2 × d  M 2  d M M  B ^ ∈ R ( 2 M − 1 ) × ( 2 M + 1 )  B ^ Equation 6 (6) y = x − E [ x ] Var [ x ] + ϵ * γ + β Where  E [ x ]  x  Var [ x ]  x  ϵ  γ  β After passing through the LN layer, it is input into the W-MSA or SW-MSA layer. Compared to multi-head self-attention (MSA), W-MSA saves a significant amount of computation by independently computing each window. For an input image of size  ( h , w ) Equations 7 8 (7) Ω ( MSA ) = 4 h w C 2 + 2 ( h w ) 2 C (8) Ω ( W − M S A ) = 4 h w C 2 + 2 M 2 h w C W-MSA reduces computation but leads to a lack of information communication between windows. To address this issue, SW-MSA must be computed in subsequent blocks. Information interaction between windows is achieved by shifting the windows down and to the right by half the window size and then computing W-MSA again for the shifted windows. Therefore, W-MSA and SW-MSA need to appear in pairs. It is for this reason that the number of blocks in Swin Transformer is typically even. In Swin-UNet, the number of blocks in Swin Transformer is 2, comprising one W-MSA block and one SW-MSA block. After passing through the W-MSA layer or SW-MSA layer, followed by a BN layer, and finally a multi-layer perceptron (MLP) for feature mapping, the final output is obtained. 2.4 The proposed STQA Swin-UNet demonstrates powerful capabilities in extracting contextual information and restoring spatial resolution; however, the convergence of transformer modules for image feature computation in deep bottleneck sections remains suboptimal. Considering the challenges of network parameterization as depth increases, this paper proposes enhancements to the deep bottleneck of Swin-UNet. Since the design of residual blocks in ResNet does not reduce feature extraction capacity with increased network depth, replacing two consecutive Swin Transformer blocks in the bottleneck position with ResNet layers is a viable solution. ResNet networks, primarily composed of multiple residual modules—a popular structure in modern neural networks—address the degradation issues caused by deepening layers, thus enabling parameter computation even in thousand-layer networks. After optimization and comparison, we adopt the final layer of the deep ResNet network as the bottleneck of Swin-UNet to improve the model’s predictive accuracy in quality assurance of preprocessing patient-specific data, as illustrated in  Figure 3 Figure 3 The proposed STQA network. Diagram of a medical imaging model with an encoder-decoder architecture. The top section shows input CT and planned dose images leading to a predicted VTDose through layers of encoding, bottleneck, and decoding with skip connections. The bottom section details the new bottleneck process, including a series of convolutional operations. Layers include patch partition, merging, linear embedding, extension, and Swin transformer, with arcs indicating data flow. As data features pass through the last layer of the ResNet deep network, both image resolution and feature dimensions remain unchanged. As shown in  Figure 3 In the encoder, the image is first divided into patches using a Patch Partition layer, and a\nlinear embedding layer tokenizes the data to produce a C-dimensional representation of size H/4\n× W/4. The divided blocks are then concatenated via a Patch Merging layer, which reduces the\npatch resolution to half of the original; although the merged features are initially four times the\noriginal dimension, an additional linear layer is applied to unify the dimension to twice the\noriginal. At the bottleneck, leveraging the advantage of ResNet’s residual blocks that do not\ndegrade in performance as the network deepens, the fifth layer structure of ResNet is employed to\novercome the convergence issues of transformer blocks in deep networks, with the input feature\nresolution set at W/32 × H/16 and remaining unchanged. Finally, the Patch Expanding layer\nupsamples the features by doubling the resolution while halving the feature dimension until\nfull-size resolution is restored, and the skip connections fuse multi-scale features from the\nencoder with the upsampled features to mitigate spatial information loss caused by downsampling. The\nalgorithm flow of STQA is as follows: (see  Algorithm 1 Algorithm 1 STQA.  2.5 Experiment setup To validate the effectiveness of STQA predictions, we compared our method with three established prediction networks using the same test set: U-Net ( 31 30 23 30 31 32 23 30 For quantitative evaluation, we adopted three established metrics: structural similarity index (SSIM), mean absolute error (MAE), and root mean square error (RMSE). The experimental dataset comprised paired radiotherapy planning data including CT images, Planned dose distributions, and corresponding VTDose ground truth (GT) maps, collected from multiple cancer patients. To leverage multimodal information, we concatenated CT and Planned dose images along the channel dimension as dual-channel inputs, preserving their distinct information characteristics while providing complementary anatomical and dosimetric features to the network. In addition, GPR analysis serves as the most widely adopted methodology for comparing measured and calculated dose distributions in PSQA for VMAT, where the agreement level is typically quantified through GPR metrics. To further evaluate the prediction accuracy across different methods, we additionally compared the three-dimensional GPR (3%/2mm criterion with a 10% threshold) of various prediction approaches. The proposed STQA architecture was implemented in PyTorch and trained/tested on an NVIDIA GeForce RTX 3090 GPU with 16GB memory using CUDA-accelerated computation. We employed the Adam optimizer with L1 loss as the primary objective function, setting the initial learning rate to 1e-5 and training for 200 epochs. To ensure fair comparison, all baseline models were re-implemented using identical training protocols and hardware configurations. The total training time for each model was recorded as follows: U-Net: 28 hours, CGAN: 34 hours, TrQA: 41 hours, SWNet: 44 hours, and STQA: 38 hours. After training, each model can generate a full 3D dose distribution within approximately 5–7 seconds, demonstrating compelling inference speed suitable for time-sensitive clinical settings. Ablation studies were conducted to systematically evaluate key architectural components and parameter settings in our framework. The investigation comprised two main aspects: (1) Performance comparison among three architectural variants: baseline Swin-UNet, our full STQA model, and a hybrid Swin-UNet+ResNet (SURNet) configuration with ResNet blocks directly cascaded at the bottleneck layer. (2) Quantitative analysis of skip connection configurations in STQA, where different numbers of cross-scale connections (0-3) were tested. Specifically, 3 skip connections represent full connections at 1/16, 1/8, and 1/4 resolution levels; 2 connections utilize 1/16 and 1/8 levels; 1 connection employs only the 1/16 level, while 0 connections indicate complete removal of skip connections. This systematic evaluation enables comprehensive understanding of feature propagation mechanisms in our proposed architecture. 3 Results   Table 2  Table 2 Table 2 Comparison of experiments based on STQA and other prediction network models. Method SSIM MAE(%) RMSE(%) U-Net 0.788 0.608 0.931 CGAN 0.891 0.419 0.867 TrQA 0.944 0.251 0.646 SWNet 0.958 0.198 0.597 STQA 0.978 0.163 0.416 For enhanced visual comparison across methodologies,  Figure 4  Figure 4 Figure 4 Qualitative analysis of predicted VTDose distributions (in Gy) across methodologies. Dose distributions are visualized for head & neck (columns 1-3), chest (columns 4-6), and abdominal (columns 7-9) cases. Rows 3, 5, 7, 9, and 11 demonstrate dose discrepancy maps between GT and predicted results. Anatomical plane assignments follow: columns 1/4/7 display axial dose distributions, columns 2/5/8 depict coronal plane mappings, and columns 3/6/9 correspond to sagittal plane patterns. Heatmap comparison grid featuring five models: GT, U-Net, CGAN, TFOA, SWNet, and STQA. Each row shows error heatmaps with varying intensity levels, represented in colors from red (high) to blue (low) and a consistent pattern of visual outcomes across different columns and models. A color scale ranges from negative twenty to eighty at the top. To evaluate the predictive performance of each network for specific cancer sites, tests were conducted separately based on three major cancer sites (head & neck, chest, abdomen), and the results of each method were compared as shown in  Table 3 Table 3 Comparison of model performance across different cancer sites. Method SSIM MAE(%) RMSE(%) H&n/abdomen/chest H&n/abdomen/chest H&n/abdomen/chest U-Net 0.782/0.816/0.821 0.522/0.513/0.505 0.865/0.841/0.822 CGAN 0.892/0.898/0.901 0.419/0.400/0.381 0.848/0.826/0.805 TrQA 0.948/0.954/0.966 0.250/0.245/0.225 0.637/0.632/0.5724 SWNet 0.964/0.967/0.971 0.195/0.186/0.162 0.583/0.577/0.468 STQA 0.980/0.984/0.985 0.159/0.152/0.145 0.411/0.408/0.365   Table 4  Table 5 Table 4 Comparison of performance and parameters among different model architectures. Method SSIM MAE(%) RMSE(%) Model_size SWNet 0.951±0.5e-3 0.188±0.05 0.587±0.24 98.1MB STQA 0.982±0.5e-3 0.160±0.04 0.418±0.31 45.2MB SURNet 0.988±0.4e-3 0.155±0.02 0.394±0.14 105.4MB Table 5 Impact of the number of skip connections on network performance. Skip connection SSIM MAE(%) RMSE(%) 0 0.815 3.256 8.032 1 0.641 1.577 3.412 2 0.957 0.193 0.543 3 0.977 0.168 0.444 4 Discussion Artificial intelligence, particularly deep learning (DL) techniques, has found extensive application in multiple facets of radiotherapy treatment planning and delivery, such as tumor target delineation ( 33 34 23 35 36 In this paper, we aim to obtain global contextual information from radiotherapy volume images to improve the accuracy of VMAT quality assurance. We innovatively improved the Swin-UNet architecture to construct the STQA network, making the network suitable for handling radiotherapy planning data. Specifically, we modified the loss function and optimizer for training the network to L1 loss and Adam, respectively. Moreover, to explore optimal network training, we attempted to train the network using a combination of two loss functions, L1 and L2, with weighted allocation. Most importantly, we replaced two consecutive Swin Transformer modules between the downsampling and upsampling layers of the Swin-UNet network with ResNet layers to overcome the problem of feature extraction degradation due to network depth, thereby improving performance. The inherent properties of Transformers allow them to handle feature representations at a stable and relatively high resolution, accurately meeting the demands for finer-grained and globally consistent predictions in dense prediction tasks. Compared to other state of the art models, we applied Transformer-based DL methods to the VTDose prediction task and achieved better accuracy. This further demonstrates the outstanding achievements of Transformers in medical imaging compared to traditional CNN networks, helping to narrow the development gap between medical imaging DL and natural image processing. Visual comparisons through representative predicted VTDose distributions reinforce these quantitative findings. STQA’s VTDose maps show superior fidelity. The dose difference maps further substantiate this, with STQA exhibiting minimal discrepancies across all cases, especially in high-dose regions and critical anatomical structures. This is particularly important as these areas are often the most challenging to predict accurately due to their complexity and the potential consequences of dosing errors.  Tables 2  4 30 23 Due to the inherent constraints associated with patient data and DL networks, certain discrepancies between predicted and measured results are unavoidable. Addressing these discrepancies in the future involves augmenting the dataset size or refining DL networks through optimization. The patients in the dataset used in this work come from multiple sites, but they are mixed for both training and testing, rather than having one set for training and another for external testing. Since data from different centers may exhibit significant differences, it can affect the effectiveness of training. In the future, balancing data processing or increasing patient data volume will further improve prediction accuracy. However, it is worth noting that while incorporating multi-institutional data could further improve the model’s generalizability by capturing a broader range of anatomical and dosimetric variations, the present study utilized data from a single institution to ensure consistency in imaging and treatment protocols. The inherent rarity and heterogeneity of medical data pose significant challenges to assembling large, diverse multi-center datasets. The predominance of chest cases may introduce a bias toward simpler anatomies, though our model still performed well on more complex sites. Future work will aim to collect a more balanced dataset across cancer sites and institutions. While we did not separately compute voxel-level sensitivity/specificity for gamma-fail classification, operating directly on volumetric VTDose provides the spatial observability required for fail-voxel localization and post-hoc In conclusion, this study proposes a new framework termed STQA for VMAT quality assurance, demonstrating superior performance compared to existing models. To strengthen the model’s generalization capacity and convergence properties, we innovatively integrated a ResNet layer into the network’s bottleneck to enhance feature extraction capabilities while adopting advanced loss functions and optimization strategies. Comprehensive validation conducted on VMAT-treated cancer patient datasets revealed that STQA achieves state-of-the-art performance in both global dose distribution prediction and edge dose accuracy across various tumor sites. This successful implementation not only addresses critical challenges in VMAT quality assurance but also paves the way for effective integration of deep learning across medical domains, potentially inspiring novel methodological developments in medical artificial intelligence. From a clinical integration perspective, STQA demonstrates practical feasibility. The average inference time for a full 3D dose prediction is approximately 5–7 seconds on an NVIDIA RTX 3090 GPU, which is compatible with routine QA workflows. The model can be deployed as a standalone application or integrated into existing treatment planning systems via a standardized DICOM RT Dose interface. Future work will focus on user interface development and real-time validation in clinical settings. Abbreviations VMAT, Volumetric modulated arc therapy; MLC, multi-leaf collimator; PSQA, Patient-specific quality assurance; ML, Machine learning; DL, Deep learning; VTDose, VMAT-delivered dose; CT, Computed tomography; MRI, Magnetic resonance imaging; PET, Positron emission tomography; W-MSA, Window Multihead Self-Attention; SW-MSA, Shifted Window Multihead Self-Attention; LN, LayerNorm; BN, BatchNorm; CV, Computer Vision; CGAN, CycleGAN; TrQA, TransQA; SWNet, Swin-UNet; SSIM, structural similarity index; MAE, mean absolute error; RMSE, Root-mean-square error; GT, Ground truth. Data availability statement The datasets presented in this article are not readily available because the data used and analyzed during the current study are available from the corresponding author on reasonable request. Requests to access the datasets should be directed to zhangyun_1983@sohu.com Ethics statement Written informed consent was obtained from the individual(s) for the publication of any potentially identifiable images or data included in this article. Author contributions YQZ: Project administration, Methodology, Writing – original draft. CG: Writing – review & editing, Conceptualization, Visualization, Formal Analysis, Resources, Funding acquisition. JJ: Writing – review & editing, Conceptualization, Data curation, Investigation. YZ: Conceptualization, Writing – review & editing, Formal Analysis. Conflict of interest The authors declare that the research was conducted in the absence of any commercial or financial relationships that could be construed as a potential conflict of interest. Generative AI statement The author(s) declare that no Generative AI was used in the creation of this manuscript. Any alternative text (alt text) provided alongside figures in this article has been generated by Frontiers with the support of artificial intelligence and reasonable efforts have been made to ensure accuracy, including review by the authors wherever possible. If you identify any issues, please contact us. Publisher’s note All claims expressed in this article are solely those of the authors and do not necessarily represent those of their affiliated organizations, or those of the publisher, the editors and the reviewers. Any product that may be evaluated in this article, or claim that may be made by its manufacturer, is not guaranteed or endorsed by the publisher. References 1 Ono T Iramina H Hirashima H Adachi T Nakamura M Mizowaki T Applications of artificial intelligence for machine- and patient-specific quality assurance in radiation therapy: current status and future directions J Radiat Res 2024 65 421–32 10.1093/jrr/rrae033 38798135 PMC11262865 2 Miften M Olch A Mihailidis D Moran J Pawlicki T Molineu A Tolerance limits and methodologies for IMRT measurement-based verification QA: Recommendations of AAPM Task Group No. 218 Med Phys 2018 45 e53–83 10.1002/mp.12810 29443390 3 Gong C Zhu K Lin C Han C Lu Z Chen Y Efficient dose-volume histogram-based pretreatment patient-specific quality assurance methodology with combined deep learning and machine learning models for volumetric modulated arc radiotherapy Med Phys 2022 49 7779–90 10.1002/mp.16010 36190117 4 Valdes G Scheuermann R Hung CY Olszanski A Bellerive M Solberg TD A mathematical framework for virtual IMRT QA using machine learning Med Phys 2016 43 4323 10.1118/1.4953835 27370147 5 Valdes G Chan MF Lim SB Scheuermann R Deasy JO Solberg TD IMRT QA using machine learning: A multi-institutional validation J Appl Clin Med Phys 2017 18 279–84 10.1002/acm2.12161 28815994 PMC5874948 6 Li J Wang L Zhang X Liu L Li J Chan MF Machine learning for patient-specific quality assurance of VMAT: prediction and classification accuracy Int J Radiat Oncol Biol Phys 2019 105 893 902 10.1016/j.ijrobp.2019.07.049 31377162 PMC7512077 7 Chan MF Witztum A Valdes G Integration of AI and machine learning in radiotherapy QA Front Artif Intell 2020 3 577620 10.3389/frai.2020.577620 33733216 PMC7861232 8 Hirashima H Ono T Nakamura M Miyabe Y Mukumoto N Iramina H Improvement of prediction and classification performance for gamma passing rate by using plan complexity and dosiomics features Radiother Oncol 2020 153 250–7 10.1016/j.radonc.2020.07.031 32712247 9 Granville DA Sutherland JG Belec JG La Russa DJ Predicting VMAT patient-specific QA results using a support vector classifier trained on treatment plan characteristics and linac QC metrics Phys Med Biol 2019 64 095017 10.1088/1361-6560/ab142e 30921785 10 Tomori S Kadoya N Takayama Y Kajikawa T Shima K Narazaki K A deep learning-based prediction model for gamma evaluation in patient-specific quality assurance Med Phys 2018 10.1002/mp.13112 30066388 11 Tomori S Kadoya N Kajikawa T Kimura Y Narazaki K Ochi T Systematic method for a deep learning-based prediction model for gamma evaluation in patient-specific quality assurance of volumetric modulated arc therapy Med Phys 2021 48 1003–18 10.1002/mp.14682 33368406 12 Interian Y Rideout V Kearney VP Gennatas E Morin O Cheung J Deep nets vs expert designed features in medical physics: An IMRT QA case study Med Phys 2018 45 2672–80 10.1002/mp.12890 29603278 13 Kadoya N Kon Y Takayama Y Matsumoto T Hayashi N Katsuta Y Quantifying the performance of two different types of commercial software programs for 3D patient dose reconstruction for prostate cancer patients: Machine log files vs. machine log files with EPID images Phys Med 2018 45 170–6 10.1016/j.ejmp.2017.12.018 29472083 14 Jia M Wu Y Yang Y Wang L Chuang C Han B Deep learning-enabled EPID-based 3D dosimetry for dose verification of step-and-shoot radiotherapy Med Phys 2021 48 6810–9 10.1002/mp.15218 34519365 15 Kalet AM Luk SMH Phillips MH Radiation therapy quality assurance tasks and tools: the many roles of machine learning Med Phys 2020 47 e168–77 10.1002/mp.13445 30768796 16 Pillai M Adapa K Das SK Mazur L Dooley J Marks LB Using artificial intelligence to improve the quality and safety of radiation therapy J Am Coll Radiol 2019 16 1267–72 10.1016/j.jacr.2019.06.001 31492404 17 Yang X Li S Shao Q Cao Y Yang Z Zhao YQ Uncertainty-guided man-machine integrated patient-specific quality assurance Radiother Oncol 2022 173 1 9 10.1016/j.radonc.2022.05.016 35618099 18 Hu T Xie L Zhang L Li G Yi Z Deep multimodal neural network based on data-feature fusion for patient-specific quality assurance Int J Neural Syst 2022 32 2150055 10.1142/S0129065721500556 34895106 19 Matsuura T Kawahara D Saito A Yamada K Ozawa S Nagata Y A synthesized gamma distribution-based patient-specific VMAT QA using a generative adversarial network Med Phys 2023 50 2488–98 10.1002/mp.16210 36609669 20 Yoganathan SA Ahmed S Paloor S Torfeh T Aouadi S Al-Hammadi N Virtual pretreatment patient-specific quality assurance of volumetric modulated arc therapy using deep learning Med Phys 2023 50 7891–903 10.1002/mp.16567 37379068 21 Courant R Edberg M Dufour N Kalogeiton V Transformers and visual transformers Colliot O Machine learning for brain disorders Humana New York, NY 2023 37988536 22 Wolf T Debut L Sanh V Chaumond J Delangue C Moi A 2020 Transformers: State-of-the-art natural language processing Proceedings of the 2020 conference on empirical methods in natural language processing: system demonstrations 38 45 10.18653/v1/2020.emnlp-demos.6 23 Zeng L Zhang M Zhang Y Zou Z Guan Y Huang B TransQA: deep hybrid transformer network for measurement-guided volumetric dose prediction of pre-treatment patient-specific quality assurance Phys Med Biol 2023 68 10.1088/1361-6560/acfa5e 37714191 24 Wu K Peng H Chen M Fu JL Chao HY 2021 Rethinking and improving relative position encoding for vision transformer Proceedings of the IEEE/CVF International Conference on Computer Vision 10033–41 10.1109/iccv48922.2021.00988 25 Li J Yan Y Liao S Yang XK Shao L Local-to-global self-attention in vision transformers 2021 10.48550/arXiv.2107.04735 26 Vaswani A Ramachandran P Srinivas A Parmar N Hechtman B Shlens J 2021 Scaling local self-attention for parameter efficient visual backbones Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition 12894–904 10.1109/cvpr46437.2021.01270 27 Liu Z Lin Y Cao Y Hu H Wei YX Zhang Z 2021 Swin transformer: Hierarchical vision transformer using shifted windows Proceedings of the IEEE/CVF international conference on computer vision 10012–22 10.1109/iccv48922.2021.00986 28 Chen J Lu Y Yu Q Luo XD Adeli E Wang Y Transunet: Transformers make strong encoders for medical image segmentation 2021 10.48550/arXiv.2102.04306 29 Zhang Y Liu H Hu Q 2021 Transfuse: Fusing transformers and cnns for medical image segmentation Medical Image Computing and Computer Assisted Intervention–MICCAI 2021: 24th International Conference Strasbourg, France September 27–October 1, 2021 14 24 Springer International Publishing 10.1007/978-3-030-87193-2_2 30 Lin A Chen B Xu J Zhang Z Lu GM Zhang D Ds-transunet: Dual swin transformer u-net for medical image segmentation IEEE Trans Instrumentation Measurement 2022 71 1 15 10.1109/tim.2022.3178991 31 Ma M Kovalchuk N Buyyounouski MK Xing L Yang Y Incorporating dosimetric features into the prediction of 3D VMAT dose distributions using deep convolutional neural network Phys Med Biol 2019 64 125017 10.1088/1361-6560/ab2146 31082805 32 Zhu J-Y Park T Isola P Efros AA 2017 Unpaired image-to-image translation using cycle-consistent adversarial networks Proceedings of the IEEE international conference on computer vision Venice, Italy 2223–32 33 Shi J Ding X Liu X Li Y Liang W Wu J Automatic clinical target volume delineation for cervical cancer in CT images using deep learning Med Phys 2021 48 3968–81 10.1002/mp.14898 33905545 34 Zou Z Gong C Zeng L Guan Y Huang B Yu X Invertible and variable augmented network for pretreatment patient-specific quality assurance dose prediction J Imaging Inf Med 2024 1 12 10.1007/s10278-023-00930-w 38343215 PMC10976903 35 Cui X Yang X Li D Dai X Guo Y Zhang W A StarGAN and transformer-based hybrid classification-regression model for multi-institution VMAT patient-specific quality assurance Med Phys 2025 52 685 702 10.1002/mp.17485 39484994 36 Hu C Wang H Zhang W Xie Y Jiao L Cui S TrDosePred: A deep learning dose prediction algorithm based on transformers for head and neck cancer radiotherapy J Appl Clin Med Phys 2023 e13942 10.1002/acm2.13942 36867441 PMC10338766 ",
  "metadata": {
    "Title of this paper": "TrDosePred: A deep learning dose prediction algorithm based on transformers for head and neck cancer radiotherapy",
    "Journal it was published in:": "Frontiers in Oncology",
    "URL": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC12488436/"
  }
}