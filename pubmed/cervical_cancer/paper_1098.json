{
  "title": "Paper_1098",
  "abstract": "pmc Cureus Cureus 2757 cureus Cureus 2168-8184 Cureus Inc. PMC12477412 PMC12477412.1 12477412 12477412 41030751 10.7759/cureus.91209 1 Radiology Otolaryngology Beyond Reporting: Claude 3.7 Sonnet Accurately Classifies T Stage and Uncovers Omitted Anatomic Invasion in Nasopharyngeal Carcinoma Magnetic Resonance Imaging (MRI) Reports Muacevic Alexander Adler John R Asari Yusuke 1 Kurokawa Ryo 1 Hagiwara Akifumi 1 2 Kurokawa Mariko 1 Sonoda Yuki 1 Kanzawa Jun 1 Fujisawa Shota 1 Hatano Sousuke 1 Gonoi Wataru 1 Abe Osamu 1  1  2 Wataru Gonoi gonoiw@gmail.com 28 8 2025 8 2025 17 8 494304 e91209 28 8 2025 28 08 2025 30 09 2025 01 10 2025 Copyright © 2025, Asari et al. 2025 Asari et al. https://creativecommons.org/licenses/by/4.0/ This is an open access article distributed under the terms of the Creative Commons Attribution License CC-BY 4.0., which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited. This article is available from https://cureus.com/articles/403546-beyond-reporting-claude-37-sonnet-accurately-classifies-t-stage-and-uncovers-omitted-anatomic-invasion-in-nasopharyngeal-carcinoma-magnetic-resonance-imaging-mri-reports Purpose This study aimed to determine whether Claude 3.7 Sonnet (Anthropic, San Francisco, CA, USA), a large language model (LLM), can (i) assign nasopharyngeal carcinoma (NPC) T classification from routine magnetic resonance imaging (MRI) reports and (ii) identify unreported anatomical structures whose invasion would warrant a higher T stage. Materials and methods This single-institution retrospective study included 38 consecutive patients (31 men; mean age 59.7±14.9 years) who underwent pretreatment MRI for NPC between April 1999 and March 2025. De-identified unstructured \"Findings\" sections were submitted once to Claude 3.7 Sonnet (temperature=0), prompting the model to assign a T stage according to the American Joint Committee on Cancer/Union for International Cancer Control 9th Edition and to list potentially missed invasive sites. Reference-standard staging and relevant omissions were established independently by two radiologists. Model accuracy for T classification and for detecting missing structures was calculated; false-positive flags were recorded. Radiologists re-evaluated MR images for any stage change prompted by the LLM. Results The LLM reproduced the reference T category in 35/38 patients (92.1%). Category-specific accuracy was 100% for T1 (9/9) and T4 (13/13), 90% for T3 (9/10), and 66.7% for T2 (4/6). Among 208 eligible unmentioned structures, the model correctly flagged 81 (38.9%), with a mean of 3.34 false-positive suggestions per case. Subsequent human review confirmed stage upgrades in 2/38 patients (5.3%), both corrected to T4 based on intracranial extension or cranial nerve involvement noted by the LLM. Conclusion Claude 3.7 Sonnet achieved high accuracy in T staging from unstructured free-text MRI reports for NPC and identified clinically important omissions, enabling radiologists to correct staging in select cases. LLM-assisted report auditing may improve staging quality and serve as an educational aid where subspecialty expertise is limited. artificial intelligence claude 3.7 sonnet large language models magnetic resonance imaging nasopharyngeal carcinoma tnm classification This work was supported by the Japan Society for the Promotion of Science (JSPS) Grants-in-Aid for Scientific Research (KAKENHI) grant no. 25K10905 pmc-status-qastatus 0 pmc-status-live yes pmc-status-embargo no pmc-status-released yes pmc-prop-open-access yes pmc-prop-olf no pmc-prop-manuscript no pmc-prop-legally-suppressed no pmc-prop-has-pdf yes pmc-prop-has-supplement no pmc-prop-pdf-only no pmc-prop-suppress-copyright no pmc-prop-is-real-version no pmc-prop-is-scanned-article no pmc-prop-preprint no pmc-prop-in-epmc yes Introduction Nasopharyngeal carcinoma (NPC) is a malignancy arising from the nasopharyngeal epithelium. NPC exhibits striking geographical disparities, with age-standardized incidence rates reaching 20-30 per 100,000 in Southern China and Southeast Asia, and in Epstein-Barr virus (EBV)-associated cases, particularly the non-keratinizing subtype, tumor cells harbor clonal EBV episomes [ 1 2 1 2 1 2 The 9th Version of the American Joint Committee on Cancer/Union for International Cancer Control (AJCC/UICC) tumor, node, and metastasis (TNM) classification for NPC was recently introduced, by incorporating more detailed anatomical criteria to improve staging accuracy and prognostic stratification. The 9th Version retains the same overall T classification structure as the 8th Version and emphasizes specific anatomic spread (e.g., involvement of prevertebral muscles for T2 and cervical vertebrae for T3) that defines advanced disease [ 3 3 4 5 In recent years, artificial intelligence (AI) techniques have been investigated to assist radiological interpretation. Large language models (LLMs) such as OpenAI's GPT-4 and GPT-4o (San Francisco, CA, USA) and Anthropic's Claude 3.5 Sonnet (San Francisco, CA, USA) have drawn particular interest for their ability to understand context and generate human-like text [ 6 7 9 10 14 15 17 18 20 General radiologists who are not head and neck specialists may struggle with nuanced interpretations of NPC cases, which can result in staging errors or ambiguities in reports. Prior research on second-opinion reviews underscores the limitations of non-expert initial interpretations [ 21 This study aims to evaluate the ability of LLMs to accurately determine the T stage of NPC and identify omissions of key anatomical information in MRI reports. Materials and methods Study design and ethical considerations This single-institution retrospective study was conducted in accordance with the principles of the Declaration of Helsinki and was approved by the Research Ethics Committee of the Graduate School of Medicine and Faculty of Medicine of the University of Tokyo (approval number: 2024425NI-(1)). The need for individual informed consent was waived due to the retrospective design of the study and the use of anonymized data. Personal identifiers of all MRI reports were removed before analysis. The overview of the study is summarized in Figure 1 Figure 1 Overview of the study NPC: nasopharyngeal carcinoma; AJCC/UICC: American Joint Committee on Cancer/Union for International Cancer Control; AI: artificial intelligence; MRI: magnetic resonance imaging Image Credit: Authors Patients and data collection We retrospectively identified 38 consecutive patients who underwent preoperative MRI for newly diagnosed NPC at the University of Tokyo, Japan, between April 1999 and March 2025. No exclusion criteria were applied. All reports were written in Japanese, and only the \"Findings\" section of the reports was used in subsequent analysis. Prompting strategy We used Claude 3.7 Sonnet and application programming interfaces (API) to access the model (Claude 3.7 Sonnet: claude-3-7-sonnet-20250219) on April 8, 2025. All analyses were conducted using the Claude 3.7 Sonnet model of the same version within a consistent API environment. This specific model was selected due to its distinguished performance in quiz-based clinical reasoning tasks in the field of diagnostic radiology, as evidenced by recent comparative studies [ 10 11 You are a specialist in head and neck tumors. Based on the following MRI interpretation report, determine the T classification according to the AJCC & UICC 9th edition TNM classification for head and neck cancer. Please assume that there is no invasion into any anatomical structures that are not mentioned in the report. MRI Report:{report_text}. Please respond in JSON format, specifying the T classification (e.g., \"T1\", \"T2\", \"T3\", \"T4\"), listing the anatomical structures whose invasion is not mentioned in the report but could potentially lead to a higher T classification, and for each of these structures indicating the potential T classification if invasion is confirmed. We ensured that both the prompt and the report text were written in Japanese to minimize potential bias that could be caused by translation and interpretation. We submitted each prompt to the model only once and used the first generated response for evaluation. Output analysis One board-certified radiologist with 12 years of head and neck imaging experience and one radiology resident with four years of head and neck imaging experience independently reviewed the reports and assigned a reference-standard T classification and identified missing anatomical elements for each case using the 9th Version of AJCC/UICC TNM classification. Any disagreement was resolved by consensus. The accuracy of the T classification generated by the LLM was then calculated. Next, the accuracy of identifying missing anatomical structures was analyzed. According to the 9th Version of the AJCC/UICC TNM classification, the anatomical structures required to determine the T classification are as follows: for T2, the parapharyngeal space, medial pterygoid muscle, lateral pterygoid muscle, and prevertebral muscle; for T3, the skull base (including pterygoid structures), paranasal sinuses, and cervical vertebrae; and for T4, the intracranial extension, cranial nerves, hypopharynx, orbit (including the inferior orbital fissure), parotid gland, and extensive soft-tissue infiltration beyond the anterolateral surface of the lateral pterygoid muscle. For each case classified as T1, T2, or T3, we counted the number of anatomical structures that could upgrade the T classification (out of 13 items for T1, nine items for T2, and six items for T3) that were not mentioned in the reports but flagged by the LLM. The output was considered correct if the LLM accurately identified both the structure name and the potential upgraded T classification. We defined any structure flagged by the LLM that was either mentioned in the report or irrelevant to upgrading the T classification as a false positive. The two radiologists reviewed each actual MR image and checked whether the unmentioned structures flagged by the LLM might warrant an upgrade in the T classification. For cases where T staging was upgraded upon re-evaluation by radiologists, we examined whether the upgrade should have occurred according to the T classification edition in use at the time of the report (whether the T stage was underestimated at the time of report creation). Results Patient characteristics The study population consisted of 31 men and seven women, with a mean age of 59.7±14.9 years. Intravenous contrast medium was utilized in 37 of 38 cases (97.4%). T classification based on radiology reports was as follows: T1 (n=9), T2 (n=6), T3 (n=10), and T4 (n=13). LLM-based T classification accuracy Among the 38 patients, the LLM accurately predicted the correct T stage in 35 cases (92.1%, Table 1 Table 1 Accuracy of LLM-based T classification and detection of unmentioned anatomical structures LLM: large language model T category Number of cases T classification accuracy Correctly flagged structures False-positive flags per case All T 38 92.1% (35/38) 38.9% (81/208) 3.34 T1 9 100% (9/9) 40% (42/105) 2.00 T2 6 66.7% (4/6) 35.4% (17/48) 3.67 T3 10 90% (9/10) 40% (22/55) 3.20 T4 13 100% (13/13) NA 4.23 The three misclassifications consisted of the following: one T2 tumor misclassified as T3, one T2 tumor misclassified as T4, and one T3 tumor misclassified as T4. Missing Anatomical Structures and Accuracy of LLM Suggestions Across the 38 MRI reports, the LLM correctly flagged 81 of 208 anatomical structures that were unmentioned but would have led to a higher T classification if infiltration had been present, resulting in a recall of 38.9%. Notably, the total number of structures flagged by the LLM (208) coincidentally matched the number of structures that should have been flagged (208), although they were determined independently. Of the 208 total flags generated by the LLM, 81 were judged correct upon review, yielding a precision of 38.9%. The remaining 127 were considered false positives. On average, the LLM produced 3.34 false-positive flags per case (Table 1 The 127 false-positive flags can be categorized as follows: 57 cases involved anatomical structures described under the same T category or a lower T category (e.g., recommending paranasal sinus checks for T4 cases), 55 cases described anatomical structures not listed in the AJCC/UICC classification (e.g., skin infiltration or carotid artery infiltration), nine cases involved incorrect T classifications, and six cases involved anatomical structures already mentioned in the report. Changes to T stage following LLM review In two out of 38 cases, the T classification was corrected based on anatomical structures flagged by the LLM. Specifically, one case had intracranial extension and the other case had cranial nerve involvement, leading to a final decision of T4 instead of the originally reported T3 (Figure 2 3 Figure 2 Post-contrast T1-weighted coronal MR image of nasopharyngeal carcinoma in a 67-year-old male patient The case was initially reported as T3; however, a final classification of T4 was made based on the LLM flag indicating intracranial extension. The arrow indicates the area of intracranial extension. LLM: large language model Figure 3 Post-contrast T1-weighted coronal MR image of nasopharyngeal carcinoma in a 59-year-old male patient The case was initially reported as T3; however, a final classification of T4 was made based on the LLM flag indicating cranial nerve involvement. The arrow indicates the area of cranial nerve involvement. LLM: large language model These upgrades would have also applied under previous editions of the AJCC classifications in use at the time the original reports were written. Discussion In this study, we found that Claude 3.7 Sonnet accurately predicted the T stage of NPC in 92.1% of cases (35 out of 38) based on MRI reports. Beyond replicating the T category, we found that the LLM correctly identified 38.9% of anatomical structures, which had not been previously documented but were indeed relevant for upgrading the T classification. Moreover, in two of 38 cases, human radiologists were able to revise the T classification after considering the LLM's suggestions. To our knowledge, this is the first documented instance where an LLM's output prompted radiologists to modify their staging assessment in real clinical cases. The need for general radiologists to interpret images in areas where they may lack subspecialty expertise is a common challenge. More than half (55.3%) of radiologists primarily practice as general radiologists in the United States, very few institutions are organized by subspecialties in Latin America, and only 11% of radiologists exclusively interpret images within their specific subspecialty area in Japan [ 22 23 A prior investigation into the application of LLMs for TNM classification reported a 47% accuracy rate for T classification using GPT-3.5 Turbo on English lung cancer CT reports [ 18 24 19 16 Despite the promising performance, we must acknowledge the risks of LLM outputs in this context. On average, there were 3.34 incorrect structure flags per case. These false-positive suggestions reflect the well-known tendency of LLMs to \"hallucinate\" plausible but inaccurate information [ 25 Several limitations of our study must be considered. First, this was a single-center retrospective study with a relatively small sample size, which limits the generalizability of our findings to broader clinical settings. Second, the MRI acquisition protocols were continuously updated, resulting in some inconsistency across patients. Third, although we evaluated the LLM using existing MRI reports, these were authored by multiple radiologists with varying levels of expertise and reporting styles. This inter-radiologist variability could have influenced both the baseline completeness of the reports and the model's performance. Fourth, while the model flagged an average of 3.34 anatomical structures per case, this relatively high number of prompts may have implications for workflow efficiency and could contribute to alert fatigue in clinical environments. Fifth, the model's performance is tied to a specific proprietary LLM, which may affect reproducibility if access or versions change over time. Generalizability to other language models or institutions using different infrastructure remains uncertain. Finally, this study did not include prospective clinical validation. While retrospective evaluation allows for controlled assessment, it does not replicate real-world conditions. Future studies should assess the performance and usability of LLMs in real-time reporting environments to determine whether the improvements observed here translate to clinical practice. Conclusions Our study provides preliminary evidence that Claude 3.7 Sonnet may achieve accurate T staging of NPC based on human radiologists' MRI reports and has the potential to identify omissions in those reports. While these findings highlight a promising step toward LLM-assisted radiology reporting in cancer staging, the results should be interpreted with caution due to the small, single-center sample, the absence of a control group, and a relatively high false-positive rate for flagged structures. Further prospective, multi-center validation is necessary before this technology can be considered ready for widespread clinical adoption. Nonetheless, this study underscores the potential of such tools as decision support and educational aids for radiologists. Yusuke Asari and Ryo Kurokawa contributed equally to the work and should be considered co-first authors. Disclosures Human subjects: Animal subjects: Conflicts of interest: Payment/services info: Financial relationships: Other relationships: Author Contributions Concept and design: Acquisition, analysis, or interpretation of data: Drafting of the manuscript: Critical review of the manuscript for important intellectual content: Supervision: References 1 Epidemiology of nasopharyngeal carcinoma: current insights and future outlook Cancer Metastasis Rev Su ZY Siak PY Lwin YY Cheah SC 919 939 43 2024 38430391 10.1007/s10555-024-10176-9 2 Epstein-Barr virus infection and nasopharyngeal carcinoma Philos Trans R Soc Lond B Biol Sci Tsao SW Tsang CM Lo KW 372 2017 10.1098/rstb.2016.0270 PMC5597737 28893937 3 Ninth version of the AJCC and UICC nasopharyngeal cancer TNM staging classification JAMA Oncol Pan JJ Mai HQ Ng WT 1627 1635 10 2024 39388190 10.1001/jamaoncol.2024.4354 PMC11581663 4 Nasopharyngeal carcinoma. A \"different\" head and neck tumour. Part A: from histology to staging Acta Otorhinolaryngol Ital Cantù G 85 98 43 2023 37099432 10.14639/0392-100X-N2222 PMC10132485 5 Diagnosis of skull-base invasion by nasopharyngeal tumors on CT with a deep-learning approach Jpn J Radiol Nakagawa J Fujima N Hirata K 450 459 42 2024 38280100 10.1007/s11604-023-01527-7 PMC11056334 6 Introducing ChatGPT 2022 https://openai.com/blog/chatgpt 7 GPT-4 Turbo with Vision fails to outperform text-only GPT-4 Turbo in the Japan Diagnostic Radiology Board Examination Jpn J Radiol Hirano Y Hanaoka S Nakao T 918 926 42 2024 38733472 10.1007/s11604-024-01561-z PMC11286662 8 Performance of ChatGPT on a radiology board-style examination: insights into current strengths and limitations Radiology Bhayana R Krishna S Bleakney RR 0 307 2023 10.1148/radiol.230582 37191485 9 Performance of ChatGPT on USMLE: potential for AI-assisted medical education using large language models PLOS Digit Health Kung TH Cheatham M Medenilla A 0 2 2023 10.1371/journal.pdig.0000198 PMC9931230 36812645 10 Diagnostic performances of Claude 3 Opus and Claude 3.5 Sonnet from patient history and key images in Radiology's \"Diagnosis Please\" cases Jpn J Radiol Kurokawa R Ohizumi Y Kanzawa J 1399 1402 42 2024 39096483 10.1007/s11604-024-01634-z PMC11588754 11 Diagnostic performances of GPT-4o, Claude 3 Opus, and Gemini 1.5 Pro in \"Diagnosis Please\" cases Jpn J Radiol Sonoda Y Kurokawa R Nakamura Y 1231 1235 42 2024 38954192 10.1007/s11604-024-01619-y PMC11522128 12 Structured clinical reasoning prompt enhances LLM's diagnostic capabilities in diagnosis please quiz cases Jpn J Radiol Sonoda Y Kurokawa R Hagiwara A 586 592 43 2025 39625594 10.1007/s11604-024-01712-2 PMC11953165 13 Influence of prior probability information on large language model performance in radiological diagnosis Jpn J Radiol Fukushima T Kurokawa R Hagiwara A 934 939 43 2025 39907980 10.1007/s11604-025-01743-3 PMC12125143 14 \"This Is a Quiz\" premise input: a key to unlocking higher diagnostic accuracy in large language models Cureus Asari Y Kurokawa R Sonoda Y 0 16 2024 10.7759/cureus.72383 PMC11586072 39583509 15 Evaluating the role of GPT-4 and GPT-4o in the detectability of chest radiography reports requiring further assessment Cureus Kanzawa J Kurokawa R Kaiume M 0 16 2024 10.7759/cureus.75532 PMC11721055 39803046 16 Evaluation of radiology residents' reporting skills using large language models: an observational study Jpn J Radiol Atsukawa N Tatekawa H Oura T 1204 1212 43 2025 40056344 10.1007/s11604-025-01764-y PMC12204868 17 The added value of including thyroid nodule features into large language models for automatic ACR TI-RADS classification based on ultrasound reports Jpn J Radiol López-Úbeda P Martín-Noguerol T Ruiz-Vinuesa A Luna A 593 602 43 2025 39585560 10.1007/s11604-024-01707-z 18 Exploring multilingual large language models for enhanced TNM classification of radiology report in lung cancer staging Cancers (Basel) Matsuo H Nishio M Matsunaga T Fujimoto K Murakami T 3621 16 2024 39518061 10.3390/cancers16213621 PMC11544964 19 Large language models for automated synoptic reports and resectability categorization in pancreatic cancer Radiology Bhayana R Nanda B Dehkharghanian T 0 311 2024 10.1148/radiol.233117 38888478 20 Preliminary assessment of TNM classification performance for pancreatic cancer in Japanese radiology reports using GPT-4 Jpn J Radiol Suzuki K Yamada H Yamazaki H Honda G Sakai S 51 55 43 2025 39162781 10.1007/s11604-024-01643-y PMC11717849 21 Impact of neuroradiologist second opinion on staging and management of head and neck cancer J Otolaryngol Head Neck Surg Lysack JT Hoy M Hudon ME Nakoneshny SC Chandarana SP Matthews TW Dort JC 39 42 2013 23739037 10.1186/1916-0216-42-39 PMC3680178 22 Generalist versus subspecialist characteristics of the U.S. radiologist workforce Radiology Rosenkrantz AB Wang W Hughes DR Duszak R Jr 929 937 286 2018 29173070 10.1148/radiol.2017171684 23 Summary of the proceedings of the International Summit 2015: general and subspecialty radiology Insights Imaging 1 5 7 2016 10.1007/s13244-015-0453-6 PMC4729710 26753633 24 Lung cancer staging using chest CT and FDG PET/CT free-text reports: comparison among three ChatGPT large language models and six human readers of varying experience AJR Am J Roentgenol Lee JE Park KS Kim YH Song HC Park B Jeong YJ 0 223 2024 10.2214/AJR.24.31696 39230409 25 ChatGPT and other large language models are double-edged swords Radiology Shen Y Heacock L Elias J Hentel KD Reig B Shih G Moy L 0 307 2023 10.1148/radiol.230163 36700838 ",
  "metadata": {
    "Title of this paper": "ChatGPT and other large language models are double-edged swords",
    "Journal it was published in:": "Cureus",
    "URL": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC12477412/"
  }
}