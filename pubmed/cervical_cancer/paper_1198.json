{
  "title": "Paper_1198",
  "abstract": "pmc Tomography Tomography 3480 tomog tomography Tomography 2379-1381 2379-139X Multidisciplinary Digital Publishing Institute  (MDPI) PMC12473366 PMC12473366.1 12473366 12473366 41003482 10.3390/tomography11090099 tomography-11-00099 1 Article A Flexible Multi-Channel Deep Network Leveraging Texture and Spatial Features for Diagnosing New COVID-19 Variants in Lung CT Scans https://orcid.org/0000-0003-1226-7610 Fekri-Ershad Shervan Conceptualization Methodology Software Validation Formal analysis Investigation Resources Data curation Writing – original draft Supervision 1 2 * Dehkordi Khalegh Behrouz 1 Sinha Usha Academic Editor 1 khalegh.behrouz@iau.ir 2 * fekriershad@iau.ac.ir 27 8 2025 9 2025 11 9 497671 99 27 5 2025 08 8 2025 16 8 2025 27 08 2025 27 09 2025 28 09 2025 © 2025 by the authors. 2025 https://creativecommons.org/licenses/by/4.0/ Licensee MDPI, Basel, Switzerland. This article is an open access article distributed under the terms and conditions of the Creative Commons Attribution (CC BY) license ( https://creativecommons.org/licenses/by/4.0/ Background: The COVID-19 pandemic has claimed thousands of lives worldwide. While infection rates have declined in recent years, emerging variants remain a deadly threat. Accurate diagnosis is critical to curbing transmission and improving treatment outcomes. However, the similarity of COVID-19 symptoms to those of the common cold and flu has spurred the development of automated diagnostic methods, particularly through lung computed-tomography (CT) scan analysis. Methodology: This paper proposes a novel deep learning-based approach for detecting diverse COVID-19 variants using advanced textural feature extraction. The framework employs a dual-channel convolutional neural network (CNN), where one channel processes texture-based features and the other analyzes spatial information. Unlike existing methods, our model dynamically learns textural patterns during training, eliminating reliance on predefined features. A modified local binary pattern (LBP) technique extracts texture data in matrix form, while the CNN’s adaptable internal architecture optimizes the balance between accuracy and computational efficiency. To enhance performance, hyperparameters are fine-tuned using the Adam optimizer and focal loss function. Results: The proposed method is evaluated on two benchmark datasets, COVID-349 and Italian COVID-Set, which include diverse COVID-19 variants. Conclusions: The results demonstrate its superior accuracy (94.63% and 95.47%, respectively), outperforming competing approaches in precision, recall, and overall diagnostic reliability. convolution neural network texture image analysis deep network feature extraction computer tomography scan This research received no external funding. pmc-status-qastatus 0 pmc-status-live yes pmc-status-embargo no pmc-status-released yes pmc-prop-open-access yes pmc-prop-olf no pmc-prop-manuscript no pmc-prop-legally-suppressed no pmc-prop-has-pdf yes pmc-prop-has-supplement no pmc-prop-pdf-only no pmc-prop-suppress-copyright no pmc-prop-is-real-version no pmc-prop-is-scanned-article no pmc-prop-preprint no pmc-prop-in-epmc yes 1. Introduction Since the onset of the global COVID-19 pandemic over 40 months ago, the virus has had a devastating impact worldwide. Official World Health Organization (WHO) reports indicate that more than 800 million confirmed cases have been recorded, with approximately 8 million deaths attributed directly to the virus as of December 2022. Additionally, nearly 40% of survivors have experienced long-term physical and respiratory complications. COVID-19 remains clinically unpredictable, posing a persistent threat to healthcare systems by straining resources and reducing efficiency. A critical challenge in managing this pandemic and future infectious disease outbreaks is the lack of rapid and accurate diagnostic tools [ 1 Rapid detection of positive cases and their quarantine are the most effective ways of controlling this epidemic. Thus far, various methods have been proposed to identify positive cases of the COVID-19 virus, some of which have been approved by the World Health Organization [ 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 11 12 13 14 15 16 17 18 Figure 1 Chest X-rays and lung CT scans are both imaging techniques, but they differ significantly in their detail. Chest X-rays provide a basic, two-dimensional (2D) image of the chest, while CT scans offer detailed, three-dimensional (3D) images of the lungs and surrounding structures. Chest X-rays (radiography) produce a 2D image by passing X-rays through the chest. X-rays provide less detail than CT scans and primarily useful for visualizing bones, heart, and large lung structures. Chest X-rays involve lower radiation exposure than CT scans. CT scan images create detailed 3D images of the chest by taking multiple X-ray images from different angles and using a computer to reconstruct them. The CT scan’s main advantages over a chest X-ray are its high detail, allowing visualization of small nodules or other abnormalities in the lungs and surrounding tissues or blood vessels. In this article, a machine-learning-based method for detecting COVID-19 is presented, which, unlike common methods in this family, does not have a feature engineering stage and uses deep features for classification. The method presented in this article includes three main stages: preprocessing, feature extraction, and classification. In the feature extraction stage, a two-channel deep convolutional neural network (DCNN) is used. Unlike common deep networks, the presented DCNN is fed in one channel with image texture features and in the other channel with visual information in the spatial domain. Layers related to classification, such as fully connected and softmax, have been removed from the internal structure and replaced with a flatten layer. Finally, a fine-tuned random forest classifier has been used. In order to increase the efficiency, both channels have been trained separately using relevant CT scan images, and their hyperparameters have been optimized using an Adam optimizer algorithm and a focal loss function. The main goal of this article is to diagnose COVID-19 based on the analysis of lung CT scan images. The following two main contributions are presented in this paper: Using a two-channel convolutional neural network with the same structure in channels and two different power sources can increase the accuracy of COVID-19 detection compared to existing methods. When using a consistent and tuned classifier, the use of deep features in a classical machine-learning pipeline in which feature extraction and classification are performed separately can achieve higher accuracy than many popular deep neural networks for COVID-19 diagnosis. The main novelty of this paper is the design of a two-channel deep convolutional neural network with two different input sources in such a way that one source carries the image information in the spatial domain, while the second source feeds the DCNN with image texture features extracted using a modified local binary patterns operator. Also, the proposed two-channel DCNN is only used for feature extraction and is applied for diagnosis of COVID-19 in a general machine-learning format. In other words, the design of a two-channel deep neural network with two separate input sources, which enables all features to originate from the training process, unlike concatenation techniques, and the use of deep features of such a network in a larger structure based on the random forest classifier is the innovation of this paper, which has not been considered in previous research. The rest of the paper is organized as follows: In Section 2 Section 3 Section 4 2. Related Works As mentioned in the Introduction Section, many different methods have been presented to identify COVID-19 patients based on the analysis of lung CT scan images [ 19 20 21 As mentioned in the Introduction, the method presented in this article is based on the structure of machine learning. Therefore, feature extraction and classification were performed separately. However, to increase the efficiency of the proposed method, a two-channel deep convolutional neural network is used in the feature extraction stage. In the rest of this section, some of the most relevant and efficient methods from these two groups are reviewed. Ravi et al. [ 22 22 Soni et al. [ 23 23 23 Perumal et al. [ 24 24 Santos and Melin [ 25 25 As previously mentioned, several researchers presented COVID-19 diagnosis methods based on classical machine-learning techniques. Ozturk et al. [ 26 26 Song et al. [ 27 27 Patel and Kashyap [ 28 28 29 29 Kaushik et al. [ 30 Liu et al. [ 31 Diagnosing pandemic diseases like COVID-19 is a multi-sectoral issue, and development and research in each sector can impact the accuracy of diagnosis and reduce mortality rates. Memos et al. [ 32 As previously explained, COVID-19 is a multifaceted disease that affects different parts of the body. Coughing is one of the common symptoms in most infected patients. Rashid et al. [ 33 33 Table 1 3. Materials and Methods As mentioned in the Introduction Section, beyond affecting the lungs’ visible appearance, the COVID-19 virus also directly impacts lung texture. Therefore, spatial domain analysis alone is insufficient for extracting discriminative features. Thus, the image texture requires specialized analysis. Machine-learning-based methods usually have two separate phases of feature extraction and classification, whereas deep learning-based networks perform feature extraction during the network’s training process. Thus far, many operators have been presented for image texture analysis, but nearly all of them are defined in the spatial domain, and using them in a deep learning-based structure is a serious challenge. In some studies, to solve this challenge, the input image is analyzed separately in two distinct phases using texture analysis operators and a deep network. The features extracted in each phase are then concatenated and fed into a supervised classifier. Research results have shown that this strategy for combining texture features and deep neural networks is inefficient for the following reasons. There is an imbalance between the number of features extracted using deep convolutional networks versus texture analysis operators and a much longer execution time of training and feature extraction in the deep network than using statistical texture analysis operators. The deep network needs to be trained, while in the other phase the texture operators are not trained. This article presents a COVID-19 diagnosis method combining machine-learning and deep learning strategies. The presented method consists of three steps, preprocessing, feature extraction, and classification. The main structure of the proposed approach is shown in Figure 2 3.1. Preprocessing Step Lung CT scan images are usually acquired by imaging devices with different brands and different qualities. Therefore, the acquired image quality in some laboratories may not be suitable. Therefore, the main goal in the preprocessing stage is to enhance the image quality and reduce noise. As mentioned above, the main innovation of this paper is the inclusion of texture features of lung CT scans in the diagnostic process. Therefore, the input of the first channel of the proposed deep CNN is the original image in the spatial domain. Also, the input of the second channel is the texture features in a matrix format of the same size as the original image. Therefore, using a single method to enhance the image quality of both channels is not efficient. To improve the quality of the original image, the histogram equalization algorithm is used as a simple and fast image enhancement method. Histogram equalization is a simple algorithm for adjusting image intensities to enhance contrast and brightness. Histogram equalization is a straightforward technique that adapts to the input image and its operator. In theory, the original input image can be recovered using the output histogram equalized image. The calculation is not computationally intensive. Histogram equalization algorithm can be performed in the following three steps: Build the histogram of the input image; Compute the normalized summation of histogram bins; Transform the input image to an output image. The BM3D filter is used to enhance the contrast and reduce the noise in the second channel. The BM3D filter [ 36 36 The modified BM3D (MBM3D) was first proposed by Rubel et al. to reduce spatially correlated noise [ 37 (1) d Q , P = ∑ i = 1 N | Q i − P | ∑ i = 1 N | Q i + P | P Q N N β (2) T K , l = β σ 0 W n o r m K , l l = 0 , 1 , … , 7 3.2. Feature Extraction Step The method presented in this article is designed based on a machine-learning strategy. Therefore, the feature extraction step is performed independently from the classification step. As mentioned above, deep features are extracted through two separate channels in the deep convolutional neural network. The block diagram of our proposed approach is shown in Figure 2 3.2.1. Modified Local Binary Patterns The local binary pattern (LBP) operator was first proposed by Ojala et al. [ 38 (3) s i = 1  if  i ≥ 0 0  if  i < 0 Finally, by checking the completion of neighbors, a binary pattern with P bit is produced. By transferring this binary pattern to ten-format digits, a number is extracted as the LBP value of the central pixel (Equation (4)). (4) L B P P , R ( c ) = ∑ n = 0 p − 1 s ( I n − I c ) 2 n For example, with 8 neighbors, the generated value ranges from 0 and 255. This process is applied independently to each image pixel. Ojala et al. [ 39 39 (5) L B P P , R x c , y c = S I 1 − I c − S I P − I c + ∑ n = 2 P S I n − I c − S I n − 1 − I c Uniformity should be calculated for all of the extracted binary patterns. Next, patterns are grouped into two categories, “uniform” and “non-uniform”, based on a threshold UT. Hence, patterns with a uniformity value of less than UT are categorized as uniform. All patterns with a uniformity value greater than UT are known as non-uniform. Finally, a label is assigned to each pattern based on Equation (6). For uniform patterns, the label is assigned based on the total number of ones in their extracted binary pattern. The label value “ P (6) M L B P P , R r i u T = { ∑ k = 1 P ( I k − I c )            i f  U ( L B P P , R ) ≤ U T P + 1 e l s e w h e r e According to Equation (6), a numeric label in the range of [0– P P,R P T T P MLBP MLBP P MLBP P R (7) = f 0 N t o t a l , f 1 N t o t a l , f 2 N t o t a l , … , f p + 1 N t o t a l f i i N total 3.2.2. Proposed Deep CNN As shown in Figure 2 Figure 3 Table 2 Section 4.5 The selection of the activation function in deep neural networks has a great impact on the final efficiency of the deep network and the dynamics of training. In most related articles, the ReLU (Rectified linear unit) activation function is usually used, which is shown in Equation (8). F(x) = max (0, x) (8) So far, different activation functions have been proposed, each of which has its own disadvantages and limitations. Therefore, the Swish function was presented for the first time by Google’s team and is defined in Equation (9). F(x) = x·sigmoid(x) (9) The test results provided by Google show that the Swish function works better than common functions such as the ReLU function in deeper models and challenging datasets. According to the Google report, replacing the ReLU function with Swish units improves the classification accuracy on the ImageNet dataset by 0.9% for Mobile NASNetA and 0.6% for the Inception-ResNet-v2 network. The Swish function is simple and can be easily replaced with ReLUs function units in any neural network. The Swish function provides this benefit along with being non-monotonic, which enhances the expression of input data and the weight to be learned. COVID-19 is still an unknown disease that produces a wide range of symptoms in different patients. Therefore, from the point of visual features, the lung CT scan of patients vary greatly from one another. Hence, we are faced with a challenging database in this article. For this reason, we have used the Swish activation function in the provided DCNN. The structure of the proposed DCNN is defined dynamically in such a way that the user can change the number of iterative blocks. The results of our tests showed that repeating the blocks three times provides the highest accuracy among the possible numbers of repetitions in the range of 1 to 6. As mentioned in the introduction, the COVID-19 is a very new disease, and the number of samples in both healthy and diseased groups is not the same. The main contribution of this paper is to present a method for COVID-19 disease diagnosis based on a machine-learning strategy that utilizes deep features. Therefore, at the end of the proposed DCNNs, there are no classification layers such as fully connected or soft max. The output of both channels is connected to a flatten layer. A flatten layer collapses the spatial dimensions of the input into a single vector. The flatten layer is used to convert the two-dimensional matrix extracted from the internal layers of the deep network into a numerical feature vector (one dimensional array). The output of the flatten layer is used as input data to train the classifier in the proposed structure. The process of the flatten layer is shown with an example in Figure 4 3.2.3. Hyperparameter Optimization In this article, a DCNN with two parallel channels is designed to detect COVID-19, one of which is fed with image texture information and the other with image spatial domain information. To adjust the weights of these two channels, the benchmark COVID-CT-349 database was divided into two parts, training and testing sets. About 30% of the dataset samples (224 images) were selected as the training set. In order to balance the size of both classes (negative COVID-19 and infected with COVID-19 cases), 112 samples were randomly selected from each class. All remaining images (522 samples) were considered as the test set. The details of the databases used in the experiments are explained in Section 4.1 The Adam optimizer was used to optimize the hyperparameters. We also used a focal loss function with γ = 2 as the loss function for both of channels. To reduce the training runtime, both channels were trained for 40 epochs. First, initial learning rate is considered as 10 −5 −6 Figure 5 FL(pt) = −αt(1 − pt)γ log(pt) (10) Focal loss can be interpreted as a binary cross-entropy function multiplied by a modulation factor, (1 − pt)γ. The modulating coefficient reduces the contribution of easily classified samples. In Equation (10), pt is a function of real labels. Also, αt is a weighting factor that balances the effect of the moderating factor. Xavier initialization (Glorot) was also used to initialize the weights. Xavier is an advanced initialization scheme for CNNs. The biases and the weights were initialized in each layer (Equation (11)). (11) W i , j ~ U − 1 S , 1 S The proposed DCNN was trained in 40 epochs. In order to select a more consistent learning rate and epoch values, our proposed DCNN was evaluated with a range of different possible values. The results are reported with details in Section 4.6 −5 −6 −2 Section 4.6 3.3. Classification Step As mentioned previously, the method presented in this article is based on a classical machine-learning structure. Therefore, the classification stage is separate from the feature extraction stage. For this reason, a variety of classifiers can be used at this stage. In this article, several different classifiers were tested; the random forest classifier provided the highest performance. The results of testing different classifiers are reported in the next section. Random forest is a supervised machine-learning algorithm widely used for both classification and regression problems. It builds multiple decision trees on different data samples and uses their majority vote for classification or their average prediction for regression. Random forest (RF) is a supervised ensemble learning method which can be used for classification. RF is made up of a set of low-depth decision trees. A decision is made in RF by constructing a multitude of decision trees during the training process and taking their majority vote. The main contribution behind random forest learning is that making a decision based on combining the decisions of several uncorrelated models, such as decision trees, performs better than them making decisions on their own. Two initial parameters, the number of trees and the maximum depth, can be used to tune random forest. Some of the advantages of random forest are as follows: In addition to classification, it can also be used for regression; Due to the concept of branches and trees, random forest predictions are more human-understandable than other classifiers; It can handle large datasets more efficiently than some other supervised classifiers; The random forest algorithm provides a higher level of accuracy in predicting outcomes than the decision tree algorithm. 4. Experimental Results 4.1. Datasets The COVID-19 virus is a relatively new and widespread virus. Since the outbreak of this disease, various databases of CT scan images of patients’ lungs have been prepared all over the world. Therefore, to analyze and compared the efficiency of diagnostic methods in this field, they must be evaluated on the same database. For this purpose, in this article, we have evaluated the efficiency of the proposed method on a benchmark dataset. Also, the performance of the proposed method has been compared only with articles that have reported their efficiency on the same database. Zhao et al. [ 40 Figure 6 Section 3.2.3 Also, in order to evaluate the generalizability of the proposed approach, another benchmark dataset from Italian Society of Medical and Interventional Radiology [ 41 4.2. Performance Evaluation Metrics Considering the low transmission and mortality rates of common respiratory diseases such as the cold and flu, distinguishing patients with COVID-19 from other people (whether healthy or with other respiratory diseases) is the main goal of this article. Therefore, we are facing a two-class problem. (12) Accuracy = T P + T N T P + T N + F N + F P  (13) Precision = T P T P + F P 4.3. Performance Evaluation of the Proposed Approach in Terms of Different Classifiers As described above, the proposed approach follows a machine-learning strategy. Thus, it is possible to perform different classifiers in the classification phase. The performance of the presented method is evaluated using different classifiers as reported in Table 3 Table 3 Random forest (RF) and support vector machine (SVM) are both powerful machine-learning algorithms, but they excel in different scenarios. RF is generally preferred for large, high-dimensional datasets and when interpretability is important, while SVMs can be more effective for smaller, well-structured datasets with clear separation boundaries. Also, in our proposed method, 6400 features are extracted using deep networks which is a high-dimensional set. Some benefits of RF are as follows: handles large datasets and high dimensionality, robust to outliers and missing data, feature importance, less prone to overfitting, interpretability, speed, and parallelism [ 42 4.4. Random Forest Tuning Random forest is a parametric classifier; if its parameters are tuned, the classifier’s efficiency can be increased. Maximum depth (D) and number of trees (N) are two main parameters in random forest that can be tuned. To find the optimal values for these two parameters, metaheuristic algorithms could be used. But it is extremely time-consuming and would reduce the generalizability of the method for real-world laboratory applications. Therefore, in this article, the ranges of allowed values for maximum depth [ 1 2 3 4 5 6 7 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 Table 4 D N Table 4 COVID-19 diagnosis is a binary classification problem where the risk of misdiagnosis is not equal for both classes. As described above, the transmission rate of the COVID-19 virus is high; hence, the risk of misdiagnosis of a patient as healthy is much higher than in other cases. In this respect, more than precision, the confusion matrix of the classification process is shown in Table 5 4.5. DCNN Optimization in Terms of Internal Blocks As explained in Section 3.2.2 Figure 7 Figure 7 As can be seen, by increasing the number of blocks up to three, the accuracy of the proposed method increased rapidly, and after that, the growth acceleration decreased drastically and the accuracy increased by just 0.01% in a five-block manner. However, the execution time of the proposed method increased rapidly as the number of blocks increased. Therefore, in order to maintain the balance between detection accuracy and execution time, the effectiveness of the proposed method has been considered in three-channel mode ( Figure 8 4.6. DCNN Optimization in Terms of Learning Rate As described above, training the proposed DCNN for 40 epochs provides maximum classification accuracy. In order to select a more consistent learning rate value and epoch number, our proposed DCNN was evaluated in terms of different possible values. The results are reported in Table 6 −6 4.7. Comparison Proposed Approach with Base-Line Methods As mentioned in the Introduction, one of the main contributions of this paper is the use of deep features in a classical machine-learning-based structure to diagnose COVID-19 patients. In this experiment, the efficiency of the proposed method is evaluated once only based on the textural features extracted by the MLBP operator and tuned random forest. Its results are shown in Table 6 Table 7 As mentioned above, one of the achievements of this research is the use of deep features in a classical machine-learning-based structure. In the scenario where the proposed DCNN without RF is considered, the same softmax layer that was used as a final layer to train the network also played the role of a classifier and the test data on the trained network were evaluated. In other words, in this scenario, the performance of the RF is compared to a classical softmax layer that is responsible for classification in DCNNs. As reported in Table 7 4.8. Comparison with State-of-the-Art Methods The main goal of this article was to provide a method to diagnose the disease of COVID-19 more accurately than the existing methods. Therefore, in this experiment, the efficiency of the proposed method has been compared with some of the most efficient methods in this field under the same conditions in terms of the database and evaluation metrics. Results are reported in Table 8 Table 9 Table 8 As can be seen in Table 9 48 48 48 48 48 As reported in the results, the accuracy of the proposed method on the Italian database is higher than that on the COVID-CT-349 database. The ratio of COVID-19 to non-COVID-19 samples in the Italian database is 46.4:53.6 percent and in the COVID-CT-349 database, 46.7:53.3 percent. Therefore, both databases are only slightly unbalanced and do not differ much from each other in terms of data balance. Therefore, the reason for the superiority of the proposed method on the Italian database is not limited to database balance or overfitting. The dimensions of the samples in the COVID-Ct-349 database vary greatly. The height of the samples ranges from 153 to 1853 and the width of the images varies from 124 to 383. Therefore, in the preprocessing stage, in order to train the model, the dimensions of all the samples must be the same. Image resizing can lead to the loss of information or the creation of unrealistic pixels, while the dimensions of the images in the Italian database are all 512 × 512, resulting in fewer constraints during the resizing stage. This is one of the reasons for the better performance of the proposed method on the Italian database. 4.9. Offline and Online Process As explained, the proposed model was trained in 60 epochs. Given the available hardware capabilities, training each channel of the proposed model took approximately 4.8 h. The training of deep neural networks is performed offline and has no direct impact on the end user. In other words, the system is trained offline only once by the development team. Then, users, including doctors and specialists, receive a response through a fully online process by providing a patient’s image to the trained system. Inference is an online process that plays a crucial role in clinical deployment. The evaluation results show that the decision time of the proposed model for a test image with dimensions of 256 × 256 is less than 5.3 s. Therefore, the results indicate that our proposed approach can make decisions in real applications. 5. Discussion As discussed above, two main contributions are pursued in this paper. The first contribution was as follows: Using a two-channel CNN with the same architecture in channels and two different power sources provides better results for COVID-19 detection compared to existing one-channel methods. The results reported in Table 7 Using deep features in combination of supervised classifiers in which feature extraction and classification are performed separately achieves higher diagnostic accuracy than many popular deep CNNs for COVID-19 diagnosis. Most of the methods compared in the Table 7 Table 8 Table 7 In this paper, the efficiency of the proposed method was evaluated on two databases with a total of 1183 images. Thus, the number of samples and the diversity of imaging laboratories are limited. Therefore, training the system with a larger and more diverse set of samples would increase the model’s robustness to environmental variations. Thus, it can be acknowledged that the proposed model was trained only on variants of the COVID-19 virus for which images were available in the databases. However, we know that this virus has the ability to mutate and produce new variants. Therefore, one of the limitations of the experiments is the dependence on the virus’s variants in the patients tested. Random forest is an ensemble learning technique that enhances prediction accuracy and stability by combining multiple decision trees. It is applicable to both classification and regression tasks. The process consists of the following four key steps: bootstrap aggregating (bagging), feature randomization, individual tree construction, and prediction Aggregation. In the third step, a decision tree is trained for each bootstrapped and feature-randomized subset of the data. These trees are usually grown to their maximum depth without pruning. For the classification tasks, each tree independently predicts the class label for a new data point. The final output is determined by majority voting—the class with the most votes across all trees becomes the model’s prediction. Our results show that trees constructed using only features from the second channel (texture information) achieved approximately 9% higher accuracy in correctly labeling the test data than those using only features from the first channel (spatial domain). The higher recall rate of the proposed approach, compared to the methods analyzed in Table 8 Table 9 As shown in Table 8 27 Table 8 Table 9 6. Conclusions The main goal of this article was to present an efficient method for diagnosing COVID-19 patients through analysis of lung CT scan images. In this regard, a method including three stages of preprocessing, feature extraction, and classification was presented. The general structure of the proposed method is designed based on classical machine-learning techniques, with the difference that deep features are used in the feature extraction stage. For feature extraction, a deep convolutional neural network with two channels is proposed. The power source of one of the channels is the texture features of the CT scan image and the power source of the second channel is the observable information of the image in the spatial domain. The results of the experiments showed the following advantages in relation to the presented method: COVID-19 causes detectable lung texture changes. The proposed DCNN without the presence of a channel that feeds with image texture features provided a lower detection accuracy than the two-channel mode. Replacing deep CNN classification layers with supervised classifiers improved the COVID-19 diagnosis accuracy. Unlike methods that concatenate deep features with texture information, in this paper, the texture features were used to feed one of the channels of a deep convolutional neural network. The results showed that the presented two-channel CNN provides higher accuracy than many compared methods. Results show that COVID-19 disease, in addition to appearance properties such as color and shape, may disturb the texture of the patient’s lungs. The proposed method is a general approach where none of its steps are dependent on the type of input image. Therefore, an idea for future research is to apply the presented model in other visual pattern classification problems. The classification task in the proposed method originates from the trained two-channel deep neural network that is trained by spatial information and texture features of CT scan images. Therefore, the proposed two-channel deep neural network has a general architecture and can be used in similar classification problems such as diagnosing various lung diseases, diagnosing breast cancer, and diagnosing malignant tumors, in which texture variations play an important role. Like other viruses, COVID-19 continually evolves and undergoes mutations, resulting in new variants with distinct characteristics such as altered transmissibility and disease severity. Therefore, current detection methods, including ours, are inherently limited to recognizing variants present in their training data. However, our proposed method’s trainable architecture allows for adaptation to emerging variants by incorporating new CT scan images from patients infected with novel COVID-19 variants. Disclaimer/Publisher’s Note: Author Contributions Conceptualization, S.F.-E. and K.B.D.; methodology, S.F.-E.; validation, S.F.-E. and K.B.D.; formal analysis, S.F.-E. and K.B.D.; investigation, S.F.-E. and K.B.D.; resources, S.F.-E. and K.B.D.; data curation, S.F.-E. and K.B.D.; writing—original draft preparation, S.F.-E. and K.B.D.; writing—review and editing, S.F.-E. and K.B.D.; visualization, S.F.-E. and K.B.D.; supervision, S.F.-E. and K.B.D.; project administration, S.F.-E. and K.B.D. All authors have read and agreed to the published version of the manuscript. Institutional Review Board Statement Not applicable. Informed Consent Statement Not applicable. Data Availability Statement The datasets generated during and/or analyzed during the current study are available from the corresponding author on reasonable request. Conflicts of Interest The authors declare no conflicts of interest. References 1. Yi J. Zhang H. Mao J. Chen Y. Zhong H. Wang Y. Review on the COVID-19 pandemic prevention and control system based on AI Eng. Appl. Artif. Intell. 2022 114 105184 10.1016/j.engappai.2022.105184 35846728 PMC9271459 2. Filchakova O. Dossym D. Ilyas A. Kuanysheva T. Abdizhamil A. Bukasov R. Review of COVID-19 testing and diagnostic methods Talanta 2022 244 123409 10.1016/j.talanta.2022.123409 35390680 PMC8970625 3. Pu R. Liu S. Ren X. Shi D. Ba Y. Huo Y. Zhang W. Ma L. Liu Y. Yang Y. The screening value of RT-LAMP and RT-PCR in the diagnosis of COVID-19: Systematic review and meta-analysis J. Virol. Methods 2022 300 114392 10.1016/j.jviromet.2021.114392 34856308 PMC8629515 4. Robinson M.L. Mirza A. Gallagher N. Boudreau A. Jacinto L.G. Yu T. Norton J. Luo C.H. Conte A. Zhou R. Limitations of molecular and antigen test performance for SARS-CoV-2 in symptomatic and asymptomatic COVID-19 contacts J. Clin. Microbiol. 2022 60 e0018722 10.1128/jcm.00187-22 35730949 PMC9297839 5. Shi W. Tong L. Zhu Y. Wang M.D. COVID-19 automatic diagnosis with radiographic imaging: Explainable attention transfer deep neural networks IEEE J. Biomed. Health Inform. 2021 25 2376 2387 10.1109/JBHI.2021.3074893 33882010 PMC8545079 6. Nascimento E.D. Fonseca W.T. de Oliveira T.R. de Correia C.R. Faça V.M. de Morais B.P. Silvestrini V.C. Pott-Junior H. Teixeira F.R. Faria R.C. COVID-19 diagnosis by SARS-CoV-2 Spike protein detection in saliva using an ultrasensitive magneto-assay based on disposable electrochemical sensor Sens. Actuators B Chem. 2022 353 131128 10.1016/j.snb.2021.131128 34866796 PMC8626148 7. Saslow D. Runowicz C.D. Solomon D. Moscicki A. Smith R.A. Eyre H.J. Cohen C. American Cancer Society guideline for the early detection of cervical neoplasia and cancer CA A Cancer J. Clin. 2002 52 342 362 10.3322/canjclin.52.6.342 12469763 8. Hussain E. Hasan M. Rahman A. Lee I. Tamanna T. Parvez M.Z. CoroDet: A deep learning based classification for COVID-19 detection using chest X-ray images Chaos Solitons Fractals 2021 142 110495 10.1016/j.chaos.2020.110495 33250589 PMC7682527 9. Satu S. Ahammed K. Abedin M.Z. Rahman A. Islam S.M.S. Azad A.K.M. Alyami S.A. Moni M.A. Convolutional neural network model to detect COVID-19 patients utilizing lung X-ray images medRxiv 2020 10.1101/2020.06.07.20124594 10. Abbas A. Abdelsamea M.M. Gaber M.M. Classification of COVID-19 in chest X-ray images using DeTraC deep convolutional neural network Appl. Intell. 2021 51 854 864 10.1007/s10489-020-01829-7 PMC7474514 34764548 11. Huang M.-L. Liao Y.-C. A lightweight CNN-based network on COVID-19 detection using X-ray and CT images Comput. Biol. Med. 2022 146 105604 10.1016/j.compbiomed.2022.105604 35576824 PMC9090861 12. Kathamuthu N.D. Subramaniam S. Le Q.H. Muthusamy S. Panchal H. Sundararajan S.C.M. Alrubaie A.J. Zahra M.M.A. A deep transfer learning-based convolution neural network model for COVID-19 detection using computed tomography scan images for medical applications Adv. Eng. Softw. 2023 175 103317 10.1016/j.advengsoft.2022.103317 36311489 PMC9595382 13. Jalali S.M.J. Ahmadian M. Ahmadian S. Hedjam R. Khosravi A. Nahavandi S. X-ray image based COVID-19 detection using evolutionary deep learning approach Expert Syst. Appl. 2022 201 116942 10.1016/j.eswa.2022.116942 35378906 PMC8966159 14. Celik G. Detection of COVID-19 and other pneumonia cases from CT and X-ray chest images using deep learning based on feature reuse residual block and depthwise dilated convolutions neural network Appl. Soft Comput. 2023 133 109906 10.1016/j.asoc.2022.109906 36504726 PMC9726212 15. Shah V. Keniya R. Shridharani A. Punjabi M. Shah J. Mehendale N. Diagnosis of COVID-19 using CT scan images and deep learning techniques Emerg. Radiol. 2021 28 497 505 10.1007/s10140-020-01886-y 33523309 PMC7848247 16. Alquran H. Alsleti M. Alsharif R. Abu Qasmieh I. Alqudah A.M. Harun N.H.B. Employing texture features of chest x-ray images and machine learning in COVID-19 detection and classification Mendel 2021 27 9 17 10.13164/mendel.2021.1.009 17. Yasar H. Ceylan M. A novel comparative study for detection of COVID-19 on CT lung images using texture analysis, machine learning, and deep learning methods Multimed. Tools Appl. 2021 80 5423 5447 10.1007/s11042-020-09894-3 33041635 PMC7537375 18. Hussain L. Nguyen T. Li H. Abbasi A.A. Lone K.J. Zhao Z. Zaib M. Chen A. Duong T.Q. Machine-learning classification of texture features of portable chest X-ray accurately classifies COVID-19 lung infection BioMed. Eng. Online 2020 19 88 10.1186/s12938-020-00831-x 33239006 PMC7686836 19. Ravi V. Narasimhan H. Chakraborty C. Pham T.D. Deep learning-based meta-classifier approach for COVID-19 classification using CT scan and chest X-ray images Multimed. Syst. 2022 28 1401 1415 10.1007/s00530-021-00826-1 34248292 PMC8258271 20. Soni M. Singh A.K. Babu K.S. Kumar S. Kumar A. Singh S. Convolutional neural network based CT scan classification method for COVID-19 test validation Smart Health 2022 25 100296 10.1016/j.smhl.2022.100296 35722028 PMC9188200 21. Perumal V. Narayanan V. Rajasekar S.J.S. Detection of COVID-19 using CXR and CT images using Transfer Learning and Haralick features Appl. Intell. 2021 51 341 358 10.1007/s10489-020-01831-z PMC8852781 35194321 22. Varela-Santos S. Melin P. A new approach for classifying coronavirus COVID-19 based on its manifestation on chest X-rays using texture features and neural networks Inf. Sci. 2021 545 403 414 10.1016/j.ins.2020.09.041 PMC7513693 32999505 23. Öztürk Ş. Özkaya U. Barstuğan M. Classification of Coronavirus (COVID-19) from X-ray and CT images using shrunken features Int. J. Imaging Syst. Technol. 2021 31 5 15 10.1002/ima.22469 32904960 PMC7461473 24. Song L. Liu X. Chen S. Liu S. Liu X. Muhammad K. Bhattacharyya S. A deep fuzzy model for diagnosis of COVID-19 from CT images Appl. Soft Comput. 2022 122 108883 10.1016/j.asoc.2022.108883 35474916 PMC9027534 25. Patel R.K. Kashyap M. Automated diagnosis of COVID stages from lung CT images using statistical features in 2-dimensional flexible analytic wavelet transform Biocybern. Biomed. Eng. 2022 42 829 841 10.1016/j.bbe.2022.06.005 35791429 PMC9247116 26. Attallah O. A computer-aided diagnostic framework for coronavirus diagnosis using texture-based radiomics images Digit. Health 2022 8 20552076221092543 10.1177/20552076221092543 35433024 PMC9005822 27. Dabov K. Foi A. Katkovnik V. Egiazarian K. Image denoising by sparse 3-D transform-domain collaborative filtering IEEE Trans. Image Process. 2007 16 2080 2095 10.1109/TIP.2007.901238 17688213 28. Rubel A. Lukin V. Uss M. Vozel B. Pogrebnyak O. Egiazarian K. Efficiency of texture image enhancement by DCT-based filtering Neurocomputing 2016 175 948 965 10.1016/j.neucom.2015.04.119 29. Ojala T. Pietikäinen M. Mäenpää T. Gray scale and rotation invariant texture classification with local binary patterns Proceedings of the European Conference on Computer Vision Dublin, Ireland 26 June–1 July 2000 404 420 30. Ojala T. Pietikainen M. Maenpaa T. Multiresolution gray-scale and rotation invariant texture classification with local binary patterns IEEE Trans. Pattern Anal. Mach. Intell. 2002 24 971 987 10.1109/TPAMI.2002.1017623 31. Zhao J. Zhang Y. He X. Xie P. Covid-ct-dataset: A ct scan dataset about COVID-19 arXiv 2020 2003.13865 32. Salama W.M. Aly M.H. Framework for COVID-19 segmentation and classification based on deep learning of computed tomography lung images J. Electron. Sci. Technol. 2022 20 100161 10.1016/j.jnlest.2022.100161 33. Wang Z. Dong J. Zhang J. Multi-model ensemble deep learning method to diagnose COVID-19 using chest computed tomography images J. Shanghai Jiaotong Univ. (Sci.) 2022 27 70 80 10.1007/s12204-021-2392-3 34975263 PMC8710815 34. Song Y. Zheng S. Li L. Zhang X. Zhang X. Huang Z. Chen J. Zhao H. Jie Y. Wang R. Deep learning enables accurate diagnosis of novel coronavirus (COVID-19) with CT images IEEE/ACM Trans. Comput. Biol. Bioinform. 2021 18 2775 2780 10.1109/TCBB.2021.3065361 33705321 PMC8851430 35. Imani M. Automatic diagnosis of coronavirus (COVID-19) using shape and texture characteristics extracted from X-Ray and CT-Scan images Biomed. Signal Process. Control. 2021 68 102602 10.1016/j.bspc.2021.102602 33824681 PMC8017558 36. Chen X. Bai Y. Wang P. Luo J. Data augmentation based semi-supervised method to improve COVID-19 CT classification Math. Biosci. Eng. 2023 20 6838 6852 10.3934/mbe.2023294 37161130 37. COVID-19 CT Segmentation Dataset Available online: http://medicalsegmentation.com/covid19/ (accessed on 10 October 2023) 38. Kordnoori S. Sabeti M. Mostafaei H. Banihashemi S.S.A. Analysis of lung scan imaging using deep multi-task learning structure for COVID-19 disease IET Image Process. 2023 17 1534 1545 10.1049/ipr2.12736 39. Wang L. Lin Z.Q. Wong A. COVID-Net: A tailored deep convolutional neural network design for detection of COVID-19 cases from chest X-ray images Sci. Rep. 2020 10 19549 10.1038/s41598-020-76550-z 33177550 PMC7658227 40. Sethy P.K. Behera S.K. Ratha P.K. Biswas P. Detection of coronavirus Disease (COVID-19) based on deep features and support vector machine Int. J. Math. Eng. Manag. Sci. 2020 5 643 651 10.33889/IJMEMS.2020.5.4.052 41. Amyar A. Modzelewski R. Li H. Ruan S. Multi-task deep learning based CT imaging analysis for COVID-19 pneumonia: Classification and segmentation Comput. Biol. Med. 2020 126 104037 10.1016/j.compbiomed.2020.104037 33065387 PMC7543793 42. Daniel Cenggoro T.W. Pardamean B. A systematic literature review of machine learning application in COVID-19 medical image classification Procedia Comput. Sci. 2023 216 749 756 10.1016/j.procs.2022.12.192 36643182 PMC9829419 43. Lee M.-H. Shomanov A. Kudaibergenova M. Viderman D. Deep learning methods for interpretation of pulmonary CT and X-ray images in patients with COVID-19-related lung involvement: A systematic review J. Clin. Med. 2023 12 3446 10.3390/jcm12103446 37240552 PMC10218920 44. Awadelkarim S.A.M. Karrar A.E. Utilization of machine learning algorithms in COVID-19 classification and prediction: A review IJCSNS 2025 25 81 45. AhmedK A. Aljahdali S. Hussain S.N. Comparative prediction performance with support vector machine and random forest classification techniques Int. J. Comput. Appl. 2013 69 12 16 10.5120/11885-7922 46. Memos V.A. Minopoulos G. Stergiou K.D. Psannis K.E. Internet-of-Things-Enabled infrastructure against infectious diseases IEEE Internet Things Mag. 2021 4 20 25 10.1109/IOTM.0001.2100023 47. Yasar H. Ceylan M. Deep learning–based approaches to improve classification parameters for diagnosing COVID-19 from CT Images Cogn. Comput. 2024 16 1806 1833 10.1007/s12559-021-09915-9 PMC8280590 34306240 48. Ibrahim A.U. Ozsoz M. Serte S. Al-Turjman F. Yakoi P.S. Pneumonia classification using deep learning from chest X-ray images during COVID-19 Cogn. Comput. 2024 16 1589 1601 10.1007/s12559-020-09787-5 PMC7781428 33425044 49. Kaushik B. Chadha A. Mahajan A. Ashok M. A three layer stacked multimodel transfer learning approach for deep feature extraction from Chest Radiographic images for the classification of COVID-19 Eng. Appl. Artif. Intell. 2025 147 110241 10.1016/j.engappai.2025.110241 50. Liu H. Zhao M. She C. Peng H. Liu M. Li B. Zafar B. Classification of CT scan and X-ray dataset based on deep learning and particle swarm optimization PLoS ONE 2025 20 e0317450 10.1371/journal.pone.0317450 39869555 PMC11771893 51. Rashid H.-A. Sajadi M.M. Mohsenin T. CoughNet-V2: A scalable multimodal DNN framework for point-of-care edge devices to detect symptomatic COVID-19 cough Proceedings of the 2022 IEEE Healthcare Innovations and Point of Care Technologies (HI-POCT) Houston, TX, USA 10–11 March 2022 37 40 Figure 1 A lung image of a male person in two imaging types. ( a b Figure 2 The block diagram of the proposed COVID-19 diagnosis system in terms of main steps. Figure 3 The internal structure of the proposed 2-channel CNN. Figure 4 The process of the flatten layer. Figure 5 Error rate vs. epochs in the training process. Figure 6 Some samples of COVID-CT-349 dataset. ( a b Figure 7 The performance evaluation based on different number of iterative blocks in terms of accuracy and execution time. Figure 8 Trade-off between execution time and accuracy in terms of number of iterative blocks. tomography-11-00099-t001_Table 1 Table 1 An overview on related studies. Ref. Year Method Classification Advantages Limitations [ 24 2021 Haralick features + pre-trained networks (VGG16, ResNet50, InceptionV3) Deep learning Lower execution time than trained deep networks Lack of deep network training [ 25 2021 GLCM + LBP + MLP Machine learning Lower computational complexity than deep method Lower performance than trained deep networks [ 26 2021 Handcrafted features (GLCM + LBP + SFTA) + PCA + SVM Machine learning Lower computational complexity than deep-based methods Lower performance than deep learning-based methods [ 22 2022 EfficientNet + KPCA + Ensemble classifiers Hybrid Higher performance than compared methods in reference Higher tunable parameters than single classifiers [ 23 2022 Fusion of Deep networks (Resnet50/Inception V3/Efficientb7) Deep learning Higher performance than compared machine-learning-based methods Higher execution time than single deep neural network-based methods [ 27 2022 Deep features + Fuzzy classification Deep learning Higher performance than compared networks in the reference Dependence of variants diagnosis on the redefinition of fuzzy rules [ 28 2022 Statistical features + DWT + PCA + SVM Machine learning Lower computational complexity than deep-based Lower performance than trained deep networks [ 29 2022 Texture (GLCM/Wavelet transform) + ResNet Hybrid Higher performance than compared deep methods in reference Lower detection accuracy than newer methods [ 34 2024 Pipeline (LBP + DWT + CNN) Hybrid Higher performance than compared networks in the reference High ratio of COVID-19 samples to non-COVID-19 sample [ 35 2024 Fine-tuned AlexNet Deep learning Higher performance than pre-trained Alex-Net and compared networks in the reference Very high ratio of non-COVID-19 samples to COVID-19 samples [ 30 2025 Fusion of pre-trained deep networks Deep learning Lower complexity than trained deep network-based methods Lack of deep network training [ 31 2025 Residual neural network + Evolutionary algorithm Deep learning Higher performance than classical deep learning-based methods High execution computation time due to using genetic algorithm tomography-11-00099-t002_Table 2 Table 2 The structure of the designed CNN in one channel. Block Layer Type Input Output Details 1 Conv.2D 128 × 128 × 3 128 × 128 × 3 3 Filters 5 × 5, Stride 1, Pad 2 Activation 128 × 128 × 3 128 × 128 × 3 Swish Pooling.2D 128 × 128 × 3 64 × 64 × 3 Max pooling, Stride 1, Spatial extent 1 2 Conv.2D 64 × 64 × 3 64 × 64 × 20 20 Filters 5 × 5, Stride 1, Pad 2 Activation 64 × 64 × 20 64 × 64 × 20 Swish Pooling.2D 64 × 64 × 20 32 × 32 × 20 Max pooling, Stride 1, Spatial extent 1 3 Conv.2D 32 × 32 × 20 32 × 32 × 25 25 Filters 5 × 5, Stride 1, Pad 2 Activation 32 × 32 × 25 32 × 32 × 25 Swish Pooling.2D 32 × 32 × 25 16 × 16 × 25 Max pooling, Stride 1, Spatial extent 1 4 Flatten 16 × 16 × 25 6400 Flatten tomography-11-00099-t003_Table 3 Table 3 Performance evaluation based on different classifiers in terms of accuracy (%). Approach Accuracy Precision Recall F-Score Naïve bayes 90.79 88.63 91.56 90.07 C4.5 tree 90.87 89.52 90.29 89.90 SVM 94.25 91.89 95.78 93.79 KNN, K = 3 91.45 90.76 90.71 90.73 KNN, K = 5 93.37 92.79 92.40 92.59 KNN, K = 7 93.08 92.27 92.40 92.33 Random forest 94.63 91.63 97.04 94.25 tomography-11-00099-t004_Table 4 Table 4 Performance evaluation based on different tuning sets for random forest on COVID-CT-349 dataset in terms of accuracy (%). Number of Trees Maximum Depth Accuracy 10 1 87.53 3 89.28 5 91.87 7 90.36 20 1 87.69 3 90.45 5 94.01 7 92.95 30 1 88.02 3 92.76 5 94.63 7 92.61 40 1 87.91 3 92.37 5 93.35 7 92.07 tomography-11-00099-t005_Table 5 Table 5 The confusion matrix of the proposed COVID-19 diagnosis method on COVID-CT-349 dataset.  Label COVID-19 Non COVID-19 Predicted  COVID-19 230 21 Non COVID-19 7 264 tomography-11-00099-t006_Table 6 Table 6 The performance evaluation based on different learning rates and weight decay values on COVID-CT-349 dataset. Learning Rate Learning Rate Weight Decay Value Accuracy 10 −4 10 −5 10 −3 92.35 10 −4 10 −5 10 −2 92.28 10 −4 10 −6 10 −3 91.38 10 −4 10 −6 10 −2 92.54 10 −5 10 −5 10 −3 93.61 10 −5 10 −5 10 −2 93.76 10 −5 10 −6 10 −3 94.31 10 −5 10 −6 10 −2 94.63 10 −6 10 −6 10 −3 94.01 10 −6 10 −6 10 −2 94.21 10 −6 10 −7 10 −3 92.61 10 −6 10 −7 10 −2 92.82 tomography-11-00099-t007_Table 7 Table 7 Comparison results with base line algorithms of the proposed method on COVID-CT-349 in terms of accuracy (%). Approach Accuracy Precision Recall F-Score MLBP + RF 89.76 89.23 86.36 87.77 Proposed DCNN 91.61 90.65 91.79 91.21 Proposed DCNN 90.72 89.36 91.45 90.39 Proposed DCNN 92.74 91.88 91.74 91.80 Proposed DCNN 91.86 90.41 92.08 91.23 Proposed approach 94.63 91.63 97.04 94.25 tomography-11-00099-t008_Table 8 Table 8 Comparison results with state-of-the-art methods on COVID-CT-349 in terms of accuracy (%). Approach Accuracy Precision Recall F-Score ResNet-50 [ 27 77.4 NR NR 74.6 VGG-16 [ 27 76 NR NR 76 EfficientNet-B1 [ 27 79 NR NR 79 DenseNet-169 [ 27 79.5 NR NR 76 Fine-tuned DenseNet-169 [ 43 87.1 NR NR 88.1 Deep fuzzy model [ 27 94.20 NR NR 93.8 ResNet-18 [ 44 90.42 88.24 91.71 89.43 CovidNet-CT [ 44 90.48 NR NR NR DRE-Net [ 45 84.74 NR NR 84 CFRCF + Gabor + RF [ 46 76.68 NR NR 74.26 CFRCF + EMAP + SVM [ 46 66.37 NR NR 61.14 LBP + RF [ 46 69.96 NR NR 65.64 Conventional CNN [ 46 77.03 NR NR 67.92 Teacher–student framework + data augmentation [ 47 79.56 84.59 74.93 79.47 Residual neural network + evolutionary algorithm [ 31 83.04 88.18 79.50 83.62 Proposed approach 94.63 91.63 97.04 94.25 tomography-11-00099-t009_Table 9 Table 9 Comparison results with state-of-the-art methods on Italian dataset [ 37 Approach Accuracy Precision Recall F-Score Deep encoder–decoder + MLP [ 48 95.40 NR 93.1 NR COVID-Net [ 49 92.60 NR NR NR ShuffleNet [ 50 70.66 53.48 65.26 58.79 Multitask [ 51 94.67 NR 96 NR Proposed approach 95.42 98.17 93.36 95.70 ",
  "metadata": {
    "Title of this paper": "CoughNet-V2: A scalable multimodal DNN framework for point-of-care edge devices to detect symptomatic COVID-19 cough",
    "Journal it was published in:": "Tomography",
    "URL": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC12473366/"
  }
}