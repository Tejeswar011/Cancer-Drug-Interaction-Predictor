{
  "title": "Paper_436",
  "abstract": "pmc Sci Rep Sci Rep 1579 scirep Scientific Reports 2045-2322 Nature Publishing Group PMC12480035 PMC12480035.1 12480035 12480035 41022932 10.1038/s41598-025-16591-4 16591 1 Article Clinical application of deep learning for enhanced multistage caries detection in panoramic radiographs http://orcid.org/0000-0003-3813-4672 Pornprasertsuk-Damrongsri Suchaya suchaya.drs@mahidol.ac.th 1 http://orcid.org/0000-0002-6472-8426 Vachmanus Sirawich 2 http://orcid.org/0000-0001-9952-6704 Papasratorn Dhanaporn 1 http://orcid.org/0000-0003-0020-863X Kitisubkanchana Jira 1 https://orcid.org/0009-0002-8544-9191 Chaikantha Sarunya 1 http://orcid.org/0000-0001-6441-2272 Arayasantiparb Raweewan 1 http://orcid.org/0000-0002-7905-1024 Mongkolwat Pattanasak 2 1 https://ror.org/01znkr924 grid.10223.32 0000 0004 1937 0490 Department of Oral and Maxillofacial Radiology, Faculty of Dentistry, Mahidol University, 2 https://ror.org/01znkr924 grid.10223.32 0000 0004 1937 0490 Faculty of Information and Communication Technology, Mahidol University, 29 9 2025 2025 15 478255 33491 31 10 2024 18 8 2025 29 09 2025 01 10 2025 01 10 2025 © The Author(s) 2025 2025 https://creativecommons.org/licenses/by-nc-nd/4.0/ Open Access http://creativecommons.org/licenses/by-nc-nd/4.0/ The detection of dental caries is typically overlooked on panoramic radiographs. This study aims to leverage deep learning to identify multistage caries on panoramic radiographs. The panoramic radiographs were confirmed with the gold standard bitewing radiographs to create a reliable ground truth. The dataset of 500 panoramic radiographs with corresponding bitewing confirmations was labelled by an experienced and calibrated radiologist for 1,792 caries from 14,997 teeth. The annotations were stored using the annotation and image markup standard to ensure consistency and reliability. The deep learning system employed a two-model approach: YOLOv5 for tooth detection and Attention U-Net for segmenting caries. The system achieved impressive results, demonstrating strong agreement with dentists for both caries counts and classifications (enamel, dentine, and pulp). However, some discrepancies exist, particularly in underestimating enamel caries. While the model occasionally overpredicts caries in healthy teeth (false positive), it prioritizes minimizing missed lesions (false negative), achieving a high recall of 0.96. Overall performance surpasses previously reported values, with an F1-score of 0.85 and an accuracy of 0.93 for caries segmentation in posterior teeth. The deep learning approach demonstrates promising potential to aid dentists in caries diagnosis, treatment planning, and dental education. Supplementary Information The online version contains supplementary material available at 10.1038/s41598-025-16591-4. Keywords Deep learning Artificial intelligence Segmentation Dental caries Caries classification Panoramic radiograph Subject terms Panoramic radiography Information technology Computer science Mahidol University and the Office of the Ministry of Higher Education, Science, Research and Innovation under the Reinventing University project: the Center of Excellence in AI-Based Medical Diagnosis (AI-MD) sub-project pmc-status-qastatus 0 pmc-status-live yes pmc-status-embargo no pmc-status-released yes pmc-prop-open-access yes pmc-prop-olf no pmc-prop-manuscript no pmc-prop-legally-suppressed no pmc-prop-has-pdf yes pmc-prop-has-supplement yes pmc-prop-pdf-only no pmc-prop-suppress-copyright no pmc-prop-is-real-version no pmc-prop-is-scanned-article no pmc-prop-preprint no pmc-prop-in-epmc yes issue-copyright-statement © Springer Nature Limited 2025 Introduction Oral diseases are a major public health problem, affecting nearly 3.5 billion people worldwide in 2022. Among the major oral diseases, untreated dental caries of permanent teeth are the most prevalent, with approximately 2 billion cases (29%), followed by severe periodontal disease, untreated dental caries of deciduous teeth, and edentulism 1 2 3 4 5 The rapid advancement of artificial intelligence (AI) algorithms, particularly deep learning (DL) models, has markedly driven AI integration into various aspects of everyday life. In dentistry, AI has found applications across numerous fields, including prosthodontics, customized computer-aided design and manufacturing of orthodontic and surgical appliances, oral cancer detection, implantology, periodontal disease management, endodontics, and cariology 6 7 8 9 10 11 12 13 14 15 The panoramic radiograph serves as an essential diagnostic tool, facilitating the screening and assessment of the maxillomandibular complex and optimizing dental interventions during initial appointments, particularly in vulnerable populations 16 17 18 19 Materials and methods This study was conducted following the Helsinki Declaration standards and received approval from the Ethics Committee of Mahidol University Multi-Faculty Cooperative IRB Review (MU-MOU CoA.2022/060.1511), approval date 15.11.2022. Studied panoramic and bitewing radiographs This study included 500 panoramic radiographs of patients with all posterior teeth bitewing radiographs taken on the same day, from January to August 2022 at the Oral and Maxillofacial Radiology Clinic, Dental Hospital, Faculty of Dentistry, Mahidol University. The inclusion criteria for panoramic radiographs were patients older than 13 years, with overlapping enamel less than the outer half of the proximal enamel, and at least one dental caries identified on the bitewing radiograph. The exclusion criteria included jawbone pathology, image distortion, noisy images, rotated teeth over 90°, amelogenesis imperfecta, dentinogenesis imperfecta, full mouth crown restorations, orthodontic brackets, and two or more implants in the same quadrant. All panoramic radiographs were taken using a CS9000C machine (Carestream Health, Inc., New York, USA) with a tube voltage of 68–72 kV, tube current of 8–10 mA, and exposure time of 15.1 s. All posterior teeth bitewing radiographs were taken, with at least four radiographs for each patient, using either a Planmeca ProX™ intraoral X-ray machine (Planmeca OY, Helsinki, Finland) or a Belmont PHOT-XIIS 505 intraoral X-ray machine (Takara Belmont Corporation, Osaka, Japan), and a VistaScan Mini Plus imaging plate scanner (DÜrr Dental Se, Bietigheim–Bissingen, Germany) with a resolution of 20 line-pairs/mm. All radiographs were anonymously exported as DICOM files by a radiological technologist (S.C.). Calibration for dental caries detection Here, 100 out of 500 panoramic radiographs were randomly selected for intrarater and interrater reliability. Radiologist #1, and Radiologist #2, a 21-year-experienced oral and maxillofacial radiologist (J.K.), independently recorded the tooth number and tooth surfaces revealing dental caries, including its classification as enamel caries (radiolucent area limited to the enamel), dentine caries (a radiolucent area extending beyond dentoenamel junction to dentine), or dental caries with pulp involvement (a large radiolucent area reaching the pulp chamber resulting in widening apical periodontal ligament space and/or thickening apical lamina dura). All radiographs were displayed on a diagnostic radiology monitor with a resolution of 2560 × 1600 (Eizo RadiForce RX430, EIZO Corporation, Ishikawa, Japan) under low ambient light conditions. Both radiologists reviewed and discussed the disagreed results together; if consensus could not be reached, a 25-year-experienced oral and maxillofacial radiologist (R.A.), Radiologist #3, was asked to independently determine the presence and classification of dental caries. The consensus data were considered ground truth. Two months later, a 27-year-experienced oral and maxillofacial radiologist (S.P.D.) repeated 100 panoramic radiographs, comprising 469 dental caries, in the same manner. The reliability values of Radiologist #1 and Radiologist #2 compared to the ground truth were 0.832 and 0.864, respectively. The intrarater correlation coefficient with a 95% confidence level of Radiologist #1 was 0.734. The interrater correlation coefficient with a 95% confidence level for Radiologist #1 and Radiologist #2 was 0.707. Figure 1  Fig. 1 Schematic of the study workflow, including ground truth labeling and AI segmentation for dental caries on panoramic radiographs. Dental caries labeling After calibration, the 500 anonymous panoramic radiographs together with bitewing radiographs of the same individuals were imported to an annotation and image markup (AIM) workstation version 4.6.0.7 (Faculty of Information and Communication Technology, Mahidol University) and were displayed on a diagnostic radiology monitor with a resolution of 2560 × 1600 (Eizo RadiForce RX430, EIZO Corporation, Ishikawa, Japan) under proper ambient light conditions. Annotation information was stored using the AIM 20 Artificial intelligence system for dental caries segmentation The caries detection system relies on semantic segmentation within image processing techniques. It operates by taking a panoramic radiograph as input and classifying and segmenting the regions of detected caries pixel by pixel. The process involves applying a tooth detection model to the panoramic radiograph to identify individual teeth. The model delineates the boundary of each tooth within the panoramic radiograph, subsequently extracting each tooth into a separate image. These separated tooth images are then input into the caries segmentation model to identify the caries regions. Once the caries regions are determined, the resulting segmented map is overlaid onto the separated tooth images and then reassembled to visualize a predicted panoramic radiograph (Fig. 2  Fig. 2 Deep learning models for tooth detection and dental caries segmentation on panoramic radiograph. Deep learning models The system comprises two DL models. One model is responsible for locating each tooth within a panoramic radiograph, while the other focuses on segmenting the caries regions on each identified tooth. The tooth detection model operates within the framework of image object detection, aiming to isolate each tooth into individual images to mitigate the influence of large, uninteresting areas of panoramic radiographs, which can impede caries segmentation efficiency. The model architecture employed was the you only look once version 5 (YOLOv5) object detection model 21 22 23 2 The semantic segmentation model of dental caries employed in this study was Attention U-Net 24 25 1 In this study, 14,997 individual tooth images were extracted from 500 panoramic radiographs to train a segmentation model. Of these, 2,161 images with annotated dental caries were randomly selected for model training, while 737 images were set aside for validation and testing. Intensity normalization was applied in preprocessing, as image acquisition conditions were consistent. The remaining images were reserved for overall system evaluation conducted by dental experts. The segmentation model was trained to classify pixels into two binary classes: caries and non-caries. The training environment consisted of an Ubuntu 22.0 operating system, running on an AMD Ryzen 9 3950 × 16-Core Processor with an Nvidia GeForce RTX 2080 SUPER GPU. Key training parameters included a learning rate of 1 × 10 −4 For preliminary model selection, we conducted direct experiments on our own dataset rather than relying on published results from different sources. We randomly selected 100 radiographic images from our dataset to evaluate several state-of-the-art segmentation architectures under identical conditions, which allowed us to compare multiple models fairly while saving time and computational resources. The architectures we tested include U-Net 25 26 27 24 28 29 The results of this comparative experiment, summarized in Table 1  Table 1 The mean Intersection-over-Union (mIoU) per cropped image for various segmentation models. Models U-Net Nested U-Net Swin U-Net Attention U-Net TransU-Net R2U-Net mIoU 0.417 0.477 0.204 0.484 0.384 0.027 Evaluation metrics The dental caries segmentation on the panoramic radiograph was compared to the ground truth labeled by the radiologists. The difference in the number of teeth with dental caries identified by AI and ground truth was recorded. The classification of dental caries—enamel caries, dentine caries, and caries with pulp involvement—was also recorded and compared. Four variables were obtained from a comparison of labeled dental caries between the ground truth and AI:  TP: Pixels that are correctly segmented compared to the labeled ground truth segmentation on posterior teeth. The smaller segmented region labeled by AI was counted as a true positive. TN: Pixels that are not labeled by either the AI or the ground truth. FP: Pixels that are labeled by the AI but are not labeled in the ground truth. FN: Pixels that are not labeled pixel by AI but are labeled in ground truth. Based on these variables, the following metrics were analyzed to determine AI performance in dental caries segmentation on panoramic radiographs:  IoU: Represents the ratio of the area of overlap between the AI-segmented caries and the ground truth, divided by the union area of both the AI segmentation and the ground truth. \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$\\:IoU=\\frac{TP}{TP+FP+FN}$$\\end{document} DSC: Quantifies how closely the AI segmentation matches the ground truth by calculating the ratio of twice the area of overlap between AI-segmented caries and the ground truth, divided by the sum of the areas of both AI-segmented caries and the ground truth. \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$\\:DSC=\\frac{2TP}{2TP+FP+FN}$$\\end{document} Precision: Represents the fraction of correctly AI-segmented caries among all the segmented caries by AI. \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$\\:Precision=\\frac{TP}{\\begin{array}{c}TP+FP\\end{array}}$$\\end{document} Recall or sensitivity: Represents the rate of correctly AI-segmented caries by AI among the labeled actual caries on ground truth. \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$\\:Recall=\\frac{TP}{TP+FN}$$\\end{document} F1-score: Quantifies the weighted average of dental caries between the precision and recall rates. \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$\\:F1-score=2\\:x\\frac{Precision\\:X\\:Recall}{Precision\\:+Recall}$$\\end{document} Specificity: Represents the rate of correctly AI-unlabeled healthy teeth among healthy teeth. \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$\\:Specificity=\\frac{TN}{TN+FP}$$\\end{document} Accuracy: Represents the rate of correctly AI-segmented caries and AI-unlabeled healthy teeth among all detected teeth. \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$\\:Accuracy=\\:\\frac{TP+TN}{TP+TN+FP+FN}$$\\end{document} Statistical analysis Statistical analyses were performed using MedCalc for Windows, version 22.023 (MedCalc Software, Ostend, Belgium). To compare AI performance in segmenting various degrees of dental caries, the linear weighted kappa was analyzed. The kappa values were defined as follows: values of ≤ 0 indicate no agreement; 0.01–0.20 as none to slight; 0.21–0.40 as fair; 0.41–0.60 as moderate; 0.61–0.80 as substantial; and 0.81–1.00 as strong agreement 30 31 Results Patient demographics and dental caries classification A dataset of 500 panoramic radiographs was obtained from 317 females with a mean age of 25.7 years and 183 males with a mean age of 26.2 years. Within this dataset, 1,792 out of 9,053 posterior teeth were confirmed to have dental caries through bitewing radiographs. When detecting both anterior and posterior teeth from panoramic radiographs, a total of 14,997 teeth were analyzed. The ground truth for caries classification was established based on three stages: 519 surfaces (27.1%) with enamel caries, 1,163 surfaces (60.7%) with dentine caries, and 234 surfaces (12.2%) exhibiting pulp involvement. Agreement of tooth number with dental caries on panoramic radiograph An analysis comparing AI caries segmentation to oral and maxillofacial radiologists (ground truth) revealed strong agreement (weighted kappa = 0.943, 95% confidence interval [CI]: 0.927–0.958) between the two methods (Italic number, Table 2 3 2 2  Table 2 Number of panoramic radiographs with different total teeth with dental caries per radiograph: ground truth vs. artificial intelligence. AI ( N Total PANs (images) Total N 0 1 2 3 4 5 6 7 8 9 10 12 13 Ground truth (N) 1  1  71 0 0 0 0 0 0 0 0 0 0 0 72 72 2 0  7  123 0 0 0 0 0 0 0 0 0 0 130 260 3 0  2  10  75 0 0 0 0 0 0 0 0 0 87 261 4 0 0  1  9  61 0 0 0 0 0 0 0 0 71 284 5 0 0  1  1  3  49 0 0 0 0 0 0 0 54 270 6 0 0 0 0 0  2  22 0 0 0 0 0 0 24 144 7 0 0 0 0 0  2  7  15 0 0 0 0 0 24 168 8 0 0 0 0 0 0  2  5  16 0 0 0 0 23 184 9 0 0 0 0 0 0 0  1  1  6 0 0 0 8 72 10 0 0 0 0 0 0 0 0 0  1  3 0 0 4 40 12 0 0 0 0 0 0 0 0 0 0 0  2 0 2 24 13 0 0 0 0 0 0 0 0 0 0 0 0  1 1 13 Total 1 80 135 85 64 53 31 21 17 7 3 2 1 500 1792 Weighted Kappa = 0.943, SE 0.008, 95% CI 0.927–0.958 N AI PANs SE CI  Fig. 3 Examples of 13 posterior teeth with dental caries that were perfectly predicted by artificial intelligence (AI): ( a b Agreement of tooth surfaces with enamel caries An analysis comparing AI segmentation to ground truth for enamel caries revealed strong agreement (weighted kappa = 0.907, 95% CI: 0.871–0.943) as Italic number, Table 3 3 ). 3  Table 3 Total tooth surfaces with enamel caries per radiograph: ground truth vs. artificial intelligence. Enamel caries AI ( N Total PANs (images) Total N 0 1 2 3 4 5 6 9 Ground truth (N) 1  1  100 0 0 0 0 0 0 101 101 2 0  7  77 0 0 0 0 0 84 168 3 0  2  6  20  2 0 0 0 30 90 4 0 0 1  3  16 0 0 0 20 80 5 0 0 0 0  2  6 0 0 8 40 6 0 0 0 0 0  1  3 0 4 24 7 0 0 0 0 0 0  1 0 1 7 9 0 0 0 0 0 0 0  1 1 9 Total 1 109 84 23 20 7 4 1 249 519 Weighted Kappa = 0.907, SE 0.018, 95% CI 0.871–0.943 N AI PANs SE CI Agreement of tooth surfaces with dentine caries An analysis comparing AI segmentation to ground truth for dentine caries revealed strong agreement (weighted kappa = 0.948, 95% CI: 0.930–0.966) as Italic number, Table 4 4 4  Table 4 Total tooth surfaces with dentine caries per radiograph: ground truth vs. artificial intelligence. Dentine caries AI ( N Total PANs (images) Total N 0 1 2 3 4 5 6 7 8 9 10 Ground truth (N) 1  2  130  1 0 0 0 0 0 0 0 0 133 133 2 0  11  114  2 0 0 0 0 0 0 0 127 254 3 0  1  6  61 0 0 0 0 0 0 0 68 204 4 0 0 0  5  41 0 0 0 0 0 0 45 180 5 0 0 0  1  1  26 0 0 0 0 0 28 140 6 0 0 0 0  2  1  12 0 0 0 0 15 90 7 0 0 0 0 0 0 0  8 0 0 0 8 56 8 0 0 0 0 0 0 0  1  4 0 0 5 40 9 0 0 0 0 0 0  1 0  1  2 0 4 36 10 0 0 0 0 0 0 0 0 0 0  3 3 30 Total 1 142 121 69 43 27 13 9 5 2 3 436 1163 Weighted Kappa = 0.948 SE 0.009, 95% CI 0.930–0.966 N AI PANs SE CI Agreement of teeth with dental caries with pulp involvement An analysis comparing AI segmentation to ground truth for dental caries with pulp involvement revealed almost perfect agreement (weighted kappa = 0.981, standard error = 0.013, 95% CI: 0.956–1.000) as Italic number in Table 5 5  Table 5 Total teeth of dental caries with pulp involvement per radiograph: ground truth vs. artificial intelligence. Pulp involvement AI ( N Total PANs (images) Total N 1 2 3 4 5 6 Ground truth (N) 1  128 0 0 0 0 0 128 128 2 0  22 0 0 0 0 22 44 3 0  1  12 0 0 0 13 39 4 0 0  1  2 0 0 3 12 5 0 0 0 0  1 0 1 5 6 0 0 0 0 0  1 1 6 Total 128 23 13 2 1 1 168 234 Weighted Kappa = 0.981, SE 0.013, 95% CI 0.956–1.000 N AI PANs SE CI Agreement of dental caries segmentation by AI and ground truth (Bland–Altman analysis) Bland–Altman scatter plots (Fig. 4 4 4  Fig. 4 Bland–Altman plots of the mean difference between the mean ground truth and the mean AI: ( a b c d Confusion matrix analysis To evaluate the diagnostic performance of the AI model at the per-tooth level, we employed a confusion matrix framework. Although commonly used for classification tasks, the confusion matrix was adapted in this study to assess the segmentation model’s ability to identify dental caries on a tooth-by-tooth basis. This approach provides clinically relevant performance indicators—such as true positives (TP), false negatives (FN), false positives (FP), and true negatives (TN)—allowing us to interpret whether the model correctly identifies carious or non-carious teeth. It also facilitates the calculation of key diagnostic metrics, such as specificity and accuracy, which are particularly meaningful in the context of dental diagnosis. Figure 5  Fig. 5 Confusion matrix of dental caries segmentation on ( a b Although semantic-segmentation performance is principally conveyed through intersection over union (IoU) and the dice similarity coefficient (DSC), we further derive a tooth-level confusion matrix by thresholding each predicted mask and assigning a binary label to every one of the 14,997 teeth. This step reframes the task as a clinically relevant classification problem that contrasts carious teeth with healthy teeth, enabling the direct computation of specificity and the area under the receiver-operating-characteristic curve, alongside established overlap metrics. Quantitative performance evaluation AI performance in segmenting dental caries was evaluated using IoU, DSC, precision, recall, specificity, and accuracy for posterior teeth and all teeth (Table 6  Table 6 Evaluation metrics demonstrating AI performance in caries segmentation of posterior teeth and all teeth. IoU DSC Precision Recall F1-score Specificity Accuracy Mean SD Mean SD Mean SD Mean SD Mean SD Mean SD Mean SD Posterior teeth 0.75 0.23 0.85 0.17 0.77 0.23 0.96 0.11 0.85 0.17 0.93 0.08 0.93 0.07 All teeth 0.66 0.23 0.79 0.19 0.68 0.24 0.96 0.11 0.79 0.19 0.94 0.05 0.94 0.05 IoU DSC Discussion This study introduces a novel approach for dental caries segmentation in panoramic radiographs utilizing the DL approach of the AI system. We depart from prior studies that relied solely on ground truth established through single radiographic techniques, such as bitewing radiographs 32 14 15 33 35 18 The results revealed promising agreement between the AI system and ground truth for caries segmentation. Kappa statistics for both the number of teeth with caries and individual caries classifications (enamel, dentine, and pulp involvement) were ≥ 0.9, signifying “strong” agreement according to Conger AJ 30 Despite the high level of agreement, some discrepancies emerged, particularly for enamel caries. The AI system tended to underestimate the number of enamel caries surfaces compared to radiologist evaluations (Table 3 36 37 3 6 4 6 4 6 19 38  Fig. 6 Examples of caries misclassification: cropped bitewing radiographs, cropped panoramic radiographs, ground truth, and artificial intelligence (AI)-segmented caries. ( a b c d e Understanding how the AI system interprets data is crucial for ensuring its effectiveness and reliability in clinical applications. Analysis of the confusion matrix (Fig. 5 7  Fig. 7 Examples of false positives: ( a b c d e f g h Panoramic radiographs are a common imaging modality used for new patients and markedly contribute to the early diagnosis and prompt treatment of dental caries. Early intervention helps prevent the need for more time-consuming and expensive procedures, such as root canals, crown restorations, tooth extractions, and dental implants 2 38 Recent studies have explored various DL models for caries segmentation on panoramic radiographic images, each demonstrating distinct strengths and limitations (Table 7 34 39 13 15 40 35  Table 7 Previous studies of caries segmentation on panoramic radiographs. Authors Year PANs Caries classification Number of caries Ground truth Network Evaluation metric outcomes Dayi et al 34 2023 504 Type I: Occlusal Type II: Proximal Type III: Cervical Type I: 746 Type II: 1,627 Type III: 378 Total: 2,751 Two dentists: o 8-year restorative dental specialist o 5-year OMFR Proposed DCDNet Occlusal and proximal caries DSC: 0.68–0.71 Precision: 0.70–0.72 Recall: 0.65–0.70 F1-score: 0.68–0.71 Chen et al 39 2023 1,100 Shallow caries Medium caries Deep caries  N/A Two professional dentists ASPP-integrated U-Net Precision: 0.74 Recall: 0.82 F1 score: 0.78 Accuracy: 0.78 Haghanifar et al 13 2023 470 Mild caries: not beyond DEJ Severe caries: beyond DEJ Total: 742 One dentist: 20-year OMFR Proposed PaXNet Precision 0.89 Recall 0.51 F0.5-score: 0.78 Accuracy: 0.86 Zhu et al 15 2023 1,159 Shallow caries Medium caries Deep caries Shallow: 946 Medium: 934 Deep: 1,337 Total: 3,217 Four dentists Proposed CariesNet DSC: 0.94 F1-score: 0.93 Precision: 0.94 Recall: 0.86 Accuracy: 0.94 Alharbi et al 40 2023 510 None N/A Three dentists: 5–8 years experience dentists U-Net3+ IoU: 0.67 DSC: 0.60 Accuracy: 0.95 Lian et al 35 2021 1,160 D1 outer third D2 middle third D3 inner third of dentine D1: 1,166 D2: 1,039 D3: 1,635 Total: 3,840 Three dentists: 3–15 years experience dentists nnU-Net, DenseNet121 IoU: 0.79 DSC: 0.66 F1-score: 0.90 Precision: 1.00 Recall: 0.821 Specificity: 1.00 Accuracy: 0.986 Present study 500 Enamel caries Dentine caries Pulp exposure Enamel: 519 Dentine: 1,163 Pulp: 234 Total: 1,916 Three dentists (OMFR): o 27-year o 25-year o 21-year Annotated based on information from PANs and BWs YOLOv5 Attention U-net IoU: 0.75 DSC: 0.85 Precision: 0.77 Recall: 0.96 F1-score: 0.85 Specificity: 0.93 Accuracy: 0.93 N/A PANs BWs OMFR DEJ DCDNet ASPP IoU DSC To assess the overall performance of our AI model, the F1-score was analyzed, which considers both precision and recall. This study achieved an F1-score of 0.85 for caries segmentation in posterior teeth (Table 6 34 39 13 15 35 34 35 40 6 15 15 Despite the promising performance of our AI model, segmenting dental caries on panoramic radiographs presents inherent difficulties 19 37 38 This study advances the field of deep learning-based caries detection by addressing key limitations in previous research through clinically grounded, multistage segmentation on panoramic radiographs. Unlike earlier studies that rely on limited datasets, binary classification, or single-image modalities, our study integrates panoramic radiographs with gold-standard bitewing confirmations to ensure accurate ground truth labeling. Furthermore, the use of a two-model architecture, YOLO for tooth detection and Attention U-Net for caries segmentation, enables precise localization and differentiation of caries stages (enamel, dentine, and pulp). This level of granularity and clinical validation is rarely seen in prior works. The model also achieves high recall (0.96), emphasizing its focus on minimizing missed diagnoses, which is critical in clinical settings. Overall, this study contributes a robust, validated, and clinically applicable system that not only outperforms many prior models in accuracy and F1-score but also aligns closely with real-world diagnostic workflows. Multistage deep learning can provide notable benefits for caries segmentation, particularly in panoramic radiographs, where caries regions are often very small and occupy only a tiny fraction of the image. Single-stage models tend to overlook these fine details due to limited pixel resolution and the dominance of unrelated structures, such as the jaw or soft tissue. A multistage framework, where the first stage localizes individual teeth and the second stage performs focused segmentation, allows the model to operate on higher-resolution regions of interest. This not only improves the ability to capture small carious lesions but also mitigates the class imbalance problem by excluding irrelevant areas and concentrating learning on diagnostically significant regions. Future development of the AI system aims to enhance its capabilities and applicability. Studying the efficiency of general dentists and dental students in identifying caries with and without AI assistance could yield valuable insights. Incorporating additional data with more complex panoramic radiographs—such as those with increased tooth overlap—with accurate annotations could further enhance the model’s robustness. Furthermore, the inclusion of external data from multiple centers and imaging devices could enhance the model’s generalizability and adaptability across diverse imaging conditions. Since this study did not confirm dental caries on anterior teeth through additional methods, expert annotations for these were not included. Nevertheless, despite the absence of specific annotations, the AI system was still able to identify caries on anterior teeth in panoramic radiographs, indicating a promising direction for further refinement. In addition, future studies should explore how dentists and radiologists interact with the AI system in real-world clinical settings. Evaluating user experience, decision-making behavior, diagnostic confidence, and workflow integration will provide critical insights into how AI can effectively support, rather than replace, clinical judgment. This line of research is essential to ensure that AI tools are both clinically useful and seamlessly integrated into everyday dental practice. In conclusion, this study demonstrated the significant potential of AI-based DL system for dental caries segmentation in panoramic radiographs. By leveraging complementary data from both high-resolution bitewing and panoramic radiographs, we established a more robust and accurate ground truth for AI training, addressing the limitations of prior studies relying on single radiographic technique. The implementation of YOLOv5 for tooth detection and Attention U-Net for caries segmentation has shown exceptional performance, achieving high accuracy, precision, recall, and specificity. This system enhances the detection of caries often overlooked in panoramic evaluations and offers a practical, efficient tool for dental practitioners. The results underscore the effectiveness of our AI solution in improving diagnostic accuracy and consistency, leading to better clinical decision-making and patient outcomes. Our approach represents a significant advancement in dental radiology, offering a reliable and scalable solution for dental caries detection and segmentation in everyday clinical practice. Supplementary Information Below is the link to the electronic supplementary material.  Supplementary Material 1 Publisher’s note Springer Nature remains neutral with regard to jurisdictional claims in published maps and institutional affiliations. These authors are equally contributed of co-first author: Sirawich Vachmanus Acknowledgements We would like to thank Assoc. Prof. Supanee Thanakun, College of Dental Medicine, Rangsit University, and Ms. Pairin Tonput, Academic Statistician, Research Office, Faculty of Dentistry, Mahidol University for their statistical analysis. Author contributions S.P.D. contributed to the conceptualization of work, design, data acquisition, data validation, data analysis, writing-original draft, writing & editing manuscript, final approval of the version to be published; S.V. contributed to the conceptualization of work, design, writing AI model algorithm, data analysis, writing & editing manuscript; D.P. contributed to the design, data analysis and interpretation, editing manuscript; J.R. contributed to the design, data acquisition and calibration, editing manuscript; S.C. contributed to data acquisition and methodology, editing manuscript; R.W. contributed to the design, data acquisition and calibration, editing manuscript; P.M. contributed to the conceptualization of work, design, data analysis, critically revised the manuscript and figures. All authors reviewed the manuscript. Funding This paper was supported by Mahidol University and the Office of the Ministry of Higher Education, Science, Research and Innovation under the Reinventing University project: the Center of Excellence in AI-Based Medical Diagnosis (AI-MD) sub-project. Data availability The data presented in this study are available upon reasonable request from the corresponding author. Declarations Competing interests The authors declare no competing interests. Ethics approval and consent to participate All procedures performed in studies involving human participates were in accordance with the ethical standards of the institutional and/or national research committee and with the 1964 Helsinki Declaration and its later amendments or comparable ethical standards. The need for informed consent to participate was waived by the Ethics Committee of Mahidol University Multi-Faculty Cooperative IRB Review (MU-MOU CoA.2022/060.1511). References 1. Organization, G. W. H. Global oral health status report: towards universal health coverage for oral health by 2030. (2022). https://creativecommons.org/licenses/by-nc-sa/3.0/igo 2. Petersen PE Bourgeois D Ogawa H Estupinan-Day S Ndiaye C The global burden of oral diseases and risks to oral health Bull. World Health Organ. 2005 83 661 669 16211157 PMC2626328 Petersen, P. E., Bourgeois, D., Ogawa, H., Estupinan-Day, S. & Ndiaye, C. The global burden of oral diseases and risks to oral health. Bull. World Health Organ. 83 16211157 PMC2626328 3. Abdelaziz M Detection, diagnosis, and monitoring of early caries: the future of individualized dental care Diagnostics (Basel) 2023 13 3649 10.3390/diagnostics13243649 38132233 PMC10742918 Abdelaziz, M. Detection, diagnosis, and monitoring of early caries: the future of individualized dental care. Diagnostics (Basel) 13 38132233 10.3390/diagnostics13243649 PMC10742918 4. Pitts, N. B. et al. ICCMS ™ https://www.iccms-web.com/uploads/asset/59284654c0a6f822230100.pdf 5. Dabiri D Diagnosing developmental defects of enamel: pilot study of online training and accuracy Pediatr. Dent. 2018 40 105 109 29663909 Dabiri, D. et al. Diagnosing developmental defects of enamel: pilot study of online training and accuracy. Pediatr. Dent. 40 29663909 6. Ghaffari M Zhu Y Shrestha A A review of advancements of artificial intelligence in dentistry Dent. Rev. 2024 4 100081 10.1016/j.dentre.2024.100081 Ghaffari, M., Zhu, Y. & Shrestha, A. A review of advancements of artificial intelligence in dentistry. Dent. Rev. 4 7. Ren R Luo H Su C Yao Y Liao W Machine learning in dental, oral and craniofacial imaging: a review of recent progress PeerJ 2021 9 e11451 10.7717/peerj.11451 34046262 PMC8136280 Ren, R., Luo, H., Su, C., Yao, Y. & Liao, W. Machine learning in dental, oral and craniofacial imaging: a review of recent progress. PeerJ 9 34046262 10.7717/peerj.11451 PMC8136280 8. Majanga, V. & Viriri, S.(2022) A survey of dental caries segmentation and detection techniques. Sci. World J. https://doi.org/10.1155/2022/8415705 10.1155/2022/8415705 PMC9017544 35450417 9. Vinayahalingam S Classification of caries in third molars on panoramic radiographs using deep learning Sci. Rep. 2021 11 12609 10.1038/s41598-021-92121-2 34131266 PMC8206082 Vinayahalingam, S. et al. Classification of caries in third molars on panoramic radiographs using deep learning. Sci. Rep. 11 34131266 10.1038/s41598-021-92121-2 PMC8206082 10. Kühnisch J Meyer O Hesenius M Hickel R Gruhn V Caries detection on intraoral images using artificial intelligence J. Dent. Res. 2022 101 158 165 10.1177/00220345211032524 34416824 PMC8808002 Kühnisch, J., Meyer, O., Hesenius, M., Hickel, R. & Gruhn, V. Caries detection on intraoral images using artificial intelligence. J. Dent. Res. 101 34416824 10.1177/00220345211032524 PMC8808002 11. Duong DL Kabir MH Kuo RF Automated caries detection with smartphone color photography using machine learning Health Inf. J. 2021 27 14604582211007530 10.1177/14604582211007530 33863251 Duong, D. L., Kabir, M. H. & Kuo, R. F. Automated caries detection with smartphone color photography using machine learning. Health Inf. J. 27 10.1177/14604582211007530 33863251 12. Estai M Evaluation of a deep learning system for automatic detection of proximal surface dental caries on bitewing radiographs Oral Surg. Oral Med. Oral Pathol. Oral Radiol. 2022 134 262 270 10.1016/j.oooo.2022.03.008 35534406 Estai, M. et al. Evaluation of a deep learning system for automatic detection of proximal surface dental caries on bitewing radiographs. Oral Surg. Oral Med. Oral Pathol. Oral Radiol. 134 35534406 10.1016/j.oooo.2022.03.008 13. Haghanifar A Tooth segmentation and dental caries detection in panoramic X-ray using ensemble transfer learning and capsule classifier Multimed Tools App 2023 82 27659 27679 10.1007/s11042-023-14435-9 Haghanifar, A. et al. Tooth segmentation and dental caries detection in panoramic X-ray using ensemble transfer learning and capsule classifier. Multimed Tools App 82 14. Ying S Wang B Zhu H Liu W Huang F Caries segmentation on tooth X-ray images with a deep network J. Dent. 2022 119 104076 10.1016/j.jdent.2022.104076 35218876 Ying, S., Wang, B., Zhu, H., Liu, W. & Huang, F. Caries segmentation on tooth X-ray images with a deep network. J. Dent. 119 35218876 10.1016/j.jdent.2022.104076 15. Zhu H CariesNet: a deep learning approach for segmentation of multi-stage caries lesion from oral panoramic x-ray image Neural Comput. Appl. 2023 35 16051 16059 10.1007/s00521-021-06684-2 PMC8736291 35017793 Zhu, H. et al. CariesNet: a deep learning approach for segmentation of multi-stage caries lesion from oral panoramic x-ray image. Neural Comput. Appl. 35 10.1007/s00521-021-06684-2 PMC8736291 35017793 16. Almeida FT Gianoni-Capenakas S Rabie H Figueiredo R Pacheco-Pereira C The use of panoramic radiographs to address the oral health needs of vulnerable Canadian populations Can. J. Dent. Hyg. 2024 58 19 25 38505315 PMC10946316 Almeida, F. T., Gianoni-Capenakas, S., Rabie, H., Figueiredo, R. & Pacheco-Pereira, C. The use of panoramic radiographs to address the oral health needs of vulnerable Canadian populations. Can. J. Dent. Hyg. 58 38505315 PMC10946316 17. Mohammad R Orthodontic evaluation of impacted maxillary canine by panoramic radiograph-A literature review J. Res. Med. Dent. Sci. 2021 9 220 227 Mohammad, R. Orthodontic evaluation of impacted maxillary canine by panoramic radiograph-A literature review. J. Res. Med. Dent. Sci. 9 18. Schwendicke, F. & Göstemeyer, G. Conventional bitewing radiography. Clin. Dent. Rev. 4 19. Kamburoğlu K Kolsuz E Murat S Yüksel S Özen T Proximal caries detection accuracy using intraoral bitewing radiography, extraoral bitewing radiography and panoramic radiography Dentomaxillofac Radiol. 2012 41 450 459 10.1259/dmfr/30526171 22868296 PMC3520392 Kamburoğlu, K., Kolsuz, E., Murat, S., Yüksel, S. & Özen, T. Proximal caries detection accuracy using intraoral bitewing radiography, extraoral bitewing radiography and panoramic radiography. Dentomaxillofac Radiol. 41 22868296 10.1259/dmfr/30526171 PMC3520392 20. Mongkolwat P Kleper V Talbot S Rubin D The National cancer informatics program (NCIP) annotation and image markup (AIM) foundation model J. Digit. Imaging 2014 27 692 701 10.1007/s10278-014-9710-3 24934452 PMC4391072 Mongkolwat, P., Kleper, V., Talbot, S. & Rubin, D. The National cancer informatics program (NCIP) annotation and image markup (AIM) foundation model. J. Digit. Imaging 27 24934452 10.1007/s10278-014-9710-3 PMC4391072 21. Jocher G ultralytics/yolov5: v7.0 - YOLOv5 SOTA realtime instance segmentation Zenodo 2022 10.5281/zenodo.7347926 Jocher, G. et al. ultralytics/yolov5: v7.0 - YOLOv5 SOTA realtime instance segmentation. Zenodo 22. Hamamci, I. E. et al. DENTEX: an abnormal tooth detection with dental enumeration and diagnosis benchmark for panoramic x-rays. ArXiv 23. Hamamci, I. E. et al. in International Conference on Medical Image Computing and Computer-Assisted Intervention. 24. Oktay, O. et al. Attention U-Net: learning where to look for the pancreas. ArXiv 25. Ronneberger O Fischer P Brox T U-Net: convolutional networks for biomedical image segmentation ArXiv Abs 2015 10.48550/arXiv.1505.04597 Ronneberger, O., Fischer, P. & Brox, T. U-Net: convolutional networks for biomedical image segmentation. ArXiv Abs 26. Zhou Z Siddiquee MMR Tajbakhsh N Liang J UNet++ A nested U-Net architecture for medical image segmentation Deep Learn. Med. Image Anal. Multimodal Learn. Clin. Decis. Support 2018 11045 3 11 10.1007/978-3-030-00889-5_1 PMC7329239 32613207 Zhou, Z., Siddiquee, M. M. R., Tajbakhsh, N., Liang, J. & UNet++: A nested U-Net architecture for medical image segmentation. Deep Learn. Med. Image Anal. Multimodal Learn. Clin. Decis. Support 11045 10.1007/978-3-030-00889-5_1 PMC7329239 32613207 27. Cao H Swin-Unet: Unet-like pure transformer for medical image segmentation ArXiv arXiv:2105 05537 2021 10.48550/arXiv.2105.05537 Cao, H. et al. Swin-Unet: Unet-like pure transformer for medical image segmentation. ArXiv arXiv:2105 05537 28. Alom, M. Z., Hasan, M., Yakopcic, C., Taha, T. M. & Asari, V. K. Recurrent residual convolutional neural network based on U-Net (R2U-Net) for medical image segmentation. ArXiv arXiv 29. Chen, J. et al. TransUNet: Transformers make strong encoders for medical image segmentation. ArXiv. arXiv:2102.04306 30. Conger AJ Kappa and rater accuracy: paradigms and parameters Educ. Psychol. Meas. 2017 77 1019 1047 10.1177/0013164416663277 29795943 PMC5965649 Conger, A. J. Kappa and rater accuracy: paradigms and parameters. Educ. Psychol. Meas. 77 29795943 10.1177/0013164416663277 PMC5965649 31. Dogan NO Bland-Altman analysis: A paradigm to understand correlation and agreement Turk. J. Emerg. Med. 2018 18 139 141 10.1016/j.tjem.2018.09.001 30533555 PMC6261099 Dogan, N. O. Bland-Altman analysis: A paradigm to understand correlation and agreement. Turk. J. Emerg. Med. 18 30533555 10.1016/j.tjem.2018.09.001 PMC6261099 32. Bayrakdar IS Deep-learning approach for caries detection and segmentation on dental bitewing radiographs Oral Radiol. 2022 38 468 479 10.1007/s11282-021-00577-9 34807344 Bayrakdar, I. S. et al. Deep-learning approach for caries detection and segmentation on dental bitewing radiographs. Oral Radiol. 38 34807344 10.1007/s11282-021-00577-9 33. Zhang Y Children’s dental panoramic radiographs dataset for caries segmentation and dental disease detection Sci. Data 2023 10 380 10.1038/s41597-023-02237-5 37316638 PMC10267170 Zhang, Y. et al. Children’s dental panoramic radiographs dataset for caries segmentation and dental disease detection. Sci. Data 10 37316638 10.1038/s41597-023-02237-5 PMC10267170 34. Dayı B Üzen H Çiçek İB Duman ŞB A novel deep learning-based approach for segmentation of different type caries lesions on panoramic radiographs Diagnostics 2023 13 202 10.3390/diagnostics13020202 36673010 PMC9858411 Dayı, B., Üzen, H., Çiçek, İ. B. & Duman, Ş. B. A novel deep learning-based approach for segmentation of different type caries lesions on panoramic radiographs. Diagnostics 13 36673010 10.3390/diagnostics13020202 PMC9858411 35. Lian L Zhu T Zhu F Zhu H Deep learning for caries detection and classification Diagnostics 2021 11 1672 10.3390/diagnostics11091672 34574013 PMC8469830 Lian, L., Zhu, T., Zhu, F. & Zhu, H. Deep learning for caries detection and classification. Diagnostics 11 34574013 10.3390/diagnostics11091672 PMC8469830 36. Keenan, J. R. & Keenan, A. V. Accuracy of dental radiographs for caries detection. Evid. Based Dent. 17 10.1038/sj.ebd.6401166 27339235 37. Schwendicke F Tzschoppe M Paris S Radiographic caries detection: A systematic review and meta-analysis J. Dent. 2015 43 924 933 10.1016/j.jdent.2015.02.009 25724114 Schwendicke, F., Tzschoppe, M. & Paris, S. Radiographic caries detection: A systematic review and meta-analysis. J. Dent. 43 25724114 10.1016/j.jdent.2015.02.009 38. Terry GL Noujeim M Langlais RP Moore WS Prihoda TJ A clinical comparison of extraoral panoramic and intraoral radiographic modalities for detecting proximal caries and visualizing open posterior interproximal contacts Dentomaxillofac Radiol. 2016 45 20150159 10.1259/dmfr.20150159 26869221 PMC4846168 Terry, G. L., Noujeim, M., Langlais, R. P., Moore, W. S. & Prihoda, T. J. A clinical comparison of extraoral panoramic and intraoral radiographic modalities for detecting proximal caries and visualizing open posterior interproximal contacts. Dentomaxillofac Radiol. 45 26869221 10.1259/dmfr.20150159 PMC4846168 39. Chen Q Automatic and visualized grading of dental caries using deep learning on panoramic radiographs Multimedia Tools Appl. 2023 82 23709 23734 10.1007/s11042-022-14089-z Chen, Q. et al. Automatic and visualized grading of dental caries using deep learning on panoramic radiographs. Multimedia Tools Appl. 82 40. Alharbi SS AlRugaibah AA Alhasson HF Khan RU Detection of cavities from dental panoramic x-ray images using nested U-Net models Appl. Sci. 2023 13 12771 10.3390/app132312771 Alharbi, S. S., AlRugaibah, A. A., Alhasson, H. F. & Khan, R. U. Detection of cavities from dental panoramic x-ray images using nested U-Net models. Appl. Sci. 13 ",
  "metadata": {
    "Title of this paper": "Detection of cavities from dental panoramic x-ray images using nested U-Net models",
    "Journal it was published in:": "Scientific Reports",
    "URL": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC12480035/"
  }
}